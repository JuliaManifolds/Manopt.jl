<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Douglas–Rachford · Manopt.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img src="../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Manopt.jl</span></div><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><a class="tocitem" href="../about.html">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../tutorials/MeanAndMedian.html">get Started: Optimize!</a></li><li><a class="tocitem" href="../tutorials/Benchmark.html">speed up! using <code>gradF!</code></a></li><li><a class="tocitem" href="../tutorials/GeodesicRegression.html">Do Geodesic regression</a></li><li><a class="tocitem" href="../tutorials/HowToRecord.html">Record values</a></li><li><a class="tocitem" href="../tutorials/StochasticGradientDescent.html">do stochastic gradient descent</a></li><li><a class="tocitem" href="../tutorials/BezierCurves.html">work with Bézier curves</a></li><li><a class="tocitem" href="../tutorials/GradientOfSecondOrderDifference.html">see the gradient of <span>$d_2$</span></a></li><li><a class="tocitem" href="../tutorials/JacobiFields.html">use Jacobi Fields</a></li><li><a class="tocitem" href="../pluto/AutomaticDifferentiation.html">AD in Manopt</a></li></ul></li><li><a class="tocitem" href="../plans/index.html">Plans</a></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="index.html">Introduction</a></li><li><a class="tocitem" href="alternating_gradient_descent.html">Alternating Gradient Descent</a></li><li><a class="tocitem" href="ChambollePock.html">Chambolle-Pock</a></li><li><a class="tocitem" href="conjugate_gradient_descent.html">Conjugate gradient descent</a></li><li><a class="tocitem" href="cyclic_proximal_point.html">Cyclic Proximal Point</a></li><li class="is-active"><a class="tocitem" href="DouglasRachford.html">Douglas–Rachford</a><ul class="internal"><li><a class="tocitem" href="#Initialization-1"><span>Initialization</span></a></li><li><a class="tocitem" href="#Iteration-1"><span>Iteration</span></a></li><li><a class="tocitem" href="#Result-1"><span>Result</span></a></li><li><a class="tocitem" href="#Interface-1"><span>Interface</span></a></li><li><a class="tocitem" href="#Options-1"><span>Options</span></a></li><li><a class="tocitem" href="#Literature-1"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="gradient_descent.html">Gradient Descent</a></li><li><a class="tocitem" href="NelderMead.html">Nelder–Mead</a></li><li><a class="tocitem" href="particle_swarm.html">Particle Swarm Optimization</a></li><li><a class="tocitem" href="quasi_Newton.html">Quasi-Newton</a></li><li><a class="tocitem" href="stochastic_gradient_descent.html">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="subgradient.html">Subgradient method</a></li><li><a class="tocitem" href="truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="trust_regions.html">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../functions/index.html">Introduction</a></li><li><a class="tocitem" href="../functions/bezier.html">Bézier curves</a></li><li><a class="tocitem" href="../functions/costs.html">Cost functions</a></li><li><a class="tocitem" href="../functions/differentials.html">Differentials</a></li><li><a class="tocitem" href="../functions/adjointdifferentials.html">Adjoint Differentials</a></li><li><a class="tocitem" href="../functions/gradients.html">Gradients</a></li><li><a class="tocitem" href="../functions/Jacobi_fields.html">Jacobi Fields</a></li><li><a class="tocitem" href="../functions/proximal_maps.html">Proximal Maps</a></li><li><a class="tocitem" href="../functions/manifold.html">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../helpers/data.html">Data</a></li><li><a class="tocitem" href="../helpers/errorMeasures.html">Error Measures</a></li><li><a class="tocitem" href="../helpers/exports.html">Exports</a></li></ul></li><li><a class="tocitem" href="../contributing.html">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../notation.html">Notation</a></li><li><a class="tocitem" href="../list.html">Function Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href="DouglasRachford.html">Douglas–Rachford</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="DouglasRachford.html">Douglas–Rachford</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/solvers/DouglasRachford.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="DRSolver-1"><a class="docs-heading-anchor" href="#DRSolver-1">Douglas–Rachford Algorithm</a><a class="docs-heading-anchor-permalink" href="#DRSolver-1" title="Permalink"></a></h1><p>The (Parallel) Douglas–Rachford ((P)DR) Algorithm was generalized to Hadamard manifolds in [<a href="#BergmannPerschSteidl2016">Bergmann, Persch, Steidl, 2016</a>].</p><p>The aim is to minimize the sum</p><div>\[F(x) = f(x) + g(x)\]</div><p>on a manifold, where the two summands have proximal maps <span>$\operatorname{prox}_{λ f}, \operatorname{prox}_{λ g}$</span> that are easy to evaluate (maybe in closed form or not too costly to approximate). Further define the Reflection operator at the proximal map as</p><div>\[\operatorname{refl}_{λ f}(x) = \exp_{\operatorname{prox}_{λ f}(x)} \bigl( -\log_{\operatorname{prox}_{λ f}(x)} x \bigr)\]</div><p>.</p><p>Let <span>$\alpha_k ∈  [0,1]$</span> with <span>$\sum_{k ∈ \mathbb N} \alpha_k(1-\alpha_k) =  ∈ fty$</span> and <span>$λ &gt; 0$</span> which might depend on iteration <span>$k$</span> as well) be given.</p><p>Then the (P)DRA algorithm for initial data <span>$x_0 ∈ \mathcal H$</span> as</p><h2 id="Initialization-1"><a class="docs-heading-anchor" href="#Initialization-1">Initialization</a><a class="docs-heading-anchor-permalink" href="#Initialization-1" title="Permalink"></a></h2><p>Initialize <span>$t_0 = x_0$</span> and <span>$k=0$</span></p><h2 id="Iteration-1"><a class="docs-heading-anchor" href="#Iteration-1">Iteration</a><a class="docs-heading-anchor-permalink" href="#Iteration-1" title="Permalink"></a></h2><p>Repeat  until a convergence criterion is reached</p><ol><li>Compute <span>$s_k = \operatorname{refl}_{λ f}\operatorname{refl}_{λ g}(t_k)$</span></li><li>within that operation store <span>$x_{k+1} = \operatorname{prox}_{λ g}(t_k)$</span> which is the prox the inner reflection reflects at.</li><li>Compute <span>$t_{k+1} = g(\alpha_k; t_k, s_k)$</span></li><li>Set <span>$k = k+1$</span></li></ol><h2 id="Result-1"><a class="docs-heading-anchor" href="#Result-1">Result</a><a class="docs-heading-anchor-permalink" href="#Result-1" title="Permalink"></a></h2><p>The result is given by the last computed <span>$x_K$</span>.</p><p>For the parallel version, the first proximal map is a vectorial version, where in each component one prox is applied to the corresponding copy of <span>$t_k$</span> and the second proximal map corresponds to the indicator function of the set, where all copies are equal (in <span>$\mathcal H^n$</span>, where <span>$n$</span> is the number of copies), leading to the second prox being the Riemannian mean.</p><h2 id="Interface-1"><a class="docs-heading-anchor" href="#Interface-1">Interface</a><a class="docs-heading-anchor-permalink" href="#Interface-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Manopt.DouglasRachford" href="#Manopt.DouglasRachford"><code>Manopt.DouglasRachford</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia"> DouglasRachford(M, F, proxMaps, x)</code></pre><p>Computes the Douglas-Rachford algorithm on the manifold <span>$\mathcal M$</span>, initial data <span>$x_0$</span> and the (two) proximal maps <code>proxMaps</code>.</p><p>For <span>$k&gt;2$</span> proximal maps the problem is reformulated using the parallelDouglasRachford: a vectorial proximal map on the power manifold <span>$\mathcal M^k$</span> and the proximal map of the set that identifies all entries again, i.e. the Karcher mean. This henve also boild down to two proximal maps, though each evauates proximal maps in parallel, i.e. component wise in a vector.</p><p><strong>Input</strong></p><ul><li><code>M</code> – a Riemannian Manifold <span>$\mathcal M$</span></li><li><code>F</code> – a cost function consisting of a sum of cost functions</li><li><code>proxes</code> – functions of the form <code>(λ,x)-&gt;...</code> performing a proximal map, where <code>⁠λ</code> denotes the proximal parameter, for each of the summands of <code>F</code>.</li><li><code>x0</code> – initial data <span>$x_0 ∈ \mathcal M$</span></li></ul><p><strong>Optional values</strong></p><p>the default parameter is given in brackets</p><ul><li><code>evaluation</code> – (<a href="../plans/index.html#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>) specify whether the proximal maps work by allocation (default) form <code>prox(M, λ, x)</code> or <a href="../plans/index.html#Manopt.MutatingEvaluation"><code>MutatingEvaluation</code></a> in place, i.e. is of the form <code>prox!(M, y, λ, x)</code>.</li><li><code>λ</code> – (<code>(iter) -&gt; 1.0</code>) function to provide the value for the proximal parameter during the calls</li><li><code>α</code> – (<code>(iter) -&gt; 0.9</code>) relaxation of the step from old to new iterate, i.e. <span>$t_{k+1} = g(α_k; t_k, s_k)$</span>, where <span>$s_k$</span> is the result of the double reflection involved in the DR algorithm</li><li><code>R</code> – (<a href="../functions/manifold.html#Manopt.reflect-Tuple{AbstractManifold, Any, Any}"><code>reflect</code></a>) method employed in the iteration to perform the reflection of <code>x</code> at the prox <code>p</code>.</li><li><code>stopping_criterion</code> – (<a href="index.html#Manopt.StopWhenAny"><code>StopWhenAny</code></a><code>(</code><a href="index.html#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(200),</code><a href="index.html#Manopt.StopWhenChangeLess"><code>StopWhenChangeLess</code></a><code>(10.0^-5))</code>) a <a href="index.html#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a>.</li><li><code>parallel</code> – (<code>false</code>) clarify that we are doing a parallel DR, i.e. on a <code>PowerManifold</code> manifold with two proxes. This can be used to trigger parallel Douglas–Rachford if you enter with two proxes. Keep in mind, that a parallel Douglas–Rachford implicitly works on a <code>PowerManifold</code> manifold and its first argument is the result then (assuming all are equal after the second prox.</li><li><code>return_options</code> – (<code>false</code>) – if activated, the extended result, i.e. the   complete <a href="../plans/index.html#Manopt.Options"><code>Options</code></a> re returned. This can be used to access recorded values.   If set to false (default) just the optimal value <code>x_opt</code> if returned</li></ul><p>... and the ones that are passed to <a href="../plans/index.html#Manopt.decorate_options"><code>decorate_options</code></a> for decorators.</p><p><strong>Output</strong></p><ul><li><code>x_opt</code> – the resulting (approximately critical) point of gradientDescent</li></ul><p>OR</p><ul><li><code>options</code> - the options returned by the solver (see <code>return_options</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/84efaf0ef77cd10faccf23a1f21374394ff889e2/src/solvers/DouglasRachford.jl#L2-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.DouglasRachford!" href="#Manopt.DouglasRachford!"><code>Manopt.DouglasRachford!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia"> DouglasRachford(M, F, proxMaps, x)</code></pre><p>Computes the Douglas-Rachford algorithm on the manifold <span>$\mathcal M$</span>, initial data <span>$x_0$</span> and the (two) proximal maps <code>proxMaps</code> in place of <code>x</code>.</p><p>For <span>$k&gt;2$</span> proximal maps the problem is reformulated using the parallelDouglasRachford: a vectorial proximal map on the power manifold <span>$\mathcal M^k$</span> and the proximal map of the set that identifies all entries again, i.e. the Karcher mean. This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, i.e. component wise in a vector.</p><p><strong>Input</strong></p><ul><li><code>M</code> – a Riemannian Manifold <span>$\mathcal M$</span></li><li><code>F</code> – a cost function consisting of a sum of cost functions</li><li><code>proxes</code> – functions of the form <code>(λ,x)-&gt;...</code> performing a proximal map, where <code>⁠λ</code> denotes the proximal parameter, for each of the summands of <code>F</code>.</li><li><code>x0</code> – initial data <span>$x_0 ∈ \mathcal M$</span></li></ul><p>For more options, see <a href="DouglasRachford.html#Manopt.DouglasRachford"><code>DouglasRachford</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/84efaf0ef77cd10faccf23a1f21374394ff889e2/src/solvers/DouglasRachford.jl#L57-L77">source</a></section></article><h2 id="Options-1"><a class="docs-heading-anchor" href="#Options-1">Options</a><a class="docs-heading-anchor-permalink" href="#Options-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Manopt.DouglasRachfordOptions" href="#Manopt.DouglasRachfordOptions"><code>Manopt.DouglasRachfordOptions</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">DouglasRachfordOptions &lt;: Options</code></pre><p>Store all options required for the DouglasRachford algorithm,</p><p><strong>Fields</strong></p><ul><li><code>x</code> - the current iterate (result) For the parallel Douglas-Rachford, this is not a value from the <code>PowerManifold</code> manifold but the mean.</li><li><code>s</code> – the last result of the double reflection at the proxes relaxed by <code>α</code>.</li><li><code>λ</code> – (<code>(iter)-&gt;1.0</code>) function to provide the value for the proximal parameter during the calls</li><li><code>α</code> – (<code>(iter)-&gt;0.9</code>) relaxation of the step from old to new iterate, i.e. <span>$x^{(k+1)} = g(α(k); x^{(k)}, t^{(k)})$</span>, where <span>$t^{(k)}$</span> is the result of the double reflection involved in the DR algorithm</li><li><code>R</code> – (<a href="../functions/manifold.html#Manopt.reflect-Tuple{AbstractManifold, Any, Any}"><code>reflect</code></a>) method employed in the iteration to perform the reflection of <code>x</code> at the prox <code>p</code>.</li><li><code>stop</code> – (<a href="index.html#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(300)</code>) a <a href="index.html#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a></li><li><code>parallel</code> – (<code>false</code>) indicate whether we are running a parallel Douglas-Rachford or not.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/84efaf0ef77cd10faccf23a1f21374394ff889e2/src/plans/proximal_plan.jl#L117-L136">source</a></section></article><p>For specific <a href="../plans/index.html#Manopt.DebugAction"><code>DebugAction</code></a>s and <a href="../plans/index.html#Manopt.RecordAction"><code>RecordAction</code></a>s see also <a href="cyclic_proximal_point.html#CPPSolver-1">Cyclic Proximal Point</a>.</p><h2 id="Literature-1"><a class="docs-heading-anchor" href="#Literature-1">Literature</a><a class="docs-heading-anchor-permalink" href="#Literature-1" title="Permalink"></a></h2><ul>
<li id="BergmannPerschSteidl2016">[<a>Bergmann, Persch, Steidl, 2016</a>]
  Bergmann, R; Persch, J.; Steidl, G.: <emph>A Parallel Douglas–Rachford
  Algorithm for Minimizing ROF-like Functionals on Images with Values in
  Symmetric Hadamard Manifolds.</emph>
  SIAM Journal on Imaging Sciences, Volume 9, Number 3, pp. 901–937, 2016.
  doi: <a href="https://doi.org/10.1137/15M1052858">10.1137/15M1052858</a>,
  arXiv: <a href="https://arxiv.org/abs/1512.02814">1512.02814</a>.
</li>
</ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="cyclic_proximal_point.html">« Cyclic Proximal Point</a><a class="docs-footer-nextpage" href="gradient_descent.html">Gradient Descent »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 9 February 2022 06:43">Wednesday 9 February 2022</span>. Using Julia version 1.6.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
