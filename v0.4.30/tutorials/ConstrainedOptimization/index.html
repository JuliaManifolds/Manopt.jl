<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Do Contrained Optimization · Manopt.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Manopt.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../about/">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../Optimize!/">Get started: Optimize!</a></li><li><a class="tocitem" href="../InplaceGradient/">Speedup using Inplace computations</a></li><li><a class="tocitem" href="../AutomaticDifferentiation/">Use Automatic Differentiation</a></li><li><a class="tocitem" href="../CountAndCache/">Count and use a Cache</a></li><li><a class="tocitem" href="../HowToRecord/">Record values</a></li><li><a class="tocitem" href="../ImplementASolver/">Implement a Solver</a></li><li class="is-active"><a class="tocitem" href>Do Contrained Optimization</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#A-first-Augmented-Lagrangian-Run"><span>A first Augmented Lagrangian Run</span></a></li><li><a class="tocitem" href="#A-faster-Augmented-Lagrangian-Run"><span>A faster Augmented Lagrangian Run</span></a></li><li><a class="tocitem" href="#Exact-Penalty-Method"><span>Exact Penalty Method</span></a></li><li><a class="tocitem" href="#Comparing-to-the-unconstraint-solver"><span>Comparing to the unconstraint solver</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../GeodesicRegression/">Do Geodesic Regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../../solvers/">Introduction</a></li><li><a class="tocitem" href="../../solvers/alternating_gradient_descent/">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/augmented_Lagrangian_method/">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../../solvers/ChambollePock/">Chambolle-Pock</a></li><li><a class="tocitem" href="../../solvers/conjugate_gradient_descent/">Conjugate gradient descent</a></li><li><a class="tocitem" href="../../solvers/cyclic_proximal_point/">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../../solvers/difference_of_convex/">Difference of Convex</a></li><li><a class="tocitem" href="../../solvers/DouglasRachford/">Douglas–Rachford</a></li><li><a class="tocitem" href="../../solvers/exact_penalty_method/">Exact Penalty Method</a></li><li><a class="tocitem" href="../../solvers/FrankWolfe/">Frank-Wolfe</a></li><li><a class="tocitem" href="../../solvers/gradient_descent/">Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/LevenbergMarquardt/">Levenberg–Marquardt</a></li><li><a class="tocitem" href="../../solvers/NelderMead/">Nelder–Mead</a></li><li><a class="tocitem" href="../../solvers/particle_swarm/">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../../solvers/primal_dual_semismooth_Newton/">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../../solvers/quasi_Newton/">Quasi-Newton</a></li><li><a class="tocitem" href="../../solvers/stochastic_gradient_descent/">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/subgradient/">Subgradient method</a></li><li><a class="tocitem" href="../../solvers/truncated_conjugate_gradient_descent/">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../../solvers/trust_regions/">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../../plans/">Specify a Solver</a></li><li><a class="tocitem" href="../../plans/problem/">Problem</a></li><li><a class="tocitem" href="../../plans/objective/">Objective</a></li><li><a class="tocitem" href="../../plans/state/">Solver State</a></li><li><a class="tocitem" href="../../plans/stepsize/">Stepsize</a></li><li><a class="tocitem" href="../../plans/stopping_criteria/">Stopping Criteria</a></li><li><a class="tocitem" href="../../plans/debug/">Debug Output</a></li><li><a class="tocitem" href="../../plans/record/">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../../functions/">Introduction</a></li><li><a class="tocitem" href="../../functions/bezier/">Bézier curves</a></li><li><a class="tocitem" href="../../functions/costs/">Cost functions</a></li><li><a class="tocitem" href="../../functions/differentials/">Differentials</a></li><li><a class="tocitem" href="../../functions/adjoint_differentials/">Adjoint Differentials</a></li><li><a class="tocitem" href="../../functions/gradients/">Gradients</a></li><li><a class="tocitem" href="../../functions/proximal_maps/">Proximal Maps</a></li><li><a class="tocitem" href="../../functions/manifold/">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../../helpers/checks/">Checks</a></li><li><a class="tocitem" href="../../helpers/data/">Data</a></li><li><a class="tocitem" href="../../helpers/errorMeasures/">Error Measures</a></li><li><a class="tocitem" href="../../helpers/exports/">Exports</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../../extensions/">Extensions</a></li><li><a class="tocitem" href="../../notation/">Notation</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to...</a></li><li class="is-active"><a href>Do Contrained Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Do Contrained Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/tutorials/ConstrainedOptimization.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="How-to-do-Constrained-Optimization"><a class="docs-heading-anchor" href="#How-to-do-Constrained-Optimization">How to do Constrained Optimization</a><a id="How-to-do-Constrained-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-do-Constrained-Optimization" title="Permalink"></a></h1><p>Ronny Bergmann</p><p>This tutorial is a short introduction to using solvers for constraint optimisation in <a href="https://manoptjl.org"><code>Manopt.jl</code></a>.</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>A constraint optimisation problem is given by</p><p class="math-container">\[\tag{P}
\begin{align*}
\operatorname*{arg\,min}_{p\in\mathcal M} &amp; f(p)\\
\text{such that} &amp;\quad g(p) \leq 0\\
&amp;\quad h(p) = 0,\\
\end{align*}\]</p><p>where <span>$f\colon \mathcal M → ℝ$</span> is a cost function, and <span>$g\colon \mathcal M → ℝ^m$</span> and <span>$h\colon \mathcal M → ℝ^n$</span> are the inequality and equality constraints, respectively. The <span>$\leq$</span> and <span>$=$</span> in (P) are meant elementwise.</p><p>This can be seen as a balance between moving constraints into the geometry of a manifold <span>$\mathcal M$</span> and keeping some, since they can be handled well in algorithms, see <a href="../../references/#BergmannHerzog:2019">[BH19]</a>, <a href="../../references/#LiuBoumal:2019">[LB19]</a> for details.</p><pre><code class="language-julia hljs">using Distributions, LinearAlgebra, Manifolds, Manopt, Random
Random.seed!(42);</code></pre><p>In this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrayte the different available forms.</p><p>We will consider the problem of a Nonnegative PCA, cf. Section 5.1.2 in <a href="../../references/#LiuBoumal:2019">[LB19]</a></p><p>let <span>$v_0 ∈ ℝ^d$</span>, <span>$\lVert v_0 \rVert=1$</span> be given spike signal, that is a signal that is sparse with only <span>$s=\lfloor δd \rfloor$</span> nonzero entries.</p><p class="math-container">\[Z = \sqrt{σ} v_0v_0^{\mathrm{T}}+N,\]</p><p>where <span>$\sigma$</span> is a signal-to-noise ratio and <span>$N$</span> is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation <span>$1/d$</span> on the off-diagonals and <span>$2/d$</span> on the daigonal</p><pre><code class="language-julia hljs">d = 150; # dimension of v0
σ = 0.1^2; # SNR
δ = 0.1; s = Int(floor(δ * d)); # Sparsity
S = sample(1:d, s; replace=false);
v0 =  [i ∈ S ? 1 / sqrt(s) : 0.0 for i in 1:d];
N = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);
Z = Z = sqrt(σ) * v0 * transpose(v0) + N;</code></pre><p>In order to recover <span>$v_0$</span> we consider the constrained optimisation problem on the sphere <span>$\mathcal S^{d-1}$</span> given by</p><p class="math-container">\[\begin{align*}
\operatorname*{arg\,min}_{p\in\mathcal S^{d-1}} &amp; -p^{\mathrm{T}}Zp^{\mathrm{T}}\\
\text{such that} &amp;\quad p \geq 0\\
\end{align*}\]</p><p>or in the previous notation <span>$f(p) = -p^{\mathrm{T}}Zp^{\mathrm{T}}$</span> and <span>$g(p) = -p$</span>. We first initialize the manifold under consideration</p><pre><code class="language-julia hljs">M = Sphere(d - 1)</code></pre><pre><code class="nohighlight hljs">Sphere(149, ℝ)</code></pre><h2 id="A-first-Augmented-Lagrangian-Run"><a class="docs-heading-anchor" href="#A-first-Augmented-Lagrangian-Run">A first Augmented Lagrangian Run</a><a id="A-first-Augmented-Lagrangian-Run-1"></a><a class="docs-heading-anchor-permalink" href="#A-first-Augmented-Lagrangian-Run" title="Permalink"></a></h2><p>We first defined <span>$f$</span> and <span>$g$</span> as usual functions</p><pre><code class="language-julia hljs">f(M, p) = -transpose(p) * Z * p;
g(M, p) = -p;</code></pre><p>since <span>$f$</span> is a functions defined in the embedding <span>$ℝ^d$</span> as well, we obtain its gradient by projection.</p><pre><code class="language-julia hljs">grad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p);</code></pre><p>For the constraints this is a little more involved, since each function <span>$g_i = g(p)_i = p_i$</span> has to return its own gradient. These are again in the embedding just <span>$\operatorname{grad} g_i(p) = -e_i$</span> the <span>$i$</span> th unit vector. We can project these again onto the tangent space at <span>$p$</span>:</p><pre><code class="language-julia hljs">grad_g(M, p) = project.(
    Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]
);</code></pre><p>We further start in a random point:</p><pre><code class="language-julia hljs">p0 = rand(M);</code></pre><p>Let’s check a few things for the initial point</p><pre><code class="language-julia hljs">f(M, p0)</code></pre><pre><code class="nohighlight hljs">0.0057476048331242344</code></pre><p>How much the function g is positive</p><pre><code class="language-julia hljs">maximum(g(M, p0))</code></pre><pre><code class="nohighlight hljs">0.17885478285466855</code></pre><p>Now as a first method we can just call the <a href="https://manoptjl.org/stable/solvers/augmented_Lagrangian_method/">Augmented Lagrangian Method</a> with a simple call:</p><pre><code class="language-julia hljs">@time v1 = augmented_Lagrangian_method(
    M, f, grad_f, p0; g=g, grad_g=grad_g,
    debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, (:Change, &quot;Δp : %1.5e&quot;), 20, &quot;\n&quot;],
    stopping_criterion = StopAfterIteration(300) | (
        StopWhenSmallerOrEqual(:ϵ, 1e-5) &amp; StopWhenChangeLess(1e-8)
    )
);</code></pre><pre><code class="nohighlight hljs">Initial F(x): 0.005748 | 
# 20    F(x): -0.123842 | Δp : 9.99649e-01
# 40    F(x): -0.123842 | Δp : 4.49057e-06
# 60    F(x): -0.123842 | Δp : 2.43595e-07
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-5).
The algorithm performed a step with a change (7.297321508879131e-19) less than 9.77237220955808e-6.
  9.580271 seconds (12.15 M allocations: 3.593 GiB, 6.96% gc time, 81.84% compilation time)</code></pre><p>Now we have both a lower function value and the point is nearly within the constraints, … up to numerical inaccuracies</p><pre><code class="language-julia hljs">f(M, v1)</code></pre><pre><code class="nohighlight hljs">-0.12384226501652346</code></pre><pre><code class="language-julia hljs">maximum( g(M, v1) )</code></pre><pre><code class="nohighlight hljs">5.0016030837045246e-21</code></pre><h2 id="A-faster-Augmented-Lagrangian-Run"><a class="docs-heading-anchor" href="#A-faster-Augmented-Lagrangian-Run">A faster Augmented Lagrangian Run</a><a id="A-faster-Augmented-Lagrangian-Run-1"></a><a class="docs-heading-anchor-permalink" href="#A-faster-Augmented-Lagrangian-Run" title="Permalink"></a></h2><p>Now this is a little slow, so we can modify two things, that we will directly do both – but one could also just change one of these – :</p><ol><li>Gradients should be evaluated in place, so for example</li></ol><pre><code class="language-julia hljs">grad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p);</code></pre><ol><li>The constraints are currently always evaluated all together, since the function <code>grad_g</code> always returns a vector of gradients.  We first change the constraints function into a vector of functions.  We further change the gradient <em>both</em> into a vector of gradient functions <span>$\operatorname{grad} g_i, i=1,\ldots,d$</span>, <em>as well as</em> gradients that are computed in place.</li></ol><pre><code class="language-julia hljs">g2 = [(M, p) -&gt; -p[i] for i in 1:d];
grad_g2! = [
    (M, X, p) -&gt; project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d
];</code></pre><p>We obtain</p><pre><code class="language-julia hljs">@time v2 = augmented_Lagrangian_method(
        M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),
        debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, (:Change, &quot;Δp : %1.5e&quot;), 20, &quot;\n&quot;],
        stopping_criterion = StopAfterIteration(300) | (
          StopWhenSmallerOrEqual(:ϵ, 1e-5) &amp; StopWhenChangeLess(1e-8)
        )
    );</code></pre><pre><code class="nohighlight hljs">Initial F(x): 0.005748 | 
# 20    F(x): -0.123842 | Δp : 9.99849e-01
# 40    F(x): -0.123842 | Δp : 3.34452e-04
# 60    F(x): -0.123842 | Δp : 8.49435e-05
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-5).
The algorithm performed a step with a change (2.357347845016813e-15) less than 9.77237220955808e-6.
  3.223448 seconds (4.19 M allocations: 1.324 GiB, 5.16% gc time, 57.25% compilation time)</code></pre><p>As a technical remark: Note that (by default) the change to <a href="https://manoptjl.org/stable/plans/problem/#Manopt.InplaceEvaluation"><code>InplaceEvaluation</code></a>s affects both the constrained solver as well as the inner solver of the subproblem in each iteration.</p><pre><code class="language-julia hljs">f(M, v2)</code></pre><pre><code class="nohighlight hljs">-0.12384249958168167</code></pre><pre><code class="language-julia hljs">maximum(g(M, v2))</code></pre><pre><code class="nohighlight hljs">2.561407150514962e-16</code></pre><p>These are the very similar to the previous values but the solver took much less time and less memory allocations.</p><h2 id="Exact-Penalty-Method"><a class="docs-heading-anchor" href="#Exact-Penalty-Method">Exact Penalty Method</a><a id="Exact-Penalty-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Exact-Penalty-Method" title="Permalink"></a></h2><p>As a second solver, we have the <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/">Exact Penalty Method</a>, which currenlty is available with two smoothing variants, which make an inner solver for smooth optimisationm, that is by default again [quasi Newton] possible: <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials"><code>LogarithmicSumOfExponentials</code></a> and <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber"><code>LinearQuadraticHuber</code></a>. We compare both here as well. The first smoothing technique is the default, so we can just call</p><pre><code class="language-julia hljs">@time v3 = exact_penalty_method(
    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),
    debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, :Change, 50, &quot;\n&quot;],
);</code></pre><pre><code class="nohighlight hljs">Initial F(x): 0.005748 | 
# 50    F(x): -0.123072 | Last Change: 0.981274
# 100   F(x): -0.123840 | Last Change: 0.014049
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (5.050819406841458e-7) less than 1.0e-6.
  3.701686 seconds (5.86 M allocations: 3.229 GiB, 9.96% gc time, 54.42% compilation time)</code></pre><p>We obtain a similar cost value as for the Augmented Lagrangian Solver above, but here the constraint is actually fulfilled and not just numerically “on the boundary”.</p><pre><code class="language-julia hljs">f(M, v3)</code></pre><pre><code class="nohighlight hljs">-0.12384024970459133</code></pre><pre><code class="language-julia hljs">maximum(g(M, v3))</code></pre><pre><code class="nohighlight hljs">-3.5868774339445668e-6</code></pre><p>The second smoothing technique is often beneficial, when we have a lot of constraints (in the above mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time.</p><pre><code class="language-julia hljs">@time v4 = exact_penalty_method(
    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!,
    evaluation=InplaceEvaluation(),
    smoothing=LinearQuadraticHuber(),
    debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, :Change, 50, &quot;\n&quot;],
);</code></pre><pre><code class="nohighlight hljs">Initial F(x): 0.005748 | 
# 50    F(x): -0.123845 | Last Change: 0.009026
# 100   F(x): -0.123842 | Last Change: 0.000843
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (3.0927140891273913e-7) less than 1.0e-6.
  2.197069 seconds (2.89 M allocations: 592.259 MiB, 5.58% gc time, 76.34% compilation time)</code></pre><p>For the result we see the same behaviour as for the other smoothing.</p><pre><code class="language-julia hljs">f(M, v4)</code></pre><pre><code class="nohighlight hljs">-0.12384248680490538</code></pre><pre><code class="language-julia hljs">maximum(g(M, v4))</code></pre><pre><code class="nohighlight hljs">2.712001613056835e-8</code></pre><h2 id="Comparing-to-the-unconstraint-solver"><a class="docs-heading-anchor" href="#Comparing-to-the-unconstraint-solver">Comparing to the unconstraint solver</a><a id="Comparing-to-the-unconstraint-solver-1"></a><a class="docs-heading-anchor-permalink" href="#Comparing-to-the-unconstraint-solver" title="Permalink"></a></h2><p>We can compare this to the <em>global</em> optimum on the sphere, which is the unconstraint optimisation problem; we can just use Quasi Newton.</p><p>Note that this is much faster, since every iteration of the algorithms above does a quasi-Newton call as well.</p><pre><code class="language-julia hljs">@time w1 = quasi_Newton(
    M, f, grad_f!, p0; evaluation=InplaceEvaluation()
);</code></pre><pre><code class="nohighlight hljs">  0.901496 seconds (633.62 k allocations: 61.472 MiB, 1.76% gc time, 97.97% compilation time)</code></pre><pre><code class="language-julia hljs">f(M, w1)</code></pre><pre><code class="nohighlight hljs">-0.1402190180980729</code></pre><p>But for sure here the constraints here are not fulfilled and we have veru positive entries in <span>$g(w_1)$</span></p><pre><code class="language-julia hljs">maximum(g(M, w1))</code></pre><pre><code class="nohighlight hljs">0.11762414497055224</code></pre><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[BH19]</dt>
<dd>
<div id="BergmannHerzog:2019">R. Bergmann and R. Herzog. <i>Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds</i>. <a href='https://doi.org/10.1137/18M1181602'>SIAM Journal on Optimization <b>29</b>, 2423–2444 (2019)</a>.</div>
</dd><dt>[LB19]</dt>
<dd>
<div id="LiuBoumal:2019">C. Liu and N. Boumal. <i>Simple algorithms for optimization on Riemannian manifolds with constraints</i>. <a href='https://doi.org/10.1007/s00245-019-09564-3'>Applied Mathematics & Optimization (2019)</a>.</div>
</dd>
</dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ImplementASolver/">« Implement a Solver</a><a class="docs-footer-nextpage" href="../GeodesicRegression/">Do Geodesic Regression »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Thursday 3 August 2023 16:04">Thursday 3 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
