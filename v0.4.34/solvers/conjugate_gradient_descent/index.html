<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Conjugate gradient descent · Manopt.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Manopt.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../about/">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../../tutorials/Optimize!/">Get started: Optimize!</a></li><li><a class="tocitem" href="../../tutorials/InplaceGradient/">Speedup using Inplace computations</a></li><li><a class="tocitem" href="../../tutorials/AutomaticDifferentiation/">Use Automatic Differentiation</a></li><li><a class="tocitem" href="../../tutorials/EmbeddingObjectives/">Define Objectives in the Embedding</a></li><li><a class="tocitem" href="../../tutorials/CountAndCache/">Count and use a Cache</a></li><li><a class="tocitem" href="../../tutorials/HowToDebug/">Print Debug Output</a></li><li><a class="tocitem" href="../../tutorials/HowToRecord/">Record values</a></li><li><a class="tocitem" href="../../tutorials/ImplementASolver/">Implement a Solver</a></li><li><a class="tocitem" href="../../tutorials/ConstrainedOptimization/">Do Contrained Optimization</a></li><li><a class="tocitem" href="../../tutorials/GeodesicRegression/">Do Geodesic Regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../adaptive-regularization-with-cubics/">Adaptive Regularization with Cubics</a></li><li><a class="tocitem" href="../alternating_gradient_descent/">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../augmented_Lagrangian_method/">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../ChambollePock/">Chambolle-Pock</a></li><li class="is-active"><a class="tocitem" href>Conjugate gradient descent</a><ul class="internal"><li><a class="tocitem" href="#State"><span>State</span></a></li><li><a class="tocitem" href="#cg-coeffs"><span>Available Coefficients</span></a></li><li class="toplevel"><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../cyclic_proximal_point/">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../difference_of_convex/">Difference of Convex</a></li><li><a class="tocitem" href="../DouglasRachford/">Douglas–Rachford</a></li><li><a class="tocitem" href="../exact_penalty_method/">Exact Penalty Method</a></li><li><a class="tocitem" href="../FrankWolfe/">Frank-Wolfe</a></li><li><a class="tocitem" href="../gradient_descent/">Gradient Descent</a></li><li><a class="tocitem" href="../LevenbergMarquardt/">Levenberg–Marquardt</a></li><li><a class="tocitem" href="../NelderMead/">Nelder–Mead</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../primal_dual_semismooth_Newton/">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../quasi_Newton/">Quasi-Newton</a></li><li><a class="tocitem" href="../stochastic_gradient_descent/">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../subgradient/">Subgradient method</a></li><li><a class="tocitem" href="../truncated_conjugate_gradient_descent/">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../trust_regions/">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../../plans/">Specify a Solver</a></li><li><a class="tocitem" href="../../plans/problem/">Problem</a></li><li><a class="tocitem" href="../../plans/objective/">Objective</a></li><li><a class="tocitem" href="../../plans/state/">Solver State</a></li><li><a class="tocitem" href="../../plans/stepsize/">Stepsize</a></li><li><a class="tocitem" href="../../plans/stopping_criteria/">Stopping Criteria</a></li><li><a class="tocitem" href="../../plans/debug/">Debug Output</a></li><li><a class="tocitem" href="../../plans/record/">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../../functions/">Introduction</a></li><li><a class="tocitem" href="../../functions/bezier/">Bézier curves</a></li><li><a class="tocitem" href="../../functions/costs/">Cost functions</a></li><li><a class="tocitem" href="../../functions/differentials/">Differentials</a></li><li><a class="tocitem" href="../../functions/adjoint_differentials/">Adjoint Differentials</a></li><li><a class="tocitem" href="../../functions/gradients/">Gradients</a></li><li><a class="tocitem" href="../../functions/proximal_maps/">Proximal Maps</a></li><li><a class="tocitem" href="../../functions/manifold/">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../../helpers/checks/">Checks</a></li><li><a class="tocitem" href="../../helpers/data/">Data</a></li><li><a class="tocitem" href="../../helpers/errorMeasures/">Error Measures</a></li><li><a class="tocitem" href="../../helpers/exports/">Exports</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../../extensions/">Extensions</a></li><li><a class="tocitem" href="../../notation/">Notation</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href>Conjugate gradient descent</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Conjugate gradient descent</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/solvers/conjugate_gradient_descent.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="CGSolver"><a class="docs-heading-anchor" href="#CGSolver">Conjugate Gradient Descent</a><a id="CGSolver-1"></a><a class="docs-heading-anchor-permalink" href="#CGSolver" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="Manopt.conjugate_gradient_descent" href="#Manopt.conjugate_gradient_descent"><code>Manopt.conjugate_gradient_descent</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">conjugate_gradient_descent(M, F, gradF, p=rand(M))
conjugate_gradient_descent(M, gradient_objective, p)</code></pre><p>perform a conjugate gradient based descent</p><p class="math-container">\[p_{k+1} = \operatorname{retr}_{p_k} \bigl( s_kδ_k \bigr),\]</p><p>where <span>$\operatorname{retr}$</span> denotes a retraction on the <code>Manifold</code> <code>M</code> and one can employ different rules to update the descent direction <span>$δ_k$</span> based on the last direction <span>$δ_{k-1}$</span> and both gradients <span>$\operatorname{grad}f(x_k)$</span>,<span>$\operatorname{grad}f(x_{k-1})$</span>. The <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> <span>$s_k$</span> may be determined by a <a href="../../plans/stepsize/#Manopt.Linesearch"><code>Linesearch</code></a>.</p><p>Alternatively to <code>f</code> and <code>grad_f</code> you can prodive the <a href="../../plans/objective/#Manopt.AbstractManifoldGradientObjective"><code>AbstractManifoldGradientObjective</code></a> <code>gradient_objective</code> directly.</p><p>Available update rules are <a href="#Manopt.SteepestDirectionUpdateRule"><code>SteepestDirectionUpdateRule</code></a>, which yields a <a href="../gradient_descent/#Manopt.gradient_descent"><code>gradient_descent</code></a>, <a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a> (the default), <a href="#Manopt.DaiYuanCoefficient"><code>DaiYuanCoefficient</code></a>, <a href="#Manopt.FletcherReevesCoefficient"><code>FletcherReevesCoefficient</code></a>, <a href="#Manopt.HagerZhangCoefficient"><code>HagerZhangCoefficient</code></a>, <a href="#Manopt.HestenesStiefelCoefficient"><code>HestenesStiefelCoefficient</code></a>, <a href="#Manopt.LiuStoreyCoefficient"><code>LiuStoreyCoefficient</code></a>, and <a href="#Manopt.PolakRibiereCoefficient"><code>PolakRibiereCoefficient</code></a>. These can all be combined with a <a href="#Manopt.ConjugateGradientBealeRestart"><code>ConjugateGradientBealeRestart</code></a> rule.</p><p>They all compute <span>$β_k$</span> such that this algorithm updates the search direction as</p><p class="math-container">\[\delta_k=\operatorname{grad}f(p_k) + β_k \delta_{k-1}\]</p><p><strong>Input</strong></p><ul><li><code>M</code> : a manifold <span>$\mathcal M$</span></li><li><code>f</code> : a cost function <span>$F:\mathcal M→ℝ$</span> to minimize implemented as a function <code>(M,p) -&gt; v</code></li><li><code>grad_f</code>: the gradient <span>$\operatorname{grad}F:\mathcal M → T\mathcal M$</span> of <span>$F$</span> implemented also as <code>(M,x) -&gt; X</code></li><li><code>p</code> : an initial value <span>$x∈\mathcal M$</span></li></ul><p><strong>Optional</strong></p><ul><li><code>coefficient</code> : (<a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a> <code>&lt;:</code> <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>) rule to compute the descent direction update coefficient <span>$β_k$</span>, as a functor, i.e. the resulting function maps <code>(amp, cgs, i) -&gt; β</code>, where <code>amp</code> is an <a href="../../plans/problem/#Manopt.AbstractManoptProblem"><code>AbstractManoptProblem</code></a>, <code>cgs</code> are the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a> <code>o</code> and <code>i</code> is the current iterate.</li><li><code>evaluation</code> – (<a href="../../plans/objective/#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>) specify whether the gradient works by allocation (default) form <code>gradF(M, x)</code> or <a href="../../plans/objective/#Manopt.InplaceEvaluation"><code>InplaceEvaluation</code></a> in place, i.e. is of the form <code>gradF!(M, X, x)</code>.</li><li><code>retraction_method</code> - (<code>default_retraction_method(M, typeof(p))</code>) a retraction method to use.</li><li><code>stepsize</code> - (<a href="../../plans/stepsize/#Manopt.ArmijoLinesearch"><code>ArmijoLinesearch</code></a> via <a href="../../plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{&lt;:AbstractManoptSolverState}}"><code>default_stepsize</code></a>) A <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> function applied to the search direction. The default is a constant step size 1.</li><li><code>stopping_criterion</code> : (<code>stopWhenAny( stopAtIteration(200), stopGradientNormLess(10.0^-8))</code>) a function indicating when to stop.</li><li><code>vector_transport_method</code> – (<code>default_vector_transport_method(M, typeof(p))</code>) vector transport method to transport the old descent direction when computing the new descent direction.</li></ul><p>If you provide the <a href="../../plans/objective/#Manopt.ManifoldGradientObjective"><code>ManifoldGradientObjective</code></a> directly, <code>evaluation</code> is ignored.</p><p><strong>Output</strong></p><p>the obtained (approximate) minimizer <span>$p^*$</span>, see <a href="../#Manopt.get_solver_return"><code>get_solver_return</code></a> for details</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/solvers/conjugate_gradient_descent.jl#L30-L86">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.conjugate_gradient_descent!" href="#Manopt.conjugate_gradient_descent!"><code>Manopt.conjugate_gradient_descent!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">conjugate_gradient_descent!(M, F, gradF, x)
conjugate_gradient_descent!(M, gradient_objective, p; kwargs...)</code></pre><p>perform a conjugate gradient based descent in place of <code>x</code>, i.e.</p><p class="math-container">\[p_{k+1} = \operatorname{retr}_{p_k} \bigl( s_k\delta_k \bigr),\]</p><p>where <span>$\operatorname{retr}$</span> denotes a retraction on the <code>Manifold</code> <code>M</code></p><p><strong>Input</strong></p><ul><li><code>M</code> : a manifold <span>$\mathcal M$</span></li><li><code>f</code> : a cost function <span>$F:\mathcal M→ℝ$</span> to minimize</li><li><code>grad_f</code>: the gradient <span>$\operatorname{grad}F:\mathcal M→ T\mathcal M$</span> of F</li><li><code>p</code> : an initial value <span>$p∈\mathcal M$</span></li></ul><p>Alternatively to <code>f</code> and <code>grad_f</code> you can prodive the <a href="../../plans/objective/#Manopt.AbstractManifoldGradientObjective"><code>AbstractManifoldGradientObjective</code></a> <code>gradient_objective</code> directly.</p><p>for more details and options, especially the <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>s,  see <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/solvers/conjugate_gradient_descent.jl#L120-L141">source</a></section></article><h2 id="State"><a class="docs-heading-anchor" href="#State">State</a><a id="State-1"></a><a class="docs-heading-anchor-permalink" href="#State" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Manopt.ConjugateGradientDescentState" href="#Manopt.ConjugateGradientDescentState"><code>Manopt.ConjugateGradientDescentState</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateGradientState &lt;: AbstractGradientSolverState</code></pre><p>specify options for a conjugate gradient descent algorithm, that solves a [<code>DefaultManoptProblem</code>].</p><p><strong>Fields</strong></p><ul><li><code>p</code>                       – the current iterate, a point on a manifold</li><li><code>X</code>                       – the current gradient, also denoted as <span>$ξ$</span> or <span>$X_k$</span> for the gradient in the <span>$k$</span>th step.</li><li><code>δ</code>                       – the current descent direction, i.e. also tangent vector</li><li><code>β</code>                       – the current update coefficient rule, see .</li><li><code>coefficient</code>             – (<a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a><code>()</code>) a <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a> function to determine the new <code>β</code></li><li><code>stepsize</code>                – (<a href="../../plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{&lt;:AbstractManoptSolverState}}"><code>default_stepsize</code></a><code>(M, ConjugateGradientDescentState; retraction_method=retraction_method)</code>) a <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> function</li><li><code>stop</code>                    – (<a href="../../plans/stopping_criteria/#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(500) |</code><a href="../../plans/stopping_criteria/#Manopt.StopWhenGradientNormLess"><code>StopWhenGradientNormLess</code></a><code>(1e-8)</code>) a <a href="../../plans/stopping_criteria/#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a></li><li><code>retraction_method</code>       – (<code>default_retraction_method(M, typeof(p))</code>) a type of retraction</li><li><code>vector_transport_method</code> – (<code>default_retraction_method(M, typeof(p))</code>) a type of retraction</li></ul><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">ConjugateGradientState(M, p)</code></pre><p>where the last five fields above can be set by their names as keyword and the <code>X</code> can be set to a tangent vector type using the keyword <code>initial_gradient</code> which defaults to <code>zero_vector(M,p)</code>, and <code>δ</code> is initialized to a copy of this vector.</p><p><strong>See also</strong></p><p><a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a>, <a href="../../plans/problem/#Manopt.DefaultManoptProblem"><code>DefaultManoptProblem</code></a>, <a href="../../plans/stepsize/#Manopt.ArmijoLinesearch"><code>ArmijoLinesearch</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L22-L51">source</a></section></article><h2 id="cg-coeffs"><a class="docs-heading-anchor" href="#cg-coeffs">Available Coefficients</a><a id="cg-coeffs-1"></a><a class="docs-heading-anchor-permalink" href="#cg-coeffs" title="Permalink"></a></h2><p>The update rules act as <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>, which internally always first evaluate the gradient itself.</p><article class="docstring"><header><a class="docstring-binding" id="Manopt.ConjugateGradientBealeRestart" href="#Manopt.ConjugateGradientBealeRestart"><code>Manopt.ConjugateGradientBealeRestart</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateGradientBealeRestart &lt;: DirectionUpdateRule</code></pre><p>An update rule might require a restart, that is using pure gradient as descent direction, if the last two gradients are nearly orthogonal, cf. <a href="../../references/#HagerZhang:2006">Hager, Zhang, Pacific J Optim, 2006</a>, page 12 (in the pdf, 46 in Journal page numbers). This method is named after E. Beale from his proceedings paper in 1972 <a href="../../references/#Beale:1972">[Bea72]</a>. This method acts as a <em>decorator</em> to any existing <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a> <code>direction_update</code>.</p><p>When obtain from the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgs</code> the last <span>$p_k,X_k$</span> and the current <span>$p_{k+1},X_{k+1}$</span> iterate and the gradient, respectively.</p><p>Then a restart is performed, i.e. <span>$β_k = 0$</span> returned if</p><p class="math-container">\[    \frac{ ⟨X_{k+1}, P_{p_{k+1}\gets p_k}X_k⟩}{\lVert X_k \rVert_{p_k}} &gt; ξ,\]</p><p>where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>, and <span>$ξ$</span> is the <code>threshold</code>. The default threshold is chosen as <code>0.2</code> as recommended in <a href="../../references/#Powell:1977">Powell, Math. Prog., 1977</a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">ConjugateGradientBealeRestart(
    direction_update::D,
    threshold=0.2;
    manifold::AbstractManifold = DefaultManifold(),
    vector_transport_method::V=default_vector_transport_method(manifold),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L594-L622">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.ConjugateDescentCoefficient" href="#Manopt.ConjugateDescentCoefficient"><code>Manopt.ConjugateDescentCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateDescentCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#Fletcher:1987">Fletcher, 1987</a> adapted to manifolds:</p><p class="math-container">\[β_k =
\frac{ \lVert X_{k+1} \rVert_{p_{k+1}}^2 }
{\langle -\delta_k,X_k \rangle_{p_k}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">ConjugateDescentCoefficient(a::StoreStateAction=())</code></pre><p>Construct the conjugate descent coefficient update rule, a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L147-L167">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.DaiYuanCoefficient" href="#Manopt.DaiYuanCoefficient"><code>Manopt.DaiYuanCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DaiYuanCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>, based on <a href="../../references/#DaiYuan:1999">Dai, Yuan, Siam J Optim, 1999</a> adapted to manifolds:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the coefficient reads</p><p class="math-container">\[β_k =
\frac{ \lVert X_{k+1} \rVert_{p_{k+1}}^2 }
{\langle P_{p_{k+1}\gets p_k}\delta_k, \nu_k \rangle_{p_{k+1}}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function DaiYuanCoefficient(
    M::AbstractManifold=DefaultManifold(2);
    t::AbstractVectorTransportMethod=default_vector_transport_method(M)
)</code></pre><p>Construct the Dai Yuan coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L190-L219">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.FletcherReevesCoefficient" href="#Manopt.FletcherReevesCoefficient"><code>Manopt.FletcherReevesCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FletcherReevesCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#FletcherReeves:1964">Flecther, Reeves, Comput. J, 1964</a> adapted to manifolds:</p><p class="math-container">\[β_k =
\frac{\lVert X_{k+1}\rVert_{p_{k+1}}^2}{\lVert X_k\rVert_{x_{k}}^2}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">FletcherReevesCoefficient(a::StoreStateAction=())</code></pre><p>Construct the Fletcher Reeves coefficient update rule, a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L258-L277">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.HagerZhangCoefficient" href="#Manopt.HagerZhangCoefficient"><code>Manopt.HagerZhangCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HagerZhangCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>, based on <a href="../../references/#HagerZhang:2005">Hager, Zhang, SIAM J Optim, 2005</a>. adapted to manifolds: let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p class="math-container">\[β_k = \Bigl\langle\nu_k -
\frac{ 2\lVert \nu_k\rVert_{p_{k+1}}^2 }{ \langle P_{p_{k+1}\gets p_k}\delta_k, \nu_k \rangle_{p_{k+1}} }
P_{p_{k+1}\gets p_k}\delta_k,
\frac{X_{k+1}}{ \langle P_{p_{k+1}\gets p_k}\delta_k, \nu_k \rangle_{p_{k+1}} }
\Bigr\rangle_{p_{k+1}}.\]</p><p>This method includes a numerical stability proposed by those authors.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function HagerZhangCoefficient(t::AbstractVectorTransportMethod)
function HagerZhangCoefficient(M::AbstractManifold = DefaultManifold(2))</code></pre><p>Construct the Hager Zhang coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L301-L329">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.HestenesStiefelCoefficient" href="#Manopt.HestenesStiefelCoefficient"><code>Manopt.HestenesStiefelCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HestenesStiefelCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#HestenesStiefel:1952">Heestenes, Stiefel, J. Research Nat. Bur. Standards, 1952</a> adapted to manifolds as follows:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>. Then the update reads</p><p class="math-container">\[β_k = \frac{\langle X_{k+1}, \nu_k \rangle_{p_{k+1}} }
    { \langle P_{p_{k+1}\gets p_k} \delta_k, \nu_k\rangle_{p_{k+1}} },\]</p><p>where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function HestenesStiefelCoefficient(transport_method::AbstractVectorTransportMethod)
function HestenesStiefelCoefficient(M::AbstractManifold = DefaultManifold(2))</code></pre><p>Construct the Heestens Stiefel coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L378-L405">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.LiuStoreyCoefficient" href="#Manopt.LiuStoreyCoefficient"><code>Manopt.LiuStoreyCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LiuStoreyCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#LiuStorey:1991">Lui, Storey, J. Optim. Theoru Appl., 1991</a> adapted to manifolds:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the coefficient reads</p><p class="math-container">\[β_k = -
\frac{ \langle X_{k+1},\nu_k \rangle_{p_{k+1}} }
{\langle \delta_k,X_k \rangle_{p_k}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function LiuStoreyCoefficient(t::AbstractVectorTransportMethod)
function LiuStoreyCoefficient(M::AbstractManifold = DefaultManifold(2))</code></pre><p>Construct the Lui Storey coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L445-L473">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.PolakRibiereCoefficient" href="#Manopt.PolakRibiereCoefficient"><code>Manopt.PolakRibiereCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PolakRibiereCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#PolakRibiere:1969">Poliak, Ribiere, ESIAM Math. Modelling Num. Anal., 1969</a> and <a href="../../references/#Polyak:1969">Polyak, USSR Comp. Math. Math. Phys., 1969</a> adapted to manifolds:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the update reads</p><p class="math-container">\[β_k =
\frac{ \langle X_{k+1}, \nu_k \rangle_{p_{k+1}} }
{\lVert X_k \rVert_{p_k}^2 }.\]</p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function PolakRibiereCoefficient(
    M::AbstractManifold=DefaultManifold(2);
    t::AbstractVectorTransportMethod=default_vector_transport_method(M)
)</code></pre><p>Construct the PolakRibiere coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L509-L540">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.SteepestDirectionUpdateRule" href="#Manopt.SteepestDirectionUpdateRule"><code>Manopt.SteepestDirectionUpdateRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SteepestDirectionUpdateRule &lt;: DirectionUpdateRule</code></pre><p>The simplest rule to update is to have no influence of the last direction and hence return an update <span>$β = 0$</span> for all <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code></p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/b574950cf349013232e8ab07fa355046bd90e8d3/src/plans/conjugate_gradient_plan.jl#L575-L582">source</a></section></article><h1 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h1><div class="citation noncanonical"><dl><dt>[Bea72]</dt>
<dd>
<div id="Beale:1972">E. M. Beale. <i>A derivation of conjugate gradients</i>.  In Numerical methods for nonlinear optimization, 39–43, London, Academic Press, London (1972).</div>
</dd><dt>[DY99]</dt>
<dd>
<div id="DaiYuan:1999">Y. H. Dai and Y. Yuan. <i>A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property</i>. <a href='https://doi.org/10.1137/s1052623497318992'>SIAM Journal on Optimization <b>10</b>, 177–182 (1999)</a>.</div>
</dd><dt>[Fle87]</dt>
<dd>
<div id="Fletcher:1987">R. Fletcher. <i>Practical Methods of Optimization</i>. John Wiley & Sons Ltd. (1987).</div>
</dd><dt>[FR64]</dt>
<dd>
<div id="FletcherReeves:1964">R. Fletcher and C. M. Reeves. <i>Function minimization by conjugate gradients</i>. <a href='https://doi.org/10.1093/comjnl/7.2.149'>The Computer Journal <b>7</b>, 149–154 (1964)</a>.</div>
</dd><dt>[HZ06]</dt>
<dd>
<div id="HagerZhang:2006">W. W. Hager and H. Zhang. <i>A survey of nonlinear conjugate gradient methods</i>. <a href='http://www.yokohamapublishers.jp/online2/pjov2-1.html'>Pacific Journal of Optimization <b>2</b>, 35–58 (2006)</a>.</div>
</dd><dt>[HZ05]</dt>
<dd>
<div id="HagerZhang:2005">W. W. Hager and H. Zhang. <i>A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search</i>. <a href='https://doi.org/10.1137/030601880'>SIAM Journal on Optimization <b>16</b>, 170–192 (2005)</a>.</div>
</dd><dt>[HS52]</dt>
<dd>
<div id="HestenesStiefel:1952">M. Hestenes and E. Stiefel. <i>Methods of conjugate gradients for solving linear systems</i>. <a href='https://doi.org/10.6028/jres.049.044'>Journal of Research of the National Bureau of Standards <b>49</b>, 409 (1952)</a>.</div>
</dd><dt>[LS91]</dt>
<dd>
<div id="LiuStorey:1991">Y. Liu and C. Storey. <i>Efficient generalized conjugate gradient algorithms,  part 1: Theory</i>. <a href='https://doi.org/10.1007/bf00940464'>Journal of Optimization Theory and Applications <b>69</b>, 129–137 (1991)</a>.</div>
</dd><dt>[PR69]</dt>
<dd>
<div id="PolakRibiere:1969">E. Polak and G. Ribière. <i>Note sur la convergence de méthodes de directions conjuguées</i>. <a href='https://doi.org/10.1051/m2an/196903r100351'>Revue française d’informatique et de recherche opérationnelle <b>3</b>, 35–43 (1969)</a>.</div>
</dd><dt>[Pol69]</dt>
<dd>
<div id="Polyak:1969">B. T. Polyak. <i>The conjugate gradient method in extremal problems</i>. <a href='https://doi.org/10.1016/0041-5553(69)90035-4'>USSR Computational Mathematics and Mathematical Physics <b>9</b>, 94–112 (1969)</a>.</div>
</dd><dt>[Pow77]</dt>
<dd>
<div id="Powell:1977">M. J. Powell. <i>Restart procedures for the conjugate gradient method</i>. <a href='https://doi.org/10.1007/bf01593790'>Mathematical Programming <b>12</b>, 241–254 (1977)</a>.</div>
</dd>
</dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ChambollePock/">« Chambolle-Pock</a><a class="docs-footer-nextpage" href="../cyclic_proximal_point/">Cyclic Proximal Point »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Saturday 2 September 2023 16:00">Saturday 2 September 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
