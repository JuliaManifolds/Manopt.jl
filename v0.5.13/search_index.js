var documenterSearchIndex = {"docs":
[{"location":"notation/#Notation","page":"Notation","title":"Notation","text":"","category":"section"},{"location":"notation/","page":"Notation","title":"Notation","text":"In this package,the notation introduced in Manifolds.jl Notation is used with the following additional parts.","category":"page"},{"location":"notation/","page":"Notation","title":"Notation","text":"Symbol Description Also used Comment\noperatornameargmin argument of a function f where a local or global minimum is attained  \nk the current iterate Ã¬ the goal is to unify this to k\n The Levi-Cevita connection  ","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#Using-automatic-differentiation-in-Manopt.jl","page":"Use automatic differentiation","title":"Using automatic differentiation in Manopt.jl","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Since Manifolds.jl 0.7, the support of automatic differentiation support has been extended.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"This tutorial explains how to use Euclidean tools to derive a gradient for a real-valued function f  mathcal M  â„. Two methods are considered: an intrinsic variant and a variant employing the embedding. These gradients can then be used within any gradient based optimization algorithm in Manopt.jl.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"While by default FiniteDifferences.jlare used, one can also use FiniteDiff.jl, ForwardDiff.jl, ReverseDiff.jl, or Zygote.jl.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"This tutorial looks at a few possibilities to approximate or derive the gradient of a function fmathcal M  â„ on a Riemannian manifold, without computing it yourself. There are mainly two different philosophies:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Working intrinsically, that is staying on the manifold and in the tangent spaces, considering to approximate the gradient by forward differences.\nWorking in an embedding where all tools from functions on Euclidean spaces can be used, like finite differences or automatic differentiation, and then compute the corresponding Riemannian gradient from there.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"First, load all necessary packages","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"using Manopt, Manifolds, Random, LinearAlgebra\nusing FiniteDifferences, ManifoldDiff, ADTypes\nRandom.seed!(42);","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#1.-(Intrinsic)-forward-differences","page":"Use automatic differentiation","title":"1. (Intrinsic) forward differences","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"A first idea is to generalize (multivariate) finite differences to Riemannian manifolds. Let X_1ldotsX_d  T_pmathcal M denote an orthonormal basis of the tangent space T_pmathcal M at the point pmathcal M on the Riemannian manifold.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"The notion of a directional derivative is generalized to a â€œdirectionâ€ YT_pmathcal M. Let c  -ÎµÎµ, Îµ0, be a curve with c(0) = p, dot c(0) = Y, for example c(t)= exp_p(tY). This yields","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"    Df(p)Y = left fracddt right_t=0 f(c(t)) = lim_t  0 frac1t(f(exp_p(tY))-f(p))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"The differential Df(p)X is approximated by a finite difference scheme for an h0 as","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"DF(p)Y  G_h(Y) = frac1h(f(exp_p(hY))-f(p))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Furthermore the gradient operatornamegradf is the Riesz representer of the differential:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"    Df(p)Y = g_p(operatornamegradf(p) Y)qquad text for all  Y  T_pmathcal M","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"and since it is a tangent vector, we can write it in terms of a basis as","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"    operatornamegradf(p) = sum_i=1^d g_p(operatornamegradf(p)X_i)X_i\n    = sum_i=1^d Df(p)X_iX_i","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"and perform the approximation from before to obtain","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"    operatornamegradf(p)  sum_i=1^d G_h(X_i)X_i","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"for some suitable step size h. This comes at the cost of d+1 function evaluations and d exponential maps.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"This is the first variant we can use. An advantage is that it is intrinsic in the sense that it does not require any embedding of the manifold.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#An-example:-the-Rayleigh-quotient","page":"Use automatic differentiation","title":"An example: the Rayleigh quotient","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"The Rayleigh quotient is concerned with finding eigenvalues (and eigenvectors) of a symmetric matrix A  â„^(n+1)(n+1). The optimization problem reads","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"F  â„^n+1  â„quad F(mathbf x) = fracmathbf x^mathrmTAmathbf xmathbf x^mathrmTmathbf x","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Minimizing this function yields the smallest eigenvalue lambda_1 as a value and the corresponding minimizer mathbf x^* is a corresponding eigenvector.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Since the length of an eigenvector is irrelevant, there is an ambiguity in the cost function. It can be better phrased on the sphere $ ð•Š^n$ of unit vectors in â„^n+1,","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"operatorname*argmin_p  ð•Š^n f(p) = operatorname*argmin_ p  ð•Š^n p^mathrmTAp","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"We can compute the Riemannian gradient exactly as","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"operatornamegrad f(p) = 2(Ap - pp^mathrmTAp)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"so we can compare it to the approximation by finite differences.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"n = 200\nA = randn(n + 1, n + 1)\nA = Symmetric(A)\nM = Sphere(n);\n\nf1(p) = p' * A'p\ngradf1(p) = 2 * (A * p - p * p' * A * p)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"gradf1 (generic function with 1 method)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Manifolds provides a finite difference scheme in tangent spaces, that you can introduce to use an existing framework (if the wrapper is implemented) form Euclidean space. Here we use FiniteDiff.jl.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"r_backend = ManifoldDiff.TangentDiffBackend(\n    AutoFiniteDifferences(central_fdm(5, 1))\n)\ngradf1_FD(p) = ManifoldDiff.gradient(M, f1, p, r_backend)\n\np = zeros(n + 1)\np[1] = 1.0\nX1 = gradf1(p)\nX2 = gradf1_FD(p)\nnorm(M, p, X1 - X2)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"1.018153081967174e-12","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"We obtain quite a good approximation of the gradient.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#EmbeddedGradient","page":"Use automatic differentiation","title":"2. Conversion of a Euclidean gradient in the embedding to a Riemannian Gradient of a (not Necessarily Isometrically) embedded manifold","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Let tilde f â„^m  â„ be a function on the embedding of an n-dimensional manifold mathcal M subset â„^mand let f  mathcal M  â„ denote the restriction of tilde f to the manifold mathcal M.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Since we can use the pushforward of the embedding to also embed the tangent space T_pmathcal M, pmathcal M, we can similarly obtain the differential Df(p)  T_pmathcal M  â„ by restricting the differential Dtilde f(p) to the tangent space.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"If both T_pmathcal M and T_pâ„^m have the same inner product, or in other words the manifold is isometrically embedded in â„^m (like for example the sphere mathbb S^nsubsetâ„^m+1), then this restriction of the differential directly translates to a projection of the gradient","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"operatornamegradf(p) = operatornameProj_T_pmathcal M(operatornamegrad tilde f(p))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"More generally take a change of the metric into account as","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"langle  operatornameProj_T_pmathcal M(operatornamegrad tilde f(p)) X rangle\n= Df(p)X = g_p(operatornamegradf(p) X)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"or in words: we have to change the Riesz representer of the (restricted/projected) differential of f (tilde f) to the one with respect to the Riemannian metric. This is done using change_representer.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#A-continued-example","page":"Use automatic differentiation","title":"A continued example","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"We continue with the Rayleigh Quotient from before, now just starting with the definition of the Euclidean case in the embedding, the function F.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"F(x) = x' * A * x / (x' * x);","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"The cost function is the same by restriction","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"f2(M, p) = F(p);","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"The gradient is now computed combining our gradient scheme with FiniteDifferences.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"function grad_f2_AD(M, p)\n    b = Manifolds.RiemannianProjectionBackend(AutoFiniteDifferences(central_fdm(5, 1)))\n    return Manifolds.gradient(M, F, p, b)\nend\nX3 = grad_f2_AD(M, p)\nnorm(M, p, X1 - X3)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"1.742525831800539e-12","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#An-example-for-a-non-isometrically-embedded-manifold","page":"Use automatic differentiation","title":"An example for a non-isometrically embedded manifold","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"on the manifold mathcal P(3) of symmetric positive definite matrices.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"The following function computes (half) the distance squared (with respect to the linear affine metric) on the manifold mathcal P(3) to the identity matrix I_3. Denoting the unit matrix we consider the function","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"    G(q)\n    = frac12d^2_mathcal P(3)(qI_3)\n    = lVert operatornameLog(q) rVert_F^2","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"where operatornameLog denotes the matrix logarithm and lVert cdot rVert_F is the Frobenius norm. This can be computed for symmetric positive definite matrices by summing the squares of the logarithms of the eigenvalues of q and dividing by two:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"G(q) = sum(log.(eigvals(Symmetric(q))) .^ 2) / 2","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"G (generic function with 1 method)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"We can also interpret this as a function on the space of matrices and apply the Euclidean finite differences machinery; in this way we can easily derive the Euclidean gradient. But when computing the Riemannian gradient, we have to change the representer (see again change_representer) after projecting onto the tangent space T_pmathcal P(n) at p.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Letâ€™s first define a point and the manifold N=mathcal P(3).","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"rotM(Î±) = [1.0 0.0 0.0; 0.0 cos(Î±) sin(Î±); 0.0 -sin(Î±) cos(Î±)]\nq = rotM(Ï€ / 6) * [1.0 0.0 0.0; 0.0 2.0 0.0; 0.0 0.0 3.0] * transpose(rotM(Ï€ / 6))\nN = SymmetricPositiveDefinite(3)\nis_point(N, q)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"true","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"We could first just compute the gradient using FiniteDifferences.jl, but this yields the Euclidean gradient:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"FiniteDifferences.grad(central_fdm(5, 1), G, q)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"([3.240417492806275e-14 -2.3531899864903462e-14 0.0; 0.0 0.3514812167654708 0.017000516835452926; 0.0 0.0 0.36129646973723023],)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Instead, we use the RiemannianProjectedBackend of ManifoldDiff.jl, which in this case internally uses FiniteDifferences.jl to compute a Euclidean gradient but then uses the conversion explained before to derive the Riemannian gradient.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"We define this here again as a function grad_G_FD that could be used in the Manopt.jl framework within a gradient based optimization.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"function grad_G_FD(N, q)\n    return Manifolds.gradient(\n        N,\n        G,\n        q,\n        ManifoldDiff.RiemannianProjectionBackend(AutoFiniteDifferences(central_fdm(5, 1))),\n    )\nend\nG1 = grad_G_FD(N, q)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"3Ã—3 Matrix{Float64}:\n  3.24042e-14  -2.64734e-14  -5.09481e-15\n -2.64734e-14   1.86368       0.826856\n -5.09481e-15   0.826856      2.81845","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Now, we can again compare this to the (known) solution of the gradient, namely the gradient of (half of) the distance squared G(q) = frac12d^2_mathcal P(3)(qI_3) is given by operatornamegrad G(q) = -operatornamelog_q I_3, where operatornamelog is th logarithmic map on the manifold.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"G2 = -log(N, q, Matrix{Float64}(I, 3, 3))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"3Ã—3 Matrix{Float64}:\n -0.0  -0.0       -0.0\n -0.0   1.86368    0.826856\n -0.0   0.826856   2.81845","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Both terms agree up to 1810^-12:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"norm(G1 - G2)\nisapprox(M, q, G1, G2; atol=2 * 1e-12)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"true","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#Summary","page":"Use automatic differentiation","title":"Summary","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"This tutorial illustrates how to use tools from Euclidean spaces, finite differences or automatic differentiation, to compute gradients on Riemannian manifolds. The scheme allows to use any differentiation framework within the embedding to derive a Riemannian gradient.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#Technical-details","page":"Use automatic differentiation","title":"Technical details","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use automatic differentiation","title":"Use automatic differentiation","text":"This tutorial was last rendered April 25, 2025, 12:10:33.","category":"page"},{"location":"solvers/proximal_point/#Proximal-point-method","page":"Proximal point method","title":"Proximal point method","text":"","category":"section"},{"location":"solvers/proximal_point/#Manopt.proximal_point","page":"Proximal point method","title":"Manopt.proximal_point","text":"proximal_point(M, prox_f, p=rand(M); kwargs...)\nproximal_point(M, mpmo, p=rand(M); kwargs...)\nproximal_point!(M, prox_f, p; kwargs...)\nproximal_point!(M, mpmo, p; kwargs...)\n\nPerform the proximal point algoritm from [FO02] which reads\n\np^(k+1) = operatornameprox_Î»_kf(p^(k))\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nprox_f: a proximal map (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nf=nothing: a cost function f mathcal Mâ„ to minimize. For running the algorithm, f is not required, but for example when recording the cost or using a stopping criterion that requires a cost function.\nÎ»= k -> 1.0: a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-12)): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_point/#Manopt.proximal_point!","page":"Proximal point method","title":"Manopt.proximal_point!","text":"proximal_point(M, prox_f, p=rand(M); kwargs...)\nproximal_point(M, mpmo, p=rand(M); kwargs...)\nproximal_point!(M, prox_f, p; kwargs...)\nproximal_point!(M, mpmo, p; kwargs...)\n\nPerform the proximal point algoritm from [FO02] which reads\n\np^(k+1) = operatornameprox_Î»_kf(p^(k))\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nprox_f: a proximal map (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nf=nothing: a cost function f mathcal Mâ„ to minimize. For running the algorithm, f is not required, but for example when recording the cost or using a stopping criterion that requires a cost function.\nÎ»= k -> 1.0: a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-12)): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_point/#State","page":"Proximal point method","title":"State","text":"","category":"section"},{"location":"solvers/proximal_point/#Manopt.ProximalPointState","page":"Proximal point method","title":"Manopt.ProximalPointState","text":"ProximalPointState{P} <: AbstractGradientSolverState\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nÎ»:         a function for the values of Î»_k per iteration(cycle k\n\nConstructor\n\nProximalPointState(M::AbstractManifold; kwargs...)\n\nInitialize the proximal point method solver state, where\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\n\nKeyword arguments\n\nÎ»=k -> 1.0 a function to compute the Î»_k k  mathcal N,\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstopping_criterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\n\nSee also\n\nproximal_point\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_point/","page":"Proximal point method","title":"Proximal point method","text":"O.Â Ferreira and P.Â R.Â Oliveira. Proximal point algorithm on Riemannian manifolds. Optimization.Â AÂ JournalÂ ofÂ MathematicalÂ ProgrammingÂ andÂ OperationsÂ Research 51, 257â€“270 (2002).\n\n\n\n","category":"page"},{"location":"solvers/conjugate_gradient_descent/#Conjugate-gradient-descent","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent","page":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent","text":"conjugate_gradient_descent(M, f, grad_f, p=rand(M))\nconjugate_gradient_descent!(M, f, grad_f, p)\nconjugate_gradient_descent(M, gradient_objective, p)\nconjugate_gradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform a conjugate gradient based descent-\n\np_k+1 = operatornameretr_p_k bigl( s_kÎ´_k bigr)\n\nwhere operatornameretr denotes a retraction on the Manifold M and one can employ different rules to update the descent direction Î´_k based on the last direction Î´_k-1 and both gradients operatornamegradf(x_k),operatornamegrad f(x_k-1). The Stepsize s_k may be determined by a Linesearch.\n\nAlternatively to f and grad_f you can provide the AbstractManifoldGradientObjective gradient_objective directly.\n\nAvailable update rules are SteepestDescentCoefficientRule, which yields a gradient_descent, ConjugateDescentCoefficient (the default), DaiYuanCoefficientRule, FletcherReevesCoefficient, HagerZhangCoefficient, HestenesStiefelCoefficient, LiuStoreyCoefficient, and PolakRibiereCoefficient. These can all be combined with a ConjugateGradientBealeRestartRule rule.\n\nThey all compute Î²_k such that this algorithm updates the search direction as\n\nÎ´_k=operatornamegradf(p_k) + Î²_k delta_k-1\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\ncoefficient::DirectionUpdateRule=ConjugateDescentCoefficient(): rule to compute the descent direction update coefficient Î²_k, as a functor, where the resulting function maps are (amp, cgs, k) -> Î² with amp an AbstractManoptProblem, cgs is the ConjugateGradientDescentState, and k is the current iterate.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(500)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent!","page":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent!","text":"conjugate_gradient_descent(M, f, grad_f, p=rand(M))\nconjugate_gradient_descent!(M, f, grad_f, p)\nconjugate_gradient_descent(M, gradient_objective, p)\nconjugate_gradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform a conjugate gradient based descent-\n\np_k+1 = operatornameretr_p_k bigl( s_kÎ´_k bigr)\n\nwhere operatornameretr denotes a retraction on the Manifold M and one can employ different rules to update the descent direction Î´_k based on the last direction Î´_k-1 and both gradients operatornamegradf(x_k),operatornamegrad f(x_k-1). The Stepsize s_k may be determined by a Linesearch.\n\nAlternatively to f and grad_f you can provide the AbstractManifoldGradientObjective gradient_objective directly.\n\nAvailable update rules are SteepestDescentCoefficientRule, which yields a gradient_descent, ConjugateDescentCoefficient (the default), DaiYuanCoefficientRule, FletcherReevesCoefficient, HagerZhangCoefficient, HestenesStiefelCoefficient, LiuStoreyCoefficient, and PolakRibiereCoefficient. These can all be combined with a ConjugateGradientBealeRestartRule rule.\n\nThey all compute Î²_k such that this algorithm updates the search direction as\n\nÎ´_k=operatornamegradf(p_k) + Î²_k delta_k-1\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\ncoefficient::DirectionUpdateRule=ConjugateDescentCoefficient(): rule to compute the descent direction update coefficient Î²_k, as a functor, where the resulting function maps are (amp, cgs, k) -> Î² with amp an AbstractManoptProblem, cgs is the ConjugateGradientDescentState, and k is the current iterate.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(500)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#State","page":"Conjugate gradient descent","title":"State","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientDescentState","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientDescentState","text":"ConjugateGradientState <: AbstractGradientSolverState\n\nspecify options for a conjugate gradient descent algorithm, that solves a [DefaultManoptProblem].\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nX::T: a tangent vector at the point p on the manifold mathcal M\nÎ´:                       the current descent direction, also a tangent vector\nÎ²:                       the current update coefficient rule, see .\ncoefficient:             function to determine the new Î²\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nConjugateGradientState(M::AbstractManifold; kwargs...)\n\nwhere the last five fields can be set by their names as keyword and the X can be set to a tangent vector type using the keyword initial_gradient which defaults to zero_vector(M,p), and Î´ is initialized to a copy of this vector.\n\nKeyword arguments\n\nThe following fields from above <re keyword arguments\n\ninitial_gradient=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\np=rand(M): a point on the manifold mathcal Mto specify the initial value\ncoefficient=[ConjugateDescentCoefficient](@ref)(): specify a CG coefficient, see also the [ManifoldDefaultsFactory`](@ref).\nstepsize=default_stepsize(M, ConjugateGradientDescentState; retraction_method=retraction_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(500)|StopWhenGradientNormLess(1e-8)): a functor indicating that the stopping criterion is fulfilled\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nconjugate_gradient_descent, DefaultManoptProblem, ArmijoLinesearch\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#cg-coeffs","page":"Conjugate gradient descent","title":"Available coefficients","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"The update rules act as DirectionUpdateRule, which internally always first evaluate the gradient itself.","category":"page"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateDescentCoefficient","page":"Conjugate gradient descent","title":"Manopt.ConjugateDescentCoefficient","text":"ConjugateDescentCoefficient()\nConjugateDescentCoefficient(M::AbstractManifold)\n\nCompute the (classical) conjugate gradient coefficient based on [Fle87] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nThen the coefficient reads\n\nÎ²_k = fraclVert X_k+1 rVert_p_k+1^2-Î´_kX_k_p_k\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ConjugateDescentCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientBealeRestart","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientBealeRestart","text":"ConjugateGradientBealeRestart(direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory}; kwargs...)\nConjugateGradientBealeRestart(M::AbstractManifold, direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory}; kwargs...)\n\nCompute a conjugate gradient coefficient with a potential restart, when two directions are nearly orthogonal. See [HZ06, page 12] (in the preprint, page 46 in Journal page numbers). This method is named after E. Beale from his proceedings paper in 1972 [Bea72]. This method acts as a decorator to any existing DirectionUpdateRule direction_update.\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nThen a restart is performed, hence Î²_k = 0 returned if\n\n  fracX_k+1 mathcal T_p_k+1p_kX_klVert X_k rVert_p_k  Îµ\n\nwhere Îµ is the threshold, which is set by default to 0.2, see [Pow77]\n\nInput\n\ndirection_update: a DirectionUpdateRule or a corresponding ManifoldDefaultsFactory to produce such a rule.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nthreshold=0.2\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ConjugateGradientBealeRestartRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.DaiYuanCoefficient","page":"Conjugate gradient descent","title":"Manopt.DaiYuanCoefficient","text":"DaiYuanCoefficient(; kwargs...)\nDaiYuanCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [DY99] adapted to Riemannian manifolds.\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_k+1p_kX_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k =\nfraclVert X_k+1 rVert_p_k+1^2mathcal T_p_k+1p_kÎ´_k Î½_k_p_k+1\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for DaiYuanCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.FletcherReevesCoefficient","page":"Conjugate gradient descent","title":"Manopt.FletcherReevesCoefficient","text":"FletcherReevesCoefficient()\nFletcherReevesCoefficient(M::AbstractManifold)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [FR64] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nThen the coefficient reads\n\nÎ²_k =\nfraclVert X_k+1 rVert_p_k+1^2lVert X_k rVert_p_k^2\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for FletcherReevesCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HagerZhangCoefficient","page":"Conjugate gradient descent","title":"Manopt.HagerZhangCoefficient","text":"HagerZhangCoefficient(; kwargs...)\nHagerZhangCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [FR64] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_k+1p_kX_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k = BiglÎ½_k - frac2lVert Î½_k rVert_p_k+1^2mathcal T_p_k+1p_kÎ´_k Î½_k_p_k+1\n  mathcal T_p_k+1p_kÎ´_k\n  fracX_k+1mathcal T_p_k+1p_kÎ´_k Î½_k_p_k+1\nBigr_p_k+1\n\nThis method includes a numerical stability proposed by those authors.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for HagerZhangCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HestenesStiefelCoefficient","page":"Conjugate gradient descent","title":"Manopt.HestenesStiefelCoefficient","text":"HestenesStiefelCoefficient(; kwargs...)\nHestenesStiefelCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [HS52] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_k+1p_kX_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k = frac X_k+1 Î½_k _p_k+1 mathcal T_p_k+1p_kÎ´_k Î½_k_p_k+1\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for HestenesStiefelCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.LiuStoreyCoefficient","page":"Conjugate gradient descent","title":"Manopt.LiuStoreyCoefficient","text":"LiuStoreyCoefficient(; kwargs...)\nLiuStoreyCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [LS91] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_k+1p_kX_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k = - frac X_k+1Î½_k _p_k+1 Î´_kX_k _p_k\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for LiuStoreyCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.PolakRibiereCoefficient","page":"Conjugate gradient descent","title":"Manopt.PolakRibiereCoefficient","text":"PolakRibiereCoefficient(; kwargs...)\nPolakRibiereCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [PR69] adapted to Riemannian manifolds.\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_k+1p_kX_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k = frac X_k+1 Î½_k _p_k+1lVert X_k rVert_p_k^2\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for PolakRibiereCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.SteepestDescentCoefficient","page":"Conjugate gradient descent","title":"Manopt.SteepestDescentCoefficient","text":"SteepestDescentCoefficient()\nSteepestDescentCoefficient(M::AbstractManifold)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm so that is falls back to a gradient_descent method, that is\n\nÎ²_k = 0\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for SteepestDescentCoefficient. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Internal-rules-for-coefficients","page":"Conjugate gradient descent","title":"Internal rules for coefficients","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientBealeRestartRule","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientBealeRestartRule","text":"ConjugateGradientBealeRestartRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on a restart idea of [Bea72], following [HZ06, page 12] adapted to manifolds.\n\nFields\n\ndirection_update::DirectionUpdateRule: the actual rule, that is restarted\nthreshold::Real: a threshold for the restart check.\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nConjugateGradientBealeRestartRule(\n    direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory};\n    kwargs...\n)\nConjugateGradientBealeRestartRule(\n    M::AbstractManifold=DefaultManifold(),\n    direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory};\n    kwargs...\n)\n\nConstruct the Beale restart coefficient update rule adapted to manifolds.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M If this is not provided, the DefaultManifold() from ManifoldsBase.jl is used.\ndirection_update: a DirectionUpdateRule or a corresponding ManifoldDefaultsFactory to produce such a rule.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nthreshold=0.2\n\nSee also\n\nConjugateGradientBealeRestart, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.DaiYuanCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.DaiYuanCoefficientRule","text":"DaiYuanCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [DY99] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nDaiYuanCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Daiâ€”Yuan coefficient update rule.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nDaiYuanCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.FletcherReevesCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.FletcherReevesCoefficientRule","text":"FletcherReevesCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [FR64] adapted to manifolds\n\nConstructor\n\nFletcherReevesCoefficientRule()\n\nConstruct the Fletcherâ€”Reeves coefficient update rule.\n\nSee also\n\nFletcherReevesCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HagerZhangCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.HagerZhangCoefficientRule","text":"HagerZhangCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [HZ05] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nHagerZhangCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Hager-Zang coefficient update rule based on [HZ05] adapted to manifolds.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nHagerZhangCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HestenesStiefelCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.HestenesStiefelCoefficientRule","text":"HestenesStiefelCoefficientRuleRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [HS52] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nHestenesStiefelCoefficientRuleRule(M::AbstractManifold; kwargs...)\n\nConstruct the Hestenes-Stiefel coefficient update rule based on [HS52] adapted to manifolds.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nHestenesStiefelCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.LiuStoreyCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.LiuStoreyCoefficientRule","text":"LiuStoreyCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [LS91] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nLiuStoreyCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Lui-Storey coefficient update rule based on [LS91] adapted to manifolds.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nLiuStoreyCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.PolakRibiereCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.PolakRibiereCoefficientRule","text":"PolakRibiereCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [PR69] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nPolakRibiereCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Daiâ€”Yuan coefficient update rule.\n\nKeyword arguments\n\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nPolakRibiereCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.SteepestDescentCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.SteepestDescentCoefficientRule","text":"SteepestDescentCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient to obtain the steepest direction, that is Î²_k=0.\n\nConstructor\n\nSteepestDescentCoefficientRule()\n\nConstruct the steepest descent coefficient update rule.\n\nSee also\n\nSteepestDescentCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#sec-cgd-technical-details","page":"Conjugate gradient descent","title":"Technical details","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"The conjugate_gradient_descent solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= or vector_transport_method_dual= (for mathcal N) does not have to be specified.\nBy default gradient descent uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).","category":"page"},{"location":"solvers/conjugate_gradient_descent/#Literature","page":"Conjugate gradient descent","title":"Literature","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"E.Â M.Â Beale. A derivation of conjugate gradients. In: Numerical methods for nonlinear optimization, edited by F.Â A.Â Lootsma (Academic Press, London, London, 1972); pp.Â 39â€“43.\n\n\n\nY.Â H.Â Dai and Y.Â Yuan. A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property. SIAMÂ JournalÂ onÂ Optimization 10, 177â€“182 (1999).\n\n\n\nR.Â Fletcher. Practical Methods of Optimization. 2Â Edition, A Wiley-Interscience Publication (John Wiley & Sons Ltd., 1987).\n\n\n\nR.Â Fletcher and C.Â M.Â Reeves. Function minimization by conjugate gradients. TheÂ ComputerÂ Journal 7, 149â€“154 (1964).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A survey of nonlinear conjugate gradient methods. PacificÂ JournalÂ ofÂ Optimization 2, 35â€“58 (2006).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search. SIAMÂ JournalÂ onÂ Optimization 16, 170â€“192 (2005).\n\n\n\nM.Â Hestenes and E.Â Stiefel. Methods of conjugate gradients for solving linear systems. JournalÂ ofÂ ResearchÂ ofÂ theÂ NationalÂ BureauÂ ofÂ Standards 49, 409 (1952).\n\n\n\nY.Â Liu and C.Â Storey. Efficient generalized conjugate gradient algorithms,  part 1: Theory. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 69, 129â€“137 (1991).\n\n\n\nE.Â Polak and G.Â RibiÃ¨re. Note sur la convergence de mÃ©thodes de directions conjuguÃ©es. RevueÂ franÃ§aiseÂ dâ€™informatiqueÂ etÂ deÂ rechercheÂ opÃ©rationnelle 3, 35â€“43 (1969).\n\n\n\nM.Â J.Â Powell. Restart procedures for the conjugate gradient method. MathematicalÂ Programming 12, 241â€“254 (1977).\n\n\n\n","category":"page"},{"location":"solvers/convex_bundle_method/#Convex-bundle-method","page":"Convex bundle method","title":"Convex bundle method","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Manopt.convex_bundle_method","page":"Convex bundle method","title":"Manopt.convex_bundle_method","text":"convex_bundle_method(M, f, âˆ‚f, p)\nconvex_bundle_method!(M, f, âˆ‚f, p)\n\nperform a convex bundle method p^(k+1) = operatornameretr_p^(k)(-g_k) where\n\ng_k = sum_jin J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nand p_k is the last serious iterate, X_q_j  f(q_j), and the Î»_j^k are solutions to the quadratic subproblem provided by the convex_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details, see [BHJ24].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nâˆ‚f:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\natol_Î»=eps() : tolerance parameter for the convex coefficients in Î».\natol_errors=eps(): : tolerance parameter for the linearization errors.\nbundle_cap=25`\nm=1e-3: : the parameter to test the decrease of the cost: f(q_k+1)  f(p_k) + m Î¾.\ndiameter=50.0: estimate for the diameter of the level set of the objective function at the starting point.\ndomain=(M, p) -> isfinite(f(M, p)): a function to that evaluates to true when the current candidate is in the domain of the objective f, and false otherwise.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nk_max=0: upper bound on the sectional curvature of the manifold.\nstepsize=default_stepsize(M, ConvexBundleMethodState): a functor inheriting from Stepsize to determine a step size\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses* inverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstopping_criterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nsub_state=convex_bundle_method_subsolver`:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem=AllocatingEvaluation:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.convex_bundle_method!","page":"Convex bundle method","title":"Manopt.convex_bundle_method!","text":"convex_bundle_method(M, f, âˆ‚f, p)\nconvex_bundle_method!(M, f, âˆ‚f, p)\n\nperform a convex bundle method p^(k+1) = operatornameretr_p^(k)(-g_k) where\n\ng_k = sum_jin J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nand p_k is the last serious iterate, X_q_j  f(q_j), and the Î»_j^k are solutions to the quadratic subproblem provided by the convex_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details, see [BHJ24].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nâˆ‚f:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\natol_Î»=eps() : tolerance parameter for the convex coefficients in Î».\natol_errors=eps(): : tolerance parameter for the linearization errors.\nbundle_cap=25`\nm=1e-3: : the parameter to test the decrease of the cost: f(q_k+1)  f(p_k) + m Î¾.\ndiameter=50.0: estimate for the diameter of the level set of the objective function at the starting point.\ndomain=(M, p) -> isfinite(f(M, p)): a function to that evaluates to true when the current candidate is in the domain of the objective f, and false otherwise.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nk_max=0: upper bound on the sectional curvature of the manifold.\nstepsize=default_stepsize(M, ConvexBundleMethodState): a functor inheriting from Stepsize to determine a step size\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses* inverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstopping_criterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nsub_state=convex_bundle_method_subsolver`:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem=AllocatingEvaluation:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#State","page":"Convex bundle method","title":"State","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Manopt.ConvexBundleMethodState","page":"Convex bundle method","title":"Manopt.ConvexBundleMethodState","text":"ConvexBundleMethodState <: AbstractManoptSolverState\n\nStores option values for a convex_bundle_method solver.\n\nFields\n\nTHe following fields require a (real) number type R, as well as point type P and a tangent vector type T`\n\natol_Î»::R:                 tolerance parameter for the convex coefficients in Î»\n`atol_errors::R:             tolerance parameter for the linearization errors\nbundle<:AbstractVector{Tuple{<:P,<:T}}: bundle that collects each iterate with the computed subgradient at the iterate\nbundle_cap::Int: the maximal number of elements the bundle is allowed to remember\ndiameter::R: estimate for the diameter of the level set of the objective function at the starting point\ndomain: the domain offas a function(M,p) -> bthat evaluates to true when the current candidate is in the domain off`, and false otherwise,\ng::T:                      descent direction\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nk_max::R:                  upper bound on the sectional curvature of the manifold\nlinearization_errors<:AbstractVector{<:R}: linearization errors at the last serious step\nm::R:                      the parameter to test the decrease of the cost: f(q_k+1)  f(p_k) + m Î¾.\np::P: a point on the manifold mathcal Mstoring the current iterate\np_last_serious::P:         last serious iterate\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\ntransported_subgradients:  subgradients of the bundle that are transported to p_last_serious\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring a subgradient at the current iterate\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nÎµ::R:                      convex combination of the linearization errors\nÎ»:::AbstractVector{<:R}:   convex coefficients from the slution of the subproblem\nÎ¾:                         the stopping parameter given by Î¾ = -lVert grvert^2  Îµ\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nConstructor\n\nConvexBundleMethodState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\nConvexBundleMethodState(M::AbstractManifold, sub_problem=convex_bundle_method_subsolver; evaluation=AllocatingEvaluation(), kwargs...)\n\nGenerate the state for the convex_bundle_method on the manifold M\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nsub_problem:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\nMost of the following keyword arguments set default values for the fields mentioned before.\n\natol_Î»=eps()\natol_errors=eps()\nbundle_cap=25`\nm=1e-2\ndiameter=50.0\ndomain=(M, p) -> isfinite(f(M, p))\nk_max=0\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstepsize=default_stepsize(M, ConvexBundleMethodState): a functor inheriting from Stepsize to determine a step size\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p) specify the type of tangent vector to use.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Stopping-criteria","page":"Convex bundle method","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Manopt.StopWhenLagrangeMultiplierLess","page":"Convex bundle method","title":"Manopt.StopWhenLagrangeMultiplierLess","text":"StopWhenLagrangeMultiplierLess <: StoppingCriterion\n\nStopping Criteria for Lagrange multipliers.\n\nCurrently these are meant for the convex_bundle_method and proximal_bundle_method, where based on the Lagrange multipliers an approximate (sub)gradient g and an error estimate Îµ is computed.\n\nThe mode=:both requires that both Îµ and lvert g rvert are smaller than their tolerances for the convex_bundle_method, and that c and lvert d rvert are smaller than their tolerances for the proximal_bundle_method.\n\nThe mode=:estimate requires that, for the convex_bundle_method -Î¾ = lvert g rvert^2 + Îµ is less than a given tolerance. For the proximal_bundle_method, the equation reads -Î½ = Î¼ lvert d rvert^2 + c.\n\nConstructors\n\nStopWhenLagrangeMultiplierLess(tolerance=1e-6; mode::Symbol=:estimate, names=nothing)\n\nCreate the stopping criterion for one of the modes mentioned. Note that tolerance can be a single number for the :estimate case, but a vector of two values is required for the :both mode. Here the first entry specifies the tolerance for Îµ (c), the second the tolerance for lvert g rvert (lvert d rvert), respectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Debug-functions","page":"Convex bundle method","title":"Debug functions","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Manopt.DebugWarnIfLagrangeMultiplierIncreases","page":"Convex bundle method","title":"Manopt.DebugWarnIfLagrangeMultiplierIncreases","text":"DebugWarnIfLagrangeMultiplierIncreases <: DebugAction\n\nprint a warning if the Lagrange parameter based value -Î¾ of the bundle method increases.\n\nConstructor\n\nDebugWarnIfLagrangeMultiplierIncreases(warn=:Once; tol=1e2)\n\nInitialize the warning to warning level (:Once) and introduce a tolerance for the test of 1e2.\n\nThe warn level can be set to :Once to only warn the first time the cost increases, to :Always to report an increase every time it happens, and it can be set to :No to deactivate the warning, then this DebugAction is inactive. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Helpers-and-internal-functions","page":"Convex bundle method","title":"Helpers and internal functions","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Manopt.convex_bundle_method_subsolver","page":"Convex bundle method","title":"Manopt.convex_bundle_method_subsolver","text":"Î» = convex_bundle_method_subsolver(M, p_last_serious, linearization_errors, transported_subgradients)\nconvex_bundle_method_subsolver!(M, Î», p_last_serious, linearization_errors, transported_subgradients)\n\nsolver for the subproblem of the convex bundle method at the last serious iterate p_k given the current linearization errors c_j^k, and transported subgradients mathrmP_p_kq_j X_q_j.\n\nThe computation can also be done in-place of Î».\n\nThe subproblem for the convex bundle method is\n\nbeginalign*\n    operatorname*argmin_Î»  â„^lvert J_krvert\n    frac12 BigllVert sum_j  J_k Î»_j mathrmP_p_kq_j X_q_j BigrrVert^2\n    + sum_j  J_k Î»_j  c_j^k\n    \n    texts tquad \n    sum_j  J_k Î»_j = 1\n    quad Î»_j  0\n    quad textfor all \n    j  J_k\nendalign*\n\nwhere J_k = j  J_k-1    Î»_j  0 cup k. See [BHJ24] for more details\n\ntip: Tip\nA default subsolver based on RipQP.jl and QuadraticModels is available if these two packages are loaded.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.DomainBackTrackingStepsize","page":"Convex bundle method","title":"Manopt.DomainBackTrackingStepsize","text":"DomainBackTrackingStepsize <: Stepsize\n\nImplement a backtrack as long as we are q = operatornameretr_p(X) yields a point closer to p than lVert X rVert_p or q is not on the domain. For the domain this step size requires a ConvexBundleMethodState\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Literature","page":"Convex bundle method","title":"Literature","text":"","category":"section"},{"location":"solvers/convex_bundle_method/","page":"Convex bundle method","title":"Convex bundle method","text":"R.Â Bergmann, R.Â Herzog and H.Â Jasa. The Riemannian Convex Bundle Method, preprint (2024), arXiv:2402.13670.\n\n\n\n","category":"page"},{"location":"changelog/#Changelog","page":"Changelog","title":"Changelog","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"All notable Changes to the Julia package Manopt.jl are documented in this file. The file was started with Version 0.4.","category":"page"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.","category":"page"},{"location":"changelog/#[0.5.13]-2025-04-25","page":"Changelog","title":"[0.5.13] 2025-04-25","text":"","category":"section"},{"location":"changelog/#Added","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Allow setting AbstractManifoldObjective through JuMP","category":"page"},{"location":"changelog/#Changed","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Remove dependency on ManoptExamples.jl which yielded a circular dependency, though only through extras\nUnify dummy types and several test functions into the ManoptTestSuite subpackage.","category":"page"},{"location":"changelog/#Fixed","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A scaling error that appeared only when calling get_cost_function on the new ScaledManifoldObjective.\nDocumentation issues for quasi-Newton solvers.\nfixes a scaling error in quasi newton","category":"page"},{"location":"changelog/#[0.5.12]-April-13,-2025","page":"Changelog","title":"[0.5.12] April 13, 2025","text":"","category":"section"},{"location":"changelog/#Added-2","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"a ScaledManifoldObjective to easier build scaled versions of objectives, especially turn maximisation problems into minimisation ones using a scaling of -1.\nIntroduce a ManifoldConstrainedSetObjective\nIntroduce a projected_gradient_method","category":"page"},{"location":"changelog/#[0.5.11]-April-8,-2025","page":"Changelog","title":"[0.5.11] April 8, 2025","text":"","category":"section"},{"location":"changelog/#Added-3","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Configurable subsolver for the linear subproblem in Levenberg-Marquardt. The default subsolver is now also robust to numerical issues that may cause Cholesky decomposition to fail.","category":"page"},{"location":"changelog/#[0.5.10]-April-4,-2025","page":"Changelog","title":"[0.5.10] April 4, 2025","text":"","category":"section"},{"location":"changelog/#Fixed-2","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"a proper implementation of the preconditioning for quasi_Newton, that can be used instead of or in combination with the initial scaling.","category":"page"},{"location":"changelog/#[0.5.9]-March-24,-2025","page":"Changelog","title":"[0.5.9] March 24, 2025","text":"","category":"section"},{"location":"changelog/#Added-4","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"add a PreconditionedDirection variant to the direction gradient processor keyword argument and its corresponding PreconditionedDirectionRule\nmake the preconditioner available in quasi Newton.\nin gradient_descent and conjugate_gradient_descent the rule can be added anyways.","category":"page"},{"location":"changelog/#Fixed-3","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the links in the AD tutorial are fixed and moved to using extref","category":"page"},{"location":"changelog/#[0.5.8]-February-28,-2025","page":"Changelog","title":"[0.5.8] February 28, 2025","text":"","category":"section"},{"location":"changelog/#Fixed-4","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fixed a small bug in the NonmonotoneLinesearchStepsize hwn the injectivity radius is an irrational number.\nfixed a small bug in check_gradient where eps might have been called on complex types.\nfixed a bug in several gradient based solvers like quasi_newton, such that they properly work with the combined cost grad objective.\nfixes a few typos in the docs.","category":"page"},{"location":"changelog/#[0.5.7]-February-20,-20265","page":"Changelog","title":"[0.5.7] February 20, 20265","text":"","category":"section"},{"location":"changelog/#Added-5","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Adds a mesh adaptive direct search algorithm (MADS), using the LTMADS variant with a lower triangular (LT) random matrix in the mesh generation.","category":"page"},{"location":"changelog/#[0.5.6]-February-10,-2025","page":"Changelog","title":"[0.5.6] February 10, 2025","text":"","category":"section"},{"location":"changelog/#Changed-2","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"bump dependencies of all JuliaManifolds ecosystem packages to be consistent with ManifoldsBase 1.0","category":"page"},{"location":"changelog/#[0.5.5]-January-4,-2025","page":"Changelog","title":"[0.5.5] January 4, 2025","text":"","category":"section"},{"location":"changelog/#Added-6","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the Levenberg-Marquardt algorithm internally uses a VectorGradientFunction, which allows","category":"page"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"to use a vector of gradients of a function returning all gradients as well for the algorithm","category":"page"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The VectorGradientFunction now also have a get_jacobian function","category":"page"},{"location":"changelog/#Changed-3","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Minimum Julia version is now 1.10 (the LTS which replaced 1.6)\nThe vectorial functions had a bug where the original vector function for the mutating case was not always treated as mutating.","category":"page"},{"location":"changelog/#Removed","page":"Changelog","title":"Removed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The geodesic regression example, first because it is not correct, second because it should become part of ManoptExamples.jl once it is correct.","category":"page"},{"location":"changelog/#[0.5.4]-December-11,-2024","page":"Changelog","title":"[0.5.4] December 11, 2024","text":"","category":"section"},{"location":"changelog/#Added-7","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"An automated detection whether the tutorials are present  if not an also no quarto run is done, an automated --exclude-tutorials option is added.\nSupport for ManifoldDiff 0.4\nicons upfront external links when they link to another package or Wikipedia.","category":"page"},{"location":"changelog/#[0.5.3]-October-18,-2024","page":"Changelog","title":"[0.5.3] October 18, 2024","text":"","category":"section"},{"location":"changelog/#Added-8","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"StopWhenChangeLess, StopWhenGradientChangeLess and StopWhenGradientLess can now use the new idea (ManifoldsBase.jl 0.15.18) of different outer norms on manifolds with components like power and product manifolds and all others that support this from the Manifolds.jl Library, like Euclidean","category":"page"},{"location":"changelog/#Changed-4","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"stabilize max_stepsize to also work when injectivity_radius dos not exist. It however would warn new users, that activate tutorial mode.\nStart a ManoptTestSuite sub package to store dummy types and common test helpers in.","category":"page"},{"location":"changelog/#[0.5.2]-October-5,-2024","page":"Changelog","title":"[0.5.2] October 5, 2024","text":"","category":"section"},{"location":"changelog/#Added-9","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"three new symbols to easier state to record the :Gradient, the :GradientNorm, and the :Stepsize.","category":"page"},{"location":"changelog/#Changed-5","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fix a few typos in the documentation\nimproved the documentation for the initial guess of ArmijoLinesearchStepsize.","category":"page"},{"location":"changelog/#[0.5.1]-September-4,-2024","page":"Changelog","title":"[0.5.1] September 4, 2024","text":"","category":"section"},{"location":"changelog/#Changed-6","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"slightly improves the test for the ExponentialFamilyProjection text on the about page.","category":"page"},{"location":"changelog/#Added-10","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the proximal_point method.","category":"page"},{"location":"changelog/#[0.5.0]-August-29,-2024","page":"Changelog","title":"[0.5.0] August 29, 2024","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"This breaking update is mainly concerned with improving a unified experience through all solvers and some usability improvements, such that for example the different gradient update rules are easier to specify.","category":"page"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"In general this introduces a few factories, that avoid having to pass the manifold to keyword arguments","category":"page"},{"location":"changelog/#Added-11","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A ManifoldDefaultsFactory that postpones the creation/allocation of manifold-specific fields in for example direction updates, step sizes and stopping criteria. As a rule of thumb, internal structures, like a solver state should store the final type. Any high-level interface, like the functions to start solvers, should accept such a factory in the appropriate places and call the internal _produce_type(factory, M), for example before passing something to the state.\na documentation_glossary.jl file containing a glossary of often used variables in fields, arguments, and keywords, to print them in a unified manner. The same for usual sections, text, and math notation that is often used within the doc-strings.","category":"page"},{"location":"changelog/#Changed-7","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Any Stepsize now has a Stepsize struct used internally as the original structs before. The newly exported terms aim to fit stepsize=... in naming and create a ManifoldDefaultsFactory instead, so that any stepsize can be created without explicitly specifying the manifold.\nConstantStepsize is no longer exported, use ConstantLength instead. The length parameter is now a positional argument following the (optional) manifold. Besides that ConstantLength works as before,just that omitting the manifold fills the one specified in the solver now.\nDecreasingStepsize is no longer exported, use DecreasingLength instead. ConstantLength works as before,just that omitting the manifold fills the one specified in the solver now.\nArmijoLinesearch is now called ArmijoLinesearchStepsize. ArmijoLinesearch works as before,just that omitting the manifold fills the one specified in the solver now.\nWolfePowellLinesearch is now called WolfePowellLinesearchStepsize, its constant c_1 is now unified with Armijo and called sufficient_decrease, c_2 was renamed to sufficient_curvature. Besides that, WolfePowellLinesearch works as before, just that omitting the manifold fills the one specified in the solver now.\nWolfePowellBinaryLinesearch is now called WolfePowellBinaryLinesearchStepsize, its constant c_1 is now unified with Armijo and called sufficient_decrease, c_2 was renamed to sufficient_curvature. Besides that, WolfePowellBinaryLinesearch works as before, just that omitting the manifold fills the one specified in the solver now.\nNonmonotoneLinesearch is now called NonmonotoneLinesearchStepsize. NonmonotoneLinesearch works as before, just that omitting the manifold fills the one specified in the solver now.\nAdaptiveWNGradient is now called AdaptiveWNGradientStepsize. Its second positional argument, the gradient function was only evaluated once for the gradient_bound default, so it has been replaced by the keyword X= accepting a tangent vector. The last positional argument p has also been moved to a keyword argument. Besides that, AdaptiveWNGradient works as before, just that omitting the manifold fills the one specified in the solver now.\nAny DirectionUpdateRule now has the Rule in its name, since the original name is used to create the ManifoldDefaultsFactory instead. The original constructor now no longer requires the manifold as a parameter, that is later done in the factory. The Rule is, however, also no longer exported.\nAverageGradient is now called AverageGradientRule. AverageGradient works as before, but the manifold as its first parameter is no longer necessary and p is now a keyword argument.\nThe IdentityUpdateRule now accepts a manifold optionally for consistency, and you can use Gradient() for short as well as its factory. Hence direction=Gradient() is now available.\nMomentumGradient is now called MomentumGradientRule. MomentumGradient works as before, but the manifold as its first parameter is no longer necessary and p is now a keyword argument.\nNesterov is now called NesterovRule. Nesterov works as before, but the manifold as its first parameter is no longer necessary and p is now a keyword argument.\nConjugateDescentCoefficient is now called ConjugateDescentCoefficientRule. ConjugateDescentCoefficient works as before, but can now use the factory in between\nthe ConjugateGradientBealeRestart is now called ConjugateGradientBealeRestartRule. For the ConjugateGradientBealeRestart the manifold is now a first parameter, that is not necessary and no longer the manifold= keyword.\nDaiYuanCoefficient is now called DaiYuanCoefficientRule. For the DaiYuanCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nFletcherReevesCoefficient is now called FletcherReevesCoefficientRule. FletcherReevesCoefficient works as before, but can now use the factory in between\nHagerZhangCoefficient is now called HagerZhangCoefficientRule. For the HagerZhangCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nHestenesStiefelCoefficient is now called HestenesStiefelCoefficientRule. For the HestenesStiefelCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nLiuStoreyCoefficient is now called LiuStoreyCoefficientRule. For the LiuStoreyCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nPolakRibiereCoefficient is now called PolakRibiereCoefficientRule. For the PolakRibiereCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nthe SteepestDirectionUpdateRule is now called SteepestDescentCoefficientRule. The SteepestDescentCoefficient is equivalent, but creates the new factory temporarily.\nAbstractGradientGroupProcessor is now called AbstractGradientGroupDirectionRule\nthe StochasticGradient is now called StochasticGradientRule. The StochasticGradient is equivalent, but creates the new factory temporarily, so that the manifold is not longer necessary.\nthe AlternatingGradient is now called AlternatingGradientRule.\nThe AlternatingGradient is equivalent, but creates the new factory temporarily, so that the manifold is not longer necessary.\nquasi_Newton had a keyword scale_initial_operator= that was inconsistently declared (sometimes boolean, sometimes real) and was unused. It is now called initial_scale=1.0 and scales the initial (diagonal, unit) matrix within the approximation of the Hessian additionally to the frac1lVert g_krVert scaling with the norm of the oldest gradient for the limited memory variant. For the full matrix variant the initial identity matrix is now scaled with this parameter.\nUnify doc strings and presentation of keyword arguments\ngeneral indexing, for example in a vector, uses i\nindex for inequality constraints is unified to i running from 1,...,m\nindex for equality constraints is unified to j running from 1,...,n\niterations are using now k\nget_manopt_parameter has been renamed to get_parameter since it is internal, so internally that is clear; accessing it from outside hence reads anyways Manopt.get_parameter\nset_manopt_parameter! has been renamed to set_parameter! since it is internal, so internally that is clear; accessing it from outside hence reads Manopt.set_parameter!\nchanged the stabilize::Bool= keyword in quasi_Newton to the more flexible project!= keyword, this is also more in line with the other solvers. Internally the same is done within the QuasiNewtonLimitedMemoryDirectionUpdate. To adapt,\nthe previous stabilize=true is now set with (project!)=embed_project! in general, and if the manifold is represented by points in the embedding, like the sphere, (project!)=project! suffices\nthe new default is (project!)=copyto!, so by default no projection/stabilization is performed.\nthe positional argument p (usually the last or the third to last if sub solvers existed) has been moved to a keyword argument p= in all State constructors\nin NelderMeadState the population moved from positional to keyword argument as well,\nthe way to initialise sub solvers in the solver states has been unified In the new variant\nthe sub_problem is always a positional argument; namely the last one\nif the sub_state is given as a optional positional argument after the problem, it has to be a manopt solver state\nyou can provide the new ClosedFormSolverState(e::AbstractEvaluationType) for the state to indicate that the sub_problem is a closed form solution (function call) and how it has to be called\nif you do not provide the sub_state as positional, the keyword evaluation= is used to generate the state ClosedFormSolverState.\nwhen previously p and eventually X where positional arguments, they are now moved to keyword arguments of the same name for start point and tangent vector.\nin detail\nAdaptiveRegularizationState(M, sub_problem [, sub_state]; kwargs...) replaces the (anyways unused) variant to only provide the objective; both X and p moved to keyword arguments.\nAugmentedLagrangianMethodState(M, objective, sub_problem; evaluation=...) was added\nAugmentedLagrangianMethodState(M, objective, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nExactPenaltyMethodState(M, sub_problem; evaluation=...) was added and ExactPenaltyMethodState(M, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nDifferenceOfConvexState(M, sub_problem; evaluation=...) was added and DifferenceOfConvexState(M, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nDifferenceOfConvexProximalState(M, sub_problem; evaluation=...) was added and DifferenceOfConvexProximalState(M, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nbumped Manifolds.jlto version 0.10; this mainly means that any algorithm working on a product manifold and requiring ArrayPartition now has to explicitly do using RecursiveArrayTools.","category":"page"},{"location":"changelog/#Fixed-5","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the AverageGradientRule filled its internal vector of gradients wrongly or mixed it up in parallel transport. This is now fixed.","category":"page"},{"location":"changelog/#Removed-2","page":"Changelog","title":"Removed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the convex_bundle_method and its ConvexBundleMethodState no longer accept the keywords k_size, p_estimate nor Ï±, they are superseded by just providing k_max.\nthe truncated_conjugate_gradient_descent(M, f, grad_f, hess_f) has the Hessian now  a mandatory argument. To use the old variant,  provide ApproxHessianFiniteDifference(M, copy(M, p), grad_f) to hess_f directly.\nall deprecated keyword arguments and a few function signatures were removed:\nget_equality_constraints, get_equality_constraints!, get_inequality_constraints, get_inequality_constraints! are removed. Use their singular forms and set the index to : instead.\nStopWhenChangeLess(Îµ) is removed, use `StopWhenChangeLess(M, Îµ) instead to fill for example the retraction properly used to determine the change\nIn the WolfePowellLinesearch and  WolfeBinaryLinesearchthe linesearch_stopsize= keyword is replaced by stop_when_stepsize_less=\nDebugChange and RecordChange had a manifold= and a invretr keyword that were replaced by the first positional argument M and inverse_retraction_method=, respectively\nin the NonlinearLeastSquaresObjective and LevenbergMarquardt the jacB= keyword is now called jacobian_tangent_basis=\nin particle_swarm the n= keyword is replaced by swarm_size=.\nupdate_stopping_criterion! has been removed and unified with set_parameter!. The code adaptions are\nto set a parameter of a stopping criterion, just replace update_stopping_criterion!(sc, :Val, v) with set_parameter!(sc, :Val, v)\nto update a stopping criterion in a solver state, replace the old update_stopping_criterion!(state, :Val, v) tat passed down to the stopping criterion by the explicit pass down with set_parameter!(state, :StoppingCriterion, :Val, v)","category":"page"},{"location":"changelog/#[0.4.69]-August-3,-2024","page":"Changelog","title":"[0.4.69] August 3, 2024","text":"","category":"section"},{"location":"changelog/#Changed-8","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Improved performance of Interior Point Newton Method.","category":"page"},{"location":"changelog/#[0.4.68]-August-2,-2024","page":"Changelog","title":"[0.4.68] August 2, 2024","text":"","category":"section"},{"location":"changelog/#Added-12","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"an Interior Point Newton Method, the interior_point_newton\na conjugate_residual Algorithm to solve a linear system on a tangent space.\nArmijoLinesearch now allows for additional additional_decrease_condition and additional_increase_condition keywords to add further conditions to accept additional conditions when to accept an decreasing or increase of the stepsize.\nadd a DebugFeasibility to have a debug print about feasibility of points in constrained optimisation employing the new is_feasible function\nadd a InteriorPointCentralityCondition that can be added for step candidates within the line search of interior_point_newton\nAdd Several new functors\nthe LagrangianCost, LagrangianGradient, LagrangianHessian, that based on a constrained objective allow to construct the Hessian objective of its Lagrangian\nthe CondensedKKTVectorField and its CondensedKKTVectorFieldJacobian, that are being used to solve a linear system within interior_point_newton\nthe KKTVectorField as well as its KKTVectorFieldJacobian and `KKTVectorFieldAdjointJacobian\nthe KKTVectorFieldNormSq and its KKTVectorFieldNormSqGradient used within the Armijo line search of interior_point_newton\nNew stopping criteria\nA StopWhenRelativeResidualLess for the conjugate_residual\nA StopWhenKKTResidualLess for the interior_point_newton","category":"page"},{"location":"changelog/#[0.4.67]-July-25,-2024","page":"Changelog","title":"[0.4.67] July 25, 2024","text":"","category":"section"},{"location":"changelog/#Added-13","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"max_stepsize methods for Hyperrectangle.","category":"page"},{"location":"changelog/#Fixed-6","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"a few typos in the documentation\nWolfePowellLinesearch no longer uses max_stepsize with invalid point by default.","category":"page"},{"location":"changelog/#[0.4.66]-June-27,-2024","page":"Changelog","title":"[0.4.66] June 27, 2024","text":"","category":"section"},{"location":"changelog/#Changed-9","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Remove functions estimate_sectional_curvature, Î¶_1, Î¶_2, close_point from convex_bundle_method\nRemove some unused fields and arguments such as p_estimate, Ï±, Î±, from ConvexBundleMethodState in favor of jut k_max\nChange parameter R placement in ProximalBundleMethodState to fifth position","category":"page"},{"location":"changelog/#[0.4.65]-June-13,-2024","page":"Changelog","title":"[0.4.65] June 13, 2024","text":"","category":"section"},{"location":"changelog/#Changed-10","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"refactor stopping criteria to not store a sc.reason internally, but instead only generate the reason (and hence allocate a string) when actually asked for a reason.","category":"page"},{"location":"changelog/#[0.4.64]-June-4,-2024","page":"Changelog","title":"[0.4.64] June 4, 2024","text":"","category":"section"},{"location":"changelog/#Added-14","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Remodel the constraints and their gradients into separate VectorGradientFunctions to reduce code duplication and encapsulate the inner model of these functions and their gradients\nIntroduce a ConstrainedManoptProblem to model different ranges for the gradients in the new VectorGradientFunctions beyond the default NestedPowerRepresentation\nintroduce a VectorHessianFunction to also model that one can provide the vector of Hessians to constraints\nintroduce a more flexible indexing beyond single indexing, to also include arbitrary ranges when accessing vector functions and their gradients and hence also for constraints and their gradients.","category":"page"},{"location":"changelog/#Changed-11","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Remodel ConstrainedManifoldObjective to store an AbstractManifoldObjective internally instead of directly f and grad_f, allowing also Hessian objectives therein and implementing access to this Hessian\nFixed a bug that Lanczos produced NaNs when started exactly in a minimizer, since the algorithm initially divides by the gradient norm.","category":"page"},{"location":"changelog/#Deprecated","page":"Changelog","title":"Deprecated","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"deprecate get_grad_equality_constraints(M, o, p), use get_grad_equality_constraint(M, o, p, :) from the more flexible indexing instead.","category":"page"},{"location":"changelog/#[0.4.63]-May-11,-2024","page":"Changelog","title":"[0.4.63] May 11, 2024","text":"","category":"section"},{"location":"changelog/#Added-15","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":":reinitialize_direction_update option for quasi-Newton behavior when the direction is not a descent one. It is now the new default for QuasiNewtonState.\nQuasi-Newton direction update rules are now initialized upon start of the solver with the new internal function initialize_update!.","category":"page"},{"location":"changelog/#Fixed-7","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"ALM and EPM no longer keep a part of the quasi-Newton subsolver state between runs.","category":"page"},{"location":"changelog/#Changed-12","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Quasi-Newton solvers: :reinitialize_direction_update is the new default behavior in case of detection of non-descent direction instead of :step_towards_negative_gradient. :step_towards_negative_gradient is still available when explicitly set using the nondescent_direction_behavior keyword argument.","category":"page"},{"location":"changelog/#[0.4.62]-May-3,-2024","page":"Changelog","title":"[0.4.62] May 3, 2024","text":"","category":"section"},{"location":"changelog/#Changed-13","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"bumped dependency of ManifoldsBase.jl to 0.15.9 and imported their numerical verify functions. This changes the throw_error keyword used internally to a error= with a symbol.","category":"page"},{"location":"changelog/#[0.4.61]-April-27,-2024","page":"Changelog","title":"[0.4.61] April 27, 2024","text":"","category":"section"},{"location":"changelog/#Added-16","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Tests use Aqua.jl to spot problems in the code\nintroduce a feature-based list of solvers and reduce the details in the alphabetical list\nadds a PolyakStepsize\nadded a get_subgradient for AbstractManifoldGradientObjectives since their gradient is a special case of a subgradient.","category":"page"},{"location":"changelog/#Fixed-8","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"get_last_stepsize was defined in quite different ways that caused ambiguities. That is now internally a bit restructured and should work nicer. Internally this means that the interim dispatch on get_last_stepsize(problem, state, step, vars...) was removed. Now the only two left are get_last_stepsize(p, s, vars...) and the one directly checking get_last_stepsize(::Stepsize) for stored values.\nthe accidentally exported set_manopt_parameter! is no longer exported","category":"page"},{"location":"changelog/#Changed-14","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"get_manopt_parameter and set_manopt_parameter! have been revised and better documented, they now use more semantic symbols (with capital letters) instead of direct field access (lower letter symbols). Since these are not exported, this is considered an internal, hence non-breaking change.\nsemantic symbols are now all nouns in upper case letters\n:active is changed to :Activity","category":"page"},{"location":"changelog/#[0.4.60]-April-10,-2024","page":"Changelog","title":"[0.4.60] April 10, 2024","text":"","category":"section"},{"location":"changelog/#Added-17","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"RecordWhenActive to allow records to be deactivated during runtime, symbol :WhenActive\nRecordSubsolver to record the result of a subsolver recording in the main solver, symbol :Subsolver\nRecordStoppingReason to record the reason a solver stopped\nmade the RecordFactory more flexible and quite similar to DebugFactory, such that it is now also easy to specify recordings at the end of solver runs. This can especially be used to record final states of sub solvers.","category":"page"},{"location":"changelog/#Changed-15","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"being a bit more strict with internal tools and made the factories for record non-exported, so this is the same as for debug.","category":"page"},{"location":"changelog/#Fixed-9","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The name :Subsolver to generate DebugWhenActive was misleading, it is now called :WhenActive referring to â€œprint debug only when set active, that is by the parent (main) solverâ€.\nthe old version of specifying Symbol => RecordAction for later access was ambiguous, since","category":"page"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"it could also mean to store the action in the dictionary under that symbol. Hence the order for access was switched to RecordAction => Symbol to resolve that ambiguity.","category":"page"},{"location":"changelog/#[0.4.59]-April-7,-2024","page":"Changelog","title":"[0.4.59] April 7, 2024","text":"","category":"section"},{"location":"changelog/#Added-18","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A Riemannian variant of the CMA-ES (Covariance Matrix Adaptation Evolutionary Strategy) algorithm, cma_es.","category":"page"},{"location":"changelog/#Fixed-10","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The constructor dispatch for StopWhenAny with Vector had incorrect element type assertion which was fixed.","category":"page"},{"location":"changelog/#[0.4.58]-March-18,-2024","page":"Changelog","title":"[0.4.58] March 18, 2024","text":"","category":"section"},{"location":"changelog/#Added-19","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"more advanced methods to add debug to the beginning of an algorithm, a step, or the end of the algorithm with DebugAction entries at :Start, :BeforeIteration, :Iteration, and :Stop, respectively.\nIntroduce a Pair-based format to add elements to these hooks, while all others ar now added to :Iteration (no longer to :All)\n(planned) add an easy possibility to also record the initial stage and not only after the first iteration.","category":"page"},{"location":"changelog/#Changed-16","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Changed the symbol for the :Step dictionary to be :Iteration, to unify this with the symbols used in recording, and removed the :All symbol. On the fine granular scale, all but :Start debugs are now reset on init. Since these are merely internal entries in the debug dictionary, this is considered non-breaking.\nintroduce a StopWhenSwarmVelocityLess stopping criterion for particle_swarm replacing the current default of the swarm change, since this is a bit more effective to compute","category":"page"},{"location":"changelog/#Fixed-11","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fixed the outdated documentation of TruncatedConjugateGradientState, that now correctly state that p is no longer stored, but the algorithm runs on TpM.\nimplemented the missing get_iterate for TruncatedConjugateGradientState.","category":"page"},{"location":"changelog/#[0.4.57]-March-15,-2024","page":"Changelog","title":"[0.4.57] March 15, 2024","text":"","category":"section"},{"location":"changelog/#Changed-17","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"convex_bundle_method uses the sectional_curvature from ManifoldsBase.jl.\nconvex_bundle_method no longer has the unused k_min keyword argument.\nManifoldsBase.jl now is running on Documenter 1.3, Manopt.jl documentation now uses DocumenterInterLinks to refer to sections and functions from ManifoldsBase.jl","category":"page"},{"location":"changelog/#Fixed-12","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fixes a type that when passing sub_kwargs to trust_regions caused an error in the decoration of the sub objective.","category":"page"},{"location":"changelog/#[0.4.56]-March-4,-2024","page":"Changelog","title":"[0.4.56] March 4, 2024","text":"","category":"section"},{"location":"changelog/#Added-20","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The option :step_towards_negative_gradient for nondescent_direction_behavior in quasi-Newton solvers does no longer emit a warning by default. This has been moved to a message, that can be accessed/displayed with DebugMessages\nDebugMessages now has a second positional argument, specifying whether all messages, or just the first (:Once) should be displayed.","category":"page"},{"location":"changelog/#[0.4.55]-March-3,-2024","page":"Changelog","title":"[0.4.55] March 3, 2024","text":"","category":"section"},{"location":"changelog/#Added-21","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Option nondescent_direction_behavior for quasi-Newton solvers. By default it checks for non-descent direction which may not be handled well by some stepsize selection algorithms.","category":"page"},{"location":"changelog/#Fixed-13","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"unified documentation, especially function signatures further.\nfixed a few typos related to math formulae in the doc strings.","category":"page"},{"location":"changelog/#[0.4.54]-February-28,-2024","page":"Changelog","title":"[0.4.54] February 28, 2024","text":"","category":"section"},{"location":"changelog/#Added-22","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"convex_bundle_method optimization algorithm for non-smooth geodesically convex functions\nproximal_bundle_method optimization algorithm for non-smooth functions.\nStopWhenSubgradientNormLess, StopWhenLagrangeMultiplierLess, and stopping criteria.","category":"page"},{"location":"changelog/#Fixed-14","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Doc strings now follow a vale.sh policy. Though this is not fully working, this PR improves a lot of the doc strings concerning wording and spelling.","category":"page"},{"location":"changelog/#[0.4.53]-February-13,-2024","page":"Changelog","title":"[0.4.53] February 13, 2024","text":"","category":"section"},{"location":"changelog/#Fixed-15","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fixes two storage action defaults, that accidentally still tried to initialize a :Population (as modified back to :Iterate 0.4.49).\nfix a few typos in the documentation and add a reference for the subgradient method.","category":"page"},{"location":"changelog/#[0.4.52]-February-5,-2024","page":"Changelog","title":"[0.4.52] February 5, 2024","text":"","category":"section"},{"location":"changelog/#Added-23","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"introduce an environment persistent way of setting global values with the set_manopt_parameter! function using Preferences.jl.\nintroduce such a value named :Mode to enable a \"Tutorial\" mode that shall often provide more warnings and information for people getting started with optimisation on manifolds","category":"page"},{"location":"changelog/#[0.4.51]-January-30,-2024","page":"Changelog","title":"[0.4.51] January 30, 2024","text":"","category":"section"},{"location":"changelog/#Added-24","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A StopWhenSubgradientNormLess stopping criterion for subgradient-based optimization.\nAllow the message= of the DebugIfEntry debug action to contain a format element to print the field in the message as well.","category":"page"},{"location":"changelog/#[0.4.50]-January-26,-2024","page":"Changelog","title":"[0.4.50] January 26, 2024","text":"","category":"section"},{"location":"changelog/#Fixed-16","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Fix Quasi Newton on complex manifolds.","category":"page"},{"location":"changelog/#[0.4.49]-January-18,-2024","page":"Changelog","title":"[0.4.49] January 18, 2024","text":"","category":"section"},{"location":"changelog/#Added-25","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A StopWhenEntryChangeLess to be able to stop on arbitrary small changes of specific fields\ngeneralises StopWhenGradientNormLess to accept arbitrary norm= functions\nrefactor the default in particle_swarm to no longer â€œmisuseâ€ the iteration change, but actually the new one the :swarm entry","category":"page"},{"location":"changelog/#[0.4.48]-January-16,-2024","page":"Changelog","title":"[0.4.48] January 16, 2024","text":"","category":"section"},{"location":"changelog/#Fixed-17","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fixes an imprecision in the interface of get_iterate that sometimes led to the swarm of particle_swarm being returned as the iterate.\nrefactor particle_swarm in naming and access functions to avoid this also in the future. To access the whole swarm, one now should use get_manopt_parameter(pss, :Population)","category":"page"},{"location":"changelog/#[0.4.47]-January-6,-2024","page":"Changelog","title":"[0.4.47] January 6, 2024","text":"","category":"section"},{"location":"changelog/#Fixed-18","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fixed a bug, where the retraction set in check_Hessian was not passed on to the optional inner check_gradient call, which could lead to unwanted side effects, see #342.","category":"page"},{"location":"changelog/#[0.4.46]-January-1,-2024","page":"Changelog","title":"[0.4.46] January 1, 2024","text":"","category":"section"},{"location":"changelog/#Changed-18","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"An error is thrown when a line search from LineSearches.jl reports search failure.\nChanged default stopping criterion in ALM algorithm to mitigate an issue occurring when step size is very small.\nDefault memory length in default ALM subsolver is now capped at manifold dimension.\nReplaced CI testing on Julia 1.8 with testing on Julia 1.10.","category":"page"},{"location":"changelog/#Fixed-19","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A bug in LineSearches.jl extension leading to slower convergence.\nFixed a bug in L-BFGS related to memory storage, which caused significantly slower convergence.","category":"page"},{"location":"changelog/#[0.4.45]-December-28,-2023","page":"Changelog","title":"[0.4.45] December 28, 2023","text":"","category":"section"},{"location":"changelog/#Added-26","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Introduce sub_kwargs and sub_stopping_criterion for trust_regions as noticed in #336","category":"page"},{"location":"changelog/#Changed-19","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"WolfePowellLineSearch, ArmijoLineSearch step sizes now allocate less\nlinesearch_backtrack! is now available\nQuasi Newton Updates can work in-place of a direction vector as well.\nFaster safe_indices in L-BFGS.","category":"page"},{"location":"changelog/#[0.4.44]-December-12,-2023","page":"Changelog","title":"[0.4.44] December 12, 2023","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Formally one could consider this version breaking, since a few functions have been moved, that in earlier versions (0.3.x) have been used in example scripts. These examples are now available again within ManoptExamples.jl, and with their â€œreappearanceâ€ the corresponding costs, gradients, differentials, adjoint differentials, and proximal maps have been moved there as well. This is not considered breaking, since the functions were only used in the old, removed examples. Each and every moved function is still documented. They have been partly renamed, and their documentation and testing has been extended.","category":"page"},{"location":"changelog/#Changed-20","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Bumped and added dependencies on all 3 Project.toml files, the main one, the docs/, an the tutorials/ one.\nartificial_S2_lemniscate is available as ManoptExample.Lemniscate and works on arbitrary manifolds now.\nartificial_S1_signal is available as ManoptExample.artificial_S1_signal\nartificial_S1_slope_signal is available as ManoptExamples.artificial_S1_slope_signal\nartificial_S2_composite_bezier_curve is available as ManoptExamples.artificial_S2_composite_Bezier_curve\nartificial_S2_rotation_image is available as ManoptExamples.artificial_S2_rotation_image\nartificial_S2_whirl_image is available as ManoptExamples.artificial_S2_whirl_image\nartificial_S2_whirl_patch is available as ManoptExamples.artificial_S2_whirl_path\nartificial_SAR_image is available as ManoptExamples.artificial_SAR_image\nartificial_SPD_image is available as ManoptExamples.artificial_SPD_image\nartificial_SPD_image2 is available as ManoptExamples.artificial_SPD_image\nadjoint_differential_forward_logs is available as ManoptExamples.adjoint_differential_forward_logs\nadjoint:differential_bezier_control is available as ManoptExamples.adjoint_differential_Bezier_control_points\nBezierSegment is available as ManoptExamples.BeziÃ©rSegment\ncost_acceleration_bezier is available as ManoptExamples.acceleration_Bezier\ncost_L2_acceleration_bezier is available as ManoptExamples.L2_acceleration_Bezier\ncostIntrICTV12 is available as ManoptExamples.Intrinsic_infimal_convolution_TV12\ncostL2TV is available as ManoptExamples.L2_Total_Variation\ncostL2TV12 is available as ManoptExamples.L2_Total_Variation_1_2\ncostL2TV2 is available as ManoptExamples.L2_second_order_Total_Variation\ncostTV is available as ManoptExamples.Total_Variation\ncostTV2 is available as ManoptExamples.second_order_Total_Variation\nde_casteljau is available as ManoptExamples.de_Casteljau\ndifferential_forward_logs is available as ManoptExamples.differential_forward_logs\ndifferential_bezier_control is available as ManoptExamples.differential_Bezier_control_points\nforward_logs is available as ManoptExamples.forward_logs\nget_bezier_degree is available as ManoptExamples.get_Bezier_degree\nget_bezier_degrees is available as ManoptExamples.get_Bezier_degrees\nget_Bezier_inner_points is available as ManoptExamples.get_Bezier_inner_points\nget_bezier_junction_tangent_vectors is available as ManoptExamples.get_Bezier_junction_tangent_vectors\nget_bezier_junctions is available as ManoptExamples.get_Bezier_junctions\nget_bezier_points is available as ManoptExamples.get_Bezier_points\nget_bezier_segments is available as ManoptExamples.get_Bezier_segments\ngrad_acceleration_bezier is available as ManoptExamples.grad_acceleration_Bezier\ngrad_L2_acceleration_bezier is available as ManoptExamples.grad_L2_acceleration_Bezier\ngrad_Intrinsic_infimal_convolution_TV12 is available as ManoptExamples.Intrinsic_infimal_convolution_TV12\ngrad_TV is available as ManoptExamples.grad_Total_Variation\ncostIntrICTV12 is available as ManoptExamples.Intrinsic_infimal_convolution_TV12\nproject_collaborative_TV is available as ManoptExamples.project_collaborative_TV\nprox_parallel_TV is available as ManoptExamples.prox_parallel_TV\ngrad_TV2 is available as ManoptExamples.prox_second_order_Total_Variation\nprox_TV is available as ManoptExamples.prox_Total_Variation\nprox_TV2 is available as ManopExamples.prox_second_order_Total_Variation","category":"page"},{"location":"changelog/#[0.4.43]-November-19,-2023","page":"Changelog","title":"[0.4.43] November 19, 2023","text":"","category":"section"},{"location":"changelog/#Added-27","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"vale.sh as a CI to keep track of a consistent documentation","category":"page"},{"location":"changelog/#[0.4.42]-November-6,-2023","page":"Changelog","title":"[0.4.42] November 6, 2023","text":"","category":"section"},{"location":"changelog/#Added-28","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"add Manopt.JuMP_Optimizer implementing JuMP's solver interface","category":"page"},{"location":"changelog/#[0.4.41]-November-2,-2023","page":"Changelog","title":"[0.4.41] November 2, 2023","text":"","category":"section"},{"location":"changelog/#Changed-21","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"trust_regions is now more flexible and the sub solver (Steihaug-Toint tCG by default) can now be exchanged.\nadaptive_regularization_with_cubics is now more flexible as well, where it previously was a bit too much tightened to the Lanczos solver as well.\nUnified documentation notation and bumped dependencies to use DocumenterCitations 1.3","category":"page"},{"location":"changelog/#[0.4.40]-October-24,-2023","page":"Changelog","title":"[0.4.40] October 24, 2023","text":"","category":"section"},{"location":"changelog/#Added-29","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"add a --help argument to docs/make.jl to document all available command line arguments\nadd a --exclude-tutorials argument to docs/make.jl. This way, when quarto is not available on a computer, the docs can still be build with the tutorials not being added to the menu such that documenter does not expect them to exist.","category":"page"},{"location":"changelog/#Changes","page":"Changelog","title":"Changes","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Bump dependencies to ManifoldsBase.jl 0.15 and Manifolds.jl 0.9\nmove the ARC CG subsolver to the main package, since TangentSpace is now already available from ManifoldsBase.","category":"page"},{"location":"changelog/#[0.4.39]-October-9,-2023","page":"Changelog","title":"[0.4.39] October 9, 2023","text":"","category":"section"},{"location":"changelog/#Changes-2","page":"Changelog","title":"Changes","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"also use the pair of a retraction and the inverse retraction (see last update) to perform the relaxation within the Douglas-Rachford algorithm.","category":"page"},{"location":"changelog/#[0.4.38]-October-8,-2023","page":"Changelog","title":"[0.4.38] October 8, 2023","text":"","category":"section"},{"location":"changelog/#Changes-3","page":"Changelog","title":"Changes","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"avoid allocations when calling get_jacobian! within the Levenberg-Marquard Algorithm.","category":"page"},{"location":"changelog/#Fixed-20","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Fix a lot of typos in the documentation","category":"page"},{"location":"changelog/#[0.4.37]-September-28,-2023","page":"Changelog","title":"[0.4.37] September 28, 2023","text":"","category":"section"},{"location":"changelog/#Changes-4","page":"Changelog","title":"Changes","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"add more of the Riemannian Levenberg-Marquard algorithms parameters as keywords, so they can be changed on call\ngeneralize the internal reflection of Douglas-Rachford, such that is also works with an arbitrary pair of a reflection and an inverse reflection.","category":"page"},{"location":"changelog/#[0.4.36]-September-20,-2023","page":"Changelog","title":"[0.4.36]  September 20, 2023","text":"","category":"section"},{"location":"changelog/#Fixed-21","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Fixed a bug that caused non-matrix points and vectors to fail when working with approximate","category":"page"},{"location":"changelog/#[0.4.35]-September-14,-2023","page":"Changelog","title":"[0.4.35]  September 14, 2023","text":"","category":"section"},{"location":"changelog/#Added-30","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The access to functions of the objective is now unified and encapsulated in proper get_ functions.","category":"page"},{"location":"changelog/#[0.4.34]-September-02,-2023","page":"Changelog","title":"[0.4.34]  September 02, 2023","text":"","category":"section"},{"location":"changelog/#Added-31","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"an ManifoldEuclideanGradientObjective to allow the cost, gradient, and Hessian and other first or second derivative based elements to be Euclidean and converted when needed.\na keyword objective_type=:Euclidean for all solvers, that specifies that an Objective shall be created of the new type","category":"page"},{"location":"changelog/#[0.4.33]-August-24,-2023","page":"Changelog","title":"[0.4.33] August 24, 2023","text":"","category":"section"},{"location":"changelog/#Added-32","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"ConstantStepsize and DecreasingStepsize now have an additional field type::Symbol to assess whether the step-size should be relatively (to the gradient norm) or absolutely constant.","category":"page"},{"location":"changelog/#[0.4.32]-August-23,-2023","page":"Changelog","title":"[0.4.32] August 23, 2023","text":"","category":"section"},{"location":"changelog/#Added-33","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The adaptive regularization with cubics (ARC) solver.","category":"page"},{"location":"changelog/#[0.4.31]-August-14,-2023","page":"Changelog","title":"[0.4.31] August 14, 2023","text":"","category":"section"},{"location":"changelog/#Added-34","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A :Subsolver keyword in the debug= keyword argument, that activates the new DebugWhenActiveto de/activate subsolver debug from the main solversDebugEvery`.","category":"page"},{"location":"changelog/#[0.4.30]-August-3,-2023","page":"Changelog","title":"[0.4.30] August 3, 2023","text":"","category":"section"},{"location":"changelog/#Changed-22","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"References in the documentation are now rendered using DocumenterCitations.jl\nAsymptote export now also accepts a size in pixel instead of its default 4cm size and render can be deactivated setting it to nothing.","category":"page"},{"location":"changelog/#[0.4.29]-July-12,-2023","page":"Changelog","title":"[0.4.29] July 12, 2023","text":"","category":"section"},{"location":"changelog/#Fixed-22","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fixed a bug, where cyclic_proximal_point did not work with decorated objectives.","category":"page"},{"location":"changelog/#[0.4.28]-June-24,-2023","page":"Changelog","title":"[0.4.28] June 24, 2023","text":"","category":"section"},{"location":"changelog/#Changed-23","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"max_stepsize was specialized for FixedRankManifold to follow Matlab Manopt.","category":"page"},{"location":"changelog/#[0.4.27]-June-15,-2023","page":"Changelog","title":"[0.4.27] June 15, 2023","text":"","category":"section"},{"location":"changelog/#Added-35","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"The AdaptiveWNGrad stepsize is available as a new stepsize functor.","category":"page"},{"location":"changelog/#Fixed-23","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Levenberg-Marquardt now possesses its parameters initial_residual_values and initial_jacobian_f also as keyword arguments, such that their default initialisations can be adapted, if necessary","category":"page"},{"location":"changelog/#[0.4.26]-June-11,-2023","page":"Changelog","title":"[0.4.26] June 11, 2023","text":"","category":"section"},{"location":"changelog/#Added-36","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"simplify usage of gradient descent as sub solver in the DoC solvers.\nadd a get_state function\ndocument indicates_convergence.","category":"page"},{"location":"changelog/#[0.4.25]-June-5,-2023","page":"Changelog","title":"[0.4.25] June 5, 2023","text":"","category":"section"},{"location":"changelog/#Fixed-24","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Fixes an allocation bug in the difference of convex algorithm","category":"page"},{"location":"changelog/#[0.4.24]-June-4,-2023","page":"Changelog","title":"[0.4.24] June 4, 2023","text":"","category":"section"},{"location":"changelog/#Added-37","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"another workflow that deletes old PR renderings from the docs to keep them smaller in overall size.","category":"page"},{"location":"changelog/#Changes-5","page":"Changelog","title":"Changes","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"bump dependencies since the extension between Manifolds.jl and ManifoldsDiff.jl has been moved to Manifolds.jl","category":"page"},{"location":"changelog/#[0.4.23]-June-4,-2023","page":"Changelog","title":"[0.4.23] June 4, 2023","text":"","category":"section"},{"location":"changelog/#Added-38","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"More details on the Count and Cache tutorial","category":"page"},{"location":"changelog/#Changed-24","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"loosen constraints slightly","category":"page"},{"location":"changelog/#[0.4.22]-May-31,-2023","page":"Changelog","title":"[0.4.22] May 31, 2023","text":"","category":"section"},{"location":"changelog/#Added-39","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A tutorial on how to implement a solver","category":"page"},{"location":"changelog/#[0.4.21]-May-22,-2023","page":"Changelog","title":"[0.4.21] May 22, 2023","text":"","category":"section"},{"location":"changelog/#Added-40","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A ManifoldCacheObjective as a decorator for objectives to cache results of calls, using LRU Caches as a weak dependency. For now this works with cost and gradient evaluations\nA ManifoldCountObjective as a decorator for objectives to enable counting of calls to for example the cost and the gradient\nadds a return_objective keyword, that switches the return of a solver to a tuple (o, s), where o is the (possibly decorated) objective, and s is the â€œclassicalâ€ solver return (state or point). This way the counted values can be accessed and the cache can be reused.\nchange solvers on the mid level (form solver(M, objective, p)) to also accept decorated objectives","category":"page"},{"location":"changelog/#Changed-25","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Switch all Requires weak dependencies to actual weak dependencies starting in Julia 1.9","category":"page"},{"location":"changelog/#[0.4.20]-May-11,-2023","page":"Changelog","title":"[0.4.20] May 11, 2023","text":"","category":"section"},{"location":"changelog/#Changed-26","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the default tolerances for the numerical check_ functions were loosened a bit, such that check_vector can also be changed in its tolerances.","category":"page"},{"location":"changelog/#[0.4.19]-May-7,-2023","page":"Changelog","title":"[0.4.19] May 7, 2023","text":"","category":"section"},{"location":"changelog/#Added-41","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the sub solver for trust_regions is now customizable and can now be exchanged.","category":"page"},{"location":"changelog/#Changed-27","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"slightly changed the definitions of the solver states for ALM and EPM to be type stable","category":"page"},{"location":"changelog/#[0.4.18]-May-4,-2023","page":"Changelog","title":"[0.4.18] May 4, 2023","text":"","category":"section"},{"location":"changelog/#Added-42","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A function check_Hessian(M, f, grad_f, Hess_f) to numerically verify the (Riemannian) Hessian of a function f","category":"page"},{"location":"changelog/#[0.4.17]-April-28,-2023","page":"Changelog","title":"[0.4.17] April 28, 2023","text":"","category":"section"},{"location":"changelog/#Added-43","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"A new interface of the form alg(M, objective, p0) to allow to reuse objectives without creating AbstractManoptSolverStates and calling solve!. This especially still allows for any decoration of the objective and/or the state using debug=, or record=.","category":"page"},{"location":"changelog/#Changed-28","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"All solvers now have the initial point p as an optional parameter making it more accessible to first time users, gradient_descent(M, f, grad_f) is equivalent to gradient_descent(M, f, grad_f, rand(M))","category":"page"},{"location":"changelog/#Fixed-25","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Unified the framework to work on manifold where points are represented by numbers for several solvers","category":"page"},{"location":"changelog/#[0.4.16]-April-18,-2023","page":"Changelog","title":"[0.4.16] April 18, 2023","text":"","category":"section"},{"location":"changelog/#Fixed-26","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the inner products used in truncated_gradient_descent now also work thoroughly on complex matrix manifolds","category":"page"},{"location":"changelog/#[0.4.15]-April-13,-2023","page":"Changelog","title":"[0.4.15] April 13, 2023","text":"","category":"section"},{"location":"changelog/#Changed-29","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"trust_regions(M, f, grad_f, hess_f, p) now has the Hessian hess_f as well as the start point p0 as an optional parameter and approximate it otherwise.\ntrust_regions!(M, f, grad_f, hess_f, p) has the Hessian as an optional parameter and approximate it otherwise.","category":"page"},{"location":"changelog/#Removed-3","page":"Changelog","title":"Removed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"support for ManifoldsBase.jl 0.13.x, since with the definition of copy(M,p::Number), in 0.14.4, that one is used instead of defining it ourselves.","category":"page"},{"location":"changelog/#[0.4.14]-April-06,-2023","page":"Changelog","title":"[0.4.14] April 06, 2023","text":"","category":"section"},{"location":"changelog/#Changed-30","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"particle_swarm now uses much more in-place operations","category":"page"},{"location":"changelog/#Fixed-27","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"particle_swarm used quite a few deepcopy(p) commands still, which were replaced by copy(M, p)","category":"page"},{"location":"changelog/#[0.4.13]-April-09,-2023","page":"Changelog","title":"[0.4.13] April 09, 2023","text":"","category":"section"},{"location":"changelog/#Added-44","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"get_message to obtain messages from sub steps of a solver\nDebugMessages to display the new messages in debug\nsafeguards in Armijo line search and L-BFGS against numerical over- and underflow that report in messages","category":"page"},{"location":"changelog/#[0.4.12]-April-4,-2023","page":"Changelog","title":"[0.4.12] April 4, 2023","text":"","category":"section"},{"location":"changelog/#Added-45","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Introduce the Difference of Convex Algorithm (DCA) difference_of_convex_algorithm(M, f, g, âˆ‚h, p0)\nIntroduce the Difference of Convex Proximal Point Algorithm (DCPPA) difference_of_convex_proximal_point(M, prox_g, grad_h, p0)\nIntroduce a StopWhenGradientChangeLess stopping criterion","category":"page"},{"location":"changelog/#[0.4.11]-March-27,-2023","page":"Changelog","title":"[0.4.11] March 27, 2023","text":"","category":"section"},{"location":"changelog/#Changed-31","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"adapt tolerances in tests to the speed/accuracy optimized distance on the sphere in Manifolds.jl (part II)","category":"page"},{"location":"changelog/#[0.4.10]-March-26,-2023","page":"Changelog","title":"[0.4.10] March 26, 2023","text":"","category":"section"},{"location":"changelog/#Changed-32","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"adapt tolerances in tests to the speed/accuracy optimized distance on the sphere in Manifolds.jl","category":"page"},{"location":"changelog/#[0.4.9]-March-3,-2023","page":"Changelog","title":"[0.4.9] March 3, 2023","text":"","category":"section"},{"location":"changelog/#Added-46","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"introduce a wrapper that allows line searches from LineSearches.jl to be used within Manopt.jl, introduce the manoptjl.org/stable/extensions/ page to explain the details.","category":"page"},{"location":"changelog/#[0.4.8]-February-21,-2023","page":"Changelog","title":"[0.4.8] February 21, 2023","text":"","category":"section"},{"location":"changelog/#Added-47","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"a status_summary that displays the main parameters within several structures of Manopt, most prominently a solver state","category":"page"},{"location":"changelog/#Changed-33","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Improved storage performance by introducing separate named tuples for points and vectors\nchanged the show methods of AbstractManoptSolverStates to display their `state_summary\nMove tutorials to be rendered with Quarto into the documentation.","category":"page"},{"location":"changelog/#[0.4.7]-February-14,-2023","page":"Changelog","title":"[0.4.7] February 14, 2023","text":"","category":"section"},{"location":"changelog/#Changed-34","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Bump [compat] entry of ManifoldDiff to also include 0.3","category":"page"},{"location":"changelog/#[0.4.6]-February-3,-2023","page":"Changelog","title":"[0.4.6] February 3, 2023","text":"","category":"section"},{"location":"changelog/#Fixed-28","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Fixed a few stopping criteria even indicated to stop before the algorithm started.","category":"page"},{"location":"changelog/#[0.4.5]-January-24,-2023","page":"Changelog","title":"[0.4.5] January 24, 2023","text":"","category":"section"},{"location":"changelog/#Changed-35","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the new default functions that include p are used where possible\na first step towards faster storage handling","category":"page"},{"location":"changelog/#[0.4.4]-January-20,-2023","page":"Changelog","title":"[0.4.4] January 20, 2023","text":"","category":"section"},{"location":"changelog/#Added-48","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Introduce ConjugateGradientBealeRestart to allow CG restarts using Bealeâ€˜s rule","category":"page"},{"location":"changelog/#Fixed-29","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"fix a type in HestenesStiefelCoefficient","category":"page"},{"location":"changelog/#[0.4.3]-January-17,-2023","page":"Changelog","title":"[0.4.3] January 17, 2023","text":"","category":"section"},{"location":"changelog/#Fixed-30","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the CG coefficient Î² can now be complex\nfix a bug in grad_distance","category":"page"},{"location":"changelog/#[0.4.2]-January-16,-2023","page":"Changelog","title":"[0.4.2] January 16, 2023","text":"","category":"section"},{"location":"changelog/#Changed-36","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"the usage of inner in line search methods, such that they work well with complex manifolds as well","category":"page"},{"location":"changelog/#[0.4.1]-January-15,-2023","page":"Changelog","title":"[0.4.1] January 15, 2023","text":"","category":"section"},{"location":"changelog/#Fixed-31","page":"Changelog","title":"Fixed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"a max_stepsize per manifold to avoid leaving the injectivity radius, which it also defaults to","category":"page"},{"location":"changelog/#[0.4.0]-January-10,-2023","page":"Changelog","title":"[0.4.0] January 10, 2023","text":"","category":"section"},{"location":"changelog/#Added-49","page":"Changelog","title":"Added","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"Dependency on ManifoldDiff.jl and a start of moving actual derivatives, differentials, and gradients there.\nAbstractManifoldObjective to store the objective within the AbstractManoptProblem\nIntroduce a CostGrad structure to store a function that computes the cost and gradient within one function.\nstarted a changelog.md to thoroughly keep track of changes","category":"page"},{"location":"changelog/#Changed-37","page":"Changelog","title":"Changed","text":"","category":"section"},{"location":"changelog/","page":"Changelog","title":"Changelog","text":"AbstractManoptProblem replaces Problem\nthe problem now contains a\nAbstractManoptSolverState replaces Options\nrandom_point(M) is replaced by rand(M) from `ManifoldsBase.jl\nrandom_tangent(M, p) is replaced by rand(M; vector_at=p)","category":"page"},{"location":"solvers/mesh_adaptive_direct_search/#Mesh-adaptive-direct-search-(MADS)","page":"MADS","title":"Mesh adaptive direct search (MADS)","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.mesh_adaptive_direct_search","page":"MADS","title":"Manopt.mesh_adaptive_direct_search","text":"mesh_adaptive_direct_search(M, f, p=rand(M); kwargs...)\nmesh_adaptive_direct_search(M, mco::AbstractManifoldCostObjective, p=rand(M); kwargs..)\nmesh_adaptive_direct_search!(M, f, p; kwargs...)\nmesh_adaptive_direct_search!(M, mco::AbstractManifoldCostObjective, p; kwargs..)\n\nThe Mesh Adaptive Direct Search (MADS) algorithm minimizes an objective function f mathcal M  â„ on the manifold M. The algorithm constructs an implicit mesh in the tangent space T_pmathcal M at the current candidate p. Each iteration consists of a search step and a poll step.\n\nThe search step selects points from the implicit mesh and attempts to find an improved candidate solution that reduces the value of f. If the search step fails to generate an improved candidate solution, the poll step is performed. It consists of a local exploration on the current implicit mesh in the neighbourhood of the current iterate.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nmesh_basis=DefaultOrthonormalBasis: a basis to generate the mesh in. The mesh is generated in coordinates of this basis in every tangent space\nmax_stepsize=injectivity_radius(M): a maximum step size to take. any vector generated on the mesh is shortened to this length to avoid leaving the injectivity radius,\npoll::AbstractMeshPollFunction=LowerTriangularAdaptivePoll(M, copy(M,p)): the poll function to use. The mesh_basis (as basis), retraction_method, and vector_transport_method are passed to this default as well.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nscale_mesh=injectivity_radius(M) / 4: initial scaling of the mesh\nsearch::AbstractMeshSearchFunction=DefaultMeshAdaptiveDirectSearch(M, copy(M,p)): the search function to use. The retraction_method is passed to this default as well.\nstopping_criterion=StopAfterIteration(500)|StopWhenPollSizeLess(1e-10): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.mesh_adaptive_direct_search!","page":"MADS","title":"Manopt.mesh_adaptive_direct_search!","text":"mesh_adaptive_direct_search(M, f, p=rand(M); kwargs...)\nmesh_adaptive_direct_search(M, mco::AbstractManifoldCostObjective, p=rand(M); kwargs..)\nmesh_adaptive_direct_search!(M, f, p; kwargs...)\nmesh_adaptive_direct_search!(M, mco::AbstractManifoldCostObjective, p; kwargs..)\n\nThe Mesh Adaptive Direct Search (MADS) algorithm minimizes an objective function f mathcal M  â„ on the manifold M. The algorithm constructs an implicit mesh in the tangent space T_pmathcal M at the current candidate p. Each iteration consists of a search step and a poll step.\n\nThe search step selects points from the implicit mesh and attempts to find an improved candidate solution that reduces the value of f. If the search step fails to generate an improved candidate solution, the poll step is performed. It consists of a local exploration on the current implicit mesh in the neighbourhood of the current iterate.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nmesh_basis=DefaultOrthonormalBasis: a basis to generate the mesh in. The mesh is generated in coordinates of this basis in every tangent space\nmax_stepsize=injectivity_radius(M): a maximum step size to take. any vector generated on the mesh is shortened to this length to avoid leaving the injectivity radius,\npoll::AbstractMeshPollFunction=LowerTriangularAdaptivePoll(M, copy(M,p)): the poll function to use. The mesh_basis (as basis), retraction_method, and vector_transport_method are passed to this default as well.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nscale_mesh=injectivity_radius(M) / 4: initial scaling of the mesh\nsearch::AbstractMeshSearchFunction=DefaultMeshAdaptiveDirectSearch(M, copy(M,p)): the search function to use. The retraction_method is passed to this default as well.\nstopping_criterion=StopAfterIteration(500)|StopWhenPollSizeLess(1e-10): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/mesh_adaptive_direct_search/#State","page":"MADS","title":"State","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.MeshAdaptiveDirectSearchState","page":"MADS","title":"Manopt.MeshAdaptiveDirectSearchState","text":"MeshAdaptiveDirectSearchState <: AbstractManoptSolverState\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nmesh_size: the current (internal) mesh size\nscale_mesh: the current scaling of the internal mesh size, yields the actual mesh size used\nmax_stepsize: an upper bound for the longest step taken in looking for a candidate in either poll or search\npoll_size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\npoll::[AbstractMeshPollFunction]: a poll step (functor) to perform\nsearch::[AbstractMeshSearchFunction}(@ref) a search step (functor) to perform\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Poll","page":"MADS","title":"Poll","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.AbstractMeshPollFunction","page":"MADS","title":"Manopt.AbstractMeshPollFunction","text":"AbstractMeshPollFunction\n\nAn abstract type for common â€œpollâ€ strategies in the mesh_adaptive_direct_search solver. A subtype of this The functor has to fulfil\n\nbe callable as poll!(problem, mesh_size; kwargs...) and modify the state\n\nas well as to provide functions\n\nis_successful(poll!) that indicates whether the last poll was successful in finding a new candidate\nget_basepoint(poll!) that returns the base point at which the mesh is build\nget_candidate(poll!) that returns the last found candidate if the poll was successful. Otherwise the base point is returned\nget_descent_direction(poll!) the the vector that points from the base point to the candidate. If the last poll was not successful, the zero vector is returned\nupdate_basepoint!(M, poll!, p) that updates the base point to p and all necessary internal data to a new point to build a mesh at\n\nThe kwargs... could include\n\nscale_mesh=1.0: to rescale the mesh globally\nmax_stepsize=Inf: avoid exceeding a step size beyond this value, e.g. injectivity radius. any vector longer than this should be shortened to the provided maximum step size.\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.LowerTriangularAdaptivePoll","page":"MADS","title":"Manopt.LowerTriangularAdaptivePoll","text":"LowerTriangularAdaptivePoll <: AbstractMeshPollFunction\n\nGenerate a mesh (poll step) based on Section 6 and 7 of [Dre07], with two small modifications:\n\nThe mesh can be scaled globally so instead of Î”_0^m=1 a certain different scale is used\nAny poll direction can be rescaled if it is too long. This is to not exceed the injectivity radius for example.\n\nFunctor\n\n(p::LowerTriangularAdaptivePoll)(problem, mesh_size; scale_mesh=1.0, max_stepsize=inf)\n\nFields\n\nbase_point::P: a point on the manifold, where the mesh is build in the tangent space\nbasis: a basis of the current tangent space with respect to which the mesh is stored\ncandidate::P: a memory for a new point/candidate\nmesh: a vector of tangent vectors storing the mesh.\nrandom_vector: a d-dimensional random vector b_l`\nrandom_index: a random index Î¹\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nX::T the last successful poll direction stored as a tangent vector. initialised to the zero vector and reset to the zero vector after moving to a new tangent space.\n\nConstructor\n\nLowerTriangularAdaptivePoll(M, p=rand(M); kwargs...)\n\nKeyword arguments\n\nbasis=DefaultOrthonormalBasis\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/","page":"MADS","title":"MADS","text":"as well as the internal functions","category":"page"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_descent_direction-Tuple{LowerTriangularAdaptivePoll}","page":"MADS","title":"Manopt.get_descent_direction","text":"get_descent_direction(ltap::LowerTriangularAdaptivePoll)\n\nReturn the direction of the last LowerTriangularAdaptivePoll that yields a descent of the cost. If the poll was not successful, the zero vector is returned\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.is_successful-Tuple{LowerTriangularAdaptivePoll}","page":"MADS","title":"Manopt.is_successful","text":"is_successful(ltap::LowerTriangularAdaptivePoll)\n\nReturn whether the last LowerTriangularAdaptivePoll step was successful\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_candidate-Tuple{LowerTriangularAdaptivePoll}","page":"MADS","title":"Manopt.get_candidate","text":"get_candidate(ltap::LowerTriangularAdaptivePoll)\n\nReturn the candidate of the last successful LowerTriangularAdaptivePoll. If the poll was unsuccessful, the base point is returned.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_basepoint-Tuple{LowerTriangularAdaptivePoll}","page":"MADS","title":"Manopt.get_basepoint","text":"get_basepoint(ltap::LowerTriangularAdaptivePoll)\n\nReturn the base point of the tangent space, where the mash for the LowerTriangularAdaptivePoll is build in.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.update_basepoint!-Union{Tuple{P}, Tuple{Any, LowerTriangularAdaptivePoll{P, T, F} where {T, F<:Real}, P}} where P","page":"MADS","title":"Manopt.update_basepoint!","text":"update_basepoint!(M, ltap::LowerTriangularAdaptivePoll, p)\n\nUpdate the base point of the LowerTriangularAdaptivePoll. This especially also updates the basis, that is used to build a (new) mesh.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Search","page":"MADS","title":"Search","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.AbstractMeshSearchFunction","page":"MADS","title":"Manopt.AbstractMeshSearchFunction","text":"AbstractMeshSearchFunction\n\nShould be callable as search!(problem, mesh_size, p, X; kwargs...)\n\nwhere X is the last successful poll direction from the tangent space at p if that exists and the zero vector otherwise.\n\nBesides that the following functions should be implemented\n\nis_successful(search!) that indicates whether the last search was successful in finding a new candidate\nget_candidate(search!) that returns the last found candidate\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.DefaultMeshAdaptiveDirectSearch","page":"MADS","title":"Manopt.DefaultMeshAdaptiveDirectSearch","text":"DefaultMeshAdaptiveDirectSearch <: AbstractMeshSearchFunction\n\nFunctor\n\n(s::DefaultMeshAdaptiveDirectSearch)(problem, mesh_size::Real, X; scale_mesh::Real=1.0, max_stepsize::Real=inf)\n\nFields\n\nq: a temporary memory for a point on the manifold\nX: information to perform the search, e.g. the last direction found by poll.\nlast_search_improved::Bool indicate whether the last search was successful, i.e. improved the cost.\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructor\n\nDefaultMeshAdaptiveDirectSearch(M::AbstractManifold, p=rand(M); kwargs...)\n\nKeyword arguments\n\n`X::T=zero_vector(M, p)\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/","page":"MADS","title":"MADS","text":"as well as the internal functions","category":"page"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.is_successful-Tuple{DefaultMeshAdaptiveDirectSearch}","page":"MADS","title":"Manopt.is_successful","text":"is_successful(dmads::DefaultMeshAdaptiveDirectSearch)\n\nReturn whether the last DefaultMeshAdaptiveDirectSearch was successful.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_candidate-Tuple{DefaultMeshAdaptiveDirectSearch}","page":"MADS","title":"Manopt.get_candidate","text":"get_candidate(dmads::DefaultMeshAdaptiveDirectSearch)\n\nReturn the last candidate a DefaultMeshAdaptiveDirectSearch found\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Additional-stopping-criteria","page":"MADS","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.StopWhenPollSizeLess","page":"MADS","title":"Manopt.StopWhenPollSizeLess","text":"StopWhenPollSizeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the poll mesh size of an MeshAdaptiveDirectSearchState.\n\nConstructor\n\nStopWhenPollSizeLess(Îµ)\n\ninitialize the stopping criterion to a threshold Îµ.\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Technical-details","page":"MADS","title":"Technical details","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/","page":"MADS","title":"MADS","text":"The mesh_adaptive_direct_search solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/mesh_adaptive_direct_search/","page":"MADS","title":"MADS","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nWithin the default initialization rand(M) is used to generate the initial population\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.","category":"page"},{"location":"solvers/mesh_adaptive_direct_search/#Literature","page":"MADS","title":"Literature","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/","page":"MADS","title":"MADS","text":"D.Â W.Â Dreisigmeyer. Direct Search Alogirthms over Riemannian Manifolds (Optimization Online, 2007).\n\n\n\n","category":"page"},{"location":"solvers/gradient_descent/#Gradient-descent","page":"Gradient Descent","title":"Gradient descent","text":"","category":"section"},{"location":"solvers/gradient_descent/#Manopt.gradient_descent","page":"Gradient Descent","title":"Manopt.gradient_descent","text":"gradient_descent(M, f, grad_f, p=rand(M); kwargs...)\ngradient_descent(M, gradient_objective, p=rand(M); kwargs...)\ngradient_descent!(M, f, grad_f, p; kwargs...)\ngradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform the gradient descent algorithm\n\np_k+1 = operatornameretr_p_kbigl( s_koperatornamegradf(p_k) bigr)\nqquad k=01\n\nwhere s_k  0 denotes a step size.\n\nThe algorithm can be performed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldGradientObjective gradient_objective directly.\n\nKeyword arguments\n\ndirection=IdentityUpdateRule(): specify to perform a certain processing of the direction, for example Nesterov, MomentumGradient or AverageGradient.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=default_stepsize(M, GradientDescentState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.gradient_descent!","page":"Gradient Descent","title":"Manopt.gradient_descent!","text":"gradient_descent(M, f, grad_f, p=rand(M); kwargs...)\ngradient_descent(M, gradient_objective, p=rand(M); kwargs...)\ngradient_descent!(M, f, grad_f, p; kwargs...)\ngradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform the gradient descent algorithm\n\np_k+1 = operatornameretr_p_kbigl( s_koperatornamegradf(p_k) bigr)\nqquad k=01\n\nwhere s_k  0 denotes a step size.\n\nThe algorithm can be performed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldGradientObjective gradient_objective directly.\n\nKeyword arguments\n\ndirection=IdentityUpdateRule(): specify to perform a certain processing of the direction, for example Nesterov, MomentumGradient or AverageGradient.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=default_stepsize(M, GradientDescentState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#State","page":"Gradient Descent","title":"State","text":"","category":"section"},{"location":"solvers/gradient_descent/#Manopt.GradientDescentState","page":"Gradient Descent","title":"Manopt.GradientDescentState","text":"GradientDescentState{P,T} <: AbstractGradientSolverState\n\nDescribes the state of a gradient based descent algorithm.\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\ndirection::DirectionUpdateRule : a processor to handle the obtained gradient and compute a direction to â€œwalk intoâ€.\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructor\n\nGradientDescentState(M::AbstractManifold; kwargs...)\n\nInitialize the gradient descent solver state, where\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\n\nKeyword arguments\n\ndirection=IdentityUpdateRule()\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstopping_criterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nstepsize=default_stepsize(M, GradientDescentState; retraction_method=retraction_method): a functor inheriting from Stepsize to determine a step size\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nSee also\n\ngradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Direction-update-rules","page":"Gradient Descent","title":"Direction update rules","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"A field of the options is the direction, a DirectionUpdateRule, which by default IdentityUpdateRule just evaluates the gradient but can be enhanced for example to","category":"page"},{"location":"solvers/gradient_descent/#Manopt.AverageGradient","page":"Gradient Descent","title":"Manopt.AverageGradient","text":"AverageGradient(; kwargs...)\nAverageGradient(M::AbstractManifold; kwargs...)\n\nAdd an average of gradients to a gradient processor. A set of previous directions (from the inner processor) and the last iterate are stored, average is taken after vector transporting them to the current iterates tangent space.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M (optional)\n\nKeyword arguments\n\np=rand(M): a point on the manifold mathcal Mto specify the initial value\ndirection=IdentityUpdateRule preprocess the actual gradient before adding momentum\ngradients=[zero_vector(M, p) for _ in 1:n] how to initialise the internal storage\nn=10 number of gradient evaluations to take the mean over\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for AverageGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.DirectionUpdateRule","page":"Gradient Descent","title":"Manopt.DirectionUpdateRule","text":"DirectionUpdateRule\n\nA general functor, that handles direction update rules. It's fields are usually only a StoreStateAction by default initialized to the fields required for the specific coefficient, but can also be replaced by a (common, global) individual one that provides these values.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.IdentityUpdateRule","page":"Gradient Descent","title":"Manopt.IdentityUpdateRule","text":"IdentityUpdateRule <: DirectionUpdateRule\n\nThe default gradient direction update is the identity, usually it just evaluates the gradient.\n\nYou can also use Gradient() to create the corresponding factory, though this only delays this parameter-free instantiation to later.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.MomentumGradient","page":"Gradient Descent","title":"Manopt.MomentumGradient","text":"MomentumGradient()\n\nAppend a momentum to a gradient processor, where the last direction and last iterate are stored and the new is composed as Î·_i = m*Î·_i-1 - s d_i, where sd_i is the current (inner) direction and Î·_i-1 is the vector transported last direction multiplied by momentum m.\n\nInput\n\nM (optional)\n\nKeyword arguments\n\np=rand(M): a point on the manifold mathcal M\ndirection=IdentityUpdateRule preprocess the actual gradient before adding momentum\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\nmomentum=0.2 amount of momentum to use\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for MomentumGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.Nesterov","page":"Gradient Descent","title":"Manopt.Nesterov","text":"Nesterov(; kwargs...)\nNesterov(M::AbstractManifold; kwargs...)\n\nAssume f is L-Lipschitz and Î¼-strongly convex. Given\n\na step size h_kfrac1L (from the GradientDescentState\na shrinkage parameter Î²_k\nand a current iterate p_k\nas well as the interim values Î³_k and v_k from the previous iterate.\n\nThis compute a Nesterov type update using the following steps, see [ZS18]\n\nCompute the positive root Î±_k(01) of Î±^2 = h_kbigl((1-Î±_k)Î³_k+Î±_k Î¼bigr).\nSet barÎ³_k+1 = (1-Î±_k)Î³_k + Î±_kÎ¼\ny_k = operatornameretr_p_kBigl(fracÎ±_kÎ³_kÎ³_k + Î±_kÎ¼operatornameretr^-1_p_kv_k Bigr)\nx_k+1 = operatornameretr_y_k(-h_k operatornamegradf(y_k))\nv_k+1 = operatornameretr_y_kBigl(frac(1-Î±_k)Î³_kbarÎ³_koperatornameretr_y_k^-1(v_k) - fracÎ±_kbarÎ³_k+1operatornamegradf(y_k) Bigr)\nÎ³_k+1 = frac11+Î²_kbarÎ³_k+1\n\nThen the direction from p_k to p_k+1 by d = operatornameretr^-1_p_kp_k+1 is returned.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M (optional)\n\nKeyword arguments\n\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nÎ³=0.001\nÎ¼=0.9\nshrinkage = k -> 0.8\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for NesterovRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.PreconditionedDirection","page":"Gradient Descent","title":"Manopt.PreconditionedDirection","text":"PreconditionedDirection(preconditioner; kwargs...)\nPreconditionedDirection(M::AbstractManifold, preconditioner; kwargs...)\n\nAdd a preconditioner to a gradient processor following the motivation for optimization, as a linear invertible map P T_pmathcal M  T_pmathcal M that usually should be\n\nsymmetric: X P(Y) = P(X) Y\npositive definite X P(X)  0 for X not the zero-vector\n\nThe gradient is then preconditioned as P(X), where X is either the gradient of the objective or the result of a previous (internally stored) gradient processor.\n\nFor example if you provide as the preconditioner the inverse of the Hessian operatornameHess^-1 f, you turn a gradient descent into a Newton method.\n\nArguments\n\nM::AbstractManifold: a Riemannian manifold mathcal M (optional)\npreconditioner:   preconditioner function, either as a (M, p, X) -> Y allocating or (M, Y, p, X) -> Y mutating function\n\nKeyword arguments\n\ndirection=IdentityUpdateRule internal DirectionUpdateRule to determine the gradients to store or a ManifoldDefaultsFactory generating one\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for PreconditionedDirectionRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"which internally use the ManifoldDefaultsFactory and produce the internal elements","category":"page"},{"location":"solvers/gradient_descent/#Manopt.AverageGradientRule","page":"Gradient Descent","title":"Manopt.AverageGradientRule","text":"AverageGradientRule <: DirectionUpdateRule\n\nAdd an average of gradients to a gradient processor. A set of previous directions (from the inner processor) and the last iterate are stored. The average is taken after vector transporting them to the current iterates tangent space.\n\nFields\n\ngradients:               the last n gradient/direction updates\nlast_iterate:            last iterate (needed to transport the gradients)\ndirection:               internal DirectionUpdateRule to determine directions to apply the averaging to\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructors\n\nAverageGradientRule(\n    M::AbstractManifold;\n    p::P=rand(M);\n    n::Int=10\n    direction::Union{<:DirectionUpdateRule,ManifoldDefaultsFactory}=IdentityUpdateRule(),\n    gradients = fill(zero_vector(p.M, o.x),n),\n    last_iterate = deepcopy(x0),\n    vector_transport_method = default_vector_transport_method(M, typeof(p))\n)\n\nAdd average to a gradient problem, where\n\nn:                       determines the size of averaging\ndirection:               is the internal DirectionUpdateRule to determine the gradients to store\ngradients:               can be pre-filled with some history\nlast_iterate:            stores the last iterate\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.ConjugateDescentCoefficientRule","page":"Gradient Descent","title":"Manopt.ConjugateDescentCoefficientRule","text":"ConjugateDescentCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient adapted to manifolds\n\nSee also conjugate_gradient_descent\n\nConstructor\n\nConjugateDescentCoefficientRule()\n\nConstruct the conjugate descent coefficient update rule, a new storage is created by default.\n\nSee also\n\nConjugateDescentCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.MomentumGradientRule","page":"Gradient Descent","title":"Manopt.MomentumGradientRule","text":"MomentumGradientRule <: DirectionUpdateRule\n\nStore the necessary information to compute the MomentumGradient direction update.\n\nFields\n\np_old::P: a point on the manifold mathcal M\nmomentum::Real: factor for the momentum\ndirection: internal DirectionUpdateRule to determine directions to add the momentum to.\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nX_old::T: a tangent vector at the point p on the manifold mathcal M\n\nConstructors\n\nMomentumGradientRule(M::AbstractManifold; kwargs...)\n\nInitialize a momentum gradient rule to s, where p and X are memory for interim values.\n\nKeyword arguments\n\np=rand(M): a point on the manifold mathcal M\ns=IdentityUpdateRule()\nmomentum=0.2\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nSee also\n\nMomentumGradient\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.NesterovRule","page":"Gradient Descent","title":"Manopt.NesterovRule","text":"NesterovRule <: DirectionUpdateRule\n\nCompute a Nesterov inspired direction update rule. See Nesterov for details\n\nFields\n\nÎ³::Real, Î¼::Real: coefficients from the last iterate\nv::P:      an interim point to compute the next gradient evaluation point y_k\nshrinkage: a function k -> ... to compute the shrinkage Î²_k per iterate k`.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nConstructor\n\nNesterovRule(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nÎ³=0.001`\nÎ¼=0.9`\nshrinkage = k -> 0.8\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nSee also\n\nNesterov\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.PreconditionedDirectionRule","page":"Gradient Descent","title":"Manopt.PreconditionedDirectionRule","text":"PreconditionedDirectionRule{E<:AbstractEvaluationType} <: DirectionUpdateRule\n\nAdd a preconditioning as gradient processor, see PreconditionedDirection for more mathematical background.\n\nFields\n\ndirection:      internal DirectionUpdateRule to determine directions to apply the preconditioning to\npreconditioner: the preconditioner function\n\nConstructors\n\nPreconditionedDirectionRule(\n    M::AbstractManifold,\n    preconditioner;\n    direction::Union{<:DirectionUpdateRule,ManifoldDefaultsFactory}=IdentityUpdateRule(),\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n)\n\nAdd preconditioning to a gradient problem.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\npreconditioner:   preconditioner function, either as a (M, p, X) -> Yallocating or(M, Y, p, X) -> Y` mutating function\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ndirection=IdentityUpdateRule internal DirectionUpdateRule to determine the gradients to store or a ManifoldDefaultsFactory generating one\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Debug-actions","page":"Gradient Descent","title":"Debug actions","text":"","category":"section"},{"location":"solvers/gradient_descent/#Manopt.DebugGradient","page":"Gradient Descent","title":"Manopt.DebugGradient","text":"DebugGradient <: DebugAction\n\ndebug for the gradient evaluated at the current iterate\n\nConstructors\n\nDebugGradient(; long=false, prefix= , format= \"$prefix%s\", io=stdout)\n\ndisplay the short (false) or long (true) default text for the gradient, or set the prefix manually. Alternatively the complete format can be set.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.DebugGradientNorm","page":"Gradient Descent","title":"Manopt.DebugGradientNorm","text":"DebugGradientNorm <: DebugAction\n\ndebug for gradient evaluated at the current iterate.\n\nConstructors\n\nDebugGradientNorm([long=false,p=print])\n\ndisplay the short (false) or long (true) default text for the gradient norm.\n\nDebugGradientNorm(prefix[, p=print])\n\ndisplay the a prefix in front of the gradient norm.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.DebugStepsize","page":"Gradient Descent","title":"Manopt.DebugStepsize","text":"DebugStepsize <: DebugAction\n\ndebug for the current step size.\n\nConstructors\n\nDebugStepsize(;long=false,prefix=\"step size:\", format=\"$prefix%s\", io=stdout)\n\ndisplay the a prefix in front of the step size.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Record-actions","page":"Gradient Descent","title":"Record actions","text":"","category":"section"},{"location":"solvers/gradient_descent/#Manopt.RecordGradient","page":"Gradient Descent","title":"Manopt.RecordGradient","text":"RecordGradient <: RecordAction\n\nrecord the gradient evaluated at the current iterate\n\nConstructors\n\nRecordGradient(Î¾)\n\ninitialize the RecordAction to the corresponding type of the tangent vector.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.RecordGradientNorm","page":"Gradient Descent","title":"Manopt.RecordGradientNorm","text":"RecordGradientNorm <: RecordAction\n\nrecord the norm of the current gradient\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.RecordStepsize","page":"Gradient Descent","title":"Manopt.RecordStepsize","text":"RecordStepsize <: RecordAction\n\nrecord the step size\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#sec-gradient-descent-technical-details","page":"Gradient Descent","title":"Technical details","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"The gradient_descent solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nBy default gradient descent uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).","category":"page"},{"location":"solvers/gradient_descent/#Literature","page":"Gradient Descent","title":"Literature","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"D.Â G.Â Luenberger. The gradient projection method along geodesics. ManagementÂ Science 18, 620â€“631 (1972).\n\n\n\nH.Â Zhang and S.Â Sra. Towards Riemannian accelerated gradient methods, arXivÂ Preprint,Â 1806.02812 (2018).\n\n\n\n","category":"page"},{"location":"solvers/#Available-solvers-in-Manopt.jl","page":"List of Solvers","title":"Available solvers in Manopt.jl","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Optimisation problems can be classified with respect to several criteria. The following list of the algorithms is a grouped with respect to the â€œinformationâ€ available about a optimisation problem","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"operatorname*argmin_pmathbb M f(p)","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Within each group short notes on advantages of the individual solvers, and required properties the cost f should have, are provided. In that list a ðŸ… is used to indicate state-of-the-art solvers, that usually perform best in their corresponding group and ðŸ« for a maybe not so fast, maybe not so state-of-the-art method, that nevertheless gets the job done most reliably.","category":"page"},{"location":"solvers/#Derivative-free","page":"List of Solvers","title":"Derivative free","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"For derivative free only function evaluations of f are used.","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Nelder-Mead a simplex based variant, that is using d+1 points, where d is the dimension of the manifold.\nParticle Swarm ðŸ« use the evolution of a set of points, called swarm, to explore the domain of the cost and find a minimizer.\nMesh adaptive direct search performs a mesh based exploration (poll) and search.\nCMA-ES uses a stochastic evolutionary strategy to perform minimization robust to local minima of the objective.","category":"page"},{"location":"solvers/#First-order","page":"List of Solvers","title":"First order","text":"","category":"section"},{"location":"solvers/#Gradient","page":"List of Solvers","title":"Gradient","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Gradient Descent uses the gradient from f to determine a descent direction. Here, the direction can also be changed to be Averaged, Momentum-based, based on Nesterovs rule.\nConjugate Gradient Descent uses information from the previous descent direction to improve the current (gradient-based) one including several such update rules.\nThe Quasi-Newton Method ðŸ… uses gradient evaluations to approximate the Hessian, which is then used in a Newton-like scheme, where both a limited memory and a full Hessian approximation are available with several different update rules.\nSteihaug-Toint Truncated Conjugate-Gradient Method a solver for a constrained problem defined on a tangent space.","category":"page"},{"location":"solvers/#Subgradient","page":"List of Solvers","title":"Subgradient","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"The following methods require the Riemannian subgradient f to be available. While the subgradient might be set-valued, the function should provide one of the subgradients.","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"The Subgradient Method takes the negative subgradient as a step direction and can be combined with a step size.\nThe Convex Bundle Method (CBM) uses a former collection of sub gradients at the previous iterates and iterate candidates to solve a local approximation to f in every iteration by solving a quadratic problem in the tangent space.\nThe Proximal Bundle Method works similar to CBM, but solves a proximal map-based problem in every iteration.","category":"page"},{"location":"solvers/#Second-order","page":"List of Solvers","title":"Second order","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Adaptive Regularisation with Cubics ðŸ… locally builds a cubic model to determine the next descent direction.\nThe Riemannian Trust-Regions Solver builds a quadratic model within a trust region to determine the next descent direction.","category":"page"},{"location":"solvers/#Splitting-based","page":"List of Solvers","title":"Splitting based","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"For splitting methods, the algorithms are based on splitting the cost into different parts, usually in a sum of two or more summands. This is usually very well tailored for non-smooth objectives.","category":"page"},{"location":"solvers/#Smooth","page":"List of Solvers","title":"Smooth","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"The following methods require that the splitting, for example into several summands, is smooth in the sense that for every summand of the cost, the gradient should still exist everywhere","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Levenberg-Marquardt minimizes the square norm of f mathcal Mâ„^d provided the gradients of the component functions, or in other words the Jacobian of f.\nStochastic Gradient Descent is based on a splitting of f into a sum of several components f_i whose gradients are provided. Steps are performed according to gradients of randomly selected components.\nThe Alternating Gradient Descent alternates gradient descent steps on the components of the product manifold. All these components should be smooth as it is required, that the gradient exists, and is (locally) convex.","category":"page"},{"location":"solvers/#Nonsmooth","page":"List of Solvers","title":"Nonsmooth","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"If the gradient does not exist everywhere, that is if the splitting yields summands that are nonsmooth, usually methods based on proximal maps are used.","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"The Chambolle-Pock algorithm uses a splitting f(p) = F(p) + G(Î›(p)), where G is defined on a manifold mathcal N and the proximal map of its Fenchel dual is required. Both these functions can be non-smooth.\nThe Cyclic Proximal Point ðŸ« uses proximal maps of the functions from splitting f into summands f_i\nDifference of Convex Algorithm (DCA) uses a splitting of the (non-convex) function f = g - h into a difference of two functions; for each of these it is required to have access to the gradient of g and the subgradient of h to state a sub problem in every iteration to be solved.\nDifference of Convex Proximal Point uses a splitting of the (non-convex) function f = g - h into a difference of two functions; provided the proximal map of g and the subgradient of h, the next iterate is computed. Compared to DCA, the corresponding sub problem is here written in a form that yields the proximal map.\nDouglasâ€”Rachford uses a splitting f(p) = F(x) + G(x) and their proximal maps to compute a minimizer of f, which can be non-smooth.\nPrimal-dual Riemannian semismooth Newton Algorithm extends Chambolle-Pock and requires the differentials of the proximal maps additionally.\nThe Proximal Point uses the proximal map of f iteratively.","category":"page"},{"location":"solvers/#Constrained","page":"List of Solvers","title":"Constrained","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Constrained problems of the form","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"beginalign*\noperatorname*argmin_pmathbb M f(p)\ntextsuch that   g(p) leq 0h(p) = 0\nendalign*","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"For these you can use","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"The Augmented Lagrangian Method (ALM), where both g and grad_g as well as h and grad_h are keyword arguments, and one of these pairs is mandatory.\nThe Exact Penalty Method (EPM) uses a penalty term instead of augmentation, but has the same interface as ALM.\nThe Interior Point Newton Method (IPM) rephrases the KKT system of a constrained problem into an Newton iteration being performed in every iteration.\nFrank-Wolfe algorithm, where besides the gradient of f either a closed form solution or a (maybe even automatically generated) sub problem solver for operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq is required, where p_k is a fixed point on the manifold (changed in every iteration).\nGradient Projection Method","category":"page"},{"location":"solvers/#On-the-tangent-space","page":"List of Solvers","title":"On the tangent space","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Conjugate Residual a solver for a linear system mathcal AX + b = 0 on a tangent space.\nSteihaug-Toint Truncated Conjugate-Gradient Method a solver for a constrained problem defined on a tangent space.","category":"page"},{"location":"solvers/#Alphabetical-list-of-algorithms","page":"List of Solvers","title":"Alphabetical list of algorithms","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Solver Function State\nAdaptive Regularisation with Cubics adaptive_regularization_with_cubics AdaptiveRegularizationState\nAugmented Lagrangian Method augmented_Lagrangian_method AugmentedLagrangianMethodState\nChambolle-Pock ChambollePock ChambollePockState\nConjugate Gradient Descent conjugate_gradient_descent ConjugateGradientDescentState\nConjugate Residual conjugate_residual ConjugateResidualState\nConvex Bundle Method convex_bundle_method ConvexBundleMethodState\nCyclic Proximal Point cyclic_proximal_point CyclicProximalPointState\nDifference of Convex Algorithm difference_of_convex_algorithm DifferenceOfConvexState\nDifference of Convex Proximal Point difference_of_convex_proximal_point DifferenceOfConvexProximalState\nDouglasâ€”Rachford DouglasRachford DouglasRachfordState\nExact Penalty Method exact_penalty_method ExactPenaltyMethodState\nFrank-Wolfe algorithm Frank_Wolfe_method FrankWolfeState\nGradient Descent gradient_descent GradientDescentState\nInterior Point Newton interior_point_Newton \nLevenberg-Marquardt LevenbergMarquardt LevenbergMarquardtState\nNelder-Mead NelderMead NelderMeadState\nParticle Swarm particle_swarm ParticleSwarmState\nPrimal-dual Riemannian semismooth Newton Algorithm primal_dual_semismooth_Newton PrimalDualSemismoothNewtonState\nProximal Bundle Method proximal_bundle_method ProximalBundleMethodState\nProximal Point proximal_point ProximalPointState\nQuasi-Newton Method quasi_Newton QuasiNewtonState\nSteihaug-Toint Truncated Conjugate-Gradient Method truncated_conjugate_gradient_descent TruncatedConjugateGradientState\nSubgradient Method subgradient_method SubGradientMethodState\nStochastic Gradient Descent stochastic_gradient_descent StochasticGradientDescentState\nRiemannian Trust-Regions trust_regions TrustRegionsState","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Note that the solvers (their AbstractManoptSolverState, to be precise) can also be decorated to enhance your algorithm by general additional properties, see debug output and recording values. This is done using the debug= and record= keywords in the function calls. Similarly, a cache= keyword is available in any of the function calls, that wraps the AbstractManoptProblem in a cache for certain parts of the objective.","category":"page"},{"location":"solvers/#Technical-details","page":"List of Solvers","title":"Technical details","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"The main function a solver calls is","category":"page"},{"location":"solvers/#Manopt.solve!-Tuple{AbstractManoptProblem, AbstractManoptSolverState}","page":"List of Solvers","title":"Manopt.solve!","text":"solve!(p::AbstractManoptProblem, s::AbstractManoptSolverState)\n\nrun the solver implemented for the AbstractManoptProblemp and the AbstractManoptSolverStates employing initialize_solver!, step_solver!, as well as the stop_solver! of the solver.\n\n\n\n\n\n","category":"method"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"which is a framework that you in general should not change or redefine. It uses the following methods, which also need to be implemented on your own algorithm, if you want to provide one.","category":"page"},{"location":"solvers/#Manopt.initialize_solver!","page":"List of Solvers","title":"Manopt.initialize_solver!","text":"initialize_solver!(ams::AbstractManoptProblem, amp::AbstractManoptSolverState)\n\nInitialize the solver to the optimization AbstractManoptProblem amp by initializing the necessary values in the AbstractManoptSolverState amp.\n\n\n\n\n\ninitialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState)\n\nExtend the initialization of the solver by a hook to run the DebugAction that was added to the :Start entry of the debug lists. All others are triggered (with iteration number 0) to trigger possible resets\n\n\n\n\n\ninitialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState)\n\nExtend the initialization of the solver by a hook to run records that were added to the :Start entry.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.step_solver!","page":"List of Solvers","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, k)\n\nDo one iteration step (the ith) for an AbstractManoptProblemp by modifying the values in the AbstractManoptSolverState ams.\n\n\n\n\n\nstep_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, k)\n\nExtend the ith step of the solver by a hook to run debug prints, that were added to the :BeforeIteration and :Iteration entries of the debug lists.\n\n\n\n\n\nstep_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, k)\n\nExtend the ith step of the solver by a hook to run records, that were added to the :Iteration entry.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.get_solver_result","page":"List of Solvers","title":"Manopt.get_solver_result","text":"get_solver_result(ams::AbstractManoptSolverState)\nget_solver_result(tos::Tuple{AbstractManifoldObjective,AbstractManoptSolverState})\nget_solver_result(o::AbstractManifoldObjective, s::AbstractManoptSolverState)\n\nReturn the final result after all iterations that is stored within the AbstractManoptSolverState ams, which was modified during the iterations.\n\nFor the case the objective is passed as well, but default, the objective is ignored, and the solver result for the state is called.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.get_solver_return","page":"List of Solvers","title":"Manopt.get_solver_return","text":"get_solver_return(s::AbstractManoptSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::AbstractManoptSolverState)\n\ndetermine the result value of a call to a solver. By default this returns the same as get_solver_result.\n\nget_solver_return(s::ReturnSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::ReturnSolverState)\n\nreturn the internally stored state of the ReturnSolverState instead of the minimizer. This means that when the state are decorated like this, the user still has to call get_solver_result on the internal state separately.\n\nget_solver_return(o::ReturnManifoldObjective, s::AbstractManoptSolverState)\n\nreturn both the objective and the state as a tuple.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Any}","page":"List of Solvers","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, k)\n\ndepending on the current AbstractManoptProblem amp, the current state of the solver stored in AbstractManoptSolverState ams and the current iterate i this function determines whether to stop the solver, which by default means to call the internal StoppingCriterion. ams.stop\n\n\n\n\n\n","category":"method"},{"location":"solvers/#API-for-solvers","page":"List of Solvers","title":"API for solvers","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"this is a short overview of the different types of high-level functions are usually available for a solver. Assume the solver is called new_solver and requires a cost f and some first order information df as well as a starting point p on M. f and df form the objective together called obj.","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Then there are basically two different variants to call","category":"page"},{"location":"solvers/#The-easy-to-access-call","page":"List of Solvers","title":"The easy to access call","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"new_solver(M, f, df, p=rand(M); kwargs...)\nnew_solver!(M, f, df, p; kwargs...)","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Where the start point should be optional. Keyword arguments include the type of evaluation, decorators like debug= or record= as well as algorithm specific ones. If you provide an immutable point p or the rand(M) point is immutable, like on the Circle() this method should turn the point into a mutable one as well.","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"The third variant works in place of p, so it is mandatory.","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"This first interface would set up the objective and pass all keywords on the objective based call.","category":"page"},{"location":"solvers/#Objective-based-calls-to-solvers","page":"List of Solvers","title":"Objective based calls to solvers","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"new_solver(M, obj, p=rand(M); kwargs...)\nnew_solver!(M, obj, p; kwargs...)","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"Here the objective would be created beforehand for example to compare different solvers on the same objective, and for the first variant the start point is optional. Keyword arguments include decorators like debug= or record= as well as algorithm specific ones.","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"This variant would generate the problem and the state and verify validity of all provided keyword arguments that affect the state. Then it would call the iterate process.","category":"page"},{"location":"solvers/#Manual-calls","page":"List of Solvers","title":"Manual calls","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"If you generate the corresponding problem and state as the previous step does, you can also use the third (lowest level) and just call","category":"page"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"solve!(problem, state)","category":"page"},{"location":"solvers/#Closed-form-sub-solvers","page":"List of Solvers","title":"Closed-form sub solvers","text":"","category":"section"},{"location":"solvers/","page":"List of Solvers","title":"List of Solvers","text":"If a subsolver solution is available in closed form, ClosedFormSubSolverState is used to indicate that.","category":"page"},{"location":"solvers/#Manopt.ClosedFormSubSolverState","page":"List of Solvers","title":"Manopt.ClosedFormSubSolverState","text":"ClosedFormSubSolverState{E<:AbstractEvaluationType} <: AbstractManoptSolverState\n\nSubsolver state indicating that a closed-form solution is available with AbstractEvaluationType E.\n\nConstructor\n\nClosedFormSubSolverState(; evaluation=AllocatingEvaluation())\n\n\n\n\n\n","category":"type"},{"location":"extensions/#Extensions","page":"Extensions","title":"Extensions","text":"","category":"section"},{"location":"extensions/#LineSearches.jl","page":"Extensions","title":"LineSearches.jl","text":"","category":"section"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"Manopt can be used with line search algorithms implemented in LineSearches.jl. This can be illustrated by the following example of optimizing Rosenbrock function constrained to the unit sphere.","category":"page"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"using Manopt, Manifolds, LineSearches\n\n# define objective function and its gradient\np = [1.0, 100.0]\nfunction rosenbrock(::AbstractManifold, x)\n    val = zero(eltype(x))\n    for i in 1:(length(x) - 1)\n        val += (p[1] - x[i])^2 + p[2] * (x[i + 1] - x[i]^2)^2\n    end\n    return val\nend\nfunction rosenbrock_grad!(M::AbstractManifold, storage, x)\n    storage .= 0.0\n    for i in 1:(length(x) - 1)\n        storage[i] += -2.0 * (p[1] - x[i]) - 4.0 * p[2] * (x[i + 1] - x[i]^2) * x[i]\n        storage[i + 1] += 2.0 * p[2] * (x[i + 1] - x[i]^2)\n    end\n    project!(M, storage, x, storage)\n    return storage\nend\n# define constraint\nn_dims = 5\nM = Manifolds.Sphere(n_dims)\n# set initial point\nx0 = vcat(zeros(n_dims - 1), 1.0)\n# use LineSearches.jl HagerZhang method with Manopt.jl quasiNewton solver\nls_hz = Manopt.LineSearchesStepsize(M, LineSearches.HagerZhang())\nx_opt = quasi_Newton(\n    M,\n    rosenbrock,\n    rosenbrock_grad!,\n    x0;\n    stepsize=ls_hz,\n    evaluation=InplaceEvaluation(),\n    stopping_criterion=StopAfterIteration(1000) | StopWhenGradientNormLess(1e-6),\n    return_state=true,\n)","category":"page"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"In general this defines the following new stepsize","category":"page"},{"location":"extensions/#Manopt.LineSearchesStepsize","page":"Extensions","title":"Manopt.LineSearchesStepsize","text":"LineSearchesStepsize <: Stepsize\n\nWrapper for line searches available in the LineSearches.jl library.\n\nConstructors\n\nLineSearchesStepsize(M::AbstractManifold, linesearch; kwargs...\nLineSearchesStepsize(\n    linesearch;\n    retraction_method=ExponentialRetraction(),\n    vector_transport_method=ParallelTransport(),\n)\n\nWrap linesearch (for example HagerZhang or MoreThuente). The initial step selection from Linesearches.jl is not yet supported and the value 1.0 is used.\n\nKeyword Arguments\n\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"extensions/#Manifolds.jl","page":"Extensions","title":"Manifolds.jl","text":"","category":"section"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"Loading Manifolds.jl introduces the following additional functions","category":"page"},{"location":"extensions/#Manopt.max_stepsize-Tuple{FixedRankMatrices, Any}","page":"Extensions","title":"Manopt.max_stepsize","text":"max_stepsize(M::FixedRankMatrices, p)\n\nReturn a reasonable guess of maximum step size on FixedRankMatrices following the choice of typical distance in Matlab Manopt, the dimension of M. See this note\n\n\n\n\n\n","category":"method"},{"location":"extensions/#Manopt.max_stepsize-Tuple{Hyperrectangle, Any}","page":"Extensions","title":"Manopt.max_stepsize","text":"max_stepsize(M::Hyperrectangle, p)\n\nThe default maximum stepsize for Hyperrectangle manifold with corners is maximum of distances from p to each boundary.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#Manopt.max_stepsize-Tuple{FiberBundle{ð”½, ManifoldsBase.TangentSpaceType, M} where {ð”½, M<:AbstractManifold{ð”½}}, Any}","page":"Extensions","title":"Manopt.max_stepsize","text":"max_stepsize(M::TangentBundle, p)\n\nTangent bundle has injectivity radius of either infinity (for flat manifolds) or 0 (for non-flat manifolds). This makes a guess of what a reasonable maximum stepsize on a tangent bundle might be.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManifoldsBase.mid_point","page":"Extensions","title":"ManifoldsBase.mid_point","text":"mid_point(M, p, q, x)\nmid_point!(M, y, p, q, x)\n\nCompute the mid point between p and q. If there is more than one mid point of (not necessarily minimizing) geodesics (for example on the sphere), the one nearest to x is returned (in place of y).\n\n\n\n\n\n","category":"function"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"Internally, Manopt.jl provides the two additional functions to choose some Euclidean space when needed as","category":"page"},{"location":"extensions/#Manopt.Rn","page":"Extensions","title":"Manopt.Rn","text":"Rn(args; kwargs...)\nRn(s::Symbol=:Manifolds, args; kwargs...)\n\nA small internal helper function to choose a Euclidean space. By default, this uses the DefaultManifold unless you load a more advanced Euclidean space like Euclidean from Manifolds.jl\n\n\n\n\n\n","category":"function"},{"location":"extensions/#Manopt.Rn_default","page":"Extensions","title":"Manopt.Rn_default","text":"Rn_default()\n\nSpecify a default value to dispatch Rn on. This default is set to Manifolds, indicating, that when this package is loded, it is the preferred package to ask for a vector space space.\n\nThe default within Manopt.jl is to use the DefaultManifold from ManifoldsBase.jl. If you load Manifolds.jl this switches to using Euclidan.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#JuMP.jl","page":"Extensions","title":"JuMP.jl","text":"","category":"section"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"Manopt can be used using the JuMP.jl interface. The manifold is provided in the @variable macro. Note that until now, only variables (points on manifolds) are supported, that are arrays, especially structs do not yet work. The algebraic expression of the objective function is specified in the @objective macro. The descent_state_type attribute specifies the solver.","category":"page"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"using JuMP, Manopt, Manifolds\nmodel = Model(Manopt.Optimizer)\n# Change the solver with this option, `GradientDescentState` is the default\nset_attribute(\"descent_state_type\", GradientDescentState)\n@variable(model, U[1:2, 1:2] in Stiefel(2, 2), start = 1.0)\n@objective(model, Min, sum((A - U) .^ 2))\noptimize!(model)\nsolution_summary(model)","category":"page"},{"location":"extensions/#Interface-functions","page":"Extensions","title":"Interface functions","text":"","category":"section"},{"location":"extensions/#Manopt.JuMP_ArrayShape","page":"Extensions","title":"Manopt.JuMP_ArrayShape","text":"struct ArrayShape{N} <: JuMP.AbstractShape\n\nShape of an Array{T,N} of size size.\n\n\n\n\n\n","category":"type"},{"location":"extensions/#Manopt.JuMP_VectorizedManifold","page":"Extensions","title":"Manopt.JuMP_VectorizedManifold","text":"struct VectorizedManifold{M} <: MOI.AbstractVectorSet\n    manifold::M\nend\n\nRepresentation of points of manifold as a vector of R^n where n is MOI.dimension(VectorizedManifold(manifold)).\n\n\n\n\n\n","category":"type"},{"location":"extensions/#MathOptInterface.dimension-Tuple{ManoptJuMPExt.VectorizedManifold}","page":"Extensions","title":"MathOptInterface.dimension","text":"MOI.dimension(set::VectorizedManifold)\n\nReturn the representation side of points on the (vectorized in representation) manifold. As the MOI variables are real, this means if the representation_size yields (in product) n, this refers to the vectorized point / tangent vector  from (a subset of â„^n).\n\n\n\n\n\n","category":"method"},{"location":"extensions/#Manopt.JuMP_Optimizer","page":"Extensions","title":"Manopt.JuMP_Optimizer","text":"Manopt.JuMP_Optimizer()\n\nCreates a new optimizer object for the MathOptInterface (MOI). An alias Manopt.JuMP_Optimizer is defined for convenience.\n\nThe minimization of a function f(X) of an array X[1:n1,1:n2,...] over a manifold M starting at X0, can be modeled as follows:\n\nusing JuMP\nmodel = Model(Manopt.JuMP_Optimizer)\n@variable(model, X[i1=1:n1,i2=1:n2,...] in M, start = X0[i1,i2,...])\n@objective(model, Min, f(X))\n\nThe optimizer assumes that M has a Array shape described by ManifoldsBase.representation_size.\n\n\n\n\n\n","category":"type"},{"location":"extensions/#MathOptInterface.empty!-Tuple{ManoptJuMPExt.Optimizer}","page":"Extensions","title":"MathOptInterface.empty!","text":"MOI.empty!(model::ManoptJuMPExt.Optimizer)\n\nClear all model data from model but keep the options set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawOptimizerAttribute}","page":"Extensions","title":"MathOptInterface.supports","text":"MOI.supports(::Optimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn a Bool indicating whether attr.name is a valid option name for Manopt.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawOptimizerAttribute}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn last value set by MOI.set(model, attr, value).\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawOptimizerAttribute, Any}","page":"Extensions","title":"MathOptInterface.set","text":"MOI.get(model::Optimizer, attr::MOI.RawOptimizerAttribute)\n\nSet the value for the keyword argument attr.name to give for the constructor model.options[DESCENT_STATE_TYPE].\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports_incremental_interface-Tuple{ManoptJuMPExt.Optimizer}","page":"Extensions","title":"MathOptInterface.supports_incremental_interface","text":"MOI.supports_incremental_interface(::JuMP_Optimizer)\n\nReturn true indicating that Manopt.JuMP_Optimizer implements MOI.add_constrained_variables and MOI.set for MOI.ObjectiveFunction so it can be used with JuMP.direct_model and does not require a MOI.Utilities.CachingOptimizer. See MOI.supports_incremental_interface.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.copy_to-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ModelLike}","page":"Extensions","title":"MathOptInterface.copy_to","text":"MOI.copy_to(dest::Optimizer, src::MOI.ModelLike)\n\nBecause supports_incremental_interface(dest) is true, this simply uses MOI.Utilities.default_copy_to and copies the variables with MOI.add_constrained_variables and the objective sense with MOI.set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports_add_constrained_variables-Tuple{ManoptJuMPExt.Optimizer, Type{<:ManoptJuMPExt.VectorizedManifold}}","page":"Extensions","title":"MathOptInterface.supports_add_constrained_variables","text":"MOI.supports_add_constrained_variables(::JuMP_Optimizer, ::Type{<:VectorizedManifold})\n\nReturn true indicating that Manopt.JuMP_Optimizer support optimization on variables constrained to belong in a vectorized manifold Manopt.JuMP_VectorizedManifold.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.add_constrained_variables-Tuple{ManoptJuMPExt.Optimizer, ManoptJuMPExt.VectorizedManifold}","page":"Extensions","title":"MathOptInterface.add_constrained_variables","text":"MOI.add_constrained_variables(model::Optimizer, set::VectorizedManifold)\n\nAdd MOI.dimension(set) variables constrained in set and return the list of variable indices that can be used to reference them as well a constraint index for the constraint enforcing the membership of the variables in the Manopt.JuMP_VectorizedManifold set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.is_valid-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariableIndex}","page":"Extensions","title":"MathOptInterface.is_valid","text":"MOI.is_valid(model::Optimizer, vi::MOI.VariableIndex)\n\nReturn whether vi is a valid variable index.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.NumberOfVariables}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, ::MOI.NumberOfVariables)\n\nReturn the number of variables added in the model, this corresponds to the MOI.dimension of the Manopt.JuMP_VectorizedManifold.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariablePrimalStart, Type{MathOptInterface.VariableIndex}}","page":"Extensions","title":"MathOptInterface.supports","text":"MOI.supports(::Manopt.JuMP_Optimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn true indicating that Manopt.JuMP_Optimizer supports starting values for the variables.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariablePrimalStart, MathOptInterface.VariableIndex, Union{Nothing, Real}}","page":"Extensions","title":"MathOptInterface.set","text":"function MOI.set(\n    model::Optimizer,\n    ::MOI.VariablePrimalStart,\n    vi::MOI.VariableIndex,\n    value::Union{Real,Nothing},\n)\n\nSet the starting value of the variable of index vi to value. Note that if value is nothing then it essentially unset any previous starting values set and hence MOI.optimize! unless another starting value is set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveSense, MathOptInterface.OptimizationSense}","page":"Extensions","title":"MathOptInterface.set","text":"MOI.set(model::Optimizer, ::MOI.ObjectiveSense, sense::MOI.OptimizationSense)\n\nModify the objective sense to either MOI.MAX_SENSE, MOI.MIN_SENSE or MOI.FEASIBILITY_SENSE.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveFunction, MathOptInterface.AbstractScalarFunction}","page":"Extensions","title":"MathOptInterface.set","text":"MOI.set(model::Optimizer, ::MOI.ObjectiveFunction{F}, func::F) where {F}\n\nSet the objective function as func for model.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.Optimizer, Union{MathOptInterface.ObjectiveSense, MathOptInterface.ObjectiveFunction}}","page":"Extensions","title":"MathOptInterface.supports","text":"MOI.supports(::Optimizer, ::Union{MOI.ObjectiveSense,MOI.ObjectiveFunction})\n\nReturn true indicating that Optimizer supports being set the objective sense (that is, min, max or feasibility) and the objective function.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#JuMP.build_variable-Tuple{Function, Any, AbstractManifold}","page":"Extensions","title":"JuMP.build_variable","text":"JuMP.build_variable(::Function, func, m::ManifoldsBase.AbstractManifold)\n\nBuild a JuMP.VariablesConstrainedOnCreation object containing variables and the Manopt.JuMP_VectorizedManifold in which they should belong as well as the shape that can be used to go from the vectorized MOI representation to the shape of the manifold, that is, Manopt.JuMP_ArrayShape.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ResultCount}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, ::MOI.ResultCount)\n\nReturn 0 if optimize! hasn't been called yet and 1 otherwise indicating that one solution is available.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.SolverName}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(::Optimizer, ::MOI.SolverName)\n\nReturn the name of the Optimizer with the value of the descent_state_type option.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveValue}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, attr::MOI.ObjectiveValue)\n\nReturn the value of the objective function evaluated at the solution.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.PrimalStatus}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, ::MOI.PrimalStatus)\n\nReturn MOI.NO_SOLUTION if optimize! hasn't been called yet and MOI.FEASIBLE_POINT otherwise indicating that a solution is available to query with MOI.VariablePrimalStart.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.DualStatus}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(::Optimizer, ::MOI.DualStatus)\n\nReturns MOI.NO_SOLUTION indicating that there is no dual solution available.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.TerminationStatus}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, ::MOI.ResultCount)\n\nReturn MOI.OPTIMIZE_NOT_CALLED if optimize! hasn't been called yet and MOI.LOCALLY_SOLVED otherwise indicating that the solver has solved the problem to local optimality the value of MOI.RawStatusString for more details on why the solver stopped.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.SolverVersion}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(::Optimizer, ::MOI.SolverVersion)\n\nReturn the version of the Manopt solver, it corresponds to the version of Manopt.jl.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.ObjectiveSense}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, ::MOI.ObjectiveSense)\n\nReturn the objective sense, defaults to MOI.FEASIBILITY_SENSE if no sense has already been set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.VariablePrimal, MathOptInterface.VariableIndex}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, attr::MOI.VariablePrimal, vi::MOI.VariableIndex)\n\nReturn the value of the solution for the variable of index vi.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.Optimizer, MathOptInterface.RawStatusString}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::Optimizer, ::MOI.RawStatusString)\n\nReturn a String containing Manopt.get_reason without the ending newline character.\n\n\n\n\n\n","category":"method"},{"location":"tutorials/ImplementOwnManifold/#Optimize-on-your-own-manifold","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"When you have used a few solvers from Manopt.jl for example like in the opening tutorial ðŸ”ï¸ Get started with Manopt.jl and also familiarized yourself with how to work with manifolds in general at ðŸš€ Get Started with Manifolds.jl, you might come across the point that you want to implementing a manifold yourself and use it within Manopt.jl. A challenge might be, which functions are necessary, since the overall interface of ManifoldsBase.jl is maybe not completely necessary.","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"This tutorial aims to help you through these steps to implement necessary parts of a manifold to get started with the solver you have in mind.","category":"page"},{"location":"tutorials/ImplementOwnManifold/#An-example-problem","page":"Optimize on your own manifold","title":"An example problem","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We get started by loading the packages we need.","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"using LinearAlgebra, Manifolds, ManifoldsBase, Random\nusing Manopt\nRandom.seed!(42)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We also define the same manifold as in the implementing a manifold tutorial.","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"\"\"\"\n    ScaledSphere <: AbstractManifold{â„}\n\nDefine a sphere of fixed radius\n\n# Fields\n\n* `dimension` dimension of the sphere\n* `radius` the radius of the sphere\n\n# Constructor\n\n    ScaledSphere(dimension,radius)\n\nInitialize the manifold to a certain `dimension` and `radius`,\nwhich by default is set to `1.0`\n\"\"\"\nstruct ScaledSphere <: AbstractManifold{â„}\n    dimension::Int\n    radius::Float64\nend","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We would like to compute a mean and/or median similar to ðŸ”ï¸ Get started with Manopt.jl!. For given a set of points q_1ldotsq_n we want to compute [Kar77]","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"  operatorname*argmin_pmathcal M\n  frac12n sum_i=1^n d_mathcal M^2(p q_i)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"On the ScaledSphere we just defined. We define a few parameters first","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"d = 5  # dimension of the sphere - embedded in R^{d+1}\nr = 2.0 # radius of the sphere\nN = 100 # data set size\n\nM = ScaledSphere(d,r)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"ScaledSphere(5, 2.0)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"If we generate a few points","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"# generate 100 points around the north pole\npts = [ [zeros(d)..., M.radius] .+ 0.5.*([rand(d)...,0.5] .- 0.5) for _=1:N]\n# project them onto the r-sphere\npts = [ r/norm(p) .* p for p in pts]","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"Then, before starting with optimization, we need the distance on the manifold, to define the cost function, as well as the logarithmic map to defined the gradient. For both, we here use the â€œlazyâ€ approach of using the Sphere as a fallback. Finally, we have to provide information about how points and tangent vectors are stored on the manifold by implementing their representation_size function, which is often required when allocating memory. While we could","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"import ManifoldsBase: distance, log, representation_size\nfunction distance(M::ScaledSphere, p, q)\n    return M.radius * distance(Sphere(M.dimension), p ./ M.radius, q ./ M.radius)\nend\nfunction log(M::ScaledSphere, p, q)\n    return M.radius * log(Sphere(M.dimension), p ./ M.radius, q ./ M.radius)\nend\nrepresentation_size(M::ScaledSphere) = (M.dimension+1,)","category":"page"},{"location":"tutorials/ImplementOwnManifold/#Define-the-cost-and-gradient","page":"Optimize on your own manifold","title":"Define the cost and gradient","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"f(M, q) = sum(distance(M, q, p)^2 for p in pts)\ngrad_f(M,q) = sum( - log(M, q, p) for p in pts)","category":"page"},{"location":"tutorials/ImplementOwnManifold/#Defining-the-necessary-functions-to-run-a-solver","page":"Optimize on your own manifold","title":"Defining the necessary functions to run a solver","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"The documentation usually lists the necessary functions in a section â€œTechnical Detailsâ€ close to the end of the documentation of a solver, for our case that is The gradient descentâ€™s Technical Details,","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"They list all details, but we can start even step by step here if we are a bit careful.","category":"page"},{"location":"tutorials/ImplementOwnManifold/#A-retraction","page":"Optimize on your own manifold","title":"A retraction","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We first implement a retraction. Informally,Â given a current point and a direction to â€œwalk intoâ€ we need a function that performs that walk. Since we take an easy one that just projects onto the sphere, we use the ProjectionRetraction type. To be precise, we have to implement the in-place variant retract_project!","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"import ManifoldsBase: retract_project!\nfunction retract_project!(M::ScaledSphere, q, p, X)\n    q .= p .+ X\n    q .*= M.radius / norm(q)\n    return q\nend","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"retract_project! (generic function with 18 methods)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"The other two technical remarks refer to the step size and the stopping criterion, so if we set these to something simpler, we should already be able to do a first run.","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We have to specify","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"that we want to use the new retraction,\na simple step size and stopping criterion","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We start with a certain point of cost","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"p0 = [zeros(d)...,1.0]\nf(M,p0)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"444.60374551157634","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"Then we can run our first solver,Â where we have to overwrite a few defaults, which would use functions we do not (yet) have. Letâ€™s discuss these in the next steps.","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"q1 = gradient_descent(M, f, grad_f, p0;\n    retraction_method = ProjectionRetraction(),   # state, that we use the retraction from above\n    stepsize = DecreasingLength(M; length=1.0), # A simple step size\n    stopping_criterion = StopAfterIteration(10),  # A simple stopping criterion\n    X = zeros(d+1),                               # how we define/represent tangent vectors\n)\nf(M,q1)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"162.4000287847332","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We at least see, that the function value decreased.","category":"page"},{"location":"tutorials/ImplementOwnManifold/#Norm-and-maximal-step-size","page":"Optimize on your own manifold","title":"Norm and maximal step size","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"To use more advanced stopping criteria and step sizes we first need an inner(M, p, X). We also need a max_stepsize(M), to avoid having too large steps on positively curved manifolds like our scaled sphere in this example","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"import ManifoldsBase: inner\nimport Manopt: max_stepsize\ninner(M::ScaledSphere, p, X,Y) = dot(X,Y) # inherited from the embedding\n # set the maximal allowed stepsize to injectivity radius.\nManopt.max_stepsize(M::ScaledSphere) = M.radius*Ï€","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"Then we can use the default step size (ArmijoLinesearch) and the default stopping criterion, which checks for a small gradient Norm","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"q2 = gradient_descent(M, f, grad_f, p0;\n    retraction_method = ProjectionRetraction(), # as before\n    X = zeros(d+1), # as before\n)\nf(M, q2)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"9.772830131357034","category":"page"},{"location":"tutorials/ImplementOwnManifold/#Making-life-easier:-default-retraction-and-zero-vector","page":"Optimize on your own manifold","title":"Making life easier: default retraction and zero vector","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"To initialize tangent vector memory, the function zero_vector(M,p) is called. Similarly, the most-used retraction is returned by default_retraction_method","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"We can use both here, to make subsequent calls to the solver less verbose. We define","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"import ManifoldsBase: zero_vector, default_retraction_method\nzero_vector(M::ScaledSphere, p) = zeros(M.dimension+1)\ndefault_retraction_method(M::ScaledSphere) = ProjectionRetraction()","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"default_retraction_method (generic function with 19 methods)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"and now we can even just call","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"q3 = gradient_descent(M, f, grad_f, p0)\nf(M, q3)","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"9.772830131357034","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"But we for example automatically also get the possibility to obtain debug information like","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"gradient_descent(M, f, grad_f, p0; debug = [:Iteration, :Cost, :Stepsize, 25, :GradientNorm, :Stop, \"\\n\"]);","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"Initial f(x): 444.603746\n# 25    f(x): 9.772833s:0.018299583806109226|grad f(p)|:0.020516914880881486\n# 50    f(x): 9.772830s:0.018299583806109226|grad f(p)|:0.00013449321419330018\nThe algorithm reached approximately critical point after 72 iterations; the gradient norm (9.20733514568335e-9) is less than 1.0e-8.","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"see How to Print Debug Output for more details.","category":"page"},{"location":"tutorials/ImplementOwnManifold/#Technical-details","page":"Optimize on your own manifold","title":"Technical details","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `..`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"2025-04-25T12:13:58.073","category":"page"},{"location":"tutorials/ImplementOwnManifold/#Literature","page":"Optimize on your own manifold","title":"Literature","text":"","category":"section"},{"location":"tutorials/ImplementOwnManifold/","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"H.Â Karcher. Riemannian center of mass and mollifier smoothing. CommunicationsÂ onÂ PureÂ andÂ AppliedÂ Mathematics 30, 509â€“541 (1977).\n\n\n\n","category":"page"},{"location":"tutorials/getstarted/#Get-started-with-Manopt.jl","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"","category":"section"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"This tutorial both introduces the basics of optimisation on manifolds as well as how to use Manopt.jl to perform optimisation on manifolds in Julia.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"For more theoretical background, see for example [Car92] for an introduction to Riemannian manifolds and [AMS08] or [Bou23] to read more about optimisation thereon.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Let mathcal M denote a (Riemannian manifold and let f  mathcal M  â„ be a cost function. The aim is to determine or obtain a point p^* where f is minimal or in other words p^* is a minimizer of f.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"This can also be written as","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"    operatorname*argmin_p  mathcal M f(p)","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"where the aim is to compute the minimizer p^* numerically. As an example, consider the generalisation of the (arithmetic) mean. In the Euclidean case with dmathbb N, that is for nmathbb N data points y_1ldotsy_n  â„^d the mean","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"  frac1nsum_i=1^n y_i","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"can not be directly generalised to data q_1ldotsq_n  mathcal M, since on a manifold there is no addition available. But the mean can also be characterised as the following minimizer","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"  operatorname*argmin_xâ„^d frac12nsum_i=1^n lVert x - y_irVert^2","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"and using the Riemannian distance d_mathcal M, this can be written on Riemannian manifolds, which is the so called Riemannian Center of Mass [Kar77]","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"  operatorname*argmin_pmathcal M\n  frac12n sum_i=1^n d_mathcal M^2(p q_i)","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Fortunately the gradient can be computed and is","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":" frac1n sum_i=1^n -log_p q_i","category":"page"},{"location":"tutorials/getstarted/#Loading-the-necessary-packages","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Loading the necessary packages","text":"","category":"section"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Letâ€™s assume you have already installed both Manopt.jl and Manifolds.jl in Julia (using for example using Pkg; Pkg.add([\"Manopt\", \"Manifolds\"])). Then we can get started by loading both packages as well as Random.jl for persistency in this tutorial.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"using Manopt, Manifolds, Random, LinearAlgebra, ManifoldDiff\nusing ManifoldDiff: grad_distance, prox_distance\nRandom.seed!(42);","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Now assume we are on the Sphere mathcal M = mathbb S^2 and we generate some random points â€œaroundâ€ some initial point p","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"n = 100\nÏƒ = Ï€ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Now we can define the cost function f and its (Riemannian) gradient operatornamegrad f for the Riemannian center of mass:","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)));","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"and just call gradient_descent. For a first start, we do not have to provide more than the manifold, the cost, the gradient, and a starting point, which we just set to the first data point","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"m1 = gradient_descent(M, f, grad_f, data[1])","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"3-element Vector{Float64}:\n 0.6868392807355564\n 0.006531599748261925\n 0.7267799809043942","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"In order to get more details, we further add the debug= keyword argument, which act as a decorator pattern.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"This way we can easily specify a certain debug to be printed. The goal is to get an output of the form","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"# i | Last Change: [...] | F(x): [...] |","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"but where we also want to fix the display format for the change and the cost numbers (the [...]) to have a certain format. Furthermore, the reason why the solver stopped should be printed at the end","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"These can easily be specified using either a Symbol when using the default format for numbers, or a tuple of a symbol and a format-string in the debug= keyword that is available for every solver. We can also,Â for illustration reasons,Â just look at the first 6 steps by setting a stopping_criterion=","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"m2 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Î”p|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop],\n    stopping_criterion = StopAfterIteration(6)\n  )","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Initial  F(x): 0.32487988924 | \n# 1     |Î”p|: 1.063609017 | F(x): 0.25232524046 | \n# 2     |Î”p|: 0.809858671 | F(x): 0.20966960102 | \n# 3     |Î”p|: 0.616665145 | F(x): 0.18546505598 | \n# 4     |Î”p|: 0.470841764 | F(x): 0.17121604104 | \n# 5     |Î”p|: 0.359345690 | F(x): 0.16300825911 | \n# 6     |Î”p|: 0.274597420 | F(x): 0.15818548927 | \nAt iteration 6 the algorithm reached its maximal number of iterations (6).\n\n3-element Vector{Float64}:\n  0.7533872481682505\n -0.06053107055583637\n  0.6547851890466334","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"See here for the list of available symbols.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"info: Technical Detail\nThe debug= keyword is actually a list of DebugActions added to every iteration, allowing you to write your own ones even. Additionally, :Stop is an action added to the end of the solver to display the reason why the solver stopped.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"The default stopping criterion for gradient_descent is, to either stop when the gradient is small (<1e-9) or a max number of iterations is reached (as a fallback). Combining stopping-criteria can be done by | or &. We further pass a number 25 to debug= to only an output every 25th iteration:","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"m3 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Î”p|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 25],\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |Â StopAfterIteration(400),\n)","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Initial  F(x): 0.32487988924 | \n# 25    |Î”p|: 0.459715605 | F(x): 0.15145076374 | \n# 50    |Î”p|: 0.000551270 | F(x): 0.15145051509 | \nThe algorithm reached approximately critical point after 73 iterations; the gradient norm (9.988871119384563e-16) is less than 1.0e-14.\n\n3-element Vector{Float64}:\n 0.6868392794788668\n 0.006531600680779286\n 0.7267799820836411","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"We can finally use another way to determine the stepsize, for example a little more expensive ArmijoLineSeach than the default stepsize rule used on the Sphere.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"m4 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Î”p|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 2],\n      stepsize = ArmijoLinesearch(; contraction_factor=0.999, sufficient_decrease=0.5),\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |Â StopAfterIteration(400),\n)","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Initial  F(x): 0.32487988924 | \n# 2     |Î”p|: 0.001318138 | F(x): 0.15145051509 | \n# 4     |Î”p|: 0.000000004 | F(x): 0.15145051509 | \n# 6     |Î”p|: 0.000000000 | F(x): 0.15145051509 | \nThe algorithm reached approximately critical point after 7 iterations; the gradient norm (5.073696618059386e-15) is less than 1.0e-14.\n\n3-element Vector{Float64}:\n 0.6868392794788669\n 0.006531600680779358\n 0.7267799820836413","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Then we reach approximately the same point as in the previous run, but in far less steps","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"[f(M, m3)-f(M,m4), distance(M, m3, m4)]","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"2-element Vector{Float64}:\n 1.6653345369377348e-16\n 1.727269835930624e-16","category":"page"},{"location":"tutorials/getstarted/#Using-the-tutorial-mode","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Using the tutorial mode","text":"","category":"section"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Since a few things on manifolds are a bit different from (classical) Euclidean optimization, Manopt.jl has a mode to warn about a few pitfalls.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"It can be set using","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Manopt.set_parameter!(:Mode, \"Tutorial\")","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"[ Info: Setting the `Manopt.jl` parameter :Mode to Tutorial.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"to activate these. Continuing from the example before, one might argue, that the minimizer of f does not depend on the scaling of the function. In theory this is of course also the case on manifolds, but for the optimizations there is a caveat. When we define the Riemannian mean without the scaling","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"f2(M, p) = sum(1 / 2 * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f2(M, p) = sum(grad_distance.(Ref(M), data, Ref(p)));","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"And we consider the gradient at the starting point in norm","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"norm(M, data[1], grad_f2(M, data[1]))","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"57.47318616893399","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"On the sphere, when we follow a geodesic, we â€œreturnâ€ to the start point after length 2Ï€. If we â€œlandâ€ short before the starting point due to a gradient of length just shy of 2Ï€, the line search would take the gradient direction (and not the negative gradient direction) as a start. The line search is still performed, but in this case returns a much too small, maybe even nearly zero step size.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"In other words, we have to be careful that the optimisation stays a â€œlocalâ€ argument we use.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"This is also warned for in \"Tutorial\" mode. Calling","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"mX = gradient_descent(M, f2, grad_f2, data[1])","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"â”Œ Warning: At iteration #0\nâ”‚ the gradient norm (57.47318616893399) is larger that 1.0 times the injectivity radius 3.141592653589793 at the current iterate.\nâ”” @ Manopt ~/work/Manopt.jl/Manopt.jl/src/plans/debug.jl:1120\nâ”Œ Warning: Further warnings will be suppressed, use DebugWarnIfGradientNormTooLarge(1.0, :Always) to get all warnings.\nâ”” @ Manopt ~/work/Manopt.jl/Manopt.jl/src/plans/debug.jl:1124\n\n3-element Vector{Float64}:\n 0.6868392794870684\n 0.006531600674920825\n 0.7267799820759485","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"So just by chance it seems we still got nearly the same point as before, but when we for example look when this one stops, that is takes more steps.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"gradient_descent(M, f2, grad_f2, data[1], debug=[:Stop]);","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"The algorithm reached approximately critical point after 140 iterations; the gradient norm (6.807380063106406e-9) is less than 1.0e-8.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"This also illustrates one way to deactivate the hints, namely by overwriting the debug= keyword, that in Tutorial mode contains additional warnings. The other option is to globally reset the :Mode back to","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Manopt.set_parameter!(:Mode, \"\")","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"[ Info: Resetting the `Manopt.jl` parameter :Mode to default.","category":"page"},{"location":"tutorials/getstarted/#Example-2:-computing-the-median-of-symmetric-positive-definite-matrices","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Example 2: computing the median of symmetric positive definite matrices","text":"","category":"section"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"For the second example letâ€™s consider the manifold of 3  3 symmetric positive definite matrices and again 100 random points","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"N = SymmetricPositiveDefinite(3)\nm = 100\nÏƒ = 0.005\nq = Matrix{Float64}(I, 3, 3)\ndata2 = [exp(N, q, Ïƒ * rand(N; vector_at=q)) for i in 1:m];","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Instead of the mean, letâ€™s consider a non-smooth optimisation task: the median can be generalized to Manifolds as the minimiser of the sum of distances, see [Bac14]. We define","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"g(N, q) = sum(1 / (2 * m) * distance.(Ref(N), Ref(q), data2))","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"g (generic function with 1 method)","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Since the function is non-smooth, we can not use a gradient-based approach. But since for every summand the proximal map is available, we can use the cyclic proximal point algorithm (CPPA). We hence define the vector of proximal maps as","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"proxes_g = Function[(N, Î», q) -> prox_distance(N, Î» / m, di, q, 1) for di in data2];","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Besides also looking at a some debug prints, we can also easily record these values. Similarly to debug=, record= also accepts Symbols, see list here, to indicate things to record. We further set return_state to true to obtain not just the (approximate) minimizer.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"res = cyclic_proximal_point(N, g, proxes_g, data2[1];\n  debug=[:Iteration,\" | \",:Change,\" | \",(:Cost, \"F(x): %1.12f\"),\"\\n\", 1000, :Stop,\n        ],\n        record=[:Iteration, :Change, :Cost, :Iterate],\n        return_state=true,\n    );","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Initial  |  | F(x): 0.005875512856\n# 1000   | Last Change: 0.003704 | F(x): 0.003239019699\n# 2000   | Last Change: 0.000015 | F(x): 0.003238996105\n# 3000   | Last Change: 0.000005 | F(x): 0.003238991748\n# 4000   | Last Change: 0.000002 | F(x): 0.003238990225\n# 5000   | Last Change: 0.000001 | F(x): 0.003238989520\nAt iteration 5000 the algorithm reached its maximal number of iterations (5000).","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"note: Technical Detail\nThe recording is realised by RecordActions that are (also) executed at every iteration. These can also be individually implemented and added to the record= array instead of symbols.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"First, the computed median can be accessed as","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"median = get_solver_result(res)","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"3Ã—3 Matrix{Float64}:\n 1.0          2.12236e-5   0.000398721\n 2.12236e-5   1.00044      0.000141798\n 0.000398721  0.000141798  1.00041","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"but we can also look at the recorded values. For simplicity (of output), lets just look at the recorded values at iteration 42","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"get_record(res)[42]","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"(42, 1.0569455860769079e-5, 0.003252547739370045, [0.9998583866917449 0.0002098880312604301 0.0002895445818451581; 0.00020988803126037459 1.0000931572564762 0.0002084371501681892; 0.00028954458184524134 0.0002084371501681892 1.000070920743257])","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"But we can also access whole series and see that the cost does not decrease that fast; actually, the CPPA might converge relatively slow. For that we can for example access the :Cost that was recorded every :Iterate as well as the (maybe a little boring) :Iteration-number in a semi-log-plot.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"x = get_record(res, :Iteration, :Iteration)\ny = get_record(res, :Iteration, :Cost)\nusing Plots\nplot(x,y,xaxis=:log, label=\"CPPA Cost\")","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"(Image: )","category":"page"},{"location":"tutorials/getstarted/#Technical-details","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Technical details","text":"","category":"section"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `..`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"2025-04-25T12:16:15.873","category":"page"},{"location":"tutorials/getstarted/#Literature","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Literature","text":"","category":"section"},{"location":"tutorials/getstarted/","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"P.-A.Â Absil, R.Â Mahony and R.Â Sepulchre. Optimization Algorithms on Matrix Manifolds (Princeton University Press, 2008), available online at press.princeton.edu/chapters/absil/.\n\n\n\nM.Â BaÄÃ¡k. Computing medians and means in Hadamard spaces. SIAMÂ JournalÂ onÂ Optimization 24, 1542â€“1566 (2014), arXiv:1210.2145.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nM.Â P.Â doÂ Carmo. Riemannian Geometry. Mathematics: Theory & Applications (BirkhÃ¤user Boston, Inc., Boston, MA, 1992); p.Â xiv+300.\n\n\n\nH.Â Karcher. Riemannian center of mass and mollifier smoothing. CommunicationsÂ onÂ PureÂ andÂ AppliedÂ Mathematics 30, 509â€“541 (1977).\n\n\n\n","category":"page"},{"location":"solvers/subgradient/#sec-subgradient-method","page":"Subgradient method","title":"Subgradient method","text":"","category":"section"},{"location":"solvers/subgradient/#Manopt.subgradient_method","page":"Subgradient method","title":"Manopt.subgradient_method","text":"subgradient_method(M, f, âˆ‚f, p=rand(M); kwargs...)\nsubgradient_method(M, sgo, p=rand(M); kwargs...)\nsubgradient_method!(M, f, âˆ‚f, p; kwargs...)\nsubgradient_method!(M, sgo, p; kwargs...)\n\nperform a subgradient method p^(k+1) = operatornameretrbigl(p^(k) s^(k)f(p^(k))bigr), where operatornameretr is a retraction, s^(k) is a step size.\n\nThough the subgradient might be set valued, the argument âˆ‚f should always return one element from the subgradient, but not necessarily deterministic. For more details see [FO98].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nâˆ‚f: the (sub)gradient  f mathcal M  Tmathcal M of f\np: a point on the manifold mathcal M\n\nalternatively to f and âˆ‚f a ManifoldSubgradientObjective sgo can be provided.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=default_stepsize(M, SubGradientMethodState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nand the ones that are passed to decorate_state! for decorators.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/subgradient/#Manopt.subgradient_method!","page":"Subgradient method","title":"Manopt.subgradient_method!","text":"subgradient_method(M, f, âˆ‚f, p=rand(M); kwargs...)\nsubgradient_method(M, sgo, p=rand(M); kwargs...)\nsubgradient_method!(M, f, âˆ‚f, p; kwargs...)\nsubgradient_method!(M, sgo, p; kwargs...)\n\nperform a subgradient method p^(k+1) = operatornameretrbigl(p^(k) s^(k)f(p^(k))bigr), where operatornameretr is a retraction, s^(k) is a step size.\n\nThough the subgradient might be set valued, the argument âˆ‚f should always return one element from the subgradient, but not necessarily deterministic. For more details see [FO98].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nâˆ‚f: the (sub)gradient  f mathcal M  Tmathcal M of f\np: a point on the manifold mathcal M\n\nalternatively to f and âˆ‚f a ManifoldSubgradientObjective sgo can be provided.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=default_stepsize(M, SubGradientMethodState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nand the ones that are passed to decorate_state! for decorators.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/subgradient/#State","page":"Subgradient method","title":"State","text":"","category":"section"},{"location":"solvers/subgradient/#Manopt.SubGradientMethodState","page":"Subgradient method","title":"Manopt.SubGradientMethodState","text":"SubGradientMethodState <: AbstractManoptSolverState\n\nstores option values for a subgradient_method solver\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\np_star: optimal value\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nX: the current element from the possible subgradients at p that was last evaluated.\n\nConstructor\n\nSubGradientMethodState(M::AbstractManifold; kwargs...)\n\nInitialise the Subgradient method state\n\nKeyword arguments\n\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstepsize=default_stepsize(M, SubGradientMethodState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/subgradient/","page":"Subgradient method","title":"Subgradient method","text":"For DebugActions and RecordActions to record (sub)gradient, its norm and the step sizes, see the gradient descent actions.","category":"page"},{"location":"solvers/subgradient/#sec-sgm-technical-details","page":"Subgradient method","title":"Technical details","text":"","category":"section"},{"location":"solvers/subgradient/","page":"Subgradient method","title":"Subgradient method","text":"The subgradient_method solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/subgradient/","page":"Subgradient method","title":"Subgradient method","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.","category":"page"},{"location":"solvers/subgradient/#Literature","page":"Subgradient method","title":"Literature","text":"","category":"section"},{"location":"solvers/subgradient/","page":"Subgradient method","title":"Subgradient method","text":"O.Â Ferreira and P.Â R.Â Oliveira. Subgradient algorithm on Riemannian manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 97, 93â€“104 (1998).\n\n\n\n","category":"page"},{"location":"solvers/projected_gradient_method/#Projected-gradient-method","page":"Projected Gradient Method","title":"Projected gradient method","text":"","category":"section"},{"location":"solvers/projected_gradient_method/#Manopt.projected_gradient_method","page":"Projected Gradient Method","title":"Manopt.projected_gradient_method","text":"projected_gradient_method(M, f, grad_f, proj, p=rand(M); kwargs...)\nprojected_gradient_method(M, obj::ManifoldConstrainedSetObjective, p=rand(M); kwargs...)\nprojected_gradient_method!(M, f, grad_f, proj, p; kwargs...)\nprojected_gradient_method!(M, obj::ManifoldConstrainedSetObjective, p; kwargs...)\n\nCompute the projected gradient method for the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquad p  mathcal C  mathcal M\nendaligned\n\nby performing the following steps\n\nUsing the stepsize Î±_k compute a candidate q_k = operatornameproj_mathcal CBigl(operatornameretr_p_kbigl(-Î±_k operatornamegrad f(p_k)bigr)Bigr)\nCompute a backtracking stepsize Î²_k  1 along Y_k = operatornameretr_p_k^-1q_k\nCompute the new iterate p_k+1 = operatornameretr_p_k( Î²_k operatornameretr_p_k^-1q_k )\n\nuntil the stopping_criterion= is fulfilled.\n\nFor more information see [BFNZ25].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nproj the function that projects onto the set mathcal C as a function (M, p) -> q or a function (M, q, p) -> q computing the projection in-place of q.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nbacktrack=ArmijoLinesearchStepsize(M; stop_increasing_at_step=0): a functor inheriting from Stepsize to determine a step size to perform the backtracking to determine the Î²_k. Note that the method requires Î²_k  1, otherwise the projection step no longer provides points within the constraints\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=ConstantStepsize(injectivity_radius(M)/2): a functor inheriting from Stepsize to determine a step size to perform the candidate projected step.\nstopping_criterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6)): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/projected_gradient_method/#Manopt.projected_gradient_method!","page":"Projected Gradient Method","title":"Manopt.projected_gradient_method!","text":"projected_gradient_method(M, f, grad_f, proj, p=rand(M); kwargs...)\nprojected_gradient_method(M, obj::ManifoldConstrainedSetObjective, p=rand(M); kwargs...)\nprojected_gradient_method!(M, f, grad_f, proj, p; kwargs...)\nprojected_gradient_method!(M, obj::ManifoldConstrainedSetObjective, p; kwargs...)\n\nCompute the projected gradient method for the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquad p  mathcal C  mathcal M\nendaligned\n\nby performing the following steps\n\nUsing the stepsize Î±_k compute a candidate q_k = operatornameproj_mathcal CBigl(operatornameretr_p_kbigl(-Î±_k operatornamegrad f(p_k)bigr)Bigr)\nCompute a backtracking stepsize Î²_k  1 along Y_k = operatornameretr_p_k^-1q_k\nCompute the new iterate p_k+1 = operatornameretr_p_k( Î²_k operatornameretr_p_k^-1q_k )\n\nuntil the stopping_criterion= is fulfilled.\n\nFor more information see [BFNZ25].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nproj the function that projects onto the set mathcal C as a function (M, p) -> q or a function (M, q, p) -> q computing the projection in-place of q.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nbacktrack=ArmijoLinesearchStepsize(M; stop_increasing_at_step=0): a functor inheriting from Stepsize to determine a step size to perform the backtracking to determine the Î²_k. Note that the method requires Î²_k  1, otherwise the projection step no longer provides points within the constraints\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=ConstantStepsize(injectivity_radius(M)/2): a functor inheriting from Stepsize to determine a step size to perform the candidate projected step.\nstopping_criterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6)): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/projected_gradient_method/#State","page":"Projected Gradient Method","title":"State","text":"","category":"section"},{"location":"solvers/projected_gradient_method/#Manopt.ProjectedGradientMethodState","page":"Projected Gradient Method","title":"Manopt.ProjectedGradientMethodState","text":"ProjectedGradientMethodState <: AbstractManoptSolverState\n\nFields\n\nbacktracking::Stepsize: a functor inheriting from Stepsize to determine a step size to determine the step size Î²_k step size from p_k to the candidate q_k\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np::P: a point on the manifold mathcal Mstoring the current iterate\nq an interims point for the projected gradient step\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size Î±_k to determine the q_k candidate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nX::T: a tangent vector at the point p on the manifold mathcal M\nY::T a temporary memory for a tangent vector to store the no. Used within the backtracking\n\nConstructor\n\nProjectedGradientMethodState(M, p=rand(M); kwargs...)\n\nKeyword arguments\n\nbacktracking=ArmijoLinesearchStepsize(M): a functor inheriting from Stepsize to determine a step size p_k to the candidate q_k\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstepsize=ConstantStepsize(M): a functor inheriting from Stepsize to determine a step size Î±_k to determine the q_k candidate\nstop=StopAfterIteration(300): a functor indicating that the stopping criterion is fulfilled\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\n\n\n\n\n","category":"type"},{"location":"solvers/projected_gradient_method/#Stopping-criteria","page":"Projected Gradient Method","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/projected_gradient_method/#Manopt.StopWhenProjectedGradientStationary","page":"Projected Gradient Method","title":"Manopt.StopWhenProjectedGradientStationary","text":"StopWhenProjectedGradientStationary <: StoppingCriterion\n\nStop when the step taken by the projection is  (before linesearch) exactly the opposite of the\n\n\n\n\n\n","category":"type"},{"location":"solvers/projected_gradient_method/#Literature","page":"Projected Gradient Method","title":"Literature","text":"","category":"section"},{"location":"solvers/projected_gradient_method/","page":"Projected Gradient Method","title":"Projected Gradient Method","text":"R.Â Bergmann, O.Â P.Â Ferreira, S.Â Z.Â NÃ©meth and J.Â Zhu. On projection mappings and the gradient projection method on hyperbolic space forms. Preprint,Â inÂ preparation (2025).\n\n\n\n","category":"page"},{"location":"solvers/augmented_Lagrangian_method/#Augmented-Lagrangian-method","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian method","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method","page":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method","text":"augmented_Lagrangian_method(M, f, grad_f, p=rand(M); kwargs...)\naugmented_Lagrangian_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\naugmented_Lagrangian_method!(M, f, grad_f, p; kwargs...)\naugmented_Lagrangian_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the augmented Lagrangian method (ALM) [LB19]. This method can work in-place of p.\n\nThe aim of the ALM is to find the solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. In every step k of the algorithm, the AugmentedLagrangianCost  mathcal L_Ï^(k)(p Î¼^(k) Î»^(k)) is minimized on \\mathcal M,   where Î¼^(k)  â„^n and Î»^(k)  â„^m are the current iterates of the Lagrange multipliers and Ï^(k) is the current penalty parameter.\n\nThe Lagrange multipliers are then updated by\n\nÎ»_j^(k+1) =operatornameclip_Î»_minÎ»_max (Î»_j^(k) + Ï^(k) h_j(p^(k+1))) textfor all j=1p\n\nand\n\nÎ¼_i^(k+1) =operatornameclip_0Î¼_max (Î¼_i^(k) + Ï^(k) g_i(p^(k+1))) text for all  i=1m\n\nwhere Î»_textmin  Î»_textmax and Î¼_textmax are the multiplier boundaries.\n\nNext, the accuracy tolerance Ïµ is updated as\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_textmin is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor.\n\nLast, the penalty parameter Ï is updated as follows: with\n\nÏƒ^(k)=max_j=1p i=1m h_j(p^(k)) max_i=1mg_i(p^(k)) -fracÎ¼_i^(k-1)Ï^(k-1)  \n\nÏ is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  Ïƒ^(k)leq Î¸_Ï Ïƒ^(k-1) \nÏ^(k-1)  textelse\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\n\nOptional (if not called with the ConstrainedManifoldObjective cmo)\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nKeyword Arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÏµ=1e-3:           the accuracy tolerance\nÏµ_min=1e-6:       the lower bound for the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor; also 1/number of iterations until maximal accuracy is needed to end algorithm naturally\nequality_constraints=nothing: the number n of equality constraints.\nIf not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nÎ»=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the equality constraints\nÎ»_max=20.0:       an upper bound for the Lagrange multiplier belonging to the equality constraints\nÎ»_min=- Î»_max:    a lower bound for the Lagrange multiplier belonging to the equality constraints\nÎ¼=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the inequality constraints\nÎ¼_max=20.0: an upper bound for the Lagrange multiplier belonging to the inequality constraints\nÏ=1.0:            the penalty parameter\nÏ„=0.8:            factor for the improvement of the evaluation of the penalty parameter\nÎ¸_Ï=0.3:          the scaling factor of the penalty parameter\nÎ¸_Ïµ=(Ïµ_min / Ïµ)^(Ïµ_exponent): the scaling factor of the exactness\nsub_cost=[AugmentedLagrangianCostÂ± (@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian cost, based on the ConstrainedManifoldObjective build from the functions provided.  This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=[AugmentedLagrangianGrad](@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian gradient, based on the [ConstrainedManifoldObjective](@ref) build from the functions provided. This is used to define thesubproblem=keyword and has hence no effect, if you setsubproblem` directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nstopping_criterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(:Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) )|StopWhenChangeLess`: a functor indicating that the stopping criterion is fulfilled\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.as the quasi newton method, the QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used.\nsub_stopping_criterion::StoppingCriterion=StopAfterIteration(300)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-8),\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method!","page":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method!","text":"augmented_Lagrangian_method(M, f, grad_f, p=rand(M); kwargs...)\naugmented_Lagrangian_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\naugmented_Lagrangian_method!(M, f, grad_f, p; kwargs...)\naugmented_Lagrangian_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the augmented Lagrangian method (ALM) [LB19]. This method can work in-place of p.\n\nThe aim of the ALM is to find the solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. In every step k of the algorithm, the AugmentedLagrangianCost  mathcal L_Ï^(k)(p Î¼^(k) Î»^(k)) is minimized on \\mathcal M,   where Î¼^(k)  â„^n and Î»^(k)  â„^m are the current iterates of the Lagrange multipliers and Ï^(k) is the current penalty parameter.\n\nThe Lagrange multipliers are then updated by\n\nÎ»_j^(k+1) =operatornameclip_Î»_minÎ»_max (Î»_j^(k) + Ï^(k) h_j(p^(k+1))) textfor all j=1p\n\nand\n\nÎ¼_i^(k+1) =operatornameclip_0Î¼_max (Î¼_i^(k) + Ï^(k) g_i(p^(k+1))) text for all  i=1m\n\nwhere Î»_textmin  Î»_textmax and Î¼_textmax are the multiplier boundaries.\n\nNext, the accuracy tolerance Ïµ is updated as\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_textmin is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor.\n\nLast, the penalty parameter Ï is updated as follows: with\n\nÏƒ^(k)=max_j=1p i=1m h_j(p^(k)) max_i=1mg_i(p^(k)) -fracÎ¼_i^(k-1)Ï^(k-1)  \n\nÏ is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  Ïƒ^(k)leq Î¸_Ï Ïƒ^(k-1) \nÏ^(k-1)  textelse\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\n\nOptional (if not called with the ConstrainedManifoldObjective cmo)\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nKeyword Arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÏµ=1e-3:           the accuracy tolerance\nÏµ_min=1e-6:       the lower bound for the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor; also 1/number of iterations until maximal accuracy is needed to end algorithm naturally\nequality_constraints=nothing: the number n of equality constraints.\nIf not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nÎ»=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the equality constraints\nÎ»_max=20.0:       an upper bound for the Lagrange multiplier belonging to the equality constraints\nÎ»_min=- Î»_max:    a lower bound for the Lagrange multiplier belonging to the equality constraints\nÎ¼=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the inequality constraints\nÎ¼_max=20.0: an upper bound for the Lagrange multiplier belonging to the inequality constraints\nÏ=1.0:            the penalty parameter\nÏ„=0.8:            factor for the improvement of the evaluation of the penalty parameter\nÎ¸_Ï=0.3:          the scaling factor of the penalty parameter\nÎ¸_Ïµ=(Ïµ_min / Ïµ)^(Ïµ_exponent): the scaling factor of the exactness\nsub_cost=[AugmentedLagrangianCostÂ± (@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian cost, based on the ConstrainedManifoldObjective build from the functions provided.  This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=[AugmentedLagrangianGrad](@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian gradient, based on the [ConstrainedManifoldObjective](@ref) build from the functions provided. This is used to define thesubproblem=keyword and has hence no effect, if you setsubproblem` directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nstopping_criterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(:Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) )|StopWhenChangeLess`: a functor indicating that the stopping criterion is fulfilled\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.as the quasi newton method, the QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used.\nsub_stopping_criterion::StoppingCriterion=StopAfterIteration(300)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-8),\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/augmented_Lagrangian_method/#State","page":"Augmented Lagrangian Method","title":"State","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianMethodState","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianMethodState","text":"AugmentedLagrangianMethodState{P,T} <: AbstractManoptSolverState\n\nDescribes the augmented Lagrangian method, with\n\nFields\n\na default value is given in brackets if a parameter can be left out in initialization.\n\nÏµ:     the accuracy tolerance\nÏµ_min: the lower bound for the accuracy tolerance\nÎ»:     the Lagrange multiplier with respect to the equality constraints\nÎ»_max: an upper bound for the Lagrange multiplier belonging to the equality constraints\nÎ»_min: a lower bound for the Lagrange multiplier belonging to the equality constraints\np::P: a point on the manifold mathcal Mstoring the current iterate\npenalty: evaluation of the current penalty term, initialized to Inf.\nÎ¼:     the Lagrange multiplier with respect to the inequality constraints\nÎ¼_max: an upper bound for the Lagrange multiplier belonging to the inequality constraints\nÏ:     the penalty parameter\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nÏ„:     factor for the improvement of the evaluation of the penalty parameter\nÎ¸_Ï:   the scaling factor of the penalty parameter\nÎ¸_Ïµ:   the scaling factor of the accuracy tolerance\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nConstructor\n\nAugmentedLagrangianMethodState(M::AbstractManifold, co::ConstrainedManifoldObjective,\n    sub_problem, sub_state; kwargs...\n)\n\nconstruct an augmented Lagrangian method options, where the manifold M and the ConstrainedManifoldObjective co are used for manifold- or objective specific defaults.\n\nAugmentedLagrangianMethodState(M::AbstractManifold, co::ConstrainedManifoldObjective,\n    sub_problem; evaluation=AllocatingEvaluation(), kwargs...\n)\n\nconstruct an augmented Lagrangian method options, where the manifold M and the ConstrainedManifoldObjective co are used for manifold- or objective specific defaults, and sub_problem is a closed form solution with evaluation as type of evaluation.\n\nKeyword arguments\n\nthe following keyword arguments are available to initialise the corresponding fields\n\nÏµ=1eâ€“3\nÏµ_min=1e-6\nÎ»=ones(n): n is the number of equality constraints in the ConstrainedManifoldObjective co.\nÎ»_max=20.0\nÎ»_min=- Î»_max\nÎ¼=ones(m): m is the number of inequality constraints in the ConstrainedManifoldObjective co.\nÎ¼_max=20.0\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nÏ=1.0\nÏ„=0.8\nÎ¸_Ï=0.3\nÎ¸_Ïµ=(Ïµ_min/Ïµ)^(Ïµ_exponent)\nstoppingcriterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual`(:Ïµ, Ïµmin)[ & ](@ref StopWhenAll)[StopWhenChangeLess](@ref)(1e-10) )[ | ](@ref StopWhenAny)[StopWhenChangeLess](@ref).\n\nSee also\n\naugmented_Lagrangian_method\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Helping-functions","page":"Augmented Lagrangian Method","title":"Helping functions","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianCost","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianCost","text":"AugmentedLagrangianCost{CO,R,T}\n\nStores the parameters Ï  â„, Î¼  â„^m, Î»  â„^n of the augmented Lagrangian associated to the ConstrainedManifoldObjective co.\n\nThis struct is also a functor (M,p) -> v that can be used as a cost function within a solver, based on the internal ConstrainedManifoldObjective it computes\n\nmathcal L_rho(p Î¼ Î»)\n= f(x) + fracÏ2 biggl(\n    sum_j=1^n Bigl( h_j(p) + fracÎ»_jÏ Bigr)^2\n    +\n    sum_i=1^m maxBigl 0 fracÎ¼_iÏ + g_i(p) Bigr^2\nBigr)\n\nFields\n\nco::CO, Ï::R, Î¼::T, Î»::T as mentioned in the formula, where R should be the\n\nnumber type used and T the vector type.\n\nConstructor\n\nAugmentedLagrangianCost(co, Ï, Î¼, Î»)\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianGrad","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianGrad","text":"AugmentedLagrangianGrad{CO,R,T} <: AbstractConstrainedFunctor{T}\n\nStores the parameters Ï  â„, Î¼  â„^m, Î»  â„^n of the augmented Lagrangian associated to the ConstrainedManifoldObjective co.\n\nThis struct is also a functor in both formats\n\n(M, p) -> X to compute the gradient in allocating fashion.\n(M, X, p) to compute the gradient in in-place fashion.\n\nadditionally this gradient does accept a positional last argument to specify the range for the internal gradient call of the constrained objective.\n\nbased on the internal ConstrainedManifoldObjective and computes the gradient $(_tex(:grad))$(_tex(:Cal, \"L\"))_{Ï}(p, Î¼, Î»), see also [AugmentedLagrangianCost`](@ref).\n\nFields\n\nco::CO, Ï::R, Î¼::T, Î»::T as mentioned in the formula, where R should be the\n\nnumber type used and T the vector type.\n\nConstructor\n\nAugmentedLagrangianGrad(co, Ï, Î¼, Î»)\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#sec-agd-technical-details","page":"Augmented Lagrangian Method","title":"Technical details","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"The augmented_Lagrangian_method solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/augmented_Lagrangian_method/","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"A copyto!(M, q, p) and copy(M,p) for points.\nEverything the subsolver requires, which by default is the quasi_Newton method\nA zero_vector(M,p).","category":"page"},{"location":"solvers/augmented_Lagrangian_method/#Literature","page":"Augmented Lagrangian Method","title":"Literature","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"C.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\n","category":"page"},{"location":"solvers/cma_es/#Covariance-matrix-adaptation-evolutionary-strategy","page":"CMA-ES","title":"Covariance matrix adaptation evolutionary strategy","text":"","category":"section"},{"location":"solvers/cma_es/","page":"CMA-ES","title":"CMA-ES","text":"The CMA-ES algorithm has been implemented based on [Han23] with basic Riemannian adaptations, related to transport of covariance matrix and its update vectors. Other attempts at adapting CMA-ES to Riemannian optimization include [CFFS10]. The algorithm is suitable for global optimization.","category":"page"},{"location":"solvers/cma_es/","page":"CMA-ES","title":"CMA-ES","text":"Covariance matrix transport between consecutive mean points is handled by eigenvector_transport! function which is based on the idea of transport of matrix eigenvectors.","category":"page"},{"location":"solvers/cma_es/#Manopt.cma_es","page":"CMA-ES","title":"Manopt.cma_es","text":"cma_es(M, f, p_m=rand(M); Ïƒ::Real=1.0, kwargs...)\n\nPerform covariance matrix adaptation evolutionary strategy search for global gradient-free randomized optimization. It is suitable for complicated non-convex functions. It can be reasonably expected to find global minimum within 3Ïƒ distance from p_m.\n\nImplementation is based on [Han23] with basic adaptations to the Riemannian setting.\n\nInput\n\nM:      a manifold mathcal M\nf:      a cost function f mathcal Mâ„ to find a minimizer p^* for\n\nKeyword arguments\n\np_m=rand(M): an initial point p\nÏƒ=1.0: initial standard deviation\nÎ»:                  (4 + Int(floor(3 * log(manifold_dimension(M))))population size (can be increased for a more thorough global search but decreasing is not recommended)\ntol_fun=1e-12: tolerance for the StopWhenPopulationCostConcentrated, similar to absolute difference between function values at subsequent points\ntol_x=1e-12: tolerance for the StopWhenPopulationStronglyConcentrated, similar to absolute difference between subsequent point but actually computed from distribution parameters.\nstopping_criterion=default_cma_es_stopping_criterion(M, Î»; tol_fun=tol_fun, tol_x=tol_x): a functor indicating that the stopping criterion is fulfilled\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nbasis               (DefaultOrthonormalBasis()) basis used to represent covariance in\nrng=default_rng(): random number generator for generating new points on M\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cma_es/#State","page":"CMA-ES","title":"State","text":"","category":"section"},{"location":"solvers/cma_es/#Manopt.CMAESState","page":"CMA-ES","title":"Manopt.CMAESState","text":"CMAESState{P,T} <: AbstractManoptSolverState\n\nState of covariance matrix adaptation evolution strategy.\n\nFields\n\np::P: a point on the manifold mathcal M storing the best point found so far\np_obj                       objective value at p\nÎ¼                           parent number\nÎ»                           population size\nÎ¼_eff                       variance effective selection mass for the mean\nc_1                         learning rate for the rank-one update\nc_c                         decay rate for cumulation path for the rank-one update\nc_Î¼                         learning rate for the rank-Î¼ update\nc_Ïƒ                         decay rate for the cumulation path for the step-size control\nc_m                         learning rate for the mean\nd_Ïƒ                         damping parameter for step-size update\npopulation                  population of the current generation\nys_c                        coordinates of random vectors for the current generation\ncovariance_matrix           coordinates of the covariance matrix\ncovariance_matrix_eigen     eigen decomposition of covariance_matrix\ncovariance_matrix_cond      condition number of covariance_matrix, updated after eigen decomposition\nbest_fitness_current_gen    best fitness value of individuals in the current generation\nmedian_fitness_current_gen  median fitness value of individuals in the current generation\nworst_fitness_current_gen   worst fitness value of individuals in the current generation\np_m                         point around which the search for new candidates is done\nÏƒ                           step size\np_Ïƒ                         coordinates of a vector in T_p_mmathcal M\np_c                         coordinates of a vector in T_p_mmathcal M\ndeviations                  standard deviations of coordinate RNG\nbuffer                      buffer for random number generation and wmean_y_c of length n_coords\ne_mv_norm                   expected value of norm of the n_coords-variable standard normal distribution\nrecombination_weights       recombination weights used for updating covariance matrix\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nbasis                       a real coefficient basis for covariance matrix\nrng                         RNG for generating new points\n\nConstructor\n\nCMAESState(\n    M::AbstractManifold,\n    p_m::P,\n    Î¼::Int,\n    Î»::Int,\n    Î¼_eff::TParams,\n    c_1::TParams,\n    c_c::TParams,\n    c_Î¼::TParams,\n    c_Ïƒ::TParams,\n    c_m::TParams,\n    d_Ïƒ::TParams,\n    stop::TStopping,\n    covariance_matrix::Matrix{TParams},\n    Ïƒ::TParams,\n    recombination_weights::Vector{TParams};\n    retraction_method::TRetraction=default_retraction_method(M, typeof(p_m)),\n    vector_transport_method::TVTM=default_vector_transport_method(M, typeof(p_m)),\n    basis::TB=DefaultOrthonormalBasis(),\n    rng::TRng=default_rng(),\n) where {\n    P,\n    TParams<:Real,\n    TStopping<:StoppingCriterion,\n    TRetraction<:AbstractRetractionMethod,\n    TVTM<:AbstractVectorTransportMethod,\n    TB<:AbstractBasis,\n    TRng<:AbstractRNG,\n}\n\nSee also\n\ncma_es\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Stopping-criteria","page":"CMA-ES","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/cma_es/#Manopt.StopWhenBestCostInGenerationConstant","page":"CMA-ES","title":"Manopt.StopWhenBestCostInGenerationConstant","text":"StopWhenBestCostInGenerationConstant <: StoppingCriterion\n\nStop if the range of the best objective function values of the last iteration_range generations is zero. This corresponds to EqualFUnValues condition from [Han23].\n\nSee also StopWhenPopulationCostConcentrated.\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenCovarianceIllConditioned","page":"CMA-ES","title":"Manopt.StopWhenCovarianceIllConditioned","text":"StopWhenCovarianceIllConditioned <: StoppingCriterion\n\nStop CMA-ES if condition number of covariance matrix exceeds threshold. This corresponds to ConditionCov condition from [Han23].\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenEvolutionStagnates","page":"CMA-ES","title":"Manopt.StopWhenEvolutionStagnates","text":"StopWhenEvolutionStagnates{TParam<:Real} <: StoppingCriterion\n\nThe best and median fitness in each iteration is tracked over the last 20% but at least min_size and no more than max_size iterations. Solver is stopped if in both histories the median of the most recent fraction of values is not better than the median of the oldest fraction.\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenPopulationCostConcentrated","page":"CMA-ES","title":"Manopt.StopWhenPopulationCostConcentrated","text":"StopWhenPopulationCostConcentrated{TParam<:Real} <: StoppingCriterion\n\nStop if the range of the best objective function value in the last max_size generations and all function values in the current generation is below tol. This corresponds to TolFun condition from [Han23].\n\nConstructor\n\nStopWhenPopulationCostConcentrated(tol::Real, max_size::Int)\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenPopulationDiverges","page":"CMA-ES","title":"Manopt.StopWhenPopulationDiverges","text":"StopWhenPopulationDiverges{TParam<:Real} <: StoppingCriterion\n\nStop if Ïƒ times maximum deviation increased by more than tol. This usually indicates a far too small Ïƒ, or divergent behavior. This corresponds to TolXUp condition from [Han23].\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenPopulationStronglyConcentrated","page":"CMA-ES","title":"Manopt.StopWhenPopulationStronglyConcentrated","text":"StopWhenPopulationStronglyConcentrated{TParam<:Real} <: StoppingCriterion\n\nStop if the standard deviation in all coordinates is smaller than tol and norm of Ïƒ * p_c is smaller than tol. This corresponds to TolX condition from [Han23].\n\nFields\n\ntol the tolerance to verify against\nat_iteration an internal field to indicate at with iteration i geq 0 the tolerance was met.\n\nConstructor\n\nStopWhenPopulationStronglyConcentrated(tol::Real)\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#sec-cma-es-technical-details","page":"CMA-ES","title":"Technical details","text":"","category":"section"},{"location":"solvers/cma_es/","page":"CMA-ES","title":"CMA-ES","text":"The cma_es solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/cma_es/","page":"CMA-ES","title":"CMA-ES","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points and similarly copy(M, p, X) for tangent vectors.\nget_coordinates!(M, Y, p, X, b) and get_vector!(M, X, p, c, b) with respect to the AbstractBasis b provided, which is DefaultOrthonormalBasis by default from the basis= keyword.\nAn is_flat(M).","category":"page"},{"location":"solvers/cma_es/#Internal-helpers","page":"CMA-ES","title":"Internal helpers","text":"","category":"section"},{"location":"solvers/cma_es/","page":"CMA-ES","title":"CMA-ES","text":"You may add new methods to eigenvector_transport! if you know a more optimized implementation for your manifold.","category":"page"},{"location":"solvers/cma_es/#Manopt.eigenvector_transport!","page":"CMA-ES","title":"Manopt.eigenvector_transport!","text":"eigenvector_transport!(\n    M::AbstractManifold,\n    matrix_eigen::Eigen,\n    p,\n    q,\n    basis::AbstractBasis,\n    vtm::AbstractVectorTransportMethod,\n)\n\nTransport the matrix with matrix_eig eigen decomposition when expanded in basis from point p to point q on M. Update matrix_eigen in-place.\n\n(p, matrix_eig) belongs to the fiber bundle of B = mathcal M  SPD(n), where n is the (real) dimension of M. The function corresponds to the Ehresmann connection defined by vector transport vtm of eigenvectors of matrix_eigen.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cma_es/#Literature","page":"CMA-ES","title":"Literature","text":"","category":"section"},{"location":"solvers/cma_es/","page":"CMA-ES","title":"CMA-ES","text":"S.Â Colutto, F.Â Fruhauf, M.Â Fuchs and O.Â Scherzer. The CMA-ES on Riemannian Manifolds to Reconstruct Shapes in 3-D Voxel Images. IEEEÂ TransactionsÂ onÂ EvolutionaryÂ Computation 14, 227â€“245 (2010).\n\n\n\nN.Â Hansen. The CMA Evolution Strategy: A Tutorial. ArXivÂ Preprint (2023).\n\n\n\n","category":"page"},{"location":"plans/record/#sec-record","page":"Recording values","title":"Record values","text":"","category":"section"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"To record values during the iterations of a solver run, there are in general two possibilities. On the one hand, the high-level interfaces provide a record= keyword, that accepts several different inputs. For more details see How to record.","category":"page"},{"location":"plans/record/#subsec-record-states","page":"Recording values","title":"Record Actions & the solver state decorator","text":"","category":"section"},{"location":"plans/record/#Manopt.RecordAction","page":"Recording values","title":"Manopt.RecordAction","text":"RecordAction\n\nA RecordAction is a small functor to record values. The usual call is given by\n\n(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, k) -> s\n\nthat performs the record for the current problem and solver combination, and where k is the current iteration.\n\nBy convention i=0 is interpreted as \"For Initialization only,\" so only initialize internal values, but not trigger any record, that the record is called from within stop_solver! which returns true afterwards.\n\nAny negative value is interpreted as a â€œresetâ€, and should hence delete all stored recordings, for example when reusing a RecordAction. The start of a solver calls the :Iteration and :Stop dictionary entries with -1, to reset those recordings.\n\nBy default any RecordAction is assumed to record its values in a field recorded_values, an Vector of recorded values. See get_record(ra).\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordChange","page":"Recording values","title":"Manopt.RecordChange","text":"RecordChange <: RecordAction\n\ndebug for the amount of change of the iterate (see get_iterate(s) of the AbstractManoptSolverState) during the last iteration.\n\nFields\n\nstorage                   : a StoreStateAction to store (at least) the last iterate to use this as the last value (to compute the change) serving as a potential cache shared with other components of the solver.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nrecorded_values           : to store the recorded values\n\nConstructor\n\nRecordChange(M=DefaultManifold();\n    inverse_retraction_method = default_inverse_retraction_method(M),\n    storage                   = StoreStateAction(M; store_points=Tuple{:Iterate})\n)\n\nwith the previous fields as keywords. For the DefaultManifold only the field storage is used. Providing the actual manifold moves the default storage to the efficient point storage.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordCost","page":"Recording values","title":"Manopt.RecordCost","text":"RecordCost <: RecordAction\n\nRecord the current cost function value, see get_cost.\n\nFields\n\nrecorded_values : to store the recorded values\n\nConstructor\n\nRecordCost()\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEntry","page":"Recording values","title":"Manopt.RecordEntry","text":"RecordEntry{T} <: RecordAction\n\nrecord a certain fields entry of type {T} during the iterates\n\nFields\n\nrecorded_values : the recorded Iterates\nfield           : Symbol the entry can be accessed with within AbstractManoptSolverState\n\nConstructor\n\nRecordEntry(::T, f::Symbol)\nRecordEntry(T::DataType, f::Symbol)\n\nInitialize the record action to record the state field f, and initialize the recorded_values to be a vector of element type T.\n\nExamples\n\nRecordEntry(rand(M), :q) to record the points from M stored in some states s.q\nRecordEntry(SVDMPoint, :p) to record the field s.p which takes values of type SVDMPoint.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEntryChange","page":"Recording values","title":"Manopt.RecordEntryChange","text":"RecordEntryChange{T} <: RecordAction\n\nrecord a certain entries change during iterates\n\nAdditional fields\n\nrecorded_values : the recorded Iterates\nfield           : Symbol the field can be accessed with within AbstractManoptSolverState\ndistance        : function (p,o,x1,x2) to compute the change/distance between two values of the entry\nstorage         : a StoreStateAction to store (at least) getproperty(o, d.field)\n\nConstructor\n\nRecordEntryChange(f::Symbol, d, a::StoreStateAction=StoreStateAction([f]))\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEvery","page":"Recording values","title":"Manopt.RecordEvery","text":"RecordEvery <: RecordAction\n\nrecord only every kth iteration. Otherwise (optionally, but activated by default) just update internal tracking values.\n\nThis method does not perform any record itself but relies on it's children's methods\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordGroup","page":"Recording values","title":"Manopt.RecordGroup","text":"RecordGroup <: RecordAction\n\ngroup a set of RecordActions into one action, where the internal RecordActions act independently, but the results can be collected in a grouped fashion, a tuple per calls of this group. The entries can be later addressed either by index or semantic Symbols\n\nConstructors\n\nRecordGroup(g::Array{<:RecordAction, 1})\n\nconstruct a group consisting of an Array of RecordActions g,\n\nRecordGroup(g, symbols)\n\nExamples\n\ng1 = RecordGroup([RecordIteration(), RecordCost()])\n\nA RecordGroup to record the current iteration and the cost. The cost can then be accessed using get_record(r,2) or r[2].\n\ng2 = RecordGroup([RecordIteration(), RecordCost()], Dict(:Cost => 2))\n\nA RecordGroup to record the current iteration and the cost, which can then be accessed using get_record(:Cost) or r[:Cost].\n\ng3 = RecordGroup([RecordIteration(), RecordCost() => :Cost])\n\nA RecordGroup identical to the previous constructor, just a little easier to use. To access all recordings of the second entry of this last g3 you can do either g4[2] or g[:Cost], the first one can only be accessed by g4[1], since no symbol was given here.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordIterate","page":"Recording values","title":"Manopt.RecordIterate","text":"RecordIterate <: RecordAction\n\nrecord the iterate\n\nConstructors\n\nRecordIterate(x0)\n\ninitialize the iterate record array to the type of x0, which indicates the kind of iterate\n\nRecordIterate(P)\n\ninitialize the iterate record array to the data type T.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordIteration","page":"Recording values","title":"Manopt.RecordIteration","text":"RecordIteration <: RecordAction\n\nrecord the current iteration\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordSolverState","page":"Recording values","title":"Manopt.RecordSolverState","text":"RecordSolverState <: AbstractManoptSolverState\n\nappend to any AbstractManoptSolverState the decorator with record capability, Internally a dictionary is kept that stores a RecordAction for several concurrent modes using a Symbol as reference. The default mode is :Iteration, which is used to store information that is recorded during the iterations. RecordActions might be added to :Start or :Stop to record values at the beginning or for the stopping time point, respectively\n\nThe original options can still be accessed using the get_state function.\n\nFields\n\noptions          the options that are extended by debug information\nrecordDictionary a Dict{Symbol,RecordAction} to keep track of all different recorded values\n\nConstructors\n\nRecordSolverState(o,dR)\n\nconstruct record decorated AbstractManoptSolverState, where dR can be\n\na RecordAction, then it is stored within the dictionary at :Iteration\nan Array of RecordActions, then it is stored as a recordDictionary(@ref).\na Dict{Symbol,RecordAction}.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordStoppingReason","page":"Recording values","title":"Manopt.RecordStoppingReason","text":"RecordStoppingReason <: RecordAction\n\nRecord reason the solver stopped, see get_reason.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordSubsolver","page":"Recording values","title":"Manopt.RecordSubsolver","text":"RecordSubsolver <: RecordAction\n\nRecord the current sub solvers recording, by calling get_record on the sub state with\n\nFields\n\nrecords: an array to store the recorded values\nsymbols: arguments for get_record. Defaults to just one symbol :Iteration, but could be set to also record the :Stop action.\n\nConstructor\n\nRecordSubsolver(; record=[:Iteration,], record_type=eltype([]))\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordTime","page":"Recording values","title":"Manopt.RecordTime","text":"RecordTime <: RecordAction\n\nrecord the time elapsed during the current iteration.\n\nThe three possible modes are\n\n:cumulative record times without resetting the timer\n:iterative record times with resetting the timer\n:total record a time only at the end of an algorithm (see stop_solver!)\n\nThe default is :cumulative, and any non-listed symbol default to using this mode.\n\nConstructor\n\nRecordTime(; mode::Symbol=:cumulative)\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordWhenActive","page":"Recording values","title":"Manopt.RecordWhenActive","text":"RecordWhenActive <: RecordAction\n\nrecord action that only records if the active boolean is set to true. This can be set from outside and is for example triggered by |RecordEvery](@ref) on recordings of the subsolver. While this is for sub solvers maybe not completely necessary, recording values that are never accessible, is not that useful.\n\nFields\n\nactive:        a boolean that can (de-)activated from outside to turn on/off debug\nalways_update: whether or not to call the inner debugs with nonpositive iterates (init/reset)\n\nConstructor\n\nRecordWhenActive(r::RecordAction, active=true, always_update=true)\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Access-functions","page":"Recording values","title":"Access functions","text":"","category":"section"},{"location":"plans/record/#Base.getindex-Tuple{RecordGroup, Vararg{Any}}","page":"Recording values","title":"Base.getindex","text":"getindex(r::RecordGroup, s::Symbol)\nr[s]\ngetindex(r::RecordGroup, sT::NTuple{N,Symbol})\nr[sT]\ngetindex(r::RecordGroup, i)\nr[i]\n\nreturn an array of recorded values with respect to the s, the symbols from the tuple sT or the index i. See get_record for details.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Base.getindex-Tuple{RecordSolverState, Symbol}","page":"Recording values","title":"Base.getindex","text":"get_index(rs::RecordSolverState, s::Symbol)\nro[s]\n\nGet the recorded values for recorded type s, see get_record for details.\n\nget_index(rs::RecordSolverState, s::Symbol, i...)\nro[s, i...]\n\nAccess the recording type of type s and call its RecordAction with [i...].\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record","page":"Recording values","title":"Manopt.get_record","text":"get_record(s::AbstractManoptSolverState, [,symbol=:Iteration])\nget_record(s::RecordSolverState, [,symbol=:Iteration])\n\nreturn the recorded values from within the RecordSolverState s that where recorded with respect to the Symbol symbol as an Array. The default refers to any recordings during an :Iteration.\n\nWhen called with arbitrary AbstractManoptSolverState, this method looks for the RecordSolverState decorator and calls get_record on the decorator.\n\n\n\n\n\n","category":"function"},{"location":"plans/record/#Manopt.get_record-Tuple{RecordAction}","page":"Recording values","title":"Manopt.get_record","text":"get_record(r::RecordAction)\n\nreturn the recorded values stored within a RecordAction r.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record-Tuple{RecordGroup}","page":"Recording values","title":"Manopt.get_record","text":"get_record(r::RecordGroup)\n\nreturn an array of tuples, where each tuple is a recorded set per iteration or record call.\n\nget_record(r::RecordGruop, k::Int)\n\nreturn an array of values corresponding to the ith entry in this record group\n\nget_record(r::RecordGruop, s::Symbol)\n\nreturn an array of recorded values with respect to the s, see RecordGroup.\n\nget_record(r::RecordGroup, s1::Symbol, s2::Symbol,...)\n\nreturn an array of tuples, where each tuple is a recorded set corresponding to the symbols s1, s2,... per iteration / record call.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record_action","page":"Recording values","title":"Manopt.get_record_action","text":"get_record_action(s::AbstractManoptSolverState, s::Symbol)\n\nreturn the action contained in the (first) RecordSolverState decorator within the AbstractManoptSolverState o.\n\n\n\n\n\n","category":"function"},{"location":"plans/record/#Manopt.get_record_state-Tuple{AbstractManoptSolverState}","page":"Recording values","title":"Manopt.get_record_state","text":"get_record_state(s::AbstractManoptSolverState)\n\nreturn the RecordSolverState among the decorators from the AbstractManoptSolverState o\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.has_record-Tuple{RecordSolverState}","page":"Recording values","title":"Manopt.has_record","text":"has_record(s::AbstractManoptSolverState)\n\nIndicate whether the AbstractManoptSolverStates are decorated with RecordSolverState\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Internal-factory-functions","page":"Recording values","title":"Internal factory functions","text":"","category":"section"},{"location":"plans/record/#Manopt.RecordActionFactory-Tuple{AbstractManoptSolverState, RecordAction}","page":"Recording values","title":"Manopt.RecordActionFactory","text":"RecordActionFactory(s::AbstractManoptSolverState, a)\n\ncreate a RecordAction where\n\na RecordAction is passed through\na [Symbol] creates\n:Change        to record the change of the iterates, see RecordChange\n:Gradient      to record the gradient, see RecordGradient\n:GradientNorm   to record the norm of the gradient, see [RecordGradientNorm`](@ref)\n:Iterate       to record the iterate\n:Iteration     to record the current iteration number\nIterativeTime  to record the time iteratively\n:Cost          to record the current cost function value\n:Stepsize      to record the current step size\n:Time          to record the total time taken after every iteration\n:IterativeTime to record the times taken for each iteration.\n\nand every other symbol is passed to RecordEntry, which results in recording the field of the state with the symbol indicating the field of the solver to record.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordActionFactory-Union{Tuple{T}, Tuple{AbstractManoptSolverState, Tuple{Symbol, T}}} where T","page":"Recording values","title":"Manopt.RecordActionFactory","text":"RecordActionFactory(s::AbstractManoptSolverState, t::Tuple{Symbol, T}) where {T}\n\ncreate a RecordAction where\n\n(:Subsolver, s) creates a RecordSubsolver with record= set to the second tuple entry\n\nFor other symbol the second entry is ignored and the symbol is used to generate a RecordEntry recording the field with the name symbol of s.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordFactory-Tuple{AbstractManoptSolverState, Vector}","page":"Recording values","title":"Manopt.RecordFactory","text":"RecordFactory(s::AbstractManoptSolverState, a)\n\nGenerate a dictionary of RecordActions.\n\nFirst all Symbols String, RecordActions and numbers are collected, excluding :Stop and :WhenActive. This collected vector is added to the :Iteration => [...] pair. :Stop is added as :StoppingCriterion to the :Stop => [...] pair. If any of these two pairs does not exist, it is pairs are created when adding the corresponding symbols\n\nFor each Pair of a Symbol and a Vector, the RecordGroupFactory is called for the Vector and the result is added to the debug dictionary's entry with said symbol. This is wrapped into the RecordWhenActive, when the :WhenActive symbol is present\n\nReturn value\n\nA dictionary for the different entry points where debug can happen, each containing a RecordAction to call.\n\nNote that upon the initialisation all dictionaries but the :StartAlgorithm one are called with an i=0 for reset.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordGroupFactory-Tuple{AbstractManoptSolverState, Vector}","page":"Recording values","title":"Manopt.RecordGroupFactory","text":"RecordGroupFactory(s::AbstractManoptSolverState, a)\n\nGenerate a [RecordGroup] of RecordActions. The following rules are used\n\nAny Symbol contained in a is passed to RecordActionFactory\nAny RecordAction is included as is.\n\nAny Pair of a RecordAction and a symbol, that is in order RecordCost() => :A is handled, that the corresponding record action can later be accessed as g[:A], where gis the record group generated here.\n\nIf this results in more than one RecordAction a RecordGroup of these is build.\n\nIf any integers are present, the last of these is used to wrap the group in a RecordEvery(k).\n\nIf :WhenActive is present, the resulting Action is wrapped in RecordWhenActive, making it deactivatable by its parent solver.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.record_or_reset!-Tuple{RecordAction, Any, Int64}","page":"Recording values","title":"Manopt.record_or_reset!","text":"record_or_reset!(r, v, k)\n\neither record (k>0 and not Inf) the value v within the RecordAction r or reset (k<0) the internal storage, where v has to match the internal value type of the corresponding RecordAction.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.set_parameter!-Tuple{RecordSolverState, Val{:Record}, Vararg{Any}}","page":"Recording values","title":"Manopt.set_parameter!","text":"set_parameter!(ams::RecordSolverState, ::Val{:Record}, args...)\n\nSet certain values specified by args... into the elements of the recordDictionary\n\n\n\n\n\n","category":"method"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"Further specific RecordActions can be found when specific types of AbstractManoptSolverState define them on their corresponding site.","category":"page"},{"location":"plans/record/#Technical-details","page":"Recording values","title":"Technical details","text":"","category":"section"},{"location":"plans/record/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, RecordSolverState}","page":"Recording values","title":"Manopt.initialize_solver!","text":"initialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState)\n\nExtend the initialization of the solver by a hook to run records that were added to the :Start entry.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.step_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","page":"Recording values","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, k)\n\nExtend the ith step of the solver by a hook to run records, that were added to the :Iteration entry.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","page":"Recording values","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, rss::RecordSolverStatek k)\n\nExtend the call to the stopping criterion by a hook to run records, that were added to the :Stop entry.\n\n\n\n\n\n","category":"method"},{"location":"solvers/adaptive-regularization-with-cubics/#Adaptive-regularization-with-cubics","page":"Adaptive Regularization with Cubics","title":"Adaptive regularization with cubics","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.adaptive_regularization_with_cubics","page":"Adaptive Regularization with Cubics","title":"Manopt.adaptive_regularization_with_cubics","text":"adaptive_regularization_with_cubics(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, f, grad_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, mho, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, Hess_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, mho, p; kwargs...)\n\nSolve an optimization problem on the manifold M by iteratively minimizing\n\nm_k(X) = f(p_k) + X operatornamegrad f(p^(k)) + frac12X operatornameHess f(p^(k))X + fracÏƒ_k3lVert X rVert^3\n\non the tangent space at the current iterate p_k, where X  T_p_kmathcal M and Ïƒ_k  0 is a regularization parameter.\n\nLet Xp^(k) denote the minimizer of the model m_k and use the model improvement\n\n  Ï_k = fracf(p_k) - f(operatornameretr_p_k(X_k))m_k(0) - m_k(X_k) + fracÏƒ_k3lVert X_krVert^3\n\nWith two thresholds Î·_2  Î·_1  0 set p_k+1 = operatornameretr_p_k(X_k) if Ï  Î·_1 and reject the candidate otherwise, that is, set p_k+1 = p_k.\n\nFurther update the regularization parameter using factors 0  Î³_1  1  Î³_2 reads\n\nÏƒ_k+1 =\nbegincases\n    maxÏƒ_min Î³_1Ïƒ_k  text if  Ï geq Î·_2 text   (the model was very successful)\n    Ïƒ_k  text if  Ï  Î·_1 Î·_2)text   (the model was successful)\n    Î³_2Ïƒ_k  text if  Ï  Î·_1text   (the model was unsuccessful)\nendcases\n\nFor more details see [ABBC20].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\n\nthe cost f and its gradient and Hessian might also be provided as a ManifoldHessianObjective\n\nKeyword arguments\n\nÏƒ=100.0 / sqrt(manifold_dimension(M): initial regularization parameter\nÏƒmin=1e-10: minimal regularization value Ïƒ_min\nÎ·1=0.1: lower model success threshold\nÎ·2=0.9: upper model success threshold\nÎ³1=0.1: regularization reduction factor (for the success case)\nÎ³2=2.0: regularization increment factor (for the non-success case)\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninitial_tangent_vector=zero_vector(M, p): initialize any tangent vector data,\nmaxIterLanczos=200: a shortcut to set the stopping criterion in the sub solver,\nÏ_regularization=1e3: a regularization to avoid dividing by zero for small values of cost and model\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions:\nstopping_criterion=StopAfterIteration(40)|StopWhenGradientNormLess(1e-9)|StopWhenAllLanczosVectorsUsed(maxIterLanczos): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=nothing: a shortcut to modify the objective of the subproblem used within in the sub_problem= keyword By default, this is initialized as a AdaptiveRagularizationWithCubicsModelObjective, which can further be decorated by using the sub_kwargs= keyword.\nsub_state=LanczosState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.adaptive_regularization_with_cubics!","page":"Adaptive Regularization with Cubics","title":"Manopt.adaptive_regularization_with_cubics!","text":"adaptive_regularization_with_cubics(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, f, grad_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, mho, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, Hess_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, mho, p; kwargs...)\n\nSolve an optimization problem on the manifold M by iteratively minimizing\n\nm_k(X) = f(p_k) + X operatornamegrad f(p^(k)) + frac12X operatornameHess f(p^(k))X + fracÏƒ_k3lVert X rVert^3\n\non the tangent space at the current iterate p_k, where X  T_p_kmathcal M and Ïƒ_k  0 is a regularization parameter.\n\nLet Xp^(k) denote the minimizer of the model m_k and use the model improvement\n\n  Ï_k = fracf(p_k) - f(operatornameretr_p_k(X_k))m_k(0) - m_k(X_k) + fracÏƒ_k3lVert X_krVert^3\n\nWith two thresholds Î·_2  Î·_1  0 set p_k+1 = operatornameretr_p_k(X_k) if Ï  Î·_1 and reject the candidate otherwise, that is, set p_k+1 = p_k.\n\nFurther update the regularization parameter using factors 0  Î³_1  1  Î³_2 reads\n\nÏƒ_k+1 =\nbegincases\n    maxÏƒ_min Î³_1Ïƒ_k  text if  Ï geq Î·_2 text   (the model was very successful)\n    Ïƒ_k  text if  Ï  Î·_1 Î·_2)text   (the model was successful)\n    Î³_2Ïƒ_k  text if  Ï  Î·_1text   (the model was unsuccessful)\nendcases\n\nFor more details see [ABBC20].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\n\nthe cost f and its gradient and Hessian might also be provided as a ManifoldHessianObjective\n\nKeyword arguments\n\nÏƒ=100.0 / sqrt(manifold_dimension(M): initial regularization parameter\nÏƒmin=1e-10: minimal regularization value Ïƒ_min\nÎ·1=0.1: lower model success threshold\nÎ·2=0.9: upper model success threshold\nÎ³1=0.1: regularization reduction factor (for the success case)\nÎ³2=2.0: regularization increment factor (for the non-success case)\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninitial_tangent_vector=zero_vector(M, p): initialize any tangent vector data,\nmaxIterLanczos=200: a shortcut to set the stopping criterion in the sub solver,\nÏ_regularization=1e3: a regularization to avoid dividing by zero for small values of cost and model\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions:\nstopping_criterion=StopAfterIteration(40)|StopWhenGradientNormLess(1e-9)|StopWhenAllLanczosVectorsUsed(maxIterLanczos): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=nothing: a shortcut to modify the objective of the subproblem used within in the sub_problem= keyword By default, this is initialized as a AdaptiveRagularizationWithCubicsModelObjective, which can further be decorated by using the sub_kwargs= keyword.\nsub_state=LanczosState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/adaptive-regularization-with-cubics/#State","page":"Adaptive Regularization with Cubics","title":"State","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.AdaptiveRegularizationState","page":"Adaptive Regularization with Cubics","title":"Manopt.AdaptiveRegularizationState","text":"AdaptiveRegularizationState{P,T} <: AbstractHessianSolverState\n\nA state for the adaptive_regularization_with_cubics solver.\n\nFields\n\nÎ·1, Î·1: bounds for evaluating the regularization parameter\nÎ³1, Î³2:  shrinking and expansion factors for regularization parameter Ïƒ\nH: the current Hessian evaluation\ns: the current solution from the subsolver\np::P: a point on the manifold mathcal Mstoring the current iterate\nq: a point for the candidates to evaluate model and Ï\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\ns: the tangent vector step resulting from minimizing the model problem in the tangent space T_pmathcal M\nÏƒ: the current cubic regularization parameter\nÏƒmin: lower bound for the cubic regularization parameter\nÏ_regularization: regularization parameter for computing Ï. When approaching convergence Ï may be difficult to compute with numerator and denominator approaching zero. Regularizing the ratio lets Ï go to 1 near convergence.\nÏ: the current regularized ratio of actual improvement and model improvement.\nÏ_denominator: a value to store the denominator from the computation of Ï to allow for a warning or error when this value is non-positive.\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nFurthermore the following integral fields are defined\n\nConstructor\n\nAdaptiveRegularizationState(M, sub_problem, sub_state; kwargs...)\n\nConstruct the solver state with all fields stated as keyword arguments and the following defaults\n\nKeyword arguments\n\nÎ·1=0.1\nÎ·2=0.9\nÎ³1=0.1\nÎ³2=2.0\nÏƒ=100/manifold_dimension(M)\n`Ïƒmin=1e-7\nÏ_regularization=1e3\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\np=rand(M): a point on the manifold mathcal M\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#Sub-solvers","page":"Adaptive Regularization with Cubics","title":"Sub solvers","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"There are several ways to approach the subsolver. The default is the first one.","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/#arc-Lanczos","page":"Adaptive Regularization with Cubics","title":"Lanczos iteration","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.LanczosState","page":"Adaptive Regularization with Cubics","title":"Manopt.LanczosState","text":"LanczosState{P,T,SC,B,I,R,TM,V,Y} <: AbstractManoptSolverState\n\nSolve the adaptive regularized subproblem with a Lanczos iteration\n\nFields\n\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstop_newton::StoppingCriterion: a functor indicating that the stopping criterion is fulfilledused for the inner Newton iteration\nÏƒ:               the current regularization parameter\nX:               the Iterate\nLanczos_vectors: the obtained Lanczos vectors\ntridig_matrix:   the tridiagonal coefficient matrix T\ncoefficients:    the coefficients y_1y_k that determine the solution\nHp:              a temporary tangent vector containing the evaluation of the Hessian\nHp_residual:     a temporary tangent vector containing the residual to the Hessian\nS:               the current obtained / approximated solution\n\nConstructor\n\nLanczosState(TpM::TangentSpace; kwargs...)\n\nKeyword arguments\n\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mas the iterate\nmaxIterLanzcos=200: shortcut to set the maximal number of iterations in the stopping_crtierion=\nÎ¸=0.5: set the parameter in the StopWhenFirstOrderProgress within the default stopping_criterion=.\nstopping_criterion=StopAfterIteration(maxIterLanczos)|StopWhenFirstOrderProgress(Î¸): a functor indicating that the stopping criterion is fulfilled\nstopping_criterion_newton=StopAfterIteration(200): a functor indicating that the stopping criterion is fulfilled used for the inner Newton iteration\nÏƒ=10.0: specify the regularization parameter\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#(Conjugate)-gradient-descent","page":"Adaptive Regularization with Cubics","title":"(Conjugate) gradient descent","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"There is a generic objective, that implements the sub problem","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.AdaptiveRagularizationWithCubicsModelObjective","page":"Adaptive Regularization with Cubics","title":"Manopt.AdaptiveRagularizationWithCubicsModelObjective","text":"AdaptiveRagularizationWithCubicsModelObjective\n\nA model for the adaptive regularization with Cubics\n\nm(X) = f(p) + operatornamegrad f(p) X _p + frac12 operatornameHess f(p)X X_p\n       +  fracÏƒ3 lVert X rVert^3\n\ncf. Eq. (33) in [ABBC20]\n\nFields\n\nobjective: an AbstractManifoldHessianObjective proving f, its gradient and Hessian\nÏƒ:         the current (cubic) regularization parameter\n\nConstructors\n\nAdaptiveRagularizationWithCubicsModelObjective(mho, Ïƒ=1.0)\n\nwith either an AbstractManifoldHessianObjective objective or an decorator containing such an objective.\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"Since the sub problem is given on the tangent space, you have to provide","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"arc_obj = AdaptiveRagularizationWithCubicsModelObjective(mho, Ïƒ)\nsub_problem = DefaultProblem(TangentSpaceAt(M,p), arc_obj)","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"where mho is the Hessian objective of f to solve. Then use this for the sub_problem keyword and use your favourite gradient based solver for the sub_state keyword, for example a ConjugateGradientDescentState","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/#Additional-stopping-criteria","page":"Adaptive Regularization with Cubics","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.StopWhenAllLanczosVectorsUsed","page":"Adaptive Regularization with Cubics","title":"Manopt.StopWhenAllLanczosVectorsUsed","text":"StopWhenAllLanczosVectorsUsed <: StoppingCriterion\n\nWhen an inner iteration has used up all Lanczos vectors, then this stopping criterion is a fallback / security stopping criterion to not access a non-existing field in the array allocated for vectors.\n\nNote that this stopping criterion (for now) is only implemented for the case that an AdaptiveRegularizationState when using a LanczosState subsolver\n\nFields\n\nmaxLanczosVectors: maximal number of Lanczos vectors\nat_iteration indicates at which iteration (including i=0) the stopping criterion was fulfilled and is -1 while it is not fulfilled.\n\nConstructor\n\nStopWhenAllLanczosVectorsUsed(maxLancosVectors::Int)\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.StopWhenFirstOrderProgress","page":"Adaptive Regularization with Cubics","title":"Manopt.StopWhenFirstOrderProgress","text":"StopWhenFirstOrderProgress <: StoppingCriterion\n\nA stopping criterion related to the Riemannian adaptive regularization with cubics (ARC) solver indicating that the model function at the current (outer) iterate,\n\nm_k(X) = f(p_k) + X operatornamegrad f(p^(k)) + frac12X operatornameHess f(p^(k))X + fracÏƒ_k3lVert X rVert^3\n\ndefined on the tangent space T_pmathcal M fulfills at the current iterate X_k that\n\nm(X_k) leq m(0)\nquadtext and quad\nlVert operatornamegrad m(X_k) rVert  Î¸ lVert X_k rVert^2\n\nFields\n\nÎ¸:      the factor Î¸ in the second condition\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\n\nConstructor\n\nStopWhenAllLanczosVectorsUsed(Î¸)\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#sec-arc-technical-details","page":"Adaptive Regularization with Cubics","title":"Technical details","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"The adaptive_regularization_with_cubics requires the following functions of a manifolds to be available","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nif you do not provide an initial regularization parameter Ïƒ, a manifold_dimension is required.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).\ninner(M, p, X, Y) is used within the algorithm step","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"Furthermore, within the Lanczos subsolver, generating a random vector (at p) using rand!(M, X; vector_at=p) in place of X is required","category":"page"},{"location":"solvers/adaptive-regularization-with-cubics/#Literature","page":"Adaptive Regularization with Cubics","title":"Literature","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/","page":"Adaptive Regularization with Cubics","title":"Adaptive Regularization with Cubics","text":"N.Â Agarwal, N.Â Boumal, B.Â Bullins and C.Â Cartis. Adaptive regularization with cubics on manifolds. MathematicalÂ Programming (2020).\n\n\n\n","category":"page"},{"location":"solvers/trust_regions/#The-Riemannian-trust-regions-solver","page":"Trust-Regions Solver","title":"The Riemannian trust regions solver","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"Minimize a function","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"operatorname*argmin_p  mathcalM f(p)","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"by using the Riemannian trust-regions solver following [ABG06] a model is build by lifting the objective at the kth iterate p_k by locally mapping the cost function f to the tangent space as f_k T_p_kmathcal M  â„ as f_k(X) = f(operatornameretr_p_k(X)). The trust region subproblem is then defined as","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"operatorname*argmin_X  T_p_kmathcal M m_k(X)","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"where","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"beginalign*\nm_k T_p_Kmathcal M  â„\nm_k(X) = f(p_k) + operatornamegrad f(p_k) X_p_k + frac12langle mathcal H_k(X)X_p_k\ntextsuch that lVert X rVert_p_k  Î”_k\nendalign*","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"Here Î”_k is a trust region radius, that is adapted every iteration, and mathcal H_k is some symmetric linear operator that approximates the Hessian operatornameHess f of f.","category":"page"},{"location":"solvers/trust_regions/#Interface","page":"Trust-Regions Solver","title":"Interface","text":"","category":"section"},{"location":"solvers/trust_regions/#Manopt.trust_regions","page":"Trust-Regions Solver","title":"Manopt.trust_regions","text":"trust_regions(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ntrust_regions(M, f, grad_f, p=rand(M); kwargs...)\ntrust_regions!(M, f, grad_f, Hess_f, p; kwargs...)\ntrust_regions!(M, f, grad_f, p; kwargs...)\n\nrun the Riemannian trust-regions solver for optimization on manifolds to minimize f, see on [ABG06, CGT00].\n\nFor the case that no Hessian is provided, the Hessian is computed using finite differences, see ApproxHessianFiniteDifference. For solving the inner trust-region subproblem of finding an update-vector, by default the truncated_conjugate_gradient_descent is used.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nacceptance_rate:        accept/reject threshold: if Ï (the performance ratio for the iterate) is at least the acceptance rate Ï', the candidate is accepted. This value should  be between 0 and rac14\naugmentation_threshold=0.75: trust-region augmentation threshold: if Ï is larger than this threshold, a solution is on the trust region boundary and negative curvature, and the radius is extended (augmented)\naugmentation_factor=2.0: trust-region augmentation factor\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎº=0.1: the linear convergence target rate of the tCG method   truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\nmax_trust_region_radius: the maximum trust-region radius\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nÏ_regularization=1e3: regularize the performance evaluation Ï to avoid numerical inaccuracies.\nreduction_factor=0.25: trust-region reduction factor\nreduction_threshold=0.1: trust-region reduction threshold: if Ï is below this threshold, the trust region radius is reduced by reduction_factor.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion=( see truncated_conjugate_gradient_descent): a functor indicating that the stopping criterion is fulfilled\nsub_problem=DefaultManoptProblem(M,ConstrainedManifoldObjective(subcost, subgrad; evaluation=evaluation)):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸ of the tCG-method truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nFor the case that no Hessian is provided, the Hessian is computed using finite difference, see ApproxHessianFiniteDifference.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntruncated_conjugate_gradient_descent\n\n\n\n\n\n","category":"function"},{"location":"solvers/trust_regions/#Manopt.trust_regions!","page":"Trust-Regions Solver","title":"Manopt.trust_regions!","text":"trust_regions(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ntrust_regions(M, f, grad_f, p=rand(M); kwargs...)\ntrust_regions!(M, f, grad_f, Hess_f, p; kwargs...)\ntrust_regions!(M, f, grad_f, p; kwargs...)\n\nrun the Riemannian trust-regions solver for optimization on manifolds to minimize f, see on [ABG06, CGT00].\n\nFor the case that no Hessian is provided, the Hessian is computed using finite differences, see ApproxHessianFiniteDifference. For solving the inner trust-region subproblem of finding an update-vector, by default the truncated_conjugate_gradient_descent is used.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nacceptance_rate:        accept/reject threshold: if Ï (the performance ratio for the iterate) is at least the acceptance rate Ï', the candidate is accepted. This value should  be between 0 and rac14\naugmentation_threshold=0.75: trust-region augmentation threshold: if Ï is larger than this threshold, a solution is on the trust region boundary and negative curvature, and the radius is extended (augmented)\naugmentation_factor=2.0: trust-region augmentation factor\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎº=0.1: the linear convergence target rate of the tCG method   truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\nmax_trust_region_radius: the maximum trust-region radius\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nÏ_regularization=1e3: regularize the performance evaluation Ï to avoid numerical inaccuracies.\nreduction_factor=0.25: trust-region reduction factor\nreduction_threshold=0.1: trust-region reduction threshold: if Ï is below this threshold, the trust region radius is reduced by reduction_factor.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion=( see truncated_conjugate_gradient_descent): a functor indicating that the stopping criterion is fulfilled\nsub_problem=DefaultManoptProblem(M,ConstrainedManifoldObjective(subcost, subgrad; evaluation=evaluation)):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸ of the tCG-method truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nFor the case that no Hessian is provided, the Hessian is computed using finite difference, see ApproxHessianFiniteDifference.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntruncated_conjugate_gradient_descent\n\n\n\n\n\n","category":"function"},{"location":"solvers/trust_regions/#State","page":"Trust-Regions Solver","title":"State","text":"","category":"section"},{"location":"solvers/trust_regions/#Manopt.TrustRegionsState","page":"Trust-Regions Solver","title":"Manopt.TrustRegionsState","text":"TrustRegionsState <: AbstractHessianSolverState\n\nStore the state of the trust-regions solver.\n\nFields\n\nacceptance_rate:         a lower bound of the performance ratio for the iterate that decides if the iteration is accepted or not.\nHX, HY, HZ:          interim storage (to avoid allocation) of `\\operatorname{Hess} f(p)[â‹…] of X, Y, Z\nmax_trust_region_radius: the maximum trust-region radius\np::P: a point on the manifold mathcal Mstoring the current iterate\nproject!:                for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nrandomize:               indicate whether X is initialised to a random vector or not\nÏ_regularization:        regularize the model fitness Ï to avoid division by zero\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nÏƒ:                       Gaussian standard deviation when creating the random initial tangent vector This field has no effect, when randomize is false.\ntrust_region_radius: the trust-region radius\nX::T: a tangent vector at the point p on the manifold mathcal M\nY:                       the solution (tangent vector) of the subsolver\nZ:                       the Cauchy point (only used if random is activated)\n\nConstructors\n\nTrustRegionsState(M, mho::AbstractManifoldHessianObjective; kwargs...)\nTrustRegionsState(M, sub_problem, sub_state; kwargs...)\nTrustRegionsState(M, sub_problem; evaluation=AllocatingEvaluation(), kwargs...)\n\ncreate a trust region state.\n\ngiven a AbstractManifoldHessianObjective mho, the default sub solver, a TruncatedConjugateGradientState with mho used to define the problem on a tangent space is created\ngiven a sub_problem and an evaluation= keyword, the sub problem solver is assumed to be the closed form solution, where evaluation determines how to call the sub function.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nsub_problem:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\nacceptance_rate=0.1\nmax_trust_region_radius=sqrt(manifold_dimension(M))\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nproject!=copyto!\nstopping_criterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nrandomize=false\nÏ_regularization=10000.0\nÎ¸=1.0\ntrust_region_radius=max_trust_region_radius / 8\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nSee also\n\ntrust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Approximation-of-the-Hessian","page":"Trust-Regions Solver","title":"Approximation of the Hessian","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"Several different methods to approximate the Hessian are available.","category":"page"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianFiniteDifference","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianFiniteDifference","text":"ApproxHessianFiniteDifference{E, P, T, G, RTR, VTR, R <: Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by a finite difference of gradient evaluation.\n\nGiven a point p and a direction X and the gradient operatornamegrad f(p) of a function f the Hessian is approximated as follows: let c be a stepsize, X  T_pmathcal M a tangent vector and q = operatornameretr_p(fracclVert X rVert_pX) be a step in direction X of length c following a retraction Then the Hessian is approximated by the finite difference of the gradients, where mathcal T_ is a vector transport.\n\noperatornameHessf(p)X \nfraclVert X rVert_pcBigl(\n  mathcal T_pgets qbigr(operatornamegradf(q)bigl) - operatornamegradf(p)\nBigl)\n\nFields\n\ngradient!!:              the gradient function (either allocating or mutating, see evaluation parameter)\nstep_length:             a step length for the finite difference\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nInternal temporary fields\n\ngrad_tmp:     a temporary storage for the gradient at the current p\ngrad_dir_tmp: a temporary storage for the gradient at the current p_dir\np_dir::P:     a temporary storage to the forward direction (or the q in the formula)\n\nConstructor\n\nApproximateFiniteDifference(M, p, grad_f; kwargs...)\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nsteplength=2^{-14} step lengthc`` to approximate the gradient evaluations\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianSymmetricRankOne","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianSymmetricRankOne","text":"ApproxHessianSymmetricRankOne{E, P, G, T, B<:AbstractBasis{â„}, VTR, R<:Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by the symmetric rank one update.\n\nFields\n\ngradient!!: the gradient function (either allocating or mutating, see evaluation parameter).\nÎ½: a small real number to ensure that the denominator in the update does not become too small and thus the method does not break down.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports.\n\nInternal temporary fields\n\np_tmp: a temporary storage the current point p.\ngrad_tmp: a temporary storage for the gradient at the current p.\nmatrix: a temporary storage for the matrix representation of the approximating operator.\nbasis: a temporary storage for an orthonormal basis at the current p.\n\nConstructor\n\nApproxHessianSymmetricRankOne(M, p, gradF; kwargs...)\n\nKeyword arguments\n\ninitial_operator (Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M))) the matrix representation of the initial approximating operator.\nbasis (DefaultOrthonormalBasis()) an orthonormal basis in the tangent space of the initial iterate p.\nnu (-1)\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianBFGS","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianBFGS","text":"ApproxHessianBFGS{E, P, G, T, B<:AbstractBasis{â„}, VTR, R<:Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by the BFGS update.\n\nFields\n\ngradient!! the gradient function (either allocating or mutating, see evaluation parameter).\nscale\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nInternal temporary fields\n\np_tmp a temporary storage the current point p.\ngrad_tmp a temporary storage for the gradient at the current p.\nmatrix a temporary storage for the matrix representation of the approximating operator.\nbasis a temporary storage for an orthonormal basis at the current p.\n\nConstructor\n\nApproxHessianBFGS(M, p, gradF; kwargs...)\n\nKeyword arguments\n\ninitial_operator (Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M))) the matrix representation of the initial approximating operator.\nbasis (DefaultOrthonormalBasis()) an orthonormal basis in the tangent space of the initial iterate p.\nnu (-1)\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"as well as their (non-exported) common supertype","category":"page"},{"location":"solvers/trust_regions/#Manopt.AbstractApproxHessian","page":"Trust-Regions Solver","title":"Manopt.AbstractApproxHessian","text":"AbstractApproxHessian <: Function\n\nAn abstract supertype for approximate Hessian functions, declares them also to be functions.\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#sec-tr-technical-details","page":"Trust-Regions Solver","title":"Technical details","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"The trust_regions solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nif you do not provide an initial max_trust_region_radius, a manifold_dimension is required.\nA copyto!(M, q, p) and copy(M,p) for points.\nBy default the tangent vectors are initialized calling zero_vector(M,p).","category":"page"},{"location":"solvers/trust_regions/#Literature","page":"Trust-Regions Solver","title":"Literature","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"P.-A.Â Absil, C.Â Baker and K.Â Gallivan. Trust-Region Methods on Riemannian Manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 7, 303â€“330 (2006).\n\n\n\nA.Â R.Â Conn, N.Â I.Â Gould and P.Â L.Â Toint. Trust Region Methods (Society for Industrial and Applied Mathematics, 2000).\n\n\n\n","category":"page"},{"location":"plans/debug/#sec-debug","page":"Debug Output","title":"Debug output","text":"","category":"section"},{"location":"plans/debug/","page":"Debug Output","title":"Debug Output","text":"Debug output can easily be added to any solver run. On the high level interfaces, like gradient_descent, you can just use the debug= keyword.","category":"page"},{"location":"plans/debug/#Manopt.DebugAction","page":"Debug Output","title":"Manopt.DebugAction","text":"DebugAction\n\nA DebugAction is a small functor to print/issue debug output. The usual call is given by (p::AbstractManoptProblem, s::AbstractManoptSolverState, k) -> s, where i is the current iterate.\n\nBy convention i=0 is interpreted as \"For Initialization only,\" only debug info that prints initialization reacts, i<0 triggers updates of variables internally but does not trigger any output.\n\nFields (assumed by subtypes to exist)\n\nprint method to perform the actual print. Can for example be set to a file export,\n\nor to @info. The default is the print function on the default Base.stdout.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugChange","page":"Debug Output","title":"Manopt.DebugChange","text":"DebugChange(M=DefaultManifold(); kwargs...)\n\ndebug for the amount of change of the iterate (stored in get_iterate(o) of the AbstractManoptSolverState) during the last iteration. See DebugEntryChange for the general case\n\nKeyword parameters\n\nstorage=StoreStateAction( [:Gradient] ) storage of the previous action\nprefix=\"Last Change:\": prefix of the debug output (ignored if you set format)\nio=stdout: default stream to print the debug to.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nthe inverse retraction   to be used for approximating distance.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugCost","page":"Debug Output","title":"Manopt.DebugCost","text":"DebugCost <: DebugAction\n\nprint the current cost function value, see get_cost.\n\nConstructors\n\nDebugCost()\n\nParameters\n\nformat=\"$prefix %f\": format to print the output\nio=stdout: default stream to print the debug to.\nlong=false: short form to set the format to f(x): (default) or current cost: and the cost\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugDivider","page":"Debug Output","title":"Manopt.DebugDivider","text":"DebugDivider <: DebugAction\n\nprint a small divider (default \" | \").\n\nConstructor\n\nDebugDivider(div,print)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEntry","page":"Debug Output","title":"Manopt.DebugEntry","text":"DebugEntry <: DebugAction\n\nprint a certain fields entry during the iterates, where a format can be specified how to print the entry.\n\nAdditional fields\n\nfield: symbol the entry can be accessed with within AbstractManoptSolverState\n\nConstructor\n\nDebugEntry(f; prefix=\"$f:\", format = \"$prefix %s\", io=stdout)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEntryChange","page":"Debug Output","title":"Manopt.DebugEntryChange","text":"DebugEntryChange{T} <: DebugAction\n\nprint a certain entries change during iterates\n\nAdditional fields\n\nprint:    function to print the result\nprefix:   prefix to the print out\nformat:   format to print (uses the prefix by default and scientific notation)\nfield:    Symbol the field can be accessed with within AbstractManoptSolverState\ndistance: function (p,o,x1,x2) to compute the change/distance between two values of the entry\nstorage:  a StoreStateAction to store the previous value of :f\n\nConstructors\n\nDebugEntryChange(f,d)\n\nKeyword arguments\n\nio=stdout:                      an IOStream used for the debug\nprefix=\"Change of $f\":          the prefix\nstorage=StoreStateAction((f,)): a StoreStateAction\ninitial_value=NaN:              an initial value for the change of o.field.\nformat=\"$prefix %e\":            format to print the change\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEvery","page":"Debug Output","title":"Manopt.DebugEvery","text":"DebugEvery <: DebugAction\n\nevaluate and print debug only every kth iteration. Otherwise no print is performed. Whether internal variables are updates is determined by always_update.\n\nThis method does not perform any print itself but relies on it's children's print.\n\nIt also sets the sub solvers active parameter, see |DebugWhenActive}(#ref). Here, the activattion_offset can be used to specify whether it refers to this iteration, the ith, when this call is before the iteration, then the offset should be 0, for the next iteration, that is if this is called after an iteration, it has to be set to 1. Since usual debug is happening after the iteration, 1 is the default.\n\nConstructor\n\nDebugEvery(d::DebugAction, every=1, always_update=true, activation_offset=1)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugFeasibility","page":"Debug Output","title":"Manopt.DebugFeasibility","text":"DebugFeasibility <: DebugAction\n\nDisplay information about the feasibility of the current iterate\n\nFields\n\natol:   absolute tolerance for when either equality or inequality constraints are counted as violated\nformat: a vector of symbols and string formatting the output\nio:     default stream to print the debug to.\n\nThe following symbols are filled with values\n\n:Feasbile display true or false depending on whether the iterate is feasible\n:FeasbileEq display = or â‰  equality constraints are fulfilled or not\n:FeasbileInEq display â‰¤ or â‰° inequality constraints are fulfilled or not\n:NumEq display the number of equality constraints infeasible\n:NumEqNz display the number of equality constraints infeasible if exists\n:NumIneq display the number of inequality constraints infeasible\n:NumIneqNz display the number of inequality constraints infeasible if exists\n:TotalEq display the sum of how much the equality constraints are violated\n:TotalInEq display the sum of how much the inequality constraints are violated\n\nformat to print the output.\n\nConstructor\n\nDebugFeasibility(     format=[\"feasible: \", :Feasible];     io::IO=stdout,     atol=1e-13 )\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugGradientChange","page":"Debug Output","title":"Manopt.DebugGradientChange","text":"DebugGradientChange()\n\ndebug for the amount of change of the gradient (stored in get_gradient(o) of the AbstractManoptSolverState o) during the last iteration. See DebugEntryChange for the general case\n\nKeyword parameters\n\nstorage=StoreStateAction( (:Gradient,) ): storage of the action for previous data\nprefix=\"Last Change:\": prefix of the debug output (ignored if you set format:\nio=stdout: default stream to print the debug to.\nformat=\"$prefix %f\": format to print the output\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugGroup","page":"Debug Output","title":"Manopt.DebugGroup","text":"DebugGroup <: DebugAction\n\ngroup a set of DebugActions into one action, where the internal prints are removed by default and the resulting strings are concatenated\n\nConstructor\n\nDebugGroup(g)\n\nconstruct a group consisting of an Array of DebugActions g, that are evaluated en bloque; the method does not perform any print itself, but relies on the internal prints. It still concatenates the result and returns the complete string\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIfEntry","page":"Debug Output","title":"Manopt.DebugIfEntry","text":"DebugIfEntry <: DebugAction\n\nIssue a warning, info, or error if a certain field does not pass a the check.\n\nThe message is printed in this case. If it contains a @printf argument identifier, that one is filled with the value of the field. That way you can print the value in this case as well.\n\nFields\n\nio:    an IO stream\ncheck: a function that takes the value of the field as input and returns a boolean\nfield: symbol the entry can be accessed with within AbstractManoptSolverState\nmsg:   if the check fails, this message is displayed\ntype: symbol specifying the type of display, possible values :print, : warn, :info, :error,           where :print prints to io.\n\nConstructor\n\nDebugEntry(field, check=(>(0)); type=:warn, message=\":$f is nonnegative\", io=stdout)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIterate","page":"Debug Output","title":"Manopt.DebugIterate","text":"DebugIterate <: DebugAction\n\ndebug for the current iterate (stored in get_iterate(o)).\n\nConstructor\n\nDebugIterate(; kwargs...)\n\nKeyword arguments\n\nio=stdout:           default stream to print the debug to.\nformat=\"$prefix %s\": format how to print the current iterate\nlong=false:          whether to have a long (\"current iterate:\") or a short (\"p:\") prefix default\nprefix:              (see long for default) set a prefix to be printed before the iterate\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIteration","page":"Debug Output","title":"Manopt.DebugIteration","text":"DebugIteration <: DebugAction\n\nConstructor\n\nDebugIteration()\n\nKeyword parameters\n\nformat=\"# %-6d\": format to print the output\nio=stdout: default stream to print the debug to.\n\ndebug for the current iteration (prefixed with # by )\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugMessages","page":"Debug Output","title":"Manopt.DebugMessages","text":"DebugMessages <: DebugAction\n\nAn AbstractManoptSolverState or one of its sub steps like a Stepsize might generate warnings throughout their computations. This debug can be used to :print them display them as :info or :warnings or even :error, depending on the message type.\n\nConstructor\n\nDebugMessages(mode=:Info, warn=:Once; io::IO=stdout)\n\nInitialize the messages debug to a certain mode. Available modes are\n\n:Error:   issue the messages as an error and hence stop at any issue occurring\n:Info:    issue the messages as an @info\n:Print:   print messages to the steam io.\n:Warning: issue the messages as a warning\n\nThe warn level can be set to :Once to only display only the first message, to :Always to report every message, one can set it to :No, to deactivate this, then this DebugAction is inactive. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugSolverState","page":"Debug Output","title":"Manopt.DebugSolverState","text":"DebugSolverState <: AbstractManoptSolverState\n\nThe debug state appends debug to any state, they act as a decorator pattern. Internally a dictionary is kept that stores a DebugAction for several occasions using a Symbol as reference.\n\nThe original options can still be accessed using the get_state function.\n\nFields\n\noptions:         the options that are extended by debug information\ndebugDictionary: a Dict{Symbol,DebugAction} to keep track of Debug for different actions\n\nConstructors\n\nDebugSolverState(o,dA)\n\nconstruct debug decorated options, where dD can be\n\na DebugAction, then it is stored within the dictionary at :Iteration\nan Array of DebugActions.\na Dict{Symbol,DebugAction}.\nan Array of Symbols, String and an Int for the DebugFactory\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugStoppingCriterion","page":"Debug Output","title":"Manopt.DebugStoppingCriterion","text":"DebugStoppingCriterion <: DebugAction\n\nprint the Reason provided by the stopping criterion. Usually this should be empty, unless the algorithm stops.\n\nFields\n\nprefix=\"\": format to print the output\nio=stdout: default stream to print the debug to.\n\nConstructor\n\nDebugStoppingCriterion(prefix = \"\"; io::IO=stdout)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugTime","page":"Debug Output","title":"Manopt.DebugTime","text":"DebugTime()\n\nMeasure time and print the intervals. Using start=true you can start the timer on construction, for example to measure the runtime of an algorithm overall (adding)\n\nThe measured time is rounded using the given time_accuracy and printed after canonicalization.\n\nKeyword parameters\n\nio=stdout:             default stream to print the debug to.\nformat=\"$prefix %s\":   format to print the output, where %s is the canonicalized time`.\nmode=:cumulative:      whether to display the total time or reset on every call using :iterative.\nprefix=\"Last Change:\": prefix of the debug output (ignored if you set format:\nstart=false:           indicate whether to start the timer on creation or not.  Otherwise it might only be started on first call.\ntime_accuracy=Millisecond(1): round the time to this period before printing the canonicalized time\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfCostIncreases","page":"Debug Output","title":"Manopt.DebugWarnIfCostIncreases","text":"DebugWarnIfCostIncreases <: DebugAction\n\nprint a warning if the cost increases.\n\nNote that this provides an additional warning for gradient descent with its default constant step size.\n\nConstructor\n\nDebugWarnIfCostIncreases(warn=:Once; tol=1e-13)\n\nInitialize the warning to warning level (:Once) and introduce a tolerance for the test of 1e-13.\n\nThe warn level can be set to :Once to only warn the first time the cost increases, to :Always to report an increase every time it happens, and it can be set to :No to deactivate the warning, then this DebugAction is inactive. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfCostNotFinite","page":"Debug Output","title":"Manopt.DebugWarnIfCostNotFinite","text":"DebugWarnIfCostNotFinite <: DebugAction\n\nA debug to see when a field (value or array within the AbstractManoptSolverState is or contains values that are not finite, for example Inf or Nan.\n\nConstructor\n\nDebugWarnIfCostNotFinite(field::Symbol, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfFieldNotFinite","page":"Debug Output","title":"Manopt.DebugWarnIfFieldNotFinite","text":"DebugWarnIfFieldNotFinite <: DebugAction\n\nA debug to see when a field from the options is not finite, for example Inf or Nan\n\nConstructor\n\nDebugWarnIfFieldNotFinite(field::Symbol, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\nExample\n\nDebugWaranIfFieldNotFinite(:Gradient)\n\nCreates a [DebugAction] to track whether the gradient does not get Nan or Inf.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfGradientNormTooLarge","page":"Debug Output","title":"Manopt.DebugWarnIfGradientNormTooLarge","text":"DebugWarnIfGradientNormTooLarge{T} <: DebugAction\n\nA debug to warn when an evaluated gradient at the current iterate is larger than (a factor times) the maximal (recommended) stepsize at the current iterate.\n\nConstructor\n\nDebugWarnIfGradientNormTooLarge(factor::T=1.0, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\nExample\n\nDebugWaranIfFieldNotFinite(:Gradient)\n\nCreates a [DebugAction] to track whether the gradient does not get Nan or Inf.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWhenActive","page":"Debug Output","title":"Manopt.DebugWhenActive","text":"DebugWhenActive <: DebugAction\n\nevaluate and print debug only if the active boolean is set. This can be set from outside and is for example triggered by DebugEvery on debugs on the subsolver.\n\nThis method does not perform any print itself but relies on it's children's prints.\n\nFor now, the main interaction is with DebugEvery which might activate or deactivate this debug\n\nFields\n\nactive:        a boolean that can (de-)activated from outside to turn on/off debug\nalways_update: whether or not to call the order debugs with iteration <=0 inactive state\n\nConstructor\n\nDebugWhenActive(d::DebugAction, active=true, always_update=true)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{String}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(s)\n\ncreate a DebugAction where\n\na Stringyields the corresponding divider\na DebugAction is passed through\na [Symbol] creates DebugEntry of that symbol, with the exceptions of :Change, :Iterate, :Iteration, and :Cost.\na Tuple{Symbol,String} creates a DebugEntry of that symbol where the String specifies the format.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{Symbol}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(s::Symbol)\n\nConvert certain Symbols in the debug=[ ... ] vector to DebugActions Currently the following ones are done. Note that the Shortcut symbols should all start with a capital letter.\n\n:Cost creates a DebugCost\n:Change creates a DebugChange\n:Gradient creates a DebugGradient\n:GradientChange creates a DebugGradientChange\n:GradientNorm creates a DebugGradientNorm\n:Iterate creates a DebugIterate\n:Iteration creates a DebugIteration\n:IterativeTime creates a DebugTime(:Iterative)\n:Stepsize creates a DebugStepsize\n:Stop creates a StoppingCriterion()\n:WarnCost creates a DebugWarnIfCostNotFinite\n:WarnGradient creates a DebugWarnIfFieldNotFinite for the ::Gradient.\n:WarnBundle creates a DebugWarnIfLagrangeMultiplierIncreases\n:Time creates a DebugTime\n:WarningMessages creates a DebugMessages(:Warning)\n:InfoMessages creates a DebugMessages(:Info)\n:ErrorMessages creates a DebugMessages(:Error)\n:Messages creates a DebugMessages() (the same as :InfoMessages)\n\nany other symbol creates a DebugEntry(s) to print the entry (o.:s) from the options.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{Tuple{Symbol, Any}}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(t::Tuple{Symbol,String)\n\nConvert certain Symbols in the debug=[ ... ] vector to DebugActions Currently the following ones are done, where the string in t[2] is passed as the format the corresponding debug. Note that the Shortcut symbols t[1] should all start with a capital letter.\n\n:Change creates a DebugChange\n:Cost creates a DebugCost\n:Gradient creates a DebugGradient\n:GradientChange creates a DebugGradientChange\n:GradientNorm creates a DebugGradientNorm\n:Iterate creates a DebugIterate\n:Iteration creates a DebugIteration\n:Stepsize creates a DebugStepsize\n:Stop creates a DebugStoppingCriterion\n:Time creates a DebugTime\n:IterativeTime creates a DebugTime(:Iterative)\n\nany other symbol creates a DebugEntry(s) to print the entry (o.:s) from the options.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugFactory-Tuple{Vector}","page":"Debug Output","title":"Manopt.DebugFactory","text":"DebugFactory(a::Vector)\n\nGenerate a dictionary of DebugActions.\n\nFirst all Symbols String, DebugActions and numbers are collected, excluding :Stop and :WhenActive. This collected vector is added to the :Iteration => [...] pair. :Stop is added as :StoppingCriterion to the :Stop => [...] pair. If necessary, these pairs are created\n\nFor each Pair of a Symbol and a Vector, the DebugGroupFactory is called for the Vector and the result is added to the debug dictionary's entry with said symbol. This is wrapped into the DebugWhenActive, when the :WhenActive symbol is present\n\nReturn value\n\nA dictionary for the different enrty points where debug can happen, each containing a DebugAction to call.\n\nNote that upon the initialisation all dictionaries but the :StartAlgorithm one are called with an i=0 for reset.\n\nExamples\n\nProviding a simple vector of symbols, numbers and strings like\n[:Iterate, \" | \", :Cost, :Stop, 10]\nAdds a group to :Iteration of three actions (DebugIteration, DebugDivider(\" | \"),  and[DebugCost](@ref)) as a [DebugGroup](@ref) inside an [DebugEvery](@ref) to only be executed every 10th iteration. It also adds the [DebugStoppingCriterion](@ref) to the:EndAlgorithm` entry of the dictionary.\nThe same can also be written a bit more precise as\nDebugFactory([:Iteration => [:Iterate, \" | \", :Cost, 10], :Stop])\nWe can even make the stoping criterion concrete and pass Actions directly, for example explicitly Making the stop more concrete, we get\nDebugFactory([:Iteration => [:Iterate, \" | \", DebugCost(), 10], :Stop => [:Stop]])\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugGroupFactory-Tuple{Vector}","page":"Debug Output","title":"Manopt.DebugGroupFactory","text":"DebugGroupFactory(a::Vector)\n\nGenerate a DebugGroup of DebugActions. The following rules are used\n\nAny Symbol is passed to DebugActionFactory\nAny (Symbol, String) generates similar actions as in 1., but the string is used for format=, see DebugActionFactory\nAny String is passed to DebugActionFactory\nAny DebugAction is included as is.\n\nIf this results in more than one DebugAction a DebugGroup of these is build.\n\nIf any integers are present, the last of these is used to wrap the group in a DebugEvery(k).\n\nIf :WhenActive is present, the resulting Action is wrapped in DebugWhenActive, making it deactivatable by its parent solver.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.reset!-Tuple{DebugTime}","page":"Debug Output","title":"Manopt.reset!","text":"reset!(d::DebugTime)\n\nreset the internal time of a DebugTime, that is start from now again.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.set_parameter!-Tuple{DebugSolverState, Val{:Debug}, Vararg{Any}}","page":"Debug Output","title":"Manopt.set_parameter!","text":"set_parameter!(ams::DebugSolverState, ::Val{:Debug}, args...)\n\nSet certain values specified by args... into the elements of the debugDictionary\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.stop!-Tuple{DebugTime}","page":"Debug Output","title":"Manopt.stop!","text":"stop!(d::DebugTime)\n\nstop the reset the internal time of a DebugTime, that is set the time to 0 (undefined)\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Technical-details","page":"Debug Output","title":"Technical details","text":"","category":"section"},{"location":"plans/debug/","page":"Debug Output","title":"Debug Output","text":"The decorator to print debug during the iterations can be activated by decorating the state of a solver and implementing your own DebugActions. For example printing a gradient from the GradientDescentState is automatically available, as explained in the gradient_descent solver.","category":"page"},{"location":"plans/debug/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, DebugSolverState}","page":"Debug Output","title":"Manopt.initialize_solver!","text":"initialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState)\n\nExtend the initialization of the solver by a hook to run the DebugAction that was added to the :Start entry of the debug lists. All others are triggered (with iteration number 0) to trigger possible resets\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.step_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Any}","page":"Debug Output","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, k)\n\nExtend the ith step of the solver by a hook to run debug prints, that were added to the :BeforeIteration and :Iteration entries of the debug lists.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Int64}","page":"Debug Output","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, k)\n\nExtend the stop_solver!, whether to stop the solver by a hook to run debug, that were added to the :Stop entry of the debug lists.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Stepsize","page":"Stepsize","title":"Stepsize and line search","text":"","category":"section"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Most iterative algorithms determine a direction along which the algorithm shall proceed and determine a step size to find the next iterate. How advanced the step size computation can be implemented depends (among others) on the properties the corresponding problem provides.","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Within Manopt.jl, the step size determination is implemented as a functor which is a subtype of Stepsize based on","category":"page"},{"location":"plans/stepsize/#Manopt.Stepsize","page":"Stepsize","title":"Manopt.Stepsize","text":"Stepsize\n\nAn abstract type for the functors representing step sizes. These are callable structures. The naming scheme is TypeOfStepSize, for example ConstantStepsize.\n\nEvery Stepsize has to provide a constructor and its function has to have the interface (p,o,i) where a AbstractManoptProblem as well as AbstractManoptSolverState and the current number of iterations are the arguments and returns a number, namely the stepsize to use.\n\nFor most it is adviable to employ a ManifoldDefaultsFactory. Then the function creating the factory should either be called TypeOf or if that is confusing or too generic, TypeOfLength\n\nSee also\n\nLinesearch\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Usually, a constructor should take the manifold M as its first argument, for consistency, to allow general step size functors to be set up based on default values that might depend on the manifold currently under consideration.","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Currently, the following step sizes are available","category":"page"},{"location":"plans/stepsize/#Manopt.AdaptiveWNGradient","page":"Stepsize","title":"Manopt.AdaptiveWNGradient","text":"AdaptiveWNGradient(; kwargs...)\nAdaptiveWNGradient(M::AbstractManifold; kwargs...)\n\nA stepsize based on the adaptive gradient method introduced by [GS23].\n\nGiven a positive threshold hatc  â„•, an minimal bound b_textmin  0, an initial b_0  b_textmin, and a gradient reduction factor threshold Î±  01).\n\nSet c_0=0 and use Ï‰_0 = lVert operatornamegrad f(p_0) rVert_p_0.\n\nFor the first iterate use the initial step size s_0 = frac1b_0.\n\nThen, given the last gradient X_k-1 = operatornamegrad f(x_k-1), and a previous Ï‰_k-1, the values (b_k Ï‰_k c_k) are computed using X_k = operatornamegrad f(p_k) and the following cases\n\nIf lVert X_k rVert_p_k  Î±Ï‰_k-1, then let hatb_k-1  b_textminb_k-1 and set\n\n(b_k Ï‰_k c_k) = begincases   bigl(hatb_k-1 lVert X_k rVert_p_k 0 bigr)  text if  c_k-1+1 = hatc    bigl( b_k-1 + fraclVert X_k rVert_p_k^2b_k-1 Ï‰_k-1 c_k-1+1 Bigr)  text if  c_k-1+1hatcendcases\n\nIf lVert X_k rVert_p_k  Î±Ï‰_k-1, the set\n\n(b_k Ï‰_k c_k) = Bigl( b_k-1 + fraclVert X_k rVert_p_k^2b_k-1 Ï‰_k-1 0 Bigr)\n\nand return the step size s_k = frac1b_k.\n\nNote that for Î±=0 this is the Riemannian variant of WNGRad.\n\nKeyword arguments\n\nadaptive=true: switches the gradient_reductionÎ±(iftrue) to0`.\nalternate_bound = (bk, hat_c) ->  min(gradient_bound == 0 ? 1.0 : gradient_bound, max(minimal_bound, bk / (3 * hat_c)): how to determine hatk_k as a function of (bmin, bk, hat_c) -> hat_bk\ncount_threshold=4:  an Integer for hatc\ngradient_reduction::R=adaptive ? 0.9 : 0.0: the gradient reduction factor threshold Î±  01)\ngradient_bound=norm(M, p, X): the bound b_k.\nminimal_bound=1e-4: the value b_textmin\np=rand(M): a point on the manifold mathcal Monly used to define the gradient_bound\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Monly used to define the gradient_bound\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.ArmijoLinesearch","page":"Stepsize","title":"Manopt.ArmijoLinesearch","text":"ArmijoLinesearch(; kwargs...)\nArmijoLinesearch(M::AbstractManifold; kwargs...)\n\nSpecify a step size that performs an Armijo line search. Given a Function fmathcal Mâ„ and its Riemannian Gradient operatornamegradf mathcal MTmathcal M, the curent point pmathcal M and a search direction XT_pmathcal M.\n\nThen the step size s is found by reducing the initial step size s until\n\nf(operatornameretr_p(sX))  f(p) - Ï„s  X operatornamegradf(p) _p\n\nis fulfilled. for a sufficient decrease value Ï„  (01).\n\nTo be a bit more optimistic, if s already fulfils this, a first search is done, increasing the given s until for a first time this step does not hold.\n\nOverall, we look for step size, that provides enough decrease, see [Bou23, p. 58] for more information.\n\nKeyword arguments\n\nadditional_decrease_condition=(M, p) -> true: specify an additional criterion that has to be met to accept a step size in the decreasing loop\nadditional_increase_condition::IF=(M, p) -> true: specify an additional criterion that has to be met to accept a step size in the (initial) increase loop\ncandidate_point=allocate_result(M, rand): speciy a point to be used as memory for the candidate points.\ncontraction_factor=0.95: how to update s in the decrease step\ninitial_stepsize=1.0`: specify an initial step size\ninitial_guess=armijo_initial_guess: Compute the initial step size of a line search based on this function. The funtion required is (p,s,k,l) -> Î± and computes the initial step size Î± based on a AbstractManoptProblem p, AbstractManoptSolverState s, the current iterate k and a last step size l.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: a safeguard, stop when the decreasing step is below this (nonnegative) bound.\nstop_when_stepsize_exceeds=max_stepsize(M): a safeguard to not choose a too long step size when initially increasing\nstop_increasing_at_step=100: stop the initial increasing loop after this amount of steps. Set to 0 to never increase in the beginning\nstop_decreasing_at_step=1000: maximal number of Armijo decreases / tests to perform\nsufficient_decrease=0.1: the sufficient decrease parameter Ï„\n\nFor the stop safe guards you can pass :Messages to a debug= to see @info messages when these happen.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ArmijoLinesearchStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.ConstantLength","page":"Stepsize","title":"Manopt.ConstantLength","text":"ConstantLength(s; kwargs...)\nConstantLength(M::AbstractManifold, s; kwargs...)\n\nSpecify a Stepsize that is constant.\n\nInput\n\nM (optional)\n\ns=min( injectivity_radius(M)/2, 1.0) : the length to use.\n\nKeyword argument\n\ntype::Symbol=relative specify the type of constant step size.\n:relative â€“ scale the gradient tangent vector X to s*X\n:absolute â€“ scale the gradient to an absolute step length s, that is fracslVert X rVert_X\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ConstantStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.DecreasingLength","page":"Stepsize","title":"Manopt.DecreasingLength","text":"DegreasingLength(; kwargs...)\nDecreasingLength(M::AbstractManifold; kwargs...)\n\nSpecify a [Stepsize]  that is decreasing as ``s_k = \\frac{(l - ak)f^i}{(k+s)^e} with the following\n\nKeyword arguments\n\nexponent=1.0:   the exponent e in the denominator\nfactor=1.0:     the factor f in the nominator\nlength=min(injectivity_radius(M)/2, 1.0): the initial step size l.\nsubtrahend=0.0: a value a that is subtracted every iteration\nshift=0.0:      shift the denominator iterator k by s.\ntype::Symbol=relative specify the type of constant step size.\n:relative â€“ scale the gradient tangent vector X to s_k*X\n:absolute â€“ scale the gradient to an absolute step length s_k, that is fracs_klVert X rVert_X\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for DecreasingStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.NonmonotoneLinesearch","page":"Stepsize","title":"Manopt.NonmonotoneLinesearch","text":"NonmonotoneLinesearch(; kwargs...)\nNonmonotoneLinesearch(M::AbstractManifold; kwargs...)\n\nA functor representing a nonmonotone line search using the Barzilai-Borwein step size [IP17].\n\nThis method first computes\n\n(x -> p, F-> f)\n\ny_k = operatornamegradf(p_k) - mathcal T_p_kp_k-1operatornamegradf(p_k-1)\n\nand\n\ns_k = - Î±_k-1  mathcal T_p_kp_k-1operatornamegradf(p_k-1)\n\nwhere Î±_k-1 is the step size computed in the last iteration and mathcal T_ is a vector transport. Then the Barzilaiâ€”Borwein step size is\n\nÎ±_k^textBB = begincases   min(Î±_textmax max(Î±_textmin Ï„_k))  textif s_k y_k_p_k  0    Î±_textmax  textelseendcases\n\nwhere\n\nÏ„_k = fracs_k s_k_p_ks_k y_k_p_k\n\nif the direct strategy is chosen, or\n\nÏ„_k =  fracs_k y_k_p_ky_k y_k_p_k\n\nin case of the inverse strategy or an alternation between the two in cases for the alternating strategy. Then find the smallest h = 0 1 2  such that\n\nf(operatornameretr_p_k(- Ïƒ^h Î±_k^textBB operatornamegradf(p_k)))  \nmax_1  j  max(k+1m) f(p_k+1-j) - Î³ Ïƒ^h Î±_k^textBB operatornamegradF(p_k) operatornamegradF(p_k)_p_k\n\nwhere Ïƒ  (01) is a step length reduction factor , m is the number of iterations after which the function value has to be lower than the current one and Î³  (01) is the sufficient decrease parameter. Finally the step size is computed as\n\nÎ±_k = Ïƒ^h Î±_k^textBB\n\nKeyword arguments\n\np=rand(M): a point on the manifold mathcal Mto store an interim result\np=allocate_result(M, rand): to store an interim result\ninitial_stepsize=1.0: the step size to start the search with\nmemory_size=10: number of iterations after which the cost value needs to be lower than the current one\nbb_min_stepsize=1e-3: lower bound for the Barzilai-Borwein step size greater than zero\nbb_max_stepsize=1e3: upper bound for the Barzilai-Borwein step size greater than min_stepsize\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstrategy=direct: defines if the new step size is computed using the :direct, :indirect or :alternating strategy\nstorage=StoreStateAction(M; store_fields=[:Iterate, :Gradient]): increase efficiency by using a StoreStateAction for :Iterate and :Gradient.\nstepsize_reduction=0.5:  step size reduction factor contained in the interval (01)\nsufficient_decrease=1e-4: sufficient decrease parameter contained in the interval (01)\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds=max_stepsize(M, p)): largest stepsize when to stop to avoid leaving the injectivity radius\nstop_increasing_at_step=100:  last step to increase the stepsize (phase 1),\nstop_decreasing_at_step=1000: last step size to decrease the stepsize (phase 2),\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.Polyak","page":"Stepsize","title":"Manopt.Polyak","text":"Polyak(; kwargs...)\nPolyak(M::AbstractManifold; kwargs...)\n\nCompute a step size according to a method propsed by Polyak, cf. the Dynamic step size discussed in Section 3.2 of [Ber15]. This has been generalised here to both the Riemannian case and to approximate the minimum cost value.\n\nLet f_textbest be the best cost value seen until now during some iterative optimisation algorithm and let Î³_k be a sequence of numbers that is square summable, but not summable.\n\nThen the step size computed here reads\n\ns_k = fracf(p^(k)) - f_textbest + Î³_klVert f(p^(k)) rVert_\n\nwhere f denotes a nonzero-subgradient of f at the current iterate p^(k).\n\nConstructor\n\nPolyak(; Î³ = k -> 1/k, initial_cost_estimate=0.0)\n\ninitialize the Polyak stepsize to a certain sequence and an initial estimate of f_\textbest.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for PolyakStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.WolfePowellLinesearch","page":"Stepsize","title":"Manopt.WolfePowellLinesearch","text":"WolfePowellLinesearch(; kwargs...)\nWolfePowellLinesearch(M::AbstractManifold; kwargs...)\n\nPerform a lineseach to fulfull both the Armijo-Goldstein conditions\n\nfbigl( operatornameretr_p(Î±X) bigr)  f(p) + c_1 Î±_k operatornamegrad f(p) X_p\n\nas well as the Wolfe conditions\n\nfracmathrmdmathrmdt fbigl(operatornameretr_p(tX)bigr)\nBigvert_t=Î±\n c_2 fracmathrmdmathrmdt fbigl(operatornameretr_p(tX)bigr)Bigvert_t=0\n\nfor some given sufficient decrease coefficient c_1 and some sufficient curvature condition coefficientc_2.\n\nThis is adopted from [NW06, Section 3.1]\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\np::P: a point on the manifold mathcal Mas temporary storage for candidates\nX::T: a tangent vector at the point p on the manifold mathcal Mas type of memory allocated for the candidates direction and tangent\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.WolfePowellBinaryLinesearch","page":"Stepsize","title":"Manopt.WolfePowellBinaryLinesearch","text":"WolfePowellBinaryLinesearch(; kwargs...)\nWolfePowellBinaryLinesearch(M::AbstractManifold; kwargs...)\n\nPerform a lineseach to fulfull both the Armijo-Goldstein conditions for some given sufficient decrease coefficient c_1 and some sufficient curvature condition coefficientc_2. Compared to WolfePowellLinesearch which tries a simpler method, this linesearch performs the following algorithm\n\nWith\n\nA(t) = f(p_+)  c_1 t operatornamegradf(p) X_x\nquadtext and quad\nW(t) = operatornamegradf(x_+) mathcal T_p_+pX_p_+  c_2 X operatornamegradf(x)_x\n\nwhere p_+ =operatornameretr_p(tX) is the current trial point, and mathcal T_ denotes a vector transport. Then the following Algorithm is performed similar to Algorithm 7 from [Hua14]\n\nset Î±=0, Î²= and t=1.\nWhile either A(t) does not hold or W(t) does not hold do steps 3-5.\nIf A(t) fails, set Î²=t.\nIf A(t) holds but W(t) fails, set Î±=t.\nIf Î² set t=fracÎ±+Î²2, otherwise set t=2Î±.\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Some step sizes use max_stepsize function as a rough upper estimate for the trust region size. It is by default equal to injectivity radius of the exponential map but in some cases a different value is used. For the FixedRankMatrices manifold an estimate from Manopt is used. Tangent bundle with the Sasaki metric has 0 injectivity radius, so the maximum stepsize of the underlying manifold is used instead. Hyperrectangle also has 0 injectivity radius and an estimate based on maximum of dimensions along each index is used instead. For manifolds with corners, however, a line search capable of handling break points along the projected search direction should be used, and such algorithms do not call max_stepsize.","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Internally these step size functions create a ManifoldDefaultsFactory. Internally these use","category":"page"},{"location":"plans/stepsize/#Manopt.armijo_initial_guess-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Int64, Real}","page":"Stepsize","title":"Manopt.armijo_initial_guess","text":"armijo_initial_guess(mp::AbstractManoptProblem, s::AbstractManoptSolverState, k, l)\n\nInput\n\nmp: the AbstractManoptProblem we are aiminig to minimize\ns:  the AbstractManoptSolverState for the current solver\nk:  the current iteration\nl:  the last step size computed in the previous iteration.\n\nReturn an initial guess for the ArmijoLinesearchStepsize.\n\nThe default provided is based on the max_stepsize(M), which we denote by m. Let further X be the current descent direction with norm n=lVert X rVert_p its length. Then this (default) initial guess returns\n\nl if m is not finite\nmin(l fracmn) otherwise\n\nThis ensures that the initial guess does not yield to large (initial) steps.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{<:AbstractManoptSolverState}}","page":"Stepsize","title":"Manopt.default_stepsize","text":"default_stepsize(M::AbstractManifold, ams::AbstractManoptSolverState)\n\nReturns the default Stepsize functor used when running the solver specified by the AbstractManoptSolverState ams running with an objective on the AbstractManifold M.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_last_stepsize-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Vararg{Any}}","page":"Stepsize","title":"Manopt.get_last_stepsize","text":"get_last_stepsize(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, vars...)\n\nreturn the last computed stepsize stored within AbstractManoptSolverState ams when solving the AbstractManoptProblem amp.\n\nThis method takes into account that ams might be decorated. In case this returns NaN, a concrete call to the stored stepsize is performed. For this, usually, the first of the vars... should be the current iterate.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_last_stepsize-Tuple{Stepsize, Vararg{Any}}","page":"Stepsize","title":"Manopt.get_last_stepsize","text":"get_last_stepsize(::Stepsize, vars...)\n\nreturn the last computed stepsize from within the stepsize. If no last step size is stored, this returns NaN.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_stepsize-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Vararg{Any}}","page":"Stepsize","title":"Manopt.get_stepsize","text":"get_stepsize(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, vars...)\n\nreturn the stepsize stored within AbstractManoptSolverState ams when solving the AbstractManoptProblem amp. This method also works for decorated options and the Stepsize function within the options, by default stored in ams.stepsize.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.linesearch_backtrack!-Union{Tuple{T}, Tuple{TF}, Tuple{AbstractManifold, Any, TF, Any, T, Any, Any, Any}, Tuple{AbstractManifold, Any, TF, Any, T, Any, Any, Any, T}, Tuple{AbstractManifold, Any, TF, Any, T, Any, Any, Any, T, Any}} where {TF, T}","page":"Stepsize","title":"Manopt.linesearch_backtrack!","text":"(s, msg) = linesearch_backtrack!(M, q, F, p, X, s, decrease, contract Î· = -X, f0 = f(p))\n\nPerform a line search backtrack in-place of q. For all details and options, see linesearch_backtrack\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.linesearch_backtrack-Union{Tuple{T}, Tuple{AbstractManifold, Any, Any, T, Any, Any, Any}, Tuple{AbstractManifold, Any, Any, T, Any, Any, Any, T}, Tuple{AbstractManifold, Any, Any, T, Any, Any, Any, T, Any}} where T","page":"Stepsize","title":"Manopt.linesearch_backtrack","text":"(s, msg) = linesearch_backtrack(M, F, p, X, s, decrease, contract Î· = -X, f0 = f(p); kwargs...)\n(s, msg) = linesearch_backtrack!(M, q, F, p, X, s, decrease, contract Î· = -X, f0 = f(p); kwargs...)\n\nperform a line search\n\non manifold M\nfor the cost function f,\nat the current point p\nwith current gradient provided in X\nan initial stepsize s\na sufficient decrease\na contraction factor Ïƒ\na search direction Î· = -X\nan offset, f_0 = F(x)\n\nKeyword arguments\n\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: to avoid numerical underflow\nstop_when_stepsize_exceeds=max_stepsize(M, p) / norm(M, p, Î·)) to avoid leaving the injectivity radius on a manifold\nstop_increasing_at_step=100: stop the initial increase of step size after these many steps\nstop_decreasing_at_step=1000`: stop the decreasing search after these many steps\nadditional_increase_condition=(M,p) -> true: impose an additional condition for an increased step size to be accepted\nadditional_decrease_condition=(M,p) -> true: impose an additional condition for an decreased step size to be accepted\n\nThese keywords are used as safeguards, where only the max stepsize is a very manifold specific one.\n\nReturn value\n\nA stepsize s and a message msg (in case any of the 4 criteria hit)\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.max_stepsize-Tuple{AbstractManifold, Any}","page":"Stepsize","title":"Manopt.max_stepsize","text":"max_stepsize(M::AbstractManifold, p)\nmax_stepsize(M::AbstractManifold)\n\nGet the maximum stepsize (at point p) on manifold M. It should be used to limit the distance an algorithm is trying to move in a single step.\n\nBy default, this returns injectivity_radius(M), if this exists. If this is not available on the the method returns Inf.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.AdaptiveWNGradientStepsize","page":"Stepsize","title":"Manopt.AdaptiveWNGradientStepsize","text":"AdaptiveWNGradientStepsize{I<:Integer,R<:Real,F<:Function} <: Stepsize\n\nA functor problem, state, k, X) -> s to an adaptive gradient method introduced by [GrapigliaStella:2023](@cite). See [AdaptiveWNGradient`](@ref) for the mathematical details.\n\nFields\n\ncount_threshold::I: an Integer for hatc\nminimal_bound::R: the value for b_textmin\nalternate_bound::F: how to determine hatk_k as a function of (bmin, bk, hat_c) -> hat_bk\ngradient_reduction::R: the gradient reduction factor threshold Î±  01)\ngradient_bound::R: the bound b_k.\nweight::R: Ï‰_k initialised to Ï‰_0 =norm(M, p, X) if this is not zero, 1.0 otherwise.\ncount::I: c_k, initialised to c_0 = 0.\n\nConstructor\n\nAdaptiveWNGrad(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\nadaptive=true: switches the gradient_reductionÎ±(iftrue) to0`.\nalternate_bound = (bk, hat_c) ->  min(gradient_bound == 0 ? 1.0 : gradient_bound, max(minimal_bound, bk / (3 * hat_c))\ncount_threshold=4\ngradient_reduction::R=adaptive ? 0.9 : 0.0\ngradient_bound=norm(M, p, X)\nminimal_bound=1e-4\np=rand(M): a point on the manifold mathcal Monly used to define the gradient_bound\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Monly used to define the gradient_bound\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.ArmijoLinesearchStepsize","page":"Stepsize","title":"Manopt.ArmijoLinesearchStepsize","text":"ArmijoLinesearchStepsize <: Linesearch\n\nA functor problem, state, k, X) -> s to provide an Armijo line search to compute step size, based on the search directionX`\n\nFields\n\ncandidate_point:               to store an interim result\ninitial_stepsize:              and initial step size\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ncontraction_factor:            exponent for line search reduction\nsufficient_decrease:           gain within Armijo's rule\nlast_stepsize:                 the last step size to start the search with\ninitial_guess:                 a function to provide an initial guess for the step size, it maps (m,p,k,l) -> Î± based on a AbstractManoptProblem p, AbstractManoptSolverState s, the current iterate k and a last step size l. It returns the initial guess Î±.\nadditional_decrease_condition: specify a condition a new point has to additionally fulfill. The default accepts all points.\nadditional_increase_condition: specify a condtion that additionally to checking a valid increase has to be fulfilled. The default accepts all points.\nstop_when_stepsize_less:       smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds:    largest stepsize when to stop.\nstop_increasing_at_step:       last step to increase the stepsize (phase 1),\nstop_decreasing_at_step:       last step size to decrease the stepsize (phase 2),\n\nPass :Messages to a debug= to see @infos when these happen.\n\nConstructor\n\nArmijoLinesearchStepsize(M::AbstractManifold; kwarg...)\n\nwith the fields keyword arguments and the retraction is set to the default retraction on M.\n\nKeyword arguments\n\ncandidate_point=(allocate_result(M, rand))\ninitial_stepsize=1.0\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ncontraction_factor=0.95\nsufficient_decrease=0.1\nlast_stepsize=initialstepsize\ninitial_guess=armijo_initial_guessâ€“ (p,s,i,l) -> l\nstop_when_stepsize_less=0.0: stop when the stepsize decreased below this version.\nstop_when_stepsize_exceeds=[max_step](@ref)(M)`: provide an absolute maximal step size.\nstop_increasing_at_step=100: for the initial increase test, stop after these many steps\nstop_decreasing_at_step=1000: in the backtrack, stop after these many steps\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.ConstantStepsize","page":"Stepsize","title":"Manopt.ConstantStepsize","text":"ConstantStepsize <: Stepsize\n\nA functor (problem, state, ...) -> s to provide a constant step size s.\n\nFields\n\nlength: constant value for the step size\ntype:   a symbol that indicates whether the stepsize is relatively (:relative),   with respect to the gradient norm, or absolutely (:absolute) constant.\n\nConstructors\n\nConstantStepsize(s::Real, t::Symbol=:relative)\n\ninitialize the stepsize to a constant s of type t.\n\nConstantStepsize(\n    M::AbstractManifold=DefaultManifold(),\n    s=min(1.0, injectivity_radius(M)/2);\n    type::Symbol=:relative\n)\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.DecreasingStepsize","page":"Stepsize","title":"Manopt.DecreasingStepsize","text":"DecreasingStepsize()\n\nA functor (problem, state, ...) -> s to provide a constant step size s.\n\nFields\n\nexponent:   a value e the current iteration numbers eth exponential is taken of\nfactor:     a value f to multiply the initial step size with every iteration\nlength:     the initial step size l.\nsubtrahend: a value a that is subtracted every iteration\nshift:      shift the denominator iterator i by s`.\ntype:       a symbol that indicates whether the stepsize is relatively (:relative),   with respect to the gradient norm, or absolutely (:absolute) constant.\n\nIn total the complete formulae reads for the ith iterate as\n\ns_i = frac(l - i a)f^i(i+s)^e\n\nand hence the default simplifies to just s_i = \fracli\n\nConstructor\n\nDecreasingStepsize(M::AbstractManifold;\n    length=min(injectivity_radius(M)/2, 1.0),\n    factor=1.0,\n    subtrahend=0.0,\n    exponent=1.0,\n    shift=0.0,\n    type=:relative,\n)\n\ninitializes all fields, where none of them is mandatory and the length is set to half and to 1 if the injectivity radius is infinite.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.Linesearch","page":"Stepsize","title":"Manopt.Linesearch","text":"Linesearch <: Stepsize\n\nAn abstract functor to represent line search type step size determinations, see Stepsize for details. One example is the ArmijoLinesearchStepsize functor.\n\nCompared to simple step sizes, the line search functors provide an interface of the form (p,o,i,X) -> s with an additional (but optional) fourth parameter to provide a search direction; this should default to something reasonable, most prominently the negative gradient.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.NonmonotoneLinesearchStepsize","page":"Stepsize","title":"Manopt.NonmonotoneLinesearchStepsize","text":"NonmonotoneLinesearchStepsize{P,T,R<:Real} <: Linesearch\n\nA functor representing a nonmonotone line search using the Barzilai-Borwein step size [IP17].\n\nFields\n\ninitial_stepsize=1.0:     the step size to start the search with\nmemory_size=10:           number of iterations after which the cost value needs to be lower than the current one\nbb_min_stepsize=1e-3:     lower bound for the Barzilai-Borwein step size greater than zero\nbb_max_stepsize=1e3:      upper bound for the Barzilai-Borwein step size greater than min_stepsize\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstrategy=direct:          defines if the new step size is computed using the :direct, :indirect or :alternating strategy\nstorage:                  (for :Iterate and :Gradient) a StoreStateAction\nstepsize_reduction:       step size reduction factor contained in the interval (0,1)\nsufficient_decrease:     sufficient decrease parameter contained in the interval (0,1)\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\ncandidate_point:          to store an interim result\nstop_when_stepsize_less:    smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds: largest stepsize when to stop.\nstop_increasing_at_step:    last step to increase the stepsize (phase 1),\nstop_decreasing_at_step:    last step size to decrease the stepsize (phase 2),\n\nConstructor\n\nNonmonotoneLinesearchStepsize(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\np=allocate_result(M, rand): to store an interim result\ninitial_stepsize=1.0\nmemory_size=10\nbb_min_stepsize=1e-3\nbb_max_stepsize=1e3\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstrategy=direct\nstorage=[StoreStateAction](@ref)(M; store_fields=[:Iterate, :Gradient])``\nstepsize_reduction=0.5\nsufficient_decrease=1e-4\nstop_when_stepsize_less=0.0\nstop_when_stepsize_exceeds=max_stepsize(M, p))\nstop_increasing_at_step=100\nstop_decreasing_at_step=1000\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.PolyakStepsize","page":"Stepsize","title":"Manopt.PolyakStepsize","text":"PolyakStepsize <: Stepsize\n\nA functor (problem, state, ...) -> s to provide a step size due to Polyak, cf. Section 3.2 of [Ber15].\n\nFields\n\nÎ³               : a function k -> ... representing a seuqnce.\nbest_cost_value : storing the best cost value\n\nConstructor\n\nPolyakStepsize(;\n    Î³ = i -> 1/i,\n    initial_cost_estimate=0.0\n)\n\nConstruct a stepsize of Polyak type.\n\nSee also\n\nPolyak\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.WolfePowellBinaryLinesearchStepsize","page":"Stepsize","title":"Manopt.WolfePowellBinaryLinesearchStepsize","text":"WolfePowellBinaryLinesearchStepsize{R} <: Linesearch\n\nDo a backtracking line search to find a step size Î± that fulfils the Wolfe conditions along a search direction X starting from p. See WolfePowellBinaryLinesearch for the math details.\n\nFields\n\nsufficient_decrease::R, sufficient_curvature::R two constants in the line search\nlast_stepsize::R\nmax_stepsize::R\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less::R: a safeguard to stop when the stepsize gets too small\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.WolfePowellLinesearchStepsize","page":"Stepsize","title":"Manopt.WolfePowellLinesearchStepsize","text":"WolfePowellLinesearchStepsize{R<:Real} <: Linesearch\n\nDo a backtracking line search to find a step size Î± that fulfils the Wolfe conditions along a search direction X starting from p. See WolfePowellLinesearch for the math details\n\nFields\n\nsufficient_decrease::R, sufficient_curvature::R two constants in the line search\ncandidate_direction::T: a tangent vector at the point p on the manifold mathcal M\ncandidate_point::P: a point on the manifold mathcal Mas temporary storage for candidates\ncandidate_tangent::T: a tangent vector at the point p on the manifold mathcal M\nlast_stepsize::R\nmax_stepsize::R\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less::R: a safeguard to stop when the stepsize gets too small\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\np::P: a point on the manifold mathcal Mas temporary storage for candidates\nX::T: a tangent vector at the point p on the manifold mathcal Mas type of memory allocated for the candidates direction and tangent\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Some solvers have a different iterate from the one used for the line search. Then the following state can be used to wrap these locally","category":"page"},{"location":"plans/stepsize/#Manopt.StepsizeState","page":"Stepsize","title":"Manopt.StepsizeState","text":"StepsizeState{P,T} <: AbstractManoptSolverState\n\nA state to store a point and a descent direction used within a linesearch, if these are different from the iterate and search direction of the main solver.\n\nFields\n\np::P: a point on a manifold\nX::T: a tangent vector at p.\n\nConstructor\n\nStepsizeState(p,X)\nStepsizeState(M::AbstractManifold; p=rand(M), x=zero_vector(M,p)\n\nSee also\n\ninterior_point_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Literature","page":"Stepsize","title":"Literature","text":"","category":"section"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"D.Â P.Â Bertsekas. Convex Optimization Algorithms (Athena Scientific, 2015); p.Â 576.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nG.Â N.Â Grapiglia and G.Â F.Â Stella. An Adaptive Riemannian Gradient Method Without Function Evaluations. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 197, 1140â€“1160 (2023).\n\n\n\nW.Â Huang. Optimization algorithms on Riemannian manifolds with applications. Ph.D. Thesis, Flordia State University (2014).\n\n\n\nB.Â Iannazzo and M.Â Porcelli. The Riemannian Barzilaiâ€“Borwein method with nonmonotone line search and the matrix geometric mean computation. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 38, 495â€“517 (2017).\n\n\n\nJ.Â Nocedal and S.Â J.Â Wright. Numerical Optimization. 2Â Edition (Springer, New York, 2006).\n\n\n\n","category":"page"},{"location":"#Welcome-to-Manopt.jl","page":"Home","title":"Welcome to Manopt.jl","text":"","category":"section"},{"location":"#Manopt.Manopt","page":"Home","title":"Manopt.Manopt","text":"ðŸ”ï¸ Manopt.jl: optimization on Manifolds in Julia.\n\nðŸ“š Documentation: manoptjl.org\nðŸ“¦ Repository: github.com/JuliaManifolds/Manopt.jl\nðŸ’¬ Discussions: github.com/JuliaManifolds/Manopt.jl/discussions\nðŸŽ¯ Issues: github.com/JuliaManifolds/Manopt.jl/issues\n\n\n\n\n\n","category":"module"},{"location":"","page":"Home","title":"Home","text":"For a function fmathcal M  â„ defined on a Riemannian manifold mathcal M algorithms in this package aim to solve","category":"page"},{"location":"","page":"Home","title":"Home","text":"operatorname*argmin_p  mathcal M f(p)","category":"page"},{"location":"","page":"Home","title":"Home","text":"or in other words: find the point p on the manifold, where f reaches its minimal function value.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Manopt.jl provides a framework for optimization on manifolds as well as a Library of optimization algorithms in Julia. It belongs to the â€œManopt familyâ€, which includes Manopt (Matlab) and pymanopt.org (Python).","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you want to delve right into Manopt.jl read the ðŸ”ï¸ Get started with Manopt.jl tutorial.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Manopt.jl makes it easy to use an algorithm for your favourite manifold as well as a manifold for your favourite algorithm. It already provides many manifolds and algorithms, which can easily be enhanced, for example to record certain data or debug output throughout iterations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you use Manopt.jlin your work, please cite the following","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{Bergmann2022,\n    Author    = {Ronny Bergmann},\n    Doi       = {10.21105/joss.03866},\n    Journal   = {Journal of Open Source Software},\n    Number    = {70},\n    Pages     = {3866},\n    Publisher = {The Open Journal},\n    Title     = {Manopt.jl: Optimization on Manifolds in {J}ulia},\n    Volume    = {7},\n    Year      = {2022},\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"To refer to a certain version or the source code in general cite for example","category":"page"},{"location":"","page":"Home","title":"Home","text":"@software{manoptjl-zenodo-mostrecent,\n    Author    = {Ronny Bergmann},\n    Copyright = {MIT License},\n    Doi       = {10.5281/zenodo.4290905},\n    Publisher = {Zenodo},\n    Title     = {Manopt.jl},\n    Year      = {2024},\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"for the most recent version or a corresponding version specific DOI, see the list of all versions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you are also using Manifolds.jl please consider to cite","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{AxenBaranBergmannRzecki:2023,\n    AUTHOR    = {Axen, Seth D. and Baran, Mateusz and Bergmann, Ronny and Rzecki, Krzysztof},\n    ARTICLENO = {33},\n    DOI       = {10.1145/3618296},\n    JOURNAL   = {ACM Transactions on Mathematical Software},\n    MONTH     = {dec},\n    NUMBER    = {4},\n    TITLE     = {Manifolds.Jl: An Extensible Julia Framework for Data Analysis on Manifolds},\n    VOLUME    = {49},\n    YEAR      = {2023}\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that both citations are in BibLaTeX format.","category":"page"},{"location":"#Main-features","page":"Home","title":"Main features","text":"","category":"section"},{"location":"#Optimization-algorithms-(solvers)","page":"Home","title":"Optimization algorithms (solvers)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For every optimization algorithm, a solver is implemented based on a AbstractManoptProblem that describes the problem to solve and its AbstractManoptSolverState that set up the solver, and stores values that are required between or for the next iteration. Together they form a plan.","category":"page"},{"location":"#Manifolds","page":"Home","title":"Manifolds","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This project is build upon ManifoldsBase.jl, a generic interface to implement manifolds. Certain functions are extended for specific manifolds from Manifolds.jl, but all other manifolds from that package can be used here, too.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The notation in the documentation aims to follow the same notation from these packages.","category":"page"},{"location":"#Visualization","page":"Home","title":"Visualization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To visualize and interpret results, Manopt.jl aims to provide both easy plot functions as well as exports. Furthermore a system to get debug during the iterations of an algorithms as well as record capabilities, for example to record a specified tuple of values per iteration, most prominently RecordCost and RecordIterate. Take a look at the ðŸ”ï¸ Get started with Manopt.jl tutorial on how to easily activate this.","category":"page"},{"location":"#Literature","page":"Home","title":"Literature","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you want to get started with manifolds, one book is [Car92], and if you want do directly dive into optimization on manifolds, good references are [AMS08] and [Bou23], which are both available online for free","category":"page"},{"location":"","page":"Home","title":"Home","text":"P.-A.Â Absil, R.Â Mahony and R.Â Sepulchre. Optimization Algorithms on Matrix Manifolds (Princeton University Press, 2008), available online at press.princeton.edu/chapters/absil/.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nM.Â P.Â doÂ Carmo. Riemannian Geometry. Mathematics: Theory & Applications (BirkhÃ¤user Boston, Inc., Boston, MA, 1992); p.Â xiv+300.\n\n\n\n","category":"page"},{"location":"references/#Literature","page":"References","title":"Literature","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"This is all literature mentioned / referenced in the Manopt.jl documentation. Usually you find a small reference section at the end of every documentation page that contains the corresponding references as well.","category":"page"},{"location":"references/","page":"References","title":"References","text":"P.-A.Â Absil, C.Â Baker and K.Â Gallivan. Trust-Region Methods on Riemannian Manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 7, 303â€“330 (2006).\n\n\n\nP.-A.Â Absil, R.Â Mahony and R.Â Sepulchre. Optimization Algorithms on Matrix Manifolds (Princeton University Press, 2008), available online at press.princeton.edu/chapters/absil/.\n\n\n\nS.Â Adachi, T.Â Okuno and A.Â Takeda. Riemannian Levenberg-Marquardt Method with Global and Local Convergence Properties. ArXivÂ Preprint (2022).\n\n\n\nN.Â Agarwal, N.Â Boumal, B.Â Bullins and C.Â Cartis. Adaptive regularization with cubics on manifolds. MathematicalÂ Programming (2020).\n\n\n\nY.Â T.Â Almeida, J.Â X.Â Cruz Neto, P.Â R.Â Oliveira and J.Â C.Â Oliveira Souza. A modified proximal point method for DC functions on Hadamard manifolds. ComputationalÂ OptimizationÂ andÂ Applications 76, 649â€“673 (2020).\n\n\n\nM.Â BaÄÃ¡k. Computing medians and means in Hadamard spaces. SIAMÂ JournalÂ onÂ Optimization 24, 1542â€“1566 (2014), arXiv:1210.2145.\n\n\n\nE.Â M.Â Beale. A derivation of conjugate gradients. In: Numerical methods for nonlinear optimization, edited by F.Â A.Â Lootsma (Academic Press, London, London, 1972); pp.Â 39â€“43.\n\n\n\nR.Â Bergmann, O.Â P.Â Ferreira, S.Â Z.Â NÃ©meth and J.Â Zhu. On projection mappings and the gradient projection method on hyperbolic space forms. Preprint,Â inÂ preparation (2025).\n\n\n\nR.Â Bergmann, O.Â P.Â Ferreira, E.Â M.Â Santos and J.Â C.Â Souza. The difference of convex algorithm on Hadamard manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications (2024).\n\n\n\nR.Â Bergmann and R.Â Herzog. Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds. SIAMÂ JournalÂ onÂ Optimization 29, 2423â€“2444 (2019), arXiv:1804.06214.\n\n\n\nR.Â Bergmann, R.Â Herzog and H.Â Jasa. The Riemannian Convex Bundle Method, preprint (2024), arXiv:2402.13670.\n\n\n\nR.Â Bergmann, R.Â Herzog, M.Â Silva Louzeiro, D.Â Tenbrinck and J.Â Vidal-NÃºÃ±ez. Fenchel duality theory and a primal-dual algorithm on Riemannian manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 21, 1465â€“1504 (2021), arXiv:1908.02022.\n\n\n\nR.Â Bergmann, J.Â Persch and G.Â Steidl. A parallel Douglas Rachford algorithm for minimizing ROF-like functionals on images with values in symmetric Hadamard manifolds. SIAMÂ JournalÂ onÂ ImagingÂ Sciences 9, 901â€“937 (2016), arXiv:1512.02814.\n\n\n\nD.Â P.Â Bertsekas. Convex Optimization Algorithms (Athena Scientific, 2015); p.Â 576.\n\n\n\nP.Â B.Â Borckmans, M.Â Ishteva and P.-A.Â Absil. A Modified Particle Swarm Optimization Algorithm for the Best Low Multilinear Rank Approximation of Higher-Order Tensors. In: 7th International Conference on Swarm INtelligence (Springer Berlin Heidelberg, 2010); pp.Â 13â€“23.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nM.Â P.Â doÂ Carmo. Riemannian Geometry. Mathematics: Theory & Applications (BirkhÃ¤user Boston, Inc., Boston, MA, 1992); p.Â xiv+300.\n\n\n\nA.Â Chambolle and T.Â Pock. A first-order primal-dual algorithm for convex problems with applications to imaging. JournalÂ ofÂ MathematicalÂ ImagingÂ andÂ Vision 40, 120â€“145 (2011).\n\n\n\nS.Â Colutto, F.Â Fruhauf, M.Â Fuchs and O.Â Scherzer. The CMA-ES on Riemannian Manifolds to Reconstruct Shapes in 3-D Voxel Images. IEEEÂ TransactionsÂ onÂ EvolutionaryÂ Computation 14, 227â€“245 (2010).\n\n\n\nA.Â R.Â Conn, N.Â I.Â Gould and P.Â L.Â Toint. Trust Region Methods (Society for Industrial and Applied Mathematics, 2000).\n\n\n\nY.Â H.Â Dai and Y.Â Yuan. A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property. SIAMÂ JournalÂ onÂ Optimization 10, 177â€“182 (1999).\n\n\n\nW.Â Diepeveen and J.Â Lellmann. An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising. SIAMÂ JournalÂ onÂ ImagingÂ Sciences 14, 1565â€“1600 (2021), arXiv:2102.10309.\n\n\n\nD.Â W.Â Dreisigmeyer. Direct Search Alogirthms over Riemannian Manifolds (Optimization Online, 2007).\n\n\n\nA.Â S.Â El-Bakry, R.Â A.Â Tapia, T.Â Tsuchiya and Y.Â Zhang. On the formulation and theory of the Newton interior-point method for nonlinear programming. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 89, 507â€“541 (1996).\n\n\n\nO.Â Ferreira and P.Â R.Â Oliveira. Subgradient algorithm on Riemannian manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 97, 93â€“104 (1998).\n\n\n\nO.Â Ferreira and P.Â R.Â Oliveira. Proximal point algorithm on Riemannian manifolds. Optimization.Â AÂ JournalÂ ofÂ MathematicalÂ ProgrammingÂ andÂ OperationsÂ Research 51, 257â€“270 (2002).\n\n\n\nR.Â Fletcher. Practical Methods of Optimization. 2Â Edition, A Wiley-Interscience Publication (John Wiley & Sons Ltd., 1987).\n\n\n\nR.Â Fletcher and C.Â M.Â Reeves. Function minimization by conjugate gradients. TheÂ ComputerÂ Journal 7, 149â€“154 (1964).\n\n\n\nG.Â N.Â Grapiglia and G.Â F.Â Stella. An Adaptive Riemannian Gradient Method Without Function Evaluations. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 197, 1140â€“1160 (2023).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A survey of nonlinear conjugate gradient methods. PacificÂ JournalÂ ofÂ Optimization 2, 35â€“58 (2006).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search. SIAMÂ JournalÂ onÂ Optimization 16, 170â€“192 (2005).\n\n\n\nN.Â Hansen. The CMA Evolution Strategy: A Tutorial. ArXivÂ Preprint (2023).\n\n\n\nM.Â Hestenes and E.Â Stiefel. Methods of conjugate gradients for solving linear systems. JournalÂ ofÂ ResearchÂ ofÂ theÂ NationalÂ BureauÂ ofÂ Standards 49, 409 (1952).\n\n\n\nN.Â Hoseini Monjezi, S.Â Nobakhtian and M.Â R.Â Pouryayevali. A proximal bundle algorithm for nonsmooth optimization on Riemannian manifolds. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 43, 293â€“325 (2023).\n\n\n\nW.Â Huang. Optimization algorithms on Riemannian manifolds with applications. Ph.D. Thesis, Flordia State University (2014).\n\n\n\nW.Â Huang, P.-A.Â Absil and K.Â A.Â Gallivan. A Riemannian BFGS method without differentiated retraction for nonconvex optimization problems. SIAMÂ JournalÂ onÂ Optimization 28, 470â€“495 (2018).\n\n\n\nW.Â Huang, K.Â A.Â Gallivan and P.-A.Â Absil. A Broyden class of quasi-Newton methods for Riemannian optimization. SIAMÂ JournalÂ onÂ Optimization 25, 1660â€“1685 (2015).\n\n\n\nB.Â Iannazzo and M.Â Porcelli. The Riemannian Barzilaiâ€“Borwein method with nonmonotone line search and the matrix geometric mean computation. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 38, 495â€“517 (2017).\n\n\n\nH.Â Karcher. Riemannian center of mass and mollifier smoothing. CommunicationsÂ onÂ PureÂ andÂ AppliedÂ Mathematics 30, 509â€“541 (1977).\n\n\n\nZ.Â Lai and A.Â Yoshise. Riemannian Interior Point Methods for Constrained Optimization on Manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 201, 433â€“469 (2024), arXiv:2203.09762.\n\n\n\nC.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\nY.Â Liu and C.Â Storey. Efficient generalized conjugate gradient algorithms,  part 1: Theory. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 69, 129â€“137 (1991).\n\n\n\nD.Â Nguyen. Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 198, 135â€“164 (2023), arXiv:2009.10159.\n\n\n\nJ.Â Nocedal and S.Â J.Â Wright. Numerical Optimization. 2Â Edition (Springer, New York, 2006).\n\n\n\nR.Â Peeters. On a Riemannian version of the Levenberg-Marquardt algorithm. Serie Research MemorandaÂ 0011 (VU University Amsterdam, Faculty of Economics, Business Administration and Econometrics, 1993).\n\n\n\nE.Â Polak and G.Â RibiÃ¨re. Note sur la convergence de mÃ©thodes de directions conjuguÃ©es. RevueÂ franÃ§aiseÂ dâ€™informatiqueÂ etÂ deÂ rechercheÂ opÃ©rationnelle 3, 35â€“43 (1969).\n\n\n\nM.Â J.Â Powell. Restart procedures for the conjugate gradient method. MathematicalÂ Programming 12, 241â€“254 (1977).\n\n\n\nJ.Â C.Â Souza and P.Â R.Â Oliveira. A proximal point algorithm for DC fuctions on Hadamard manifolds. JournalÂ ofÂ GlobalÂ Optimization 63, 797â€“810 (2015).\n\n\n\nM.Â Weber and S.Â Sra. Riemannian Optimization via Frank-Wolfe Methods. MathematicalÂ Programming 199, 525â€“556 (2022).\n\n\n\nH.Â Zhang and S.Â Sra. Towards Riemannian accelerated gradient methods, arXivÂ Preprint,Â 1806.02812 (2018).\n\n\n\n","category":"page"},{"location":"tutorials/StochasticGradientDescent/#How-to-run-stochastic-gradient-descent","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"","category":"section"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"This tutorial illustrates how to use the stochastic_gradient_descent solver and different DirectionUpdateRules to introduce the average or momentum variant, see Stochastic Gradient Descent.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"Computationally, we look at a very simple but large scale problem, the Riemannian Center of Mass or FrÃ©chet mean: for given points p_i mathcal M, i=1N this optimization problem reads","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"operatorname*argmin_xmathcal M frac12sum_i=1^N\n  operatornamed^2_mathcal M(xp_i)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"which of course can be (and is) solved by a gradient descent, see the introductory tutorial or Statistics in Manifolds.jl. If N is very large, evaluating the complete gradient might be quite expensive. A remedy is to evaluate only one of the terms at a time and choose a random order for these.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"We first initialize the packages","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"using Manifolds, Manopt, Random, BenchmarkTools, ManifoldDiff\nusing ManifoldDiff: grad_distance\nRandom.seed!(42);","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"We next generate a (little) large(r) data set","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"n = 5000\nÏƒ = Ï€ / 12\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"Note that due to the construction of the points as zero mean tangent vectors, the mean should be very close to our initial point p.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"In order to use the stochastic gradient, we now need a function that returns the vector of gradients. There are two ways to define it in Manopt.jl: either as a single function that returns a vector, or as a vector of functions.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"The first variant is of course easier to define, but the second is more efficient when only evaluating one of the gradients.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"For the mean, the gradient is","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"operatornamegradf(p) = sum_i=1^N operatornamegradf_i(x) quad textwhere operatornamegradf_i(x) = -log_x p_i","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"which we define in Manopt.jl in two different ways: either as one function returning all gradients as a vector (see gradF), or, maybe more fitting for a large scale problem, as a vector of small gradient functions (see gradf)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"F(M, p) = 1 / (2 * n) * sum(map(q -> distance(M, p, q)^2, data))\ngradF(M, p) = [grad_distance(M, p, q) for q in data]\ngradf = [(M, p) -> grad_distance(M, q, p) for q in data];\np0 = 1 / sqrt(3) * [1.0, 1.0, 1.0]","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"3-element Vector{Float64}:\n 0.5773502691896258\n 0.5773502691896258\n 0.5773502691896258","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"The calls are only slightly different, but notice that accessing the second gradient element requires evaluating all logs in the first function, while we only call one of the functions in the second array of functions. So while you can use both gradF and gradf in the following call, the second one is (much) faster:","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"p_opt1 = stochastic_gradient_descent(M, gradF, p)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"3-element Vector{Float64}:\n -0.4124602512237471\n  0.7450900936719854\n  0.38494647999455556","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"@benchmark stochastic_gradient_descent($M, $gradF, $p0)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"BenchmarkTools.Trial: 1 sample with 1 evaluation per sample.\n Single result which took 6.315 s (7.61% GC) to evaluate,\n with a memory estimate of 7.83 GiB, over 200213003 allocations.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"p_opt2 = stochastic_gradient_descent(M, gradf, p0)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"3-element Vector{Float64}:\n 0.6828818855405705\n 0.17545293717581142\n 0.7091463863243863","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"@benchmark stochastic_gradient_descent($M, $gradf, $p0)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"BenchmarkTools.Trial: 2590 samples with 1 evaluation per sample.\n Range (min â€¦ max):  622.222 Î¼s â€¦ 13.493 ms  â”Š GC (min â€¦ max): 0.00% â€¦ 19.38%\n Time  (median):       1.590 ms              â”Š GC (median):    0.00%\n Time  (mean Â± Ïƒ):     1.928 ms Â±  1.151 ms  â”Š GC (mean Â± Ïƒ):  6.37% Â± 12.02%\n\n   â–‚â– â–                          â–ˆ                              \n  â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–†â–‡â–†â–…â–…â–„â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â– â–‚\n  622 Î¼s          Histogram: frequency by time         5.65 ms <\n\n Memory estimate: 861.17 KiB, allocs estimate: 20050.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"This result is reasonably close. But we can improve it by using a DirectionUpdateRule, namely:","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"On the one hand MomentumGradient, which requires both the manifold and the initial value, to keep track of the iterate and parallel transport the last direction to the current iterate. The necessary vector_transport_method keyword is set to a suitable default on every manifold, see default_vector_transport_method. We get â€œâ€œâ€","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"p_opt3 = stochastic_gradient_descent(\n    M, gradf, p0; direction=MomentumGradient(; direction=StochasticGradient())\n)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"3-element Vector{Float64}:\n  0.5825640847534528\n -0.1914698842542591\n  0.7899103560398689","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"MG = MomentumGradient(; direction=StochasticGradient());\n@benchmark stochastic_gradient_descent($M, $gradf, p=$p0; direction=$MG)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"BenchmarkTools.Trial: 838 samples with 1 evaluation per sample.\n Range (min â€¦ max):  5.173 ms â€¦ 19.883 ms  â”Š GC (min â€¦ max): 0.00% â€¦ 58.66%\n Time  (median):     5.356 ms              â”Š GC (median):    0.00%\n Time  (mean Â± Ïƒ):   5.965 ms Â±  1.386 ms  â”Š GC (mean Â± Ïƒ):  8.97% Â± 13.04%\n\n  â–„â–ˆâ–ˆâ–†â–ƒ                           â–‚â–‚â–‚â–‚                        \n  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–â–„â–â–â–„â–„â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–„â–„â–â–â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–„â–‡â–‡â–…â–†â–…â–†â–‡â–‡â–ˆâ–‡â–…â–…â–„â–„â–â–„â–… â–ˆ\n  5.17 ms      Histogram: log(frequency) by time     9.32 ms <\n\n Memory estimate: 7.71 MiB, allocs estimate: 200052.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"And on the other hand the AverageGradient computes an average of the last n gradients. This is done by","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"p_opt4 = stochastic_gradient_descent(\n    M, gradf, p0; direction=AverageGradient(; n=10, direction=StochasticGradient()), debug=[],\n)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"3-element Vector{Float64}:\n  0.6861198497295143\n -0.539808429194456\n  0.4876949985162476","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"AG = AverageGradient(; n=10, direction=StochasticGradient(M));\n@benchmark stochastic_gradient_descent($M, $gradf, p=$p0; direction=$AG, debug=[])","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"BenchmarkTools.Trial: 244 samples with 1 evaluation per sample.\n Range (min â€¦ max):  18.342 ms â€¦ 40.250 ms  â”Š GC (min â€¦ max): 0.00% â€¦ 29.31%\n Time  (median):     21.182 ms              â”Š GC (median):    0.00%\n Time  (mean Â± Ïƒ):   20.499 ms Â±  2.789 ms  â”Š GC (mean Â± Ïƒ):  7.53% Â±  7.17%\n\n  â–ˆâ–‡        â–‡â–†â–„                                                \n  â–ˆâ–ˆâ–†â–†â–„â–„â–â–„â–â–„â–ˆâ–ˆâ–ˆâ–‡â–‡â–„â–â–â–„â–„â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–„â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–„ â–†\n  18.3 ms      Histogram: log(frequency) by time      34.9 ms <\n\n Memory estimate: 21.90 MiB, allocs estimate: 600077.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"Note that the default StoppingCriterion is a fixed number of iterations which helps the comparison here.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"For both update rules we have to internally specify that we are still in the stochastic setting, since both rules can also be used with the IdentityUpdateRule within gradient_descent.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"For this not-that-large-scale example we can of course also use a gradient descent with ArmijoLinesearch,","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"fullGradF(M, p) = 1/n*sum(grad_distance(M, q, p) for q in data)\np_opt5 = gradient_descent(M, F, fullGradF, p0; stepsize=ArmijoLinesearch())","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"3-element Vector{Float64}:\n  0.7050420977039097\n -0.006374163035874202\n  0.7091368066253959","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"but in general it is expected to be a bit slow.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"AL = ArmijoLinesearch();\n@benchmark gradient_descent($M, $F, $fullGradF, $p0; stepsize=$AL)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"BenchmarkTools.Trial: 25 samples with 1 evaluation per sample.\n Range (min â€¦ max):  200.576 ms â€¦ 226.664 ms  â”Š GC (min â€¦ max): 6.45% â€¦ 6.68%\n Time  (median):     204.509 ms               â”Š GC (median):    7.40%\n Time  (mean Â± Ïƒ):   206.296 ms Â±   5.992 ms  â”Š GC (mean Â± Ïƒ):  7.57% Â± 0.65%\n\n       â–â–ˆâ– â–â–   â–  â–                                             \n  â–†â–â–†â–†â–†â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–†â–â–ˆâ–â–â–ˆâ–â–â–â–â–†â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–â–â–â–† â–\n  201 ms           Histogram: frequency by time          227 ms <\n\n Memory estimate: 230.56 MiB, allocs estimate: 6338505.","category":"page"},{"location":"tutorials/StochasticGradientDescent/#Technical-details","page":"How to run stochastic gradient descent","title":"Technical details","text":"","category":"section"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `..`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"2025-04-25T12:15:32.532","category":"page"},{"location":"contributing/#Contributing-to-Manopt.jl","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"First, thanks for taking the time to contribute. Any contribution is appreciated and welcome.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"The following is a set of guidelines to Manopt.jl.","category":"page"},{"location":"contributing/#Table-of-contents","page":"Contributing to Manopt.jl","title":"Table of contents","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Contributing to Manopt.jl     - Table of Contents\nI just have a question\nHow can I file an issue?\nHow can I contribute?\nAdd a missing method\nProvide a new algorithm\nProvide a new example\nCode style","category":"page"},{"location":"contributing/#I-just-have-a-question","page":"Contributing to Manopt.jl","title":"I just have a question","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"The developer can most easily be reached in the Julia Slack channel #manifolds. You can apply for the Julia Slack workspace here if you haven't joined yet. You can also ask your question on discourse.julialang.org.","category":"page"},{"location":"contributing/#How-can-I-file-an-issue?","page":"Contributing to Manopt.jl","title":"How can I file an issue?","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"If you found a bug or want to propose a feature, please open an issue in within the GitHub repository.","category":"page"},{"location":"contributing/#How-can-I-contribute?","page":"Contributing to Manopt.jl","title":"How can I contribute?","text":"","category":"section"},{"location":"contributing/#Add-a-missing-method","page":"Contributing to Manopt.jl","title":"Add a missing method","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"There is still a lot of methods for within the optimization framework of  Manopt.jl, may it be functions, gradients, differentials, proximal maps, step size rules or stopping criteria. If you notice a method missing and can contribute an implementation, please do so, and the maintainers try help with the necessary details. Even providing a single new method is a good contribution.","category":"page"},{"location":"contributing/#Provide-a-new-algorithm","page":"Contributing to Manopt.jl","title":"Provide a new algorithm","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"A main contribution you can provide is another algorithm that is not yet included in the package. An algorithm is always based on a concrete type of a AbstractManoptProblem storing the main information of the task and a concrete type of an AbstractManoptSolverState storing all information that needs to be known to the solver in general. The actual algorithm is split into an initialization phase, see initialize_solver!, and the implementation of the ith step of the solver itself, see  before the iterative procedure, see step_solver!. For these two functions, it would be great if a new algorithm uses functions from the ManifoldsBase.jl interface as generically as possible. For example, if possible use retract!(M,q,p,X) in favor of exp!(M,q,p,X) to perform a step starting in p in direction X (in place of q), since the exponential map might be too expensive to evaluate or might not be available on a certain manifold. See Retractions and inverse retractions for more details. Further, if possible, prefer retract!(M,q,p,X) in favor of retract(M,p,X), since a computation in place of a suitable variable q reduces memory allocations.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Usually, the methods implemented in Manopt.jl also have a high-level interface, that is easier to call, creates the necessary problem and options structure and calls the solver.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"The two technical functions initialize_solver! and step_solver! should be documented with technical details, while the high level interface should usually provide a general description and some literature references to the algorithm at hand.","category":"page"},{"location":"contributing/#Provide-a-new-example","page":"Contributing to Manopt.jl","title":"Provide a new example","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Example problems are available at ManoptExamples.jl, where also their reproducible Quarto-Markdown files are stored.","category":"page"},{"location":"contributing/#Code-style","page":"Contributing to Manopt.jl","title":"Code style","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Try to follow the documentation guidelines from the Julia documentation as well as Blue Style. Run JuliaFormatter.jl on the repository in the way set in the .JuliaFormatter.toml file, which enforces a number of conventions consistent with the Blue Style. Furthermore vale is run on both Markdown and code files, affecting documentation and source code comments","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Please follow a few internal conventions:","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"It is preferred that the AbstractManoptProblem's struct contains information about the general structure of the problem.\nAny implemented function should be accompanied by its mathematical formulae if a closed form exists.\nAbstractManoptProblem and helping functions are stored within the plan/ folder and sorted by properties of the problem and/or solver at hand.\nthe solver state is usually stored with the solver itself\nWithin the source code of one algorithm, following the state, the high level interface should be next, then the initialization, then the step.\nOtherwise an alphabetical order of functions is preferable.\nThe preceding implies that the mutating variant of a function follows the non-mutating variant.\nThere should be no dangling = signs.\nAlways add a newline between things of different types (struct/method/const).\nAlways add a newline between methods for different functions (including mutating/nonmutating variants).\nPrefer to have no newline between methods for the same function; when reasonable, merge the documentation strings.\nAll import/using/include should be in the main module file.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Concerning documentation","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"if possible provide both mathematical formulae and literature references using DocumenterCitations.jl and BibTeX where possible\nAlways document all input variables and keyword arguments","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"If you implement an algorithm with a certain numerical example in mind, it would be great, if this could be added to the ManoptExamples.jl package as well.","category":"page"},{"location":"helpers/checks/#Verifying-gradients-and-Hessians","page":"Checks","title":"Verifying gradients and Hessians","text":"","category":"section"},{"location":"helpers/checks/","page":"Checks","title":"Checks","text":"If you have computed a gradient or differential and you are not sure whether it is correct.","category":"page"},{"location":"helpers/checks/#Manopt.check_Hessian","page":"Checks","title":"Manopt.check_Hessian","text":"check_Hessian(M, f, grad_f, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M, vector_at=p); kwargs...)\n\nVerify numerically whether the Hessian Hess_f(M,p, X) of f(M,p) is correct.\n\nFor this either a second-order retraction or a critical point p of f is required. The approximation is then\n\nf(operatornameretr_p(tX)) = f(p) + toperatornamegrad f(p) X + fract^22operatornameHessf(p)X X + mathcal O(t^3)\n\nor in other words, that the error between the function f and its second order Taylor behaves in error mathcal O(t^3), which indicates that the Hessian is correct, cf. also [Bou23, Section 6.8].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot is generated.\n\nKeyword arguments\n\ncheck_grad=true: verify that operatornamegradf(p)  T_pmathcal M.\ncheck_linearity=true: verify that the Hessian is linear, see is_Hessian_linear using a, b, X, and Y\ncheck_symmetry=true: verify that the Hessian is symmetric, see is_Hessian_symmetric\ncheck_vector=false: verify that \\operatorname{Hess} f(p)[X] âˆˆ T_{p}\\mathcal Musingis_vector`.\nmode=:Default: specify the mode for the verification; the default assumption is, that the retraction provided is of second order. Otherwise one can also verify the Hessian if the point p is a critical point. THen set the mode to :CritalPoint to use gradient_descent to find a critical point. Note: this requires (and evaluates) new tangent vectors X and Y\natol, rtol:      (same defaults as isapprox) tolerances that are passed down to all checks\na, b            two real values to verify linearity of the Hessian (if check_linearity=true)\nN=101: number of points to verify within the log_range default range 10^-810^0\nexactness_tol=1e-12: if all errors are below this tolerance, the verification is considered to be exact\nio=nothing: provide an IO to print the result to\ngradient=grad_f(M, p): instead of the gradient function you can also provide the gradient at p directly\nHessian=Hess_f(M, p, X): instead of the Hessian function you can provide the result of operatornameHess f(p)X directly. Note that evaluations of the Hessian might still be necessary for checking linearity and symmetry and/or when using :CriticalPoint mode.\nlimits=(-8.0, 0.0): specify the limits in the log_range\nlog_range=range(limits[1], limits[2]; length=N): specify the range of points (in log scale) to sample the Hessian line\nN=101: number of points to use within the log_range default range 10^-810^0\nplot=false: whether to plot the resulting verification (requires Plots.jl to be loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nslope_tol=0.1: tolerance for the slope (global) of the approximation\nerror=:none: how to handle errors, possible values: :error, :info, :warn\nwindow=nothing: specify window sizes within the log_range that are used for the slope estimation. the default is, to use all window sizes 2:N.\n\nThe kwargs... are also passed down to the check_vector and the check_gradient call, such that tolerances can easily be set.\n\nWhile check_vector is also passed to the inner call to check_gradient as well as the retraction_method, this inner check_gradient is meant to be just for inner verification, so it does not throw an error nor produce a plot itself.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.check_differential","page":"Checks","title":"Manopt.check_differential","text":"check_differential(M, F, dF, p=rand(M), X=rand(M; vector_at=p); kwargs...)\n\nCheck numerically whether the differential dF(M,p,X) of F(M,p) is correct.\n\nThis implements the method described in [Bou23, Section 4.8].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot is generated,\n\nKeyword arguments\n\nexactness_tol=1e-12: if all errors are below this tolerance, the differential is considered to be exact\nio=nothing: provide an IO to print the result to\nlimits=(-8.0, 0.0): specify the limits in the log_range\nlog_range=range(limits[1], limits[2]; length=N): specify the range of points (in log scale) to sample the differential line\nN=101: number of points to verify within the log_range default range 10^-810^0\nname=\"differential\": name to display in the plot\nplot=false: whether to plot the result (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nslope_tol=0.1: tolerance for the slope (global) of the approximation\nthrow_error=false: throw an error message if the differential is wrong\nwindow=nothing: specify window sizes within the log_range that are used for the slope estimation. The default is, to use all window sizes 2:N.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.check_gradient","page":"Checks","title":"Manopt.check_gradient","text":"check_gradient(M, f, grad_f, p=rand(M), X=rand(M; vector_at=p); kwargs...)\n\nVerify numerically whether the gradient grad_f(M,p) of f(M,p) is correct, that is whether\n\nf(operatornameretr_p(tX)) = f(p) + toperatornamegrad f(p) X + mathcal O(t^2)\n\nor in other words, that the error between the function f and its first order Taylor behaves in error mathcal O(t^2), which indicates that the gradient is correct, cf. also [Bou23, Section 4.8].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot is generated.\n\nKeyword arguments\n\ncheck_vector=true: verify that operatornamegradf(p)  T_pmathcal M using is_vector.\nexactness_tol=1e-12: if all errors are below this tolerance, the gradient is considered to be exact\nio=nothing: provide an IO to print the result to\ngradient=grad_f(M, p): instead of the gradient function you can also provide the gradient at p directly\nlimits=(-8.0, 0.0): specify the limits in the log_range\nlog_range=range(limits[1], limits[2]; length=N):\nspecify the range of points (in log scale) to sample the gradient line\nN=101: number of points to verify within the log_range default range 10^-810^0\nplot=false: whether to plot the result (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nslope_tol=0.1: tolerance for the slope (global) of the approximation\natol, rtol: (same defaults as isapprox) tolerances that are passed down to is_vector if check_vector is set to true\nerror=:none: how to handle errors, possible values: :error, :info, :warn\nwindow=nothing: specify window sizes within the log_range that are used for the slope estimation. the default is, to use all window sizes 2:N.\n\nThe remaining keyword arguments are also passed down to the check_vector call, such that tolerances can easily be set.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.is_Hessian_linear","page":"Checks","title":"Manopt.is_Hessian_linear","text":"is_Hessian_linear(M, Hess_f, p,\n    X=rand(M; vector_at=p), Y=rand(M; vector_at=p), a=randn(), b=randn();\n    error=:none, io=nothing, kwargs...\n)\n\nVerify whether the Hessian function Hess_f fulfills linearity,\n\noperatornameHess f(p)aX + bY = boperatornameHess f(p)X\n + boperatornameHess f(p)Y\n\nwhich is checked using isapprox and the keyword arguments are passed to this function.\n\nOptional arguments\n\nerror=:none: how to handle errors, possible values: :error, :info, :warn\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.is_Hessian_symmetric","page":"Checks","title":"Manopt.is_Hessian_symmetric","text":"is_Hessian_symmetric(M, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M; vector_at=p);\nerror=:none, io=nothing, atol::Real=0, rtol::Real=atol>0 ? 0 : âˆšeps\n\n)\n\nVerify whether the Hessian function Hess_f fulfills symmetry, which means that\n\noperatornameHess f(p)X Y = X operatornameHess f(p)Y\n\nwhich is checked using isapprox and the kwargs... are passed to this function.\n\nOptional arguments\n\natol, rtol   with the same defaults as the usual isapprox\nerror=:none: how to handle errors, possible values: :error, :info, :warn\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Literature","page":"Checks","title":"Literature","text":"","category":"section"},{"location":"helpers/checks/","page":"Checks","title":"Checks","text":"N.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\n","category":"page"},{"location":"solvers/difference_of_convex/#Difference-of-convex","page":"Difference of Convex","title":"Difference of convex","text":"","category":"section"},{"location":"solvers/difference_of_convex/#solver-difference-of-convex","page":"Difference of Convex","title":"Difference of convex algorithm","text":"","category":"section"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm","page":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm","text":"difference_of_convex_algorithm(M, f, g, âˆ‚h, p=rand(M); kwargs...)\ndifference_of_convex_algorithm(M, mdco, p; kwargs...)\ndifference_of_convex_algorithm!(M, f, g, âˆ‚h, p; kwargs...)\ndifference_of_convex_algorithm!(M, mdco, p; kwargs...)\n\nCompute the difference of convex algorithm [BFSS24] to minimize\n\n    operatorname*argmin_pmathcal M g(p) - h(p)\n\nwhere you need to provide f(p) = g(p) - h(p), g and the subdifferential h of h.\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nTake X^(k)   h(p^(k))\nSet the next iterate to the solution of the subproblem\n\n  p^(k+1)  operatorname*argmin_q  mathcal M g(q) - X^(k) log_p^(k)q\n\nuntil the stopping criterion (see the stopping_criterion keyword is fulfilled.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing:        specify operatornamegrad f, for debug / analysis or enhancing the stopping_criterion=\ngrad_g=nothing:          specify the gradient of g. If specified, a subsolver is automatically set up.\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled\ng=nothing:               specify the function g If specified, a subsolver is automatically set up.\nsub_cost=LinearizedDCCost(g, p, initial_vector): a cost to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=LinearizedDCGrad(grad_g, p, initial_vector; evaluation=evaluation): gradient to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_state=(GradientDescentState or TrustRegionsState if sub_hessian is provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_stopping_criterion=StopAfterIteration(300)|StopWhenStepsizeLess(1e-9)|StopWhenGradientNormLess(1e-9): a stopping criterion used withing the default sub_state= This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_stepsize=ArmijoLinesearch(M)) specify a step size used within the sub_state. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm!","page":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm!","text":"difference_of_convex_algorithm(M, f, g, âˆ‚h, p=rand(M); kwargs...)\ndifference_of_convex_algorithm(M, mdco, p; kwargs...)\ndifference_of_convex_algorithm!(M, f, g, âˆ‚h, p; kwargs...)\ndifference_of_convex_algorithm!(M, mdco, p; kwargs...)\n\nCompute the difference of convex algorithm [BFSS24] to minimize\n\n    operatorname*argmin_pmathcal M g(p) - h(p)\n\nwhere you need to provide f(p) = g(p) - h(p), g and the subdifferential h of h.\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nTake X^(k)   h(p^(k))\nSet the next iterate to the solution of the subproblem\n\n  p^(k+1)  operatorname*argmin_q  mathcal M g(q) - X^(k) log_p^(k)q\n\nuntil the stopping criterion (see the stopping_criterion keyword is fulfilled.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing:        specify operatornamegrad f, for debug / analysis or enhancing the stopping_criterion=\ngrad_g=nothing:          specify the gradient of g. If specified, a subsolver is automatically set up.\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled\ng=nothing:               specify the function g If specified, a subsolver is automatically set up.\nsub_cost=LinearizedDCCost(g, p, initial_vector): a cost to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=LinearizedDCGrad(grad_g, p, initial_vector; evaluation=evaluation): gradient to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_state=(GradientDescentState or TrustRegionsState if sub_hessian is provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_stopping_criterion=StopAfterIteration(300)|StopWhenStepsizeLess(1e-9)|StopWhenGradientNormLess(1e-9): a stopping criterion used withing the default sub_state= This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_stepsize=ArmijoLinesearch(M)) specify a step size used within the sub_state. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#solver-difference-of-convex-proximal-point","page":"Difference of Convex","title":"Difference of convex proximal point","text":"","category":"section"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point","page":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point","text":"difference_of_convex_proximal_point(M, grad_h, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point(M, mdcpo, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point!(M, grad_h, p; kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, p; kwargs...)\n\nCompute the difference of convex proximal point algorithm [SO15] to minimize\n\n    operatorname*argmin_pmathcal M g(p) - h(p)\n\nwhere you have to provide the subgradient h of h and either\n\nthe proximal map operatornameprox_Î»g of g as a function prox_g(M, Î», p) or  prox_g(M, q, Î», p)\nthe functions g and grad_g to compute the proximal map using a sub solver\nyour own sub-solver, specified by sub_problem=and sub_state=\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nX^(k)   operatornamegrad h(p^(k))\nq^(k) = operatornameretr_p^(k)(Î»_kX^(k))\nr^(k) = operatornameprox_Î»_kg(q^(k))\nX^(k) = operatornameretr^-1_p^(k)(r^(k))\nCompute a stepsize s_k and\nset p^(k+1) = operatornameretr_p^(k)(s_kX^(k)).\n\nuntil the stopping_criterion is fulfilled.\n\nSee [ACOO20] for more details on the modified variant, where steps 4-6 are slightly changed, since here the classical proximal point method for DC functions is obtained for s_k = 1 and one can hence employ usual line search method.\n\nKeyword arguments\n\nÎ»:                          ( k -> 1/2 ) a function returning the sequence of prox parameters Î»_k\ncost=nothing: provide the cost f, for debug reasons / analysis\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing: specify operatornamegrad f, for debug / analysis  or enhancing the stopping_criterion\nprox_g=nothing: specify a proximal map for the sub problem or both of the following\ng=nothing: specify the function g.\ngrad_g=nothing: specify the gradient of g. If both gand grad_g are specified, a subsolver is automatically set up.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=ConstantLength(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8)): a functor indicating that the stopping criterion is fulfilled A StopWhenGradientNormLess(1e-8) is added with |, when a gradient is provided.\nsub_cost=ProximalDCCost(g, copy(M, p), Î»(1))): cost to be used within the default sub_problem that is initialized as soon as g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=ProximalDCGrad(grad_g, copy(M, p), Î»(1); evaluation=evaluation): gradient to be used within the default sub_problem, that is initialized as soon as grad_g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=(GradientDescentState or TrustRegionsState if sub_hessian is provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_stopping_criterion=(StopAfterIteration(300)|[StopWhenGradientNormLess](@ref)(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define thesubstate=keyword and has hence no effect, if you setsubstate` directly.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point!","page":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point!","text":"difference_of_convex_proximal_point(M, grad_h, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point(M, mdcpo, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point!(M, grad_h, p; kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, p; kwargs...)\n\nCompute the difference of convex proximal point algorithm [SO15] to minimize\n\n    operatorname*argmin_pmathcal M g(p) - h(p)\n\nwhere you have to provide the subgradient h of h and either\n\nthe proximal map operatornameprox_Î»g of g as a function prox_g(M, Î», p) or  prox_g(M, q, Î», p)\nthe functions g and grad_g to compute the proximal map using a sub solver\nyour own sub-solver, specified by sub_problem=and sub_state=\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nX^(k)   operatornamegrad h(p^(k))\nq^(k) = operatornameretr_p^(k)(Î»_kX^(k))\nr^(k) = operatornameprox_Î»_kg(q^(k))\nX^(k) = operatornameretr^-1_p^(k)(r^(k))\nCompute a stepsize s_k and\nset p^(k+1) = operatornameretr_p^(k)(s_kX^(k)).\n\nuntil the stopping_criterion is fulfilled.\n\nSee [ACOO20] for more details on the modified variant, where steps 4-6 are slightly changed, since here the classical proximal point method for DC functions is obtained for s_k = 1 and one can hence employ usual line search method.\n\nKeyword arguments\n\nÎ»:                          ( k -> 1/2 ) a function returning the sequence of prox parameters Î»_k\ncost=nothing: provide the cost f, for debug reasons / analysis\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing: specify operatornamegrad f, for debug / analysis  or enhancing the stopping_criterion\nprox_g=nothing: specify a proximal map for the sub problem or both of the following\ng=nothing: specify the function g.\ngrad_g=nothing: specify the gradient of g. If both gand grad_g are specified, a subsolver is automatically set up.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=ConstantLength(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8)): a functor indicating that the stopping criterion is fulfilled A StopWhenGradientNormLess(1e-8) is added with |, when a gradient is provided.\nsub_cost=ProximalDCCost(g, copy(M, p), Î»(1))): cost to be used within the default sub_problem that is initialized as soon as g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=ProximalDCGrad(grad_g, copy(M, p), Î»(1); evaluation=evaluation): gradient to be used within the default sub_problem, that is initialized as soon as grad_g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=(GradientDescentState or TrustRegionsState if sub_hessian is provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_stopping_criterion=(StopAfterIteration(300)|[StopWhenGradientNormLess](@ref)(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define thesubstate=keyword and has hence no effect, if you setsubstate` directly.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Solver-states","page":"Difference of Convex","title":"Solver states","text":"","category":"section"},{"location":"solvers/difference_of_convex/#Manopt.DifferenceOfConvexState","page":"Difference of Convex","title":"Manopt.DifferenceOfConvexState","text":"DifferenceOfConvexState{Pr,St,P,T,SC<:StoppingCriterion} <:\n           AbstractManoptSolverState\n\nA struct to store the current state of the [difference_of_convex_algorithm])(@ref). It comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring a subgradient at the current iterate\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nThe sub task consists of a method to solve\n\n    operatorname*argmin_qmathcal M g(p) - X log_p q\n\nis needed. Besides a problem and a state, one can also provide a function and an AbstractEvaluationType, respectively, to indicate a closed form solution for the sub task.\n\nConstructors\n\nDifferenceOfConvexState(M, sub_problem, sub_state; kwargs...)\nDifferenceOfConvexState(M, sub_solver; evaluation=InplaceEvaluation(), kwargs...)\n\nGenerate the state either using a solver from Manopt, given by an AbstractManoptProblem sub_problem and an AbstractManoptSolverState sub_state, or a closed form solution sub_solver for the sub-problem the function expected to be of the form (M, p, X) -> q or (M, q, p, X) -> q, where by default its AbstractEvaluationType evaluation is in-place of q. Here the elements passed are the current iterate p and the subgradient X of h can be passed to that function.\n\nfurther keyword arguments\n\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstopping_criterion=StopAfterIteration(200): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.DifferenceOfConvexProximalState","page":"Difference of Convex","title":"Manopt.DifferenceOfConvexProximalState","text":"DifferenceOfConvexProximalState{P, T, Pr, St, S<:Stepsize, SC<:StoppingCriterion, RTR<:AbstractRetractionMethod, ITR<:AbstractInverseRetractionMethod}\n    <: AbstractSubProblemSolverState\n\nA struct to store the current state of the algorithm as well as the form. It comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\np::P: a point on the manifold mathcal Mstoring the current iterate\nq::P: a point on the manifold mathcal M storing the gradient step\nr::P: a point on the manifold mathcal M storing the result of the proximal map\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nX, Y: the current gradient and descent direction, respectively their common type is set by the keyword X\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nConstructor\n\nDifferenceOfConvexProximalState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\n\nconstruct an difference of convex proximal point state\n\nDifferenceOfConvexProximalState(M::AbstractManifold, sub_problem;\n    evaluation=AllocatingEvaluation(), kwargs...\n\n)\n\nconstruct an difference of convex proximal point state, where sub_problem is a closed form solution with evaluation as type of evaluation.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nsub_problem:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=ConstantLength(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopWhenChangeLess`(1e-8): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#The-difference-of-convex-objective","page":"Difference of Convex","title":"The difference of convex objective","text":"","category":"section"},{"location":"solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexObjective","page":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexObjective","text":"ManifoldDifferenceOfConvexObjective{E} <: AbstractManifoldCostObjective{E}\n\nSpecify an objective for a difference_of_convex_algorithm.\n\nThe objective f mathcal M  â„ is given as\n\n    f(p) = g(p) - h(p)\n\nwhere both g and h are convex, lower semicontinuous and proper. Furthermore the subdifferential h of h is required.\n\nFields\n\ncost: an implementation of f(p) = g(p)-h(p) as a function f(M,p).\nâˆ‚h!!: a deterministic version of h mathcal M  Tmathcal M, in the sense that calling âˆ‚h(M, p) returns a subgradient of h at p and if there is more than one, it returns a deterministic choice.\n\nNote that the subdifferential might be given in two possible signatures\n\nâˆ‚h(M,p) which does an AllocatingEvaluation\nâˆ‚h!(M, X, p) which does an InplaceEvaluation in place of X.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"as well as for the corresponding sub problem","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.LinearizedDCCost","page":"Difference of Convex","title":"Manopt.LinearizedDCCost","text":"LinearizedDCCost\n\nA functor (M,q) â†’ â„ to represent the inner problem of a ManifoldDifferenceOfConvexObjective. This is a cost function of the form\n\n    F_p_kX_k(p) = g(p) - X_k log_p_kp\n\nfor a point p_k and a tangent vector X_k at p_k (for example outer iterates) that are stored within this functor as well.\n\nFields\n\ng a function\npk a point on a manifold\nXk a tangent vector at pk\n\nBoth interim values can be set using set_parameter!(::LinearizedDCCost, ::Val{:p}, p) and set_parameter!(::LinearizedDCCost, ::Val{:X}, X), respectively.\n\nConstructor\n\nLinearizedDCCost(g, p, X)\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.LinearizedDCGrad","page":"Difference of Convex","title":"Manopt.LinearizedDCGrad","text":"LinearizedDCGrad\n\nA functor (M,X,p) â†’ â„ to represent the gradient of the inner problem of a ManifoldDifferenceOfConvexObjective. This is a gradient function of the form\n\n    F_p_kX_k(p) = g(p) - X_k log_p_kp\n\nits gradient is given by using F=F_1(F_2(p)), where F_1(X) = X_kX and F_2(p) = log_p_kp and the chain rule as well as the adjoint differential of the logarithmic map with respect to its argument for D^*F_2(p)\n\n    operatornamegrad F(q) = operatornamegrad f(q) - DF_2^*(q)X\n\nfor a point pk and a tangent vector Xk at pk (the outer iterates) that are stored within this functor as well\n\nFields\n\ngrad_g!! the gradient of g (see also LinearizedDCCost)\npk a point on a manifold\nXk a tangent vector at pk\n\nBoth interim values can be set using set_parameter!(::LinearizedDCGrad, ::Val{:p}, p) and set_parameter!(::LinearizedDCGrad, ::Val{:X}, X), respectively.\n\nConstructor\n\nLinearizedDCGrad(grad_g, p, X; evaluation=AllocatingEvaluation())\n\nWhere you specify whether grad_g is AllocatingEvaluation or InplaceEvaluation, while this function still provides both signatures.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexProximalObjective","page":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexProximalObjective","text":"ManifoldDifferenceOfConvexProximalObjective{E} <: Problem\n\nSpecify an objective difference_of_convex_proximal_point algorithm. The problem is of the form\n\n    operatorname*argmin_pmathcal M g(p) - h(p)\n\nwhere both g and h are convex, lower semicontinuous and proper.\n\nFields\n\ncost:     implementation of f(p) = g(p)-h(p)\ngradient: the gradient of the cost\ngrad_h!!: a function operatornamegradh mathcal M  Tmathcal M,\n\nNote that both the gradients might be given in two possible signatures as allocating or in-place.\n\nConstructor\n\nManifoldDifferenceOfConvexProximalObjective(gradh; cost=nothing, gradient=nothing)\n\nan note that neither cost nor gradient are required for the algorithm, just for eventual debug or stopping criteria.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"as well as for the corresponding sub problems","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.ProximalDCCost","page":"Difference of Convex","title":"Manopt.ProximalDCCost","text":"ProximalDCCost\n\nA functor (M, p) â†’ â„ to represent the inner cost function of a ManifoldDifferenceOfConvexProximalObjective. This is the cost function of the proximal map of g.\n\n    F_p_k(p) = frac12Î»d_mathcal M(p_kp)^2 + g(p)\n\nfor a point pk and a proximal parameter Î».\n\nFields\n\ng  - a function\npk - a point on a manifold\nÎ»  - the prox parameter\n\nBoth interim values can be set using set_parameter!(::ProximalDCCost, ::Val{:p}, p) and set_parameter!(::ProximalDCCost, ::Val{:Î»}, Î»), respectively.\n\nConstructor\n\nProximalDCCost(g, p, Î»)\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.ProximalDCGrad","page":"Difference of Convex","title":"Manopt.ProximalDCGrad","text":"ProximalDCGrad\n\nA functor (M,X,p) â†’ â„ to represent the gradient of the inner cost function of a ManifoldDifferenceOfConvexProximalObjective. This is the gradient function of the proximal map cost function of g. Based on\n\n    F_p_k(p) = frac12Î»d_mathcal M(p_kp)^2 + g(p)\n\nit reads\n\n    operatornamegrad F_p_k(p) = operatornamegrad g(p) - frac1Î»log_p p_k\n\nfor a point pk and a proximal parameter Î».\n\nFields\n\ngrad_g  - a gradient function\npk - a point on a manifold\nÎ»  - the prox parameter\n\nBoth interim values can be set using set_parameter!(::ProximalDCGrad, ::Val{:p}, p) and set_parameter!(::ProximalDCGrad, ::Val{:Î»}, Î»), respectively.\n\nConstructor\n\nProximalDCGrad(grad_g, pk, Î»; evaluation=AllocatingEvaluation())\n\nWhere you specify whether grad_g is AllocatingEvaluation or InplaceEvaluation, while this function still always provides both signatures.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Helper-functions","page":"Difference of Convex","title":"Helper functions","text":"","category":"section"},{"location":"solvers/difference_of_convex/#Manopt.get_subtrahend_gradient","page":"Difference of Convex","title":"Manopt.get_subtrahend_gradient","text":"X = get_subtrahend_gradient(amp, q)\nget_subtrahend_gradient!(amp, X, q)\n\nEvaluate the (sub)gradient of the subtrahend h from within a ManifoldDifferenceOfConvexObjective amp at the point q (in place of X).\n\nThe evaluation is done in place of X for the !-variant. The T=AllocatingEvaluation problem might still allocate memory within. When the non-mutating variant is called with a T=InplaceEvaluation memory for the result is allocated.\n\n\n\n\n\nX = get_subtrahend_gradient(M::AbstractManifold, dcpo::ManifoldDifferenceOfConvexProximalObjective, p)\nget_subtrahend_gradient!(M::AbstractManifold, X, dcpo::ManifoldDifferenceOfConvexProximalObjective, p)\n\nEvaluate the gradient of the subtrahend h from within a ManifoldDifferenceOfConvexProximalObjectivePat the pointp` (in place of X).\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#sec-cp-technical-details","page":"Difference of Convex","title":"Technical details","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"The difference_of_convex_algorithm and difference_of_convex_proximal_point solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= or retraction_method_dual= (for mathcal N) does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified.","category":"page"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"By default, one of the stopping criteria is StopWhenChangeLess, which either requires","category":"page"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= or retraction_method_dual= (for mathcal N) does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.\nA copyto!(M, q, p) and copy(M,p) for points.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).\neverything the subsolver requires, which by default is the trust_regions or if you do not provide a Hessian gradient_descent.","category":"page"},{"location":"solvers/difference_of_convex/#Literature","page":"Difference of Convex","title":"Literature","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"Y.Â T.Â Almeida, J.Â X.Â Cruz Neto, P.Â R.Â Oliveira and J.Â C.Â Oliveira Souza. A modified proximal point method for DC functions on Hadamard manifolds. ComputationalÂ OptimizationÂ andÂ Applications 76, 649â€“673 (2020).\n\n\n\nR.Â Bergmann, O.Â P.Â Ferreira, E.Â M.Â Santos and J.Â C.Â Souza. The difference of convex algorithm on Hadamard manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications (2024).\n\n\n\nJ.Â C.Â Souza and P.Â R.Â Oliveira. A proximal point algorithm for DC fuctions on Hadamard manifolds. JournalÂ ofÂ GlobalÂ Optimization 63, 797â€“810 (2015).\n\n\n\n","category":"page"},{"location":"solvers/interior_point_Newton/#Interior-point-Newton-method","page":"Interior Point Newton","title":"Interior point Newton method","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Manopt.interior_point_Newton","page":"Interior Point Newton","title":"Manopt.interior_point_Newton","text":"interior_point_Newton(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ninterior_point_Newton(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\ninterior_point_Newton!(M, f, grad]_f, Hess_f, p; kwargs...)\ninterior_point_Newton(M, ConstrainedManifoldObjective, p; kwargs...)\n\nperform the interior point Newton method following [LY24].\n\nIn order to solve the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nThis algorithms iteratively solves the linear system based on extending the KKT system by a slack variable s.\n\noperatornameJ F(p Î¼ Î» s)X Y Z W = -F(p Î¼ Î» s)\ntext where \nX  T_pmathcal M YW  â„^m Z  â„^n\n\nsee CondensedKKTVectorFieldJacobian and CondensedKKTVectorField, respectively, for the reduced form, this is usually solved in. From the resulting X and Z in the reeuced form, the other two, Y, W, are then computed.\n\nFrom the gradient (XYZW) at the current iterate (p Î¼ Î» s), a line search is performed using the KKTVectorFieldNormSq norm of the KKT vector field (squared) and its gradient KKTVectorFieldNormSqGradient together with the InteriorPointCentralityCondition.\n\nNote that since the vector field F includes the gradients of the constraint functions g h, its gradient or Jacobian requires the Hessians of the constraints.\n\nFor that seach direction a line search is performed, that additionally ensures that the constraints are further fulfilled.\n\nInput\n\nM: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\n\nor a ConstrainedManifoldObjective cmo containing f, grad_f, Hess_f, and the constraints\n\nKeyword arguments\n\nThe keyword arguments related to the constraints (the first eleven) are ignored if you pass a ConstrainedManifoldObjective cmo\n\ncentrality_condition=missing; an additional condition when to accept a step size. This can be used to ensure that the resulting iterate is still an interior point if you provide a check (N,q) -> true/false, where N is the manifold of the step_problem.\nequality_constraints=nothing: the number n of equality constraints.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ng=nothing: the inequality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\ngradient_range=nothing: specify how gradients are represented, where nothing is equivalent to NestedPowerRepresentation\ngradient_equality_range=gradient_range: specify how the gradients of the equality constraints are represented\ngradient_inequality_range=gradient_range: specify how the gradients of the inequality constraints are represented\nh=nothing: the equality constraints\nHess_g=nothing: the Hessian of the inequality constraints\nHess_h=nothing: the Hessian of the equality constraints\ninequality_constraints=nothing: the number m of inequality constraints.\nÎ»=ones(length(h(M, p))): the Lagrange multiplier with respect to the equality constraints h\nÎ¼=ones(length(g(M, p))): the Lagrange multiplier with respect to the inequality constraints g\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nÏ=Î¼'s / length(Î¼):  store the orthogonality Î¼'s/m to compute the barrier parameter Î² in the sub problem.\ns=copy(Î¼): initial value for the slack variables\nÏƒ=calculate_Ïƒ(M, cmo, p, Î¼, Î», s):  scaling factor for the barrier parameter Î² in the sub problem, which is updated during the iterations\nstep_objective: a ManifoldGradientObjective of the norm of the KKT vector field KKTVectorFieldNormSq and its gradient KKTVectorFieldNormSqGradient\nstep_problem: the manifold mathcal M  â„^m  â„^n  â„^m together with the step_objective as the problem the linesearch stepsize= employs for determining a step size\nstep_state: the StepsizeState with point and search direction\nstepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size with the centrality_condtion keyword as additional criterion to accept a step, if this is provided\nstopping_criterion=StopAfterIteration(200)|StopWhenKKTResidualLess(1e-8): a functor indicating that the stopping criterion is fulfilled a stopping criterion, by default depending on the residual of the KKT vector field or a maximal number of steps, which ever hits first.\nsub_kwargs=(;): keyword arguments to decorate the sub options, for example debug, that automatically respects the main solvers debug options (like sub-sampling) as well\nsub_objective: The SymmetricLinearSystemObjective modelling the system of equations to use in the sub solver, includes the CondensedKKTVectorFieldJacobian mathcal A(X) and the CondensedKKTVectorField b in mathcal A(X) + b = 0 we aim to solve. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_stopping_criterion=StopAfterIteration(manifold_dimension(M))|StopWhenRelativeResidualLess(c,1e-8), where c = lVert b rVert_ from the system to solve. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=ConjugateResidualState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_space=Rn a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nX=zero_vector(M,p): th initial gradient with respect to p.\nY=zero(Î¼):  the initial gradient with respct to Î¼\nZ=zero(Î»):  the initial gradient with respct to Î»\nW=zero(s):  the initial gradient with respct to s\n\nAs well as internal keywords used to set up these given keywords like _step_M, _step_p, _sub_M, _sub_p, and _sub_X, that should not be changed.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective, respectively.\n\nnote: Note\nThe centrality_condition=mising disables to check centrality during the line search, but you can pass InteriorPointCentralityCondition(cmo, Î³), where Î³ is a constant, to activate this check.\n\nOutput\n\nThe obtained approximate constrained minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/interior_point_Newton/#Manopt.interior_point_Newton!","page":"Interior Point Newton","title":"Manopt.interior_point_Newton!","text":"interior_point_Newton(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ninterior_point_Newton(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\ninterior_point_Newton!(M, f, grad]_f, Hess_f, p; kwargs...)\ninterior_point_Newton(M, ConstrainedManifoldObjective, p; kwargs...)\n\nperform the interior point Newton method following [LY24].\n\nIn order to solve the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nThis algorithms iteratively solves the linear system based on extending the KKT system by a slack variable s.\n\noperatornameJ F(p Î¼ Î» s)X Y Z W = -F(p Î¼ Î» s)\ntext where \nX  T_pmathcal M YW  â„^m Z  â„^n\n\nsee CondensedKKTVectorFieldJacobian and CondensedKKTVectorField, respectively, for the reduced form, this is usually solved in. From the resulting X and Z in the reeuced form, the other two, Y, W, are then computed.\n\nFrom the gradient (XYZW) at the current iterate (p Î¼ Î» s), a line search is performed using the KKTVectorFieldNormSq norm of the KKT vector field (squared) and its gradient KKTVectorFieldNormSqGradient together with the InteriorPointCentralityCondition.\n\nNote that since the vector field F includes the gradients of the constraint functions g h, its gradient or Jacobian requires the Hessians of the constraints.\n\nFor that seach direction a line search is performed, that additionally ensures that the constraints are further fulfilled.\n\nInput\n\nM: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\n\nor a ConstrainedManifoldObjective cmo containing f, grad_f, Hess_f, and the constraints\n\nKeyword arguments\n\nThe keyword arguments related to the constraints (the first eleven) are ignored if you pass a ConstrainedManifoldObjective cmo\n\ncentrality_condition=missing; an additional condition when to accept a step size. This can be used to ensure that the resulting iterate is still an interior point if you provide a check (N,q) -> true/false, where N is the manifold of the step_problem.\nequality_constraints=nothing: the number n of equality constraints.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ng=nothing: the inequality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\ngradient_range=nothing: specify how gradients are represented, where nothing is equivalent to NestedPowerRepresentation\ngradient_equality_range=gradient_range: specify how the gradients of the equality constraints are represented\ngradient_inequality_range=gradient_range: specify how the gradients of the inequality constraints are represented\nh=nothing: the equality constraints\nHess_g=nothing: the Hessian of the inequality constraints\nHess_h=nothing: the Hessian of the equality constraints\ninequality_constraints=nothing: the number m of inequality constraints.\nÎ»=ones(length(h(M, p))): the Lagrange multiplier with respect to the equality constraints h\nÎ¼=ones(length(g(M, p))): the Lagrange multiplier with respect to the inequality constraints g\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nÏ=Î¼'s / length(Î¼):  store the orthogonality Î¼'s/m to compute the barrier parameter Î² in the sub problem.\ns=copy(Î¼): initial value for the slack variables\nÏƒ=calculate_Ïƒ(M, cmo, p, Î¼, Î», s):  scaling factor for the barrier parameter Î² in the sub problem, which is updated during the iterations\nstep_objective: a ManifoldGradientObjective of the norm of the KKT vector field KKTVectorFieldNormSq and its gradient KKTVectorFieldNormSqGradient\nstep_problem: the manifold mathcal M  â„^m  â„^n  â„^m together with the step_objective as the problem the linesearch stepsize= employs for determining a step size\nstep_state: the StepsizeState with point and search direction\nstepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size with the centrality_condtion keyword as additional criterion to accept a step, if this is provided\nstopping_criterion=StopAfterIteration(200)|StopWhenKKTResidualLess(1e-8): a functor indicating that the stopping criterion is fulfilled a stopping criterion, by default depending on the residual of the KKT vector field or a maximal number of steps, which ever hits first.\nsub_kwargs=(;): keyword arguments to decorate the sub options, for example debug, that automatically respects the main solvers debug options (like sub-sampling) as well\nsub_objective: The SymmetricLinearSystemObjective modelling the system of equations to use in the sub solver, includes the CondensedKKTVectorFieldJacobian mathcal A(X) and the CondensedKKTVectorField b in mathcal A(X) + b = 0 we aim to solve. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_stopping_criterion=StopAfterIteration(manifold_dimension(M))|StopWhenRelativeResidualLess(c,1e-8), where c = lVert b rVert_ from the system to solve. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=ConjugateResidualState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_space=Rn a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nX=zero_vector(M,p): th initial gradient with respect to p.\nY=zero(Î¼):  the initial gradient with respct to Î¼\nZ=zero(Î»):  the initial gradient with respct to Î»\nW=zero(s):  the initial gradient with respct to s\n\nAs well as internal keywords used to set up these given keywords like _step_M, _step_p, _sub_M, _sub_p, and _sub_X, that should not be changed.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective, respectively.\n\nnote: Note\nThe centrality_condition=mising disables to check centrality during the line search, but you can pass InteriorPointCentralityCondition(cmo, Î³), where Î³ is a constant, to activate this check.\n\nOutput\n\nThe obtained approximate constrained minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/interior_point_Newton/#State","page":"Interior Point Newton","title":"State","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Manopt.InteriorPointNewtonState","page":"Interior Point Newton","title":"Manopt.InteriorPointNewtonState","text":"InteriorPointNewtonState{P,T} <: AbstractHessianSolverState\n\nFields\n\nÎ»:           the Lagrange multiplier with respect to the equality constraints\nÎ¼:           the Lagrange multiplier with respect to the inequality constraints\np::P: a point on the manifold mathcal Mstoring the current iterate\ns:           the current slack variable\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nX:           the current gradient with respect to p\nY:           the current gradient with respect to Î¼\nZ:           the current gradient with respect to Î»\nW:           the current gradient with respect to s\nÏ:           store the orthogonality Î¼'s/m to compute the barrier parameter Î² in the sub problem\nÏƒ:           scaling factor for the barrier parameter Î² in the sub problem\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstep_problem: an AbstractManoptProblem storing the manifold and objective for the line search\nstep_state: storing iterate and search direction in a state for the line search, see StepsizeState\n\nConstructor\n\nInteriorPointNewtonState(\n    M::AbstractManifold,\n    cmo::ConstrainedManifoldObjective,\n    sub_problem::Pr,\n    sub_state::St;\n    kwargs...\n)\n\nInitialize the state, where both the AbstractManifold and the ConstrainedManifoldObjective are used to fill in reasonable defaults for the keywords.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\ncmo:         a ConstrainedManifoldObjective\nsub_problem:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\nLet m and n denote the number of inequality and equality constraints, respectively\n\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nÎ¼=ones(m)\nX=zero_vector(M,p)\nY=zero(Î¼)\nÎ»=zeros(n)\nZ=zero(Î»)\ns=ones(m)\nW=zero(s)\nÏ=Î¼'s/m\nÏƒ=calculate_Ïƒ(M, cmo, p, Î¼, Î», s)\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstep_objective=ManifoldGradientObjective(KKTVectorFieldNormSq(cmo), KKTVectorFieldNormSqGradient(cmo); evaluation=InplaceEvaluation())\nvector_space=Rn: a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nstep_problem: wrap the manifold mathcal M  â„^m  â„^n  â„^m\nstep_state: the StepsizeState with point and search direction\nstepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size with the InteriorPointCentralityCondition as additional condition to accept a step\n\nand internally _step_M and _step_p for the manifold and point in the stepsize.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Subproblem-functions","page":"Interior Point Newton","title":"Subproblem functions","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Manopt.CondensedKKTVectorField","page":"Interior Point Newton","title":"Manopt.CondensedKKTVectorField","text":"CondensedKKTVectorField{O<:ConstrainedManifoldObjective,T,R} <: AbstractConstrainedSlackFunctor{T,R}\n\nGiven the constrained optimization problem\n\nbeginaligned\nmin_p mathcalM f(p)\ntextsubject to  g_i(p)leq 0 quad text for  i= 1  m\nquad h_j(p)=0 quad text for  j=1n\nendaligned\n\nThen reformulating the KKT conditions of the Lagrangian from the optimality conditions of the Lagrangian\n\nmathcal L(p Î¼ Î») = f(p) + sum_j=1^n Î»_jh_j(p) + sum_i=1^m Î¼_ig_i(p)\n\nin a perturbed / barrier method in a condensed form using a slack variable s  â„^m and a barrier parameter Î² and the Riemannian gradient of the Lagrangian with respect to the first parameter operatornamegrad_p L(p Î¼ Î»).\n\nLet mathcal N = mathcal M  â„^n. We obtain the linear system\n\nmathcal A(pÎ»)XY = -b(pÎ»)qquad textwhere  (XY)  T_(pÎ»)mathcal N\n\nwhere mathcal A T_(pÎ»)mathcal N  T_(pÎ»)mathcal N is a linear operator and this struct models the right hand side b(pÎ»)  T_(pÎ»)mathcal M given by\n\nb(pÎ») = beginpmatrix\noperatornamegrad f(p)\n+ displaystylesum_j=1^n Î»_j operatornamegrad h_j(p)\n+ displaystylesum_i=1^m Î¼_i operatornamegrad g_i(p)\n+ displaystylesum_i=1^m fracÎ¼_is_ibigl(\n  Î¼_i(g_i(p)+s_i) + Î² - Î¼_is_i\nbigr)operatornamegrad g_i(p)\nh(p)\nendpmatrix\n\nFields\n\ncmo the ConstrainedManifoldObjective\nÎ¼::T the vector in â„^m of coefficients for the inequality constraints\ns::T the vector in â„^m of sclack variables\nÎ²::R the barrier parameter Î²â„\n\nConstructor\n\nCondensedKKTVectorField(cmo, Î¼, s, Î²)\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.CondensedKKTVectorFieldJacobian","page":"Interior Point Newton","title":"Manopt.CondensedKKTVectorFieldJacobian","text":"CondensedKKTVectorFieldJacobian{O<:ConstrainedManifoldObjective,T,R}  <: AbstractConstrainedSlackFunctor{T,R}\n\nGiven the constrained optimization problem\n\nbeginaligned\nmin_p mathcalM f(p)\ntextsubject to  g_i(p)leq 0 quad text for  i= 1  m\nquad h_j(p)=0 quad text for  j=1n\nendaligned\n\nwe reformulate the KKT conditions of the Lagrangian from the optimality conditions of the Lagrangian\n\nmathcal L(p Î¼ Î») = f(p) + sum_j=1^n Î»_jh_j(p) + sum_i=1^m Î¼_ig_i(p)\n\nin a perturbed / barrier method enhanced as well as condensed form as using operatornamegrad_o L(p Î¼ Î») the Riemannian gradient of the Lagrangian with respect to the first parameter.\n\nLet mathcal N = mathcal M  â„^n. We obtain the linear system\n\nmathcal A(pÎ»)XY = -b(pÎ»)qquad textwhere  X  T_pmathcal M Y  â„^n\n\nwhere mathcal A T_(pÎ»)mathcal N  T_(pÎ»)mathcal N is a linear operator on T_(pÎ»)mathcal N = T_pmathcal M  â„^n given by\n\nmathcal A(pÎ»)XY = beginpmatrix\noperatornameHess_pmathcal L(p Î¼ Î»)X\n+ displaystylesum_i=1^m fracÎ¼_is_ioperatornamegrad g_i(p) Xoperatornamegrad g_i(p)\n+ displaystylesum_j=1^n Y_j operatornamegrad h_j(p)\n\nBigl( operatornamegrad h_j(p) X Bigr)_j=1^n\nendpmatrix\n\nFields\n\ncmo the ConstrainedManifoldObjective\nÎ¼::V the vector in â„^m of coefficients for the inequality constraints\ns::V the vector in â„^m of slack variables\nÎ²::R the barrier parameter Î²â„\n\nConstructor\n\nCondensedKKTVectorFieldJacobian(cmo, Î¼, s, Î²)\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorField","page":"Interior Point Newton","title":"Manopt.KKTVectorField","text":"KKTVectorField{O<:ConstrainedManifoldObjective}\n\nImplement the vectorfield F KKT-conditions, inlcuding a slack variable for the inequality constraints.\n\nGiven the LagrangianCost\n\nmathcal L(p Î¼ Î») = f(p) + sum_i=1^m Î¼_ig_i(p) + sum_j=1^n Î»_jh_j(p)\n\nthe LagrangianGradient\n\noperatornamegradmathcal L(p Î¼ Î») = operatornamegradf(p) + sum_j=1^n Î»_j operatornamegrad h_j(p) + sum_i=1^m Î¼_i operatornamegrad g_i(p)\n\nand introducing the slack variables s=-g(p)  â„^m the vector field is given by\n\nF(p Î¼ Î» s) = beginpmatrix\noperatornamegrad_p mathcal L(p Î¼ Î»)\ng(p) + s\nh(p)\nÎ¼  s\nendpmatrix text where  p in mathcal M Î¼ s in â„^mtext and  Î» in â„^n\n\nwhere  denotes the Hadamard (or elementwise) product\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nWhile the point p is arbitrary and usually not needed, it serves as internal memory in the computations. Furthermore Both fields together also calrify the product manifold structure to use.\n\nConstructor\n\nKKTVectorField(cmo::ConstrainedManifoldObjective)\n\nExample\n\nDefine F = KKTVectorField(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcal Mâ„^mâ„^nâ„^m. Then, you can call this cost as F(N, q) or as the in-place variant F(N, Y, q), where q is a point on N and Y is a tangent vector at q for the result.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldJacobian","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldJacobian","text":"KKTVectorFieldJacobian{O<:ConstrainedManifoldObjective}\n\nImplement the Jacobian of the vector field F of the KKT-conditions, inlcuding a slack variable for the inequality constraints, see KKTVectorField and KKTVectorFieldAdjointJacobian..\n\noperatornameJ F(p Î¼ Î» s)X Y Z W = beginpmatrix\n    operatornameHess_p mathcal L(p Î¼ Î»)X + displaystylesum_i=1^m Y_i operatornamegrad g_i(p) + displaystylesum_j=1^n Z_j operatornamegrad h_j(p)\n    Bigl( operatornamegrad g_i(p) X + W_iBigr)_i=1^m\n    Bigl( operatornamegrad h_j(p) X Bigr)_j=1^n\n    Î¼  W + s  Y\nendpmatrix\n\nwhere  denotes the Hadamard (or elementwise) product\n\nSee also the LagrangianHessian operatornameHess_p mathcal L(p Î¼ Î»)X.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldJacobian(cmo::ConstrainedManifoldObjective)\n\nGenerate the Jacobian of the KKT vector field related to some ConstrainedManifoldObjective cmo.\n\nExample\n\nDefine JF = KKTVectorFieldJacobian(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcal Mâ„^mâ„^nâ„^m. Then, you can call this cost as JF(N, q, Y) or as the in-place variant JF(N, Z, q, Y), where q is a point on N and Y and Z are a tangent vector at q.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldAdjointJacobian","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldAdjointJacobian","text":"KKTVectorFieldAdjointJacobian{O<:ConstrainedManifoldObjective}\n\nImplement the Adjoint of the Jacobian of the vector field F of the KKT-conditions, inlcuding a slack variable for the inequality constraints, see KKTVectorField and KKTVectorFieldJacobian.\n\noperatornameJ^* F(p Î¼ Î» s)X Y Z W = beginpmatrix\n    operatornameHess_p mathcal L(p Î¼ Î»)X + displaystylesum_i=1^m Y_i operatornamegrad g_i(p) + displaystylesum_j=1^n Z_j operatornamegrad h_j(p)\n    Bigl( operatornamegrad g_i(p) X + s_iW_iBigr)_i=1^m\n    Bigl( operatornamegrad h_j(p) X Bigr)_j=1^n\n    Î¼  W + Y\nendpmatrix\n\nwhere  denotes the Hadamard (or elementwise) product\n\nSee also the LagrangianHessian operatornameHess_p mathcal L(p Î¼ Î»)X.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldAdjointJacobian(cmo::ConstrainedManifoldObjective)\n\nGenerate the Adjoint Jacobian of the KKT vector field related to some ConstrainedManifoldObjective cmo.\n\nExample\n\nDefine AdJF = KKTVectorFieldAdjointJacobian(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcal Mâ„^mâ„^nâ„^m. Then, you can call this cost as AdJF(N, q, Y) or as the in-place variant AdJF(N, Z, q, Y), where q is a point on N and Y and Z are a tangent vector at q.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldNormSq","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldNormSq","text":"KKTVectorFieldNormSq{O<:ConstrainedManifoldObjective}\n\nImplement the square of the norm of the vectorfield F of the KKT-conditions, inlcuding a slack variable for the inequality constraints, see KKTVectorField, where this functor applies the norm to. In [LY24] this is called the merit function.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldNormSq(cmo::ConstrainedManifoldObjective)\n\nExample\n\nDefine f = KKTVectorFieldNormSq(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcal Mâ„^mâ„^nâ„^m. Then, you can call this cost as f(N, q), where q is a point on N.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldNormSqGradient","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldNormSqGradient","text":"KKTVectorFieldNormSqGradient{O<:ConstrainedManifoldObjective}\n\nCompute the gradient of the KKTVectorFieldNormSq Ï†(pÎ¼Î»s) = lVert F(pÎ¼Î»s)rVert^2, that is of the norm squared of the KKTVectorField F.\n\nThis is given in [LY24] as the gradient of their merit function, which we can write with the adjoint J^* of the Jacobian\n\noperatornamegrad Ï† = 2operatornameJ^* F(p Î¼ Î» s)F(p Î¼ Î» s)\n\nand hence is computed with KKTVectorFieldAdjointJacobian and KKTVectorField.\n\nFor completeness, the gradient reads, using the LagrangianGradient L = operatornamegrad_p mathcal L(pÎ¼Î»)  T_pmathcal M, for a shorthand of the first component of F, as\n\noperatornamegrad Ï†\n=\n2 beginpmatrix\noperatornamegrad_p mathcal L(pÎ¼Î»)L + (g_i(p) + s_i)operatornamegrad g_i(p) + h_j(p)operatornamegrad h_j(p)\n  Bigl( operatornamegrad g_i(p) L + s_iBigr)_i=1^m + Î¼  s  s\n  Bigl( operatornamegrad h_j(p) L Bigr)_j=1^n\n  g + s + Î¼  Î¼  s\nendpmatrix\n\nwhere  denotes the Hadamard (or elementwise) product.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldNormSqGradient(cmo::ConstrainedManifoldObjective)\n\nExample\n\nDefine grad_f = KKTVectorFieldNormSqGradient(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcal Mâ„^mâ„^nâ„^m. Then, you can call this cost as grad_f(N, q) or as the in-place variant grad_f(N, Y, q), where q is a point on N and Y is a tangent vector at q returning the resulting gradient at.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Helpers","page":"Interior Point Newton","title":"Helpers","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Manopt.InteriorPointCentralityCondition","page":"Interior Point Newton","title":"Manopt.InteriorPointCentralityCondition","text":"InteriorPointCentralityCondition{CO,R}\n\nA functor to check the centrality condition.\n\nIn order to obtain a step in the linesearch performed within the interior_point_Newton, Section 6 of [LY24] propose the following additional conditions to hold inspired by the Euclidean case described in Section 6 [ETTZ96]:\n\nFor a given ConstrainedManifoldObjective assume consider the KKTVectorField F, that is we are at a point q = (p Î» Î¼ s)  on mathcal M  â„^m  â„^n  â„^mand a search direction V = (X Y Z W).\n\nThen, let\n\nÏ„_1 = fracmmin Î¼  sÎ¼^mathrmTs\nquadtext and quad\nÏ„_2 = fracÎ¼^mathrmTslVert F(q) rVert\n\nwhere  denotes the Hadamard (or elementwise) product.\n\nFor a new candidate q(Î±) = bigl(p(Î±) Î»(Î±) Î¼(Î±) s(Î±)bigr) = (operatornameretr_p(Î±X) Î»+Î±Y Î¼+Î±Z s+Î±W), we then define two functions\n\nc_1(Î±) = min Î¼(Î±)  s(Î±)  - fracÎ³Ï„_1 Î¼(Î±)^mathrmTs(Î±)m\nquadtext and quad\nc_2(Î±) = Î¼(Î±)^mathrmTs(Î±)  Î³Ï„_2 lVert F(q(Î±)) rVert\n\nWhile the paper now states that the (Armijo) linesearch starts at a point tilde Î±, it is easier to include the condition that c_1(Î±)  0 and c_2(Î±)  0 into the linesearch as well.\n\nThe functor InteriorPointCentralityCondition(cmo, Î³, Î¼, s, normKKT)(N,qÎ±) defined here evaluates this condition and returns true if both c_1 and c_2 are nonnegative.\n\nFields\n\ncmo: a ConstrainedManifoldObjective\nÎ³: a constant\nÏ„1, Ï„2: the constants given in the formula.\n\nConstructor\n\nInteriorPointCentralityCondition(cmo, Î³)\nInteriorPointCentralityCondition(cmo, Î³, Ï„1, Ï„2)\n\nInitialise the centrality conditions. The parameters Ï„1, Ï„2 are initialise to zero if not provided.\n\nnote: Note\nBesides get_parameter for all three constants, and set_parameter! for Î³, to update Ï„_1 and Ï„_2, call set_parameter(ipcc, :Ï„, N, q) to update both Ï„_1 and Ï„_2 according to the formulae above.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.calculate_Ïƒ","page":"Interior Point Newton","title":"Manopt.calculate_Ïƒ","text":"calculate_Ïƒ(M, cmo, p, Î¼, Î», s; kwargs...)\n\nCompute the new Ïƒ factor for the barrier parameter in interior_point_Newton as\n\nminfrac12 lVert F(p Î¼ Î» s)rVert^frac12 \n\nwhere F is the KKT vector field, hence the KKTVectorFieldNormSq is used.\n\nKeyword arguments\n\nvector_space=Rn a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nN the manifold mathcal M  â„^m  â„^n  â„^m the vector field lives on (generated using vector_space)\nq provide memory on N for interims evaluation of the vector field\n\n\n\n\n\n","category":"function"},{"location":"solvers/interior_point_Newton/#Additional-stopping-criteria","page":"Interior Point Newton","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Manopt.StopWhenKKTResidualLess","page":"Interior Point Newton","title":"Manopt.StopWhenKKTResidualLess","text":"StopWhenKKTResidualLess <: StoppingCriterion\n\nStop when the KKT residual\n\nr^2\n= \\lVert \\operatorname{grad}_p \\mathcal L(p, Î¼, Î») \\rVert^2\n+ \\sum_{i=1}^m [Î¼_i]_{-}^2 + [g_i(p)]_+^2 + \\lvert \\mu_ig_i(p)^2\n+ \\sum_{j=1}^n \\lvert h_i(p)\\rvert^2.\n\nis less than a given threshold r  Îµ. We use v_+ = max0v and v_- = min0t for the positive and negative part of v, respectively\n\nFields\n\nÎµ: a threshold\nresidual: store the last residual if the stopping criterion is hit.\nat_iteration:\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#References","page":"Interior Point Newton","title":"References","text":"","category":"section"},{"location":"solvers/interior_point_Newton/","page":"Interior Point Newton","title":"Interior Point Newton","text":"A.Â S.Â El-Bakry, R.Â A.Â Tapia, T.Â Tsuchiya and Y.Â Zhang. On the formulation and theory of the Newton interior-point method for nonlinear programming. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 89, 507â€“541 (1996).\n\n\n\nZ.Â Lai and A.Â Yoshise. Riemannian Interior Point Methods for Constrained Optimization on Manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 201, 433â€“469 (2024), arXiv:2203.09762.\n\n\n\n","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/#solver-pdrssn","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton algorithm","text":"","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The Primal-dual Riemannian semismooth Newton Algorithm is a second-order method derived from the ChambollePock.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The aim is to solve an optimization problem on a manifold with a cost function of the form","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"F(p) + G(Î›(p))","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"where Fmathcal M  overlineâ„, Gmathcal N  overlineâ„, and Î›mathcal M mathcal N. If the manifolds mathcal M or mathcal N are not Hadamard, it has to be considered locally only, that is on geodesically convex sets mathcal C subset mathcal M and mathcal D subsetmathcal N such that Î›(mathcal C) subset mathcal D.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The algorithm comes down to applying the Riemannian semismooth Newton method to the rewritten primal-dual optimality conditions. Define the vector field X mathcalM times mathcalT_n^* mathcalN rightarrow mathcalT mathcalM times mathcalT_n^* mathcalN as","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Xleft(p xi_nright)=left(beginarrayc\n-log _p operatornameprox_sigma Fleft(exp _pleft(mathcalP_p leftarrow mleft(-sigmaleft(D_m Lambdaright)^*leftmathcalP_Lambda(m) leftarrow n xi_nrightright)^sharpright)right) \nxi_n-operatornameprox_tau G_n^*left(xi_n+tauleft(mathcalP_n leftarrow Lambda(m) D_m Lambdaleftlog _m prightright)^flatright)\nendarrayright)","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"and solve for X(pÎ¾_n)=0.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Given base points mmathcal C, n=Î›(m)mathcal D, initial primal and dual values p^(0) mathcal C, Î¾_n^(0)  mathcal T_n^*mathcal N, and primal and dual step sizes sigma, tau.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The algorithms performs the steps k=1 (until a StoppingCriterion is reached)","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Choose any element\nV^(k)  _C X(p^(k)Î¾_n^(k))\nof the Clarke generalized covariant derivative\nSolve\nV^(k) (d_p^(k) d_n^(k)) = - X(p^(k)Î¾_n^(k))\nin the vector space mathcalT_p^(k) mathcalM times mathcalT_n^* mathcalN\nUpdate\np^(k+1) = exp_p^(k)(d_p^(k))\nand\nÎ¾_n^(k+1) = Î¾_n^(k) + d_n^(k)","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Furthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction and a vector transport.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Finally you can also update the base points m and n during the iterations. This introduces a few additional vector transports. The same holds for the case that Î›(m^(k))neq n^(k) at some point. All these cases are covered in the algorithm.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton","text":"primal_dual_semismooth_Newton(M, N, cost, p, X, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_dual_G, linearized_operator, adjoint_linearized_operator)\n\nPerform the Primal-Dual Riemannian semismooth Newton algorithm.\n\nGiven a cost function mathcal E mathcal M  overlineâ„ of the form\n\nmathcal E(p) = F(p) + G( Î›(p) )\n\nwhere F mathcal M  overlineâ„, G mathcal N  overlineâ„, and Î› mathcal M  mathcal N. The remaining input parameters are\n\np, X:                          primal and dual start points pmathcal M and X  T_nmathcal N\nm,n:                           base points on mathcal M and `\\mathcal N, respectively.\nlinearized_forward_operator:   the linearization DÎ›() of the operator Î›().\nadjoint_linearized_operator:   the adjoint DÎ›^* of the linearized operator DÎ›(m)  T_mmathcal M  T_Î›(m)mathcal N\nprox_F, prox_G_Dual:           the proximal maps of F and G^ast_n\ndiff_prox_F, diff_prox_dual_G: the (Clarke Generalized) differentials of the proximal maps of F and G^ast_n\n\nFor more details on the algorithm, see [DL21].\n\nKeyword arguments\n\ndual_stepsize=1/sqrt(8): proximal parameter of the dual prox\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the exact operator, that is required if Î›(m)=n does not hold; missing indicates, that the forward operator is exact.\nprimal_stepsize=1/sqrt(8): proximal parameter of the primal prox\nreg_param=1e-5: regularisation parameter for the Newton matrix Note that this changes the arguments the forward_operator is called.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(50): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton!","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton!","text":"primal_dual_semismooth_Newton(M, N, cost, p, X, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_dual_G, linearized_operator, adjoint_linearized_operator)\n\nPerform the Primal-Dual Riemannian semismooth Newton algorithm.\n\nGiven a cost function mathcal E mathcal M  overlineâ„ of the form\n\nmathcal E(p) = F(p) + G( Î›(p) )\n\nwhere F mathcal M  overlineâ„, G mathcal N  overlineâ„, and Î› mathcal M  mathcal N. The remaining input parameters are\n\np, X:                          primal and dual start points pmathcal M and X  T_nmathcal N\nm,n:                           base points on mathcal M and `\\mathcal N, respectively.\nlinearized_forward_operator:   the linearization DÎ›() of the operator Î›().\nadjoint_linearized_operator:   the adjoint DÎ›^* of the linearized operator DÎ›(m)  T_mmathcal M  T_Î›(m)mathcal N\nprox_F, prox_G_Dual:           the proximal maps of F and G^ast_n\ndiff_prox_F, diff_prox_dual_G: the (Clarke Generalized) differentials of the proximal maps of F and G^ast_n\n\nFor more details on the algorithm, see [DL21].\n\nKeyword arguments\n\ndual_stepsize=1/sqrt(8): proximal parameter of the dual prox\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the exact operator, that is required if Î›(m)=n does not hold; missing indicates, that the forward operator is exact.\nprimal_stepsize=1/sqrt(8): proximal parameter of the primal prox\nreg_param=1e-5: regularisation parameter for the Newton matrix Note that this changes the arguments the forward_operator is called.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(50): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/primal_dual_semismooth_Newton/#State","page":"Primal-dual Riemannian semismooth Newton","title":"State","text":"","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.PrimalDualSemismoothNewtonState","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.PrimalDualSemismoothNewtonState","text":"PrimalDualSemismoothNewtonState <: AbstractPrimalDualSolverState\n\nFields\n\nm::P: a point on the manifold mathcal M\nn::Q: a point on the manifold mathcal N\np::P: a point on the manifold mathcal Mstoring the current iterate\nX::T: a tangent vector at the point p on the manifold mathcal M\nprimal_stepsize::Float64:  proximal parameter of the primal prox\ndual_stepsize::Float64:    proximal parameter of the dual prox\nreg_param::Float64:        regularisation parameter for the Newton matrix\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base:        function to update the primal base\nupdate_dual_base:          function to update the dual base\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nwhere for the update functions a AbstractManoptProblem amp, AbstractManoptSolverState ams and the current iterate i are the arguments. If you activate these to be different from the default identity, you have to provide p.Î› for the algorithm to work (which might be missing).\n\nConstructor\n\nPrimalDualSemismoothNewtonState(M::AbstractManifold; kwargs...)\n\nGenerate a state for the primal_dual_semismooth_Newton.\n\nKeyword arguments\n\nm=rand(M)\nn=rand(N)\np=rand(M)\nX=zero_vector(M, p)\nprimal_stepsize=1/sqrt(8)\ndual_stepsize=1/sqrt(8)\nreg_param=1e-5\nupdate_primal_base=(amp, ams, k) -> o.m\nupdate_dual_base=(amp, ams, k) -> o.n\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstopping_criterion=[StopAfterIteration](@ref)(50)`: a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/primal_dual_semismooth_Newton/#sec-ssn-technical-details","page":"Primal-dual Riemannian semismooth Newton","title":"Technical details","text":"","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The primal_dual_semismooth_Newton solver requires the following functions of a manifold to be available for both the manifold mathcal Mand mathcal N","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points.\nA get_basis for the DefaultOrthonormalBasis on mathcal M\nexp and log (on mathcal M)\nA DiagonalizingOrthonormalBasis to compute the differentials of the exponential and logarithmic map\nTangent vectors storing the social and cognitive vectors are initialized calling zero_vector(M,p).","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/#Literature","page":"Primal-dual Riemannian semismooth Newton","title":"Literature","text":"","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"W.Â Diepeveen and J.Â Lellmann. An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising. SIAMÂ JournalÂ onÂ ImagingÂ Sciences 14, 1565â€“1600 (2021), arXiv:2102.10309.\n\n\n\n","category":"page"},{"location":"solvers/DouglasRachford/#Douglasâ€”Rachford-algorithm","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford algorithm","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"The (Parallel) Douglasâ€”Rachford ((P)DR) algorithm was generalized to Hadamard manifolds in [BPS16].","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"The aim is to minimize the sum","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"f(p) = g(p) + h(p)","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"on a manifold, where the two summands have proximal maps operatornameprox_Î» g operatornameprox_Î» h that are easy to evaluate (maybe in closed form, or not too costly to approximate). Further, define the reflection operator at the proximal map as","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"operatornamerefl_Î» g(p) = operatornameretr_operatornameprox_Î» g(p) bigl( -operatornameretr^-1_operatornameprox_Î» g(p) p bigr)","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"Let alpha_k   01 with sum_k  â„• alpha_k(1-alpha_k) =  infty and Î»  0 (which might depend on iteration k as well) be given.","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"Then the (P)DRA algorithm for initial data p^(0)  mathcal M as","category":"page"},{"location":"solvers/DouglasRachford/#Initialization","page":"Douglasâ€”Rachford","title":"Initialization","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"Initialize q^(0) = p^(0) and k=0","category":"page"},{"location":"solvers/DouglasRachford/#Iteration","page":"Douglasâ€”Rachford","title":"Iteration","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"Repeat until a convergence criterion is reached","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"Compute r^(k) = operatornamerefl_Î» goperatornamerefl_Î» h(q^(k))\nWithin that operation, store p^(k+1) = operatornameprox_Î» h(q^(k)) which is the prox the inner reflection reflects at.\nCompute q^(k+1) = g(alpha_k q^(k) r^(k)), where g is a curve approximating the shortest geodesic, provided by a retraction and its inverse\nSet k = k+1","category":"page"},{"location":"solvers/DouglasRachford/#Result","page":"Douglasâ€”Rachford","title":"Result","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"The result is given by the last computed p^(K) at the last iterate K.","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"For the parallel version, the first proximal map is a vectorial version where in each component one prox is applied to the corresponding copy of t_k and the second proximal map corresponds to the indicator function of the set, where all copies are equal (in mathcal M^n, where n is the number of copies), leading to the second prox being the Riemannian mean.","category":"page"},{"location":"solvers/DouglasRachford/#Interface","page":"Douglasâ€”Rachford","title":"Interface","text":"","category":"section"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachford","page":"Douglasâ€”Rachford","title":"Manopt.DouglasRachford","text":"DouglasRachford(M, f, proxes_f, p)\nDouglasRachford(M, mpo, p)\nDouglasRachford!(M, f, proxes_f, p)\nDouglasRachford!(M, mpo, p)\n\nCompute the Douglas-Rachford algorithm on the manifold mathcal M, starting from pgiven the (two) proximal mapsproxes_f`, see [BPS16].\n\nFor k2 proximal maps, the problem is reformulated using the parallel Douglas Rachford: a vectorial proximal map on the power manifold mathcal M^k is introduced as the first proximal map and the second proximal map of the is set to the mean (Riemannian center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, that is, component wise in a vector.\n\nnote: Note\n\n\nThe parallel Douglas Rachford does not work in-place for now, since    while creating the new staring point p' on the power manifold, a copy of p    Is created\n\nIf you provide a ManifoldProximalMapObjective mpo instead, the proximal maps are kept unchanged.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nproxes_f: functions of the form (M, Î», p)-> q performing a proximal maps, where â Î» denotes the proximal parameter, for each of the summands of F. These can also be given in the InplaceEvaluation variants (M, q, Î» p) -> q computing in place of q.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nÎ±= k -> 0.9: relaxation of the step from old to new iterate, to be precise p^(k+1) = g(Î±_k p^(k) q^(k)), where q^(k) is the result of the double reflection involved in the DR algorithm and g is a curve induced by the retraction and its inverse.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nÎ»= k -> 1.0: function to provide the value for the proximal parameter Î»_k\nR=reflect(!):           method employed in the iteration to perform the reflection of p at the prox of p. This uses by default reflect or reflect! depending on reflection_evaluation and the retraction and inverse retraction specified by retraction_method and inverse_retraction_method, respectively.\nreflection_evaluation: (AllocatingEvaluation whether R works in-place or allocating\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-5): a functor indicating that the stopping criterion is fulfilled\nparallel=false: indicate whether to use a parallel Douglas-Rachford or not.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\nDouglasRachford(M, f, proxes_f, p; kwargs...)\n\na doc string with some math t_k+1 = g(Î±_k t_k s_k)\n\n\n\n\n\n","category":"function"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachford!","page":"Douglasâ€”Rachford","title":"Manopt.DouglasRachford!","text":"DouglasRachford(M, f, proxes_f, p)\nDouglasRachford(M, mpo, p)\nDouglasRachford!(M, f, proxes_f, p)\nDouglasRachford!(M, mpo, p)\n\nCompute the Douglas-Rachford algorithm on the manifold mathcal M, starting from pgiven the (two) proximal mapsproxes_f`, see [BPS16].\n\nFor k2 proximal maps, the problem is reformulated using the parallel Douglas Rachford: a vectorial proximal map on the power manifold mathcal M^k is introduced as the first proximal map and the second proximal map of the is set to the mean (Riemannian center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, that is, component wise in a vector.\n\nnote: Note\n\n\nThe parallel Douglas Rachford does not work in-place for now, since    while creating the new staring point p' on the power manifold, a copy of p    Is created\n\nIf you provide a ManifoldProximalMapObjective mpo instead, the proximal maps are kept unchanged.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nproxes_f: functions of the form (M, Î», p)-> q performing a proximal maps, where â Î» denotes the proximal parameter, for each of the summands of F. These can also be given in the InplaceEvaluation variants (M, q, Î» p) -> q computing in place of q.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nÎ±= k -> 0.9: relaxation of the step from old to new iterate, to be precise p^(k+1) = g(Î±_k p^(k) q^(k)), where q^(k) is the result of the double reflection involved in the DR algorithm and g is a curve induced by the retraction and its inverse.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nÎ»= k -> 1.0: function to provide the value for the proximal parameter Î»_k\nR=reflect(!):           method employed in the iteration to perform the reflection of p at the prox of p. This uses by default reflect or reflect! depending on reflection_evaluation and the retraction and inverse retraction specified by retraction_method and inverse_retraction_method, respectively.\nreflection_evaluation: (AllocatingEvaluation whether R works in-place or allocating\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nstopping_criterion=StopAfterIteration(200)|StopWhenChangeLess(1e-5): a functor indicating that the stopping criterion is fulfilled\nparallel=false: indicate whether to use a parallel Douglas-Rachford or not.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/DouglasRachford/#State","page":"Douglasâ€”Rachford","title":"State","text":"","category":"section"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachfordState","page":"Douglasâ€”Rachford","title":"Manopt.DouglasRachfordState","text":"DouglasRachfordState <: AbstractManoptSolverState\n\nStore all options required for the DouglasRachford algorithm,\n\nFields\n\nÎ±:                         relaxation of the step from old to new iterate, to be precise x^(k+1) = g(Î±(k) x^(k) t^(k)), where t^(k) is the result of the double reflection involved in the DR algorithm\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ»:                         function to provide the value for the proximal parameter during the calls\nparallel:                  indicate whether to use a parallel Douglas-Rachford or not.\nR:                          method employed in the iteration to perform the reflection of x at the prox p.\np::P: a point on the manifold mathcal Mstoring the current iterate For the parallel Douglas-Rachford, this is not a value from the PowerManifold manifold but the mean.\nreflection_evaluation:     whether R works in-place or allocating\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\ns:                         the last result of the double reflection at the proximal maps relaxed by Î±.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nConstructor\n\nDouglasRachfordState(M::AbstractManifold; kwargs...)\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\n\nKeyword arguments\n\nÎ±= k -> 0.9: relaxation of the step from old to new iterate, to be precise x^(k+1) = g(Î±(k) x^(k) t^(k)), where t^(k) is the result of the double reflection involved in the DR algorithm\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ»= k -> 1.0: function to provide the value for the proximal parameter during the calls\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nR=reflect(!): method employed in the iteration to perform the reflection of p at the prox of p, which function is used depends on reflection_evaluation.\nreflection_evaluation=AllocatingEvaluation()) specify whether the reflection works in-place or allocating (default)\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(300): a functor indicating that the stopping criterion is fulfilled\nparallel=false: indicate whether to use a parallel Douglas-Rachford or not.\n\n\n\n\n\n","category":"type"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"For specific DebugActions and RecordActions see also Cyclic Proximal Point.","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"Furthermore, this solver has a short hand notation for the involved reflection.","category":"page"},{"location":"solvers/DouglasRachford/#Manopt.reflect","page":"Douglasâ€”Rachford","title":"Manopt.reflect","text":"reflect(M, f, x; kwargs...)\nreflect!(M, q, f, x; kwargs...)\n\nreflect the point x from the manifold M at the point f(x) of the function f mathcal M  mathcal M, given by\n\n    operatornamerefl_f(x) = operatornamerefl_f(x)(x)\n\nCompute the result in q.\n\nsee also reflect(M,p,x), to which the keywords are also passed to.\n\n\n\n\n\nreflect(M, p, x, kwargs...)\nreflect!(M, q, p, x, kwargs...)\n\nReflect the point x from the manifold M at point p, given by\n\noperatornamerefl\n\nwhere operatornameretr and operatornameretr^-1 denote a retraction and an inverse retraction, respectively. This can also be done in place of q.\n\nKeyword arguments\n\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nand for the reflect! additionally\n\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M as temporary memory to compute the inverse retraction in place. otherwise this is the memory that would be allocated anyways.\n\n\n\n\n\nreflect(M, f, x; kwargs...)\nreflect!(M, q, f, x; kwargs...)\n\nreflect the point x from the manifold M at the point f(x) of the function f mathcal M  mathcal M, given by\n\n    operatornamerefl_f(x) = operatornamerefl_f(x)(x)\n\nCompute the result in q.\n\nsee also reflect(M,p,x), to which the keywords are also passed to.\n\n\n\n\n\nreflect(M, p, x, kwargs...)\nreflect!(M, q, p, x, kwargs...)\n\nReflect the point x from the manifold M at point p, given by\n\noperatornamerefl_p(q) = operatornameretr_p(-operatornameretr^-1_p q)\n\nwhere operatornameretr and operatornameretr^-1 denote a retraction and an inverse retraction, respectively.\n\nThis can also be done in place of q.\n\nKeyword arguments\n\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nand for the reflect! additionally\n\nX=zero_vector(M,p): a temporary memory to compute the inverse retraction in place. otherwise this is the memory that would be allocated anyways.\n\n\n\n\n\n","category":"function"},{"location":"solvers/DouglasRachford/#sec-dr-technical-details","page":"Douglasâ€”Rachford","title":"Technical details","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"The DouglasRachford solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points.","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"By default, one of the stopping criteria is StopWhenChangeLess, which requires","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"An inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.","category":"page"},{"location":"solvers/DouglasRachford/#Literature","page":"Douglasâ€”Rachford","title":"Literature","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford","text":"","category":"page"},{"location":"tutorials/CountAndCache/#How-to-count-and-cache-function-calls","page":"Count and use a cache","title":"How to count and cache function calls","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"In this tutorial, we want to investigate the caching and counting (statistics) features of Manopt.jl. We reuse the optimization tasks from the introductory tutorial ðŸ”ï¸ Get started with Manopt.jl.","category":"page"},{"location":"tutorials/CountAndCache/#Introduction","page":"Count and use a cache","title":"Introduction","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"There are surely many ways to keep track for example of how often the cost function is called, for example with a functor, as we used in an example in How to Record Data","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"mutable struct MyCost{I<:Integer}\n    count::I\nend\nMyCost() = MyCost{Int64}(0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    # [ .. Actual implementation of the cost here ]\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"This still leaves a bit of work to the user, especially for tracking more than just the number of cost function evaluations.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"When a function like the objective or gradient is expensive to compute, it may make sense to cache its results. Manopt.jl tries to minimize the number of repeated calls but sometimes they are necessary and harmless when the function is cheap to compute. Caching of expensive function calls can for example be added using Memoize.jl by the user. The approach in the solvers of Manopt.jl aims to simplify adding both these capabilities on the level of calling a solver.","category":"page"},{"location":"tutorials/CountAndCache/#Technical-background","page":"Count and use a cache","title":"Technical background","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"The two ingredients for a solver in Manopt.jl are the AbstractManoptProblem and the AbstractManoptSolverState, where the former consists of the domain, that is the AsbtractManifold and AbstractManifoldObjective.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Both recording and debug capabilities are implemented in a decorator pattern to the solver state. They can be easily added using the record= and debug= in any solver call. This pattern was recently extended, such that also the objective can be decorated. This is how both caching and counting are implemented, as decorators of the AbstractManifoldObjective and hence for example changing/extending the behaviour of a call to get_cost.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Letâ€™s finish off the technical background by loading the necessary packages. Besides Manopt.jl and Manifolds.jl we also need LRUCaches.jl which are (since Julia 1.9) a weak dependency and provide the least recently used strategy for our caches.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"using Manopt, Manifolds, Random, LRUCache, LinearAlgebra, ManifoldDiff\nusing ManifoldDiff: grad_distance","category":"page"},{"location":"tutorials/CountAndCache/#Counting","page":"Count and use a cache","title":"Counting","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"We first define our task, the Riemannian Center of Mass from the ðŸ”ï¸ Get started with Manopt.jl tutorial.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"n = 100\nÏƒ = Ï€ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\nRandom.seed!(42)\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)));","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"to now count how often the cost and the gradient are called, we use the count= keyword argument that works in any solver to specify the elements of the objective whose calls we want to count calls to. A full list is available in the documentation of the AbstractManifoldObjective. To also see the result, we have to set return_objective=true. This returns (objective, p) instead of just the solver result p. We can further also set return_state=true to get even more information about the solver run.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"gradient_descent(M, f, grad_f, data[1]; count=[:Cost, :Gradient], return_objective=true, return_state=true)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 66 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Statistics on function calls\n  * :Gradient : 199\n  * :Cost     : 275","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"And we see that statistics are shown in the end.","category":"page"},{"location":"tutorials/CountAndCache/#Caching","page":"Count and use a cache","title":"Caching","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"To now also cache these calls, we can use the cache= keyword argument. Since now both the cache and the count â€œextendâ€ the capability of the objective, the order is important: on the high-level interface, the count is treated first, which means that only actual function calls and not cache look-ups are counted. With the proper initialisation, you can use any caches here that support the get!(function, cache, key)! update. All parts of the objective that can currently be cached are listed at ManifoldCachedObjective. The solver call has a keyword cache that takes a tuple(c, vs, n) of three arguments, where c is a symbol for the type of cache, vs is a vector of symbols, which calls to cache and n is the size of the cache. If the last element is not provided, a suitable default (currentlyn=10) is used.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Here we want to use c=:LRU caches for vs=[Cost, :Gradient] with a size of n=25.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"r = gradient_descent(M, f, grad_f, data[1];\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true, return_state=true)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 66 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 66\n  * :Cost     : 149","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Since the default setup with ArmijoLinesearch needs the gradient and the cost, and similarly the stopping criterion might (independently) evaluate the gradient, the caching is quite helpful here.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"And of course also for this advanced return value of the solver, we can still access the result as usual:","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"get_solver_result(r)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"3-element Vector{Float64}:\n 0.6868392807355564\n 0.006531599748261925\n 0.7267799809043942","category":"page"},{"location":"tutorials/CountAndCache/#Advanced-caching-examples","page":"Count and use a cache","title":"Advanced caching examples","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"There are more options other than caching single calls to specific parts of the objective. For example you may want to cache intermediate results of computing the cost and share that with the gradient computation. We present three solutions to this:","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"An easy approach from within Manopt.jl: the ManifoldCostGradientObjective\nA shared storage approach using a functor\nA shared (internal) cache approach also using a functor","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"For that we switch to another example: the Rayleigh quotient. We aim to maximize the Rayleigh quotient displaystylefracx^mathrmTAxx^mathrmTx, for some Aâ„^m+1times m+1 and xâ„^m+1 but since we consider this on the sphere and Manopt.jl (as many other optimization toolboxes) minimizes, we consider","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"g(p) = -p^mathrmTApqquad pmathbb S^m","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"The Euclidean gradient (that is in $ R^{m+1}$) is actually just nabla g(p) = -2Ap, the Riemannian gradient the projection of nabla g(p) onto the tangent space T_pmathbb S^m.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"m = 25\nRandom.seed!(42)\nA = randn(m + 1, m + 1)\nA = Symmetric(A)\np_star = eigvecs(A)[:, end] # minimizer (or similarly -p)\nf_star = -eigvals(A)[end] # cost (note that we get - the largest Eigenvalue)\n\nN = Sphere(m);\n\ng(M, p) = -p' * A*p\nâˆ‡g(p) = -2 * A * p\ngrad_g(M,p) = project(M, p, âˆ‡g(p))\ngrad_g!(M,X, p) = project!(M, X, p, âˆ‡g(p))","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"grad_g! (generic function with 1 method)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"But since both the cost and the gradient require the computation of the matrix-vector product Ap, it might be beneficial to only compute this once.","category":"page"},{"location":"tutorials/CountAndCache/#The-[ManifoldCostGradientObjective](@ref)-approach","page":"Count and use a cache","title":"The ManifoldCostGradientObjective approach","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"The ManifoldCostGradientObjective uses a combined function to compute both the gradient and the cost at the same time. We define the in-place variant as","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"function g_grad_g!(M::AbstractManifold, X, p)\n    X .= -A*p\n    c = p'*X\n    X .*= 2\n    project!(M, X, p, X)\n    return (c, X)\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"g_grad_g! (generic function with 1 method)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"where we only compute the matrix-vector product once. The small disadvantage might be, that we always compute both, the gradient and the cost. Luckily, the cache we used before, takes this into account and caches both results, such that we indeed end up computing A*p only once when asking to a cost and a gradient.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Letâ€™s compare both methods","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"p0 = [(1/5 .* ones(5))..., zeros(m-4)...];\n@time s1 = gradient_descent(N, g, grad_g!, p0;\n    stopping_criterion =Â StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"  1.434592 seconds (2.40 M allocations: 121.434 MiB, 1.30% gc time, 99.69% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 602\n  * :Cost     : 1449\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"versus","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"obj = ManifoldCostGradientObjective(g_grad_g!; evaluation=InplaceEvaluation())\n@time s2 = gradient_descent(N, obj, p0;\n    stopping_criterion=StopWhenGradientNormLess(1e-5),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"  0.744949 seconds (1.15 M allocations: 66.560 MiB, 2.20% gc time, 96.87% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 1448\n  * :Cost     : 1448\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"first of all both yield the same result","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"p1 = get_solver_result(s1)\np2 = get_solver_result(s2)\n[distance(N, p1, p2), g(N, p1), g(N, p2), f_star]","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"4-element Vector{Float64}:\n  0.0\n -7.8032957637779\n -7.8032957637779\n -7.803295763793949","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"and we can see that the combined number of evaluations is once 2051, once just the number of cost evaluations 1449. Note that the involved additional 847 gradient evaluations are merely a multiplication with 2. On the other hand, the additional caching of the gradient in these cases might be less beneficial. It is beneficial, when the gradient and the cost are very often required together.","category":"page"},{"location":"tutorials/CountAndCache/#A-shared-storage-approach-using-a-functor","page":"Count and use a cache","title":"A shared storage approach using a functor","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"An alternative to the previous approach is the usage of a functor that introduces a â€œshared storageâ€ of the result of computing A*p. We additionally have to store p though, since we have to make sure that we are still evaluating the cost and/or gradient at the same point at which the cached A*p was computed. We again consider the (more efficient) in-place variant. This can be done as follows","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"struct StorageG{T,M}\n    A::M\n    Ap::T\n    p::T\nend\nfunction (g::StorageG)(::Val{:Cost}, M::AbstractManifold, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    return -g.p'*g.Ap\nend\nfunction (g::StorageG)(::Val{:Gradient}, M::AbstractManifold, X, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    X .= -2 .* g.Ap\n    project!(M, X, p, X)\n    return X\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Here we use the first parameter to distinguish both functions. For the mutating case the signatures are different regardless of the additional argument but for the allocating case, the signatures of the cost and the gradient function are the same.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"#Define the new functor\nstorage_g = StorageG(A, zero(p0), zero(p0))\n# and cost and gradient that use this functor as\ng3(M,p) = storage_g(Val(:Cost), M, p)\ngrad_g3!(M, X, p) = storage_g(Val(:Gradient), M, X, p)\n@time s3 = gradient_descent(N, g3, grad_g3!, p0;\n    stopping_criterion =Â StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 2),\n    return_objective=true#, return_state=true\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"  0.538007 seconds (562.52 k allocations: 29.823 MiB, 99.22% compilation time)\n\n## Cache\n  * :Cost     : 2/2 entries of type Float64 used\n  * :Gradient : 2/2 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 602\n  * :Cost     : 1449\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"This of course still yields the same result","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"p3 = get_solver_result(s3)\ng(N, p3) - f_star","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"1.6049384043981263e-11","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"And while we again have a split off the cost and gradient evaluations, we can observe that the allocations are less than half of the previous approach.","category":"page"},{"location":"tutorials/CountAndCache/#A-local-cache-approach","page":"Count and use a cache","title":"A local cache approach","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"This variant is very similar to the previous one, but uses a whole cache instead of just one place to store A*p. This makes the code a bit nicer, and it is possible to store more than just the last p either cost or gradient was called with.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"struct CacheG{C,M}\n    A::M\n    cache::C\nend\nfunction (g::CacheG)(::Val{:Cost}, M, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    return -p'*Ap\nend\nfunction (g::CacheG)(::Val{:Gradient}, M, X, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    X .= -2 .* Ap\n    project!(M, X, p, X)\n    return X\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"However, the resulting solver run is not always faster, since the whole cache instead of storing just Ap and p is a bit more costly. Then the tradeoff is, whether this pays off.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"#Define the new functor\ncache_g = CacheG(A, LRU{typeof(p0),typeof(p0)}(; maxsize=25))\n# and cost and gradient that use this functor as\ng4(M,p) = cache_g(Val(:Cost), M, p)\ngrad_g4!(M, X, p) = cache_g(Val(:Gradient), M, X, p)\n@time s4 = gradient_descent(N, g4, grad_g4!, p0;\n    stopping_criterion =Â StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"  0.484528 seconds (520.09 k allocations: 27.936 MiB, 98.96% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 602\n  * :Cost     : 1449\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"and for safety letâ€™s verify that we are reasonably close","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"p4 = get_solver_result(s4)\ng(N, p4) - f_star","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"1.6049384043981263e-11","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"For this example, or maybe even gradient_descent in general it seems, this additional (second, inner) cache does not improve the result further, it is about the same effort both time and allocation-wise.","category":"page"},{"location":"tutorials/CountAndCache/#Summary","page":"Count and use a cache","title":"Summary","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"While the second approach of ManifoldCostGradientObjective is very easy to implement, both the storage and the (local) cache approach are more efficient. All three are an improvement over the first implementation without sharing interim results. The results with storage or cache have further advantage of being more flexible, since the stored information could also be reused in a third function, for example when also computing the Hessian.","category":"page"},{"location":"tutorials/CountAndCache/#Technical-details","page":"Count and use a cache","title":"Technical details","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a cache","title":"Count and use a cache","text":"2025-04-25T12:11:31.503","category":"page"},{"location":"tutorials/InplaceGradient/#Speedup-using-in-place-evaluation","page":"Speedup using in-place computations","title":"Speedup using in-place evaluation","text":"","category":"section"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"When it comes to time critical operations, a main ingredient in Julia is given by mutating functions, that is those that compute in place without additional memory allocations. In the following, we illustrate how to do this with Manopt.jl.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"Letâ€™s start with the same function as in ðŸ”ï¸ Get started with Manopt.jl and compute the mean of some points, only that here we use the sphere mathbb S^30 and n=800 points.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"From the aforementioned example.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"We first load all necessary packages.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"using Manopt, Manifolds, Random, BenchmarkTools\nusing ManifoldDiff: grad_distance, grad_distance!\nRandom.seed!(42);","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"And setup our data","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"Random.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nÏƒ = Ï€ / 8\np = zeros(Float64, m + 1)\np[2] = 1.0\ndata = [exp(M, p, Ïƒ * rand(M; vector_at=p)) for i in 1:n];","category":"page"},{"location":"tutorials/InplaceGradient/#Classical-definition","page":"Speedup using in-place computations","title":"Classical definition","text":"","category":"section"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"The variant from the previous tutorial defines a cost f(x) and its gradient operatornamegradf(p) â€œâ€œâ€","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)))","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"grad_f (generic function with 1 method)","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"We further set the stopping criterion to be a little more strict. Then we obtain","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"sc = StopWhenGradientNormLess(3e-10)\np0 = zeros(Float64, m + 1); p0[1] = 1/sqrt(2); p0[2] = 1/sqrt(2)\nm1 = gradient_descent(M, f, grad_f, p0; stopping_criterion=sc);","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"We can also benchmark this as","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"@benchmark gradient_descent($M, $f, $grad_f, $p0; stopping_criterion=$sc)","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"BenchmarkTools.Trial: 89 samples with 1 evaluation per sample.\n Range (min â€¦ max):  52.976 ms â€¦ 104.222 ms  â”Š GC (min â€¦ max): 8.05% â€¦ 5.55%\n Time  (median):     55.145 ms               â”Š GC (median):    9.99%\n Time  (mean Â± Ïƒ):   56.391 ms Â±   6.102 ms  â”Š GC (mean Â± Ïƒ):  9.92% Â± 1.43%\n\n    â–…â–ˆâ–ˆâ–…â–ƒâ–\n  â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–…â–‡â–…â–â–…â–â–â–…â–…â–â–â–â–…â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–… â–\n  53 ms         Histogram: log(frequency) by time      81.7 ms <\n\n Memory estimate: 173.54 MiB, allocs estimate: 1167348.","category":"page"},{"location":"tutorials/InplaceGradient/#In-place-computation-of-the-gradient","page":"Speedup using in-place computations","title":"In-place computation of the gradient","text":"","category":"section"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"We can reduce the memory allocations by implementing the gradient to be evaluated in-place. We do this by using a functor. The motivation is twofold: on one hand, we want to avoid variables from the global scope, for example the manifold M or the data, being used within the function. Considering to do the same for more complicated cost functions might also be worth pursuing.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"Here, we store the data (as reference) and one introduce temporary memory to avoid reallocation of memory per grad_distance computation. We get","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"struct GradF!{TD,TTMP}\n    data::TD\n    tmp::TTMP\nend\nfunction (grad_f!::GradF!)(M, X, p)\n    fill!(X, 0)\n    for di in grad_f!.data\n        grad_distance!(M, grad_f!.tmp, di, p)\n        X .+= grad_f!.tmp\n    end\n    X ./= length(grad_f!.data)\n    return X\nend","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"For the actual call to the solver, we first have to generate an instance of GradF! and tell the solver, that the gradient is provided in an InplaceEvaluation. We can further also use gradient_descent! to even work in-place of the initial point we pass.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"grad_f2! = GradF!(data, similar(data[1]))\nm2 = deepcopy(p0)\ngradient_descent!(\n    M, f, grad_f2!, m2; evaluation=InplaceEvaluation(), stopping_criterion=sc\n);","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"We can again benchmark this","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"@benchmark gradient_descent!(\n    $M, $f, $grad_f2!, m2; evaluation=$(InplaceEvaluation()), stopping_criterion=$sc\n) setup = (m2 = deepcopy($p0))","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"BenchmarkTools.Trial: 130 samples with 1 evaluation per sample.\n Range (min â€¦ max):  36.646 ms â€¦ 64.781 ms  â”Š GC (min â€¦ max): 0.00% â€¦ 0.00%\n Time  (median):     37.559 ms              â”Š GC (median):    0.00%\n Time  (mean Â± Ïƒ):   38.658 ms Â±  3.904 ms  â”Š GC (mean Â± Ïƒ):  0.73% Â± 2.68%\n\n  â–ˆâ–ˆâ–…â–…â–„â–‚â– â–‚\n  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–…â–â–â–â–…â–â–â–â–â–…â–…â–…â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–… â–…\n  36.6 ms      Histogram: log(frequency) by time        61 ms <\n\n Memory estimate: 3.59 MiB, allocs estimate: 6863.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"which is faster by about a factor of 2 compared to the first solver-call. Note that the results m1 and m2 are of course the same.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"distance(M, m1, m2)","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"4.8317610992693745e-11","category":"page"},{"location":"tutorials/InplaceGradient/#Technical-details","page":"Speedup using in-place computations","title":"Technical details","text":"","category":"section"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"Status `~/Repositories/Julia/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.13.0\n  [6e4b80f9] BenchmarkTools v1.6.0\nâŒƒ [5ae59095] Colors v0.12.11\n  [31c24e10] Distributions v0.25.117\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.26.0\n  [8ac3fa9e] LRUCache v1.6.1\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.13\n  [3362f125] ManifoldsBase v1.0.1\n  [0fc0a36d] Manopt v0.5.5 `..`\n  [91a5bcdd] Plots v1.40.9\n  [731186ca] RecursiveArrayTools v3.29.0\nInfo Packages marked with âŒƒ have new versions available and may be upgradable.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using in-place computations","title":"Speedup using in-place computations","text":"2025-02-10T13:22:51.002","category":"page"},{"location":"plans/state/#sec-solver-state","page":"Solver State","title":"Solver state","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"Given an AbstractManoptProblem, that is a certain optimisation task, the state specifies the solver to use. It contains the parameters of a solver and all fields necessary during the algorithm, for example the current iterate, a StoppingCriterion or a Stepsize.","category":"page"},{"location":"plans/state/#Manopt.AbstractManoptSolverState","page":"Solver State","title":"Manopt.AbstractManoptSolverState","text":"AbstractManoptSolverState\n\nA general super type for all solver states.\n\nFields\n\nThe following fields are assumed to be default. If you use different ones, adapt the the access functions get_iterate and get_stopping_criterion accordingly\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.get_state","page":"Solver State","title":"Manopt.get_state","text":"get_state(s::AbstractManoptSolverState, recursive::Bool=true)\n\nreturn the (one step) undecorated AbstractManoptSolverState of the (possibly) decorated s. As long as your decorated state stores the state within s.state and the dispatch_objective_decorator is set to Val{true}, the internal state are extracted automatically.\n\nBy default the state that is stored within a decorated state is assumed to be at s.state. Overwrite _get_state(s, ::Val{true}, recursive) to change this behaviour for your states` for both the recursive and the direct case.\n\nIf recursive is set to false, only the most outer decorator is taken away instead of all.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_count","page":"Solver State","title":"Manopt.get_count","text":"get_count(ams::AbstractManoptSolverState, ::Symbol)\n\nObtain the count for a certain countable size, for example the :Iterations. This function returns 0 if there was nothing to count\n\nAvailable symbols from within the solver state\n\n:Iterations is passed on to the stop field to obtain the iteration at which the solver stopped.\n\n\n\n\n\nget_count(co::ManifoldCountObjective, s::Symbol, mode::Symbol=:None)\n\nGet the number of counts for a certain symbol s.\n\nDepending on the mode different results appear if the symbol does not exist in the dictionary\n\n:None:  (default) silent mode, returns -1 for non-existing entries\n:warn:  issues a warning if a field does not exist\n:error: issues an error if a field does not exist\n\n\n\n\n\n","category":"function"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"Since every subtype of an AbstractManoptSolverState directly relate to a solver, the concrete states are documented together with the corresponding solvers. This page documents the general features available for every state.","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A first example is to obtain or set, the current iterate. This might be useful to continue investigation at the current iterate, or to set up a solver for a next experiment, respectively.","category":"page"},{"location":"plans/state/#Manopt.get_iterate","page":"Solver State","title":"Manopt.get_iterate","text":"get_iterate(O::AbstractManoptSolverState)\n\nreturn the (last stored) iterate within AbstractManoptSolverStates`. This should usually refer to a single point on the manifold the solver is working on\n\nBy default this also removes all decorators of the state beforehand.\n\n\n\n\n\nget_iterate(agst::AbstractGradientSolverState)\n\nreturn the iterate stored within gradient options. THe default returns agst.p.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.set_iterate!","page":"Solver State","title":"Manopt.set_iterate!","text":"set_iterate!(s::AbstractManoptSolverState, M::AbstractManifold, p)\n\nset the iterate within an AbstractManoptSolverState to some (start) value p.\n\n\n\n\n\nset_iterate!(agst::AbstractGradientSolverState, M, p)\n\nset the (current) iterate stored within an AbstractGradientSolverState to p. The default function modifies s.p.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_gradient-Tuple{AbstractManoptSolverState}","page":"Solver State","title":"Manopt.get_gradient","text":"get_gradient(s::AbstractManoptSolverState)\n\nreturn the (last stored) gradient within AbstractManoptSolverStates`. By default also undecorates the state beforehand\n\n\n\n\n\n","category":"method"},{"location":"plans/state/#Manopt.set_gradient!","page":"Solver State","title":"Manopt.set_gradient!","text":"set_gradient!(s::AbstractManoptSolverState, M::AbstractManifold, p, X)\n\nset the gradient within an (possibly decorated) AbstractManoptSolverState to some (start) value X in the tangent space at p.\n\n\n\n\n\nset_gradient!(agst::AbstractGradientSolverState, M, p, X)\n\nset the (current) gradient stored within an AbstractGradientSolverState to X. The default function modifies s.X.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"An internal function working on the state and elements within a state is used to pass messages from (sub) activities of a state to the corresponding DebugMessages","category":"page"},{"location":"plans/state/#Manopt.get_message","page":"Solver State","title":"Manopt.get_message","text":"get_message(du::AbstractManoptSolverState)\n\nget a message (String) from internal functors, in a summary. This should return any message a sub-step might have issued as well.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"Furthermore, to access the stopping criterion use","category":"page"},{"location":"plans/state/#Manopt.get_stopping_criterion","page":"Solver State","title":"Manopt.get_stopping_criterion","text":"get_stopping_criterion(ams::AbstractManoptSolverState)\n\nReturn the StoppingCriterion stored within the AbstractManoptSolverState ams.\n\nFor an undecorated state, this is assumed to be in ams.stop. Overwrite _get_stopping_criterion(yms::YMS) to change this for your manopt solver (yms) assuming it has type YMS`.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Decorators-for-AbstractManoptSolverStates","page":"Solver State","title":"Decorators for AbstractManoptSolverStates","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A solver state can be decorated using the following trait and function to initialize","category":"page"},{"location":"plans/state/#Manopt.dispatch_state_decorator","page":"Solver State","title":"Manopt.dispatch_state_decorator","text":"dispatch_state_decorator(s::AbstractManoptSolverState)\n\nIndicate internally, whether an AbstractManoptSolverState s is of decorating type, and stores (encapsulates) a state in itself, by default in the field s.state.\n\nDecorators indicate this by returning Val{true} for further dispatch.\n\nThe default is Val{false}, so by default a state is not decorated.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.is_state_decorator","page":"Solver State","title":"Manopt.is_state_decorator","text":"is_state_decorator(s::AbstractManoptSolverState)\n\nIndicate, whether AbstractManoptSolverState s are of decorator type.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.decorate_state!","page":"Solver State","title":"Manopt.decorate_state!","text":"decorate_state!(s::AbstractManoptSolverState)\n\ndecorate the AbstractManoptSolverStates with specific decorators.\n\nOptional arguments\n\noptional arguments provide necessary details on the decorators.\n\ndebug=Array{Union{Symbol,DebugAction,String,Int},1}(): a set of symbols representing DebugActions, Strings used as dividers and a sub-sampling integer. These are passed as a DebugGroup within :Iteration to the DebugSolverState decorator dictionary. Only exception is :Stop that is passed to :Stop.\nrecord=Array{Union{Symbol,RecordAction,Int},1}(): specify recordings by using Symbols or RecordActions directly. An integer can again be used for only recording every ith iteration.\nreturn_state=false: indicate whether to wrap the options in a ReturnSolverState, indicating that the solver should return options and not (only) the minimizer.\n\nother keywords are ignored.\n\nSee also\n\nDebugSolverState, RecordSolverState, ReturnSolverState\n\n\n\n\n\n","category":"function"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A simple example is the","category":"page"},{"location":"plans/state/#Manopt.ReturnSolverState","page":"Solver State","title":"Manopt.ReturnSolverState","text":"ReturnSolverState{O<:AbstractManoptSolverState} <: AbstractManoptSolverState\n\nThis internal type is used to indicate that the contained AbstractManoptSolverState state should be returned at the end of a solver instead of the usual minimizer.\n\nSee also\n\nget_solver_result\n\n\n\n\n\n","category":"type"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"as well as DebugSolverState and RecordSolverState.","category":"page"},{"location":"plans/state/#State-actions","page":"Solver State","title":"State actions","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A state action is a struct for callback functions that can be attached within for example the just mentioned debug decorator or the record decorator.","category":"page"},{"location":"plans/state/#Manopt.AbstractStateAction","page":"Solver State","title":"Manopt.AbstractStateAction","text":"AbstractStateAction\n\na common Type for AbstractStateActions that might be triggered in decorators, for example within the DebugSolverState or within the RecordSolverState.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"Several state decorators or actions might store intermediate values like the (last) iterate to compute some change or the last gradient. In order to minimise the storage of these, there is a generic StoreStateAction that acts as generic common storage that can be shared among different actions.","category":"page"},{"location":"plans/state/#Manopt.StoreStateAction","page":"Solver State","title":"Manopt.StoreStateAction","text":"StoreStateAction <: AbstractStateAction\n\ninternal storage for AbstractStateActions to store a tuple of fields from an AbstractManoptSolverStates\n\nThis functor possesses the usual interface of functions called during an iteration and acts on (p, s, k), where p is a AbstractManoptProblem, s is an AbstractManoptSolverState and k is the current iteration.\n\nFields\n\nvalues:        a dictionary to store interim values based on certain Symbols\nkeys:          a Vector of Symbols to refer to fields of AbstractManoptSolverState\npoint_values:  a NamedTuple of mutable values of points on a manifold to be stored in StoreStateAction. Manifold is later determined by AbstractManoptProblem passed to update_storage!.\npoint_init:    a NamedTuple of boolean values indicating whether a point in point_values with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector keys.\nvector_values: a NamedTuple of mutable values of tangent vectors on a manifold to be stored in StoreStateAction. Manifold is later determined by AbstractManoptProblem passed to update_storage!. It is not specified at which point the vectors are tangent but for storage it should not matter.\nvector_init:   a NamedTuple of boolean values indicating whether a tangent vector in vector_values: with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector keys.\nonce:          whether to update the internal values only once per iteration\nlastStored:    last iterate, where this AbstractStateAction was called (to determine once)\n\nTo handle the general storage, use get_storage and has_storage with keys as Symbols. For the point storage use PointStorageKey. For tangent vector storage use VectorStorageKey. Point and tangent storage have been optimized to be more efficient.\n\nConstructors\n\nStoreStateAction(s::Vector{Symbol})\n\nThis is equivalent as providing s to the keyword store_fields, just that here, no manifold is necessity for the construction.\n\nStoreStateAction(M)\n\nKeyword arguments\n\nstore_fields (Symbol[])\nstore_points (Symbol[])\nstore_vectors (Symbol[])\n\nas vectors of symbols each referring to fields of the state (lower case symbols) or semantic ones (upper case).\n\np_init (rand(M)) but making sure this is not a number but a (mutatable) array\nX_init (zero_vector(M, p_init))\n\nare used to initialize the point and vector storage, change these if you use other types (than the default) for your points/vectors on M.\n\nonce (true) whether to update internal storage only once per iteration or on every update call\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.get_storage","page":"Solver State","title":"Manopt.get_storage","text":"get_storage(a::AbstractStateAction, key::Symbol)\n\nReturn the internal value of the AbstractStateAction a at the Symbol key.\n\n\n\n\n\nget_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key}\n\nReturn the internal value of the AbstractStateAction a at the Symbol key that represents a point.\n\n\n\n\n\nget_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key}\n\nReturn the internal value of the AbstractStateAction a at the Symbol key that represents a vector.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.has_storage","page":"Solver State","title":"Manopt.has_storage","text":"has_storage(a::AbstractStateAction, key::Symbol)\n\nReturn whether the AbstractStateAction a has a value stored at the Symbol key.\n\n\n\n\n\nhas_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key}\n\nReturn whether the AbstractStateAction a has a point value stored at the Symbol key.\n\n\n\n\n\nhas_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key}\n\nReturn whether the AbstractStateAction a has a point value stored at the Symbol key.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.update_storage!","page":"Solver State","title":"Manopt.update_storage!","text":"update_storage!(a::AbstractStateAction, amp::AbstractManoptProblem, s::AbstractManoptSolverState)\n\nUpdate the AbstractStateAction a internal values to the ones given on the AbstractManoptSolverState s. Optimized using the information from amp\n\n\n\n\n\nupdate_storage!(a::AbstractStateAction, d::Dict{Symbol,<:Any})\n\nUpdate the AbstractStateAction a internal values to the ones given in the dictionary d. The values are merged, where the values from d are preferred.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.PointStorageKey","page":"Solver State","title":"Manopt.PointStorageKey","text":"struct PointStorageKey{key} end\n\nRefer to point storage of StoreStateAction in get_storage and has_storage functions\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.VectorStorageKey","page":"Solver State","title":"Manopt.VectorStorageKey","text":"struct VectorStorageKey{key} end\n\nRefer to tangent storage of StoreStateAction in get_storage and has_storage functions\n\n\n\n\n\n","category":"type"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"as well as two internal functions","category":"page"},{"location":"plans/state/#Manopt._storage_copy_vector","page":"Solver State","title":"Manopt._storage_copy_vector","text":"_storage_copy_vector(M::AbstractManifold, X)\n\nMake a copy of tangent vector X from manifold M for storage in StoreStateAction.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt._storage_copy_point","page":"Solver State","title":"Manopt._storage_copy_point","text":"_storage_copy_point(M::AbstractManifold, p)\n\nMake a copy of point p from manifold M for storage in StoreStateAction.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Abstract-states","page":"Solver State","title":"Abstract states","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"In a few cases it is useful to have a hierarchy of types. These are","category":"page"},{"location":"plans/state/#Manopt.AbstractSubProblemSolverState","page":"Solver State","title":"Manopt.AbstractSubProblemSolverState","text":"AbstractSubProblemSolverState <: AbstractManoptSolverState\n\nAn abstract type for solvers that involve a subsolver.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractGradientSolverState","page":"Solver State","title":"Manopt.AbstractGradientSolverState","text":"AbstractGradientSolverState <: AbstractManoptSolverState\n\nA generic AbstractManoptSolverState type for gradient based options data.\n\nIt assumes that\n\nthe iterate is stored in the field p\nthe gradient at p is stored in X.\n\nSee also\n\nGradientDescentState, StochasticGradientDescentState, SubGradientMethodState, QuasiNewtonState.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractHessianSolverState","page":"Solver State","title":"Manopt.AbstractHessianSolverState","text":"AbstractHessianSolverState <: AbstractGradientSolverState\n\nAn AbstractManoptSolverState type to represent algorithms that employ the Hessian. These options are assumed to have a field (gradient) to store the current gradient operatornamegradf(x)\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractPrimalDualSolverState","page":"Solver State","title":"Manopt.AbstractPrimalDualSolverState","text":"AbstractPrimalDualSolverState\n\nA general type for all primal dual based options to be used within primal dual based algorithms\n\n\n\n\n\n","category":"type"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"For the sub problem state, there are two access functions","category":"page"},{"location":"plans/state/#Manopt.get_sub_problem","page":"Solver State","title":"Manopt.get_sub_problem","text":"get_sub_problem(ams::AbstractSubProblemSolverState)\n\nAccess the sub problem of a solver state that involves a sub optimisation task. By default this returns ams.sub_problem.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_sub_state","page":"Solver State","title":"Manopt.get_sub_state","text":"get_sub_state(ams::AbstractSubProblemSolverState)\n\nAccess the sub state of a solver state that involves a sub optimisation task. By default this returns ams.sub_state.\n\n\n\n\n\n","category":"function"},{"location":"about/#About","page":"About","title":"About","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"Manopt.jl inherited its name from Manopt, a Matlab toolbox for optimization on manifolds. This Julia package was started and is currently maintained by Ronny Bergmann.","category":"page"},{"location":"about/#Contributors","page":"About","title":"Contributors","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"Thanks to the following contributors to Manopt.jl:","category":"page"},{"location":"about/","page":"About","title":"About","text":"Constantin Ahlmann-Eltze implemented the gradient and differential check functions\nRenÃ©e Dornig implemented the particle swarm, the Riemannian Augmented Lagrangian Method, the Exact Penalty Method, as well as the NonmonotoneLinesearch. These solvers are also the first one with modular/exchangable sub solvers.\nWillem Diepeveen implemented the primal-dual Riemannian semismooth Newton solver.\nHajg Jasa implemented the convex bundle method and the proximal bundle method and a default subsolver each of them.\nEven Stephansen KjemsÃ¥s contributed to the implementation of the Frank Wolfe Method solver.\nMathias Ravn Munkvold contributed most of the implementation of the Adaptive Regularization with Cubics solver as well as its Lanczos subsolver\nSander Engen Oddsen contributed to the implementation of the LTMADS solver.\nTom-Christian Riemer implemented the trust regions and quasi Newton solvers as well as the truncated conjugate gradient descent subsolver.\nMarkus A. Stokkenes contributed most of the implementation of the Interior Point Newton Method as well as its default Conjugate Residual subsolver\nManuel Weiss implemented most of the conjugate gradient update rules","category":"page"},{"location":"about/","page":"About","title":"About","text":"as well as various contributors providing small extensions, finding small bugs and mistakes and fixing them by opening PRs. Thanks to all of you.","category":"page"},{"location":"about/","page":"About","title":"About","text":"If you want to contribute a manifold or algorithm or have any questions, visit the GitHub repository to clone/fork the repository or open an issue.","category":"page"},{"location":"about/#Work-using-Manopt.jl","page":"About","title":"Work using Manopt.jl","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"ExponentialFamilyProjection.jl package uses Manopt.jl to project arbitrary functions onto the closest exponential family distributions. The package also integrates with RxInfer.jl to enable Bayesian inference in a larger set of probabilistic models.\nCaesar.jl within non-Gaussian factor graph inference algorithms","category":"page"},{"location":"about/","page":"About","title":"About","text":"If you are missing a package, that uses Manopt.jl, please open an issue. It would be great to collect anything and anyone using Manopt.jl in this list.","category":"page"},{"location":"about/#Further-packages","page":"About","title":"Further packages","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"Manopt.jl belongs to the Manopt family:","category":"page"},{"location":"about/","page":"About","title":"About","text":"manopt.org The Matlab version of Manopt, see also their :octocat: GitHub repository\npymanopt.org The Python version of Manopt providing also several AD backends, see also their :octocat: GitHub repository","category":"page"},{"location":"about/","page":"About","title":"About","text":"but there are also more packages providing tools on manifolds in other languages","category":"page"},{"location":"about/","page":"About","title":"About","text":"Jax Geometry (Python/Jax) for differential geometry and stochastic dynamics with deep learning\nGeomstats (Python with several backends) focusing on statistics and machine learning :octocat: GitHub repository\nGeoopt (Python & PyTorch) Riemannian ADAM & SGD. :octocat: GitHub repository\nMcTorch (Python & PyToch) Riemannian SGD, Adagrad, ASA & CG.\nROPTLIB (C++) a Riemannian OPTimization LIBrary :octocat: GitHub repository\nTF Riemopt (Python & TensorFlow) Riemannian optimization using TensorFlow","category":"page"},{"location":"tutorials/ImplementASolver/#How-to-implementing-your-own-solver","page":"Implement a solver","title":"How to implementing your own solver","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"When you have used a few solvers from Manopt.jl for example like in the opening tutorial Get started: optimize you might come to the idea of implementing a solver yourself.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"After a short introduction of the algorithm we aim to implement, this tutorial first discusses the structural details, for example what a solver consists of and â€œworks withâ€. Afterwards, we show how to implement the algorithm. Finally, we discuss how to make the algorithm both nice for the user as well as initialized in a way, that it can benefit from features already available in Manopt.jl.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"note: Note\nIf you have implemented your own solver, we would be very happy to have that within Manopt.jl as well, so maybe consider opening a Pull Request","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"using Manopt, Manifolds, Random","category":"page"},{"location":"tutorials/ImplementASolver/#Our-guiding-example:-a-random-walk-minimization","page":"Implement a solver","title":"Our guiding example: a random walk minimization","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Since most serious algorithms should be implemented in Manopt.jl themselves directly, we implement a solver that randomly walks on the manifold and keeps track of the lowest point visited. As for algorithms in Manopt.jl we aim to implement this generically for any manifold that is implemented using ManifoldsBase.jl.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"The random walk minimization","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Given:","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"a manifold mathcal M\na starting point p=p^(0)\na cost function f mathcal M  â„.\na parameter sigma  0.\na retraction operatornameretr_p(X) that maps X  T_pmathcal M to the manifold.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We can run the following steps of the algorithm","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"set k=0\nset our best point q = p^(0)\nRepeat until a stopping criterion is fulfilled\nChoose a random tangent vector X^(k)  T_p^(k)mathcal M of length lVert X^(k) rVert = sigma\nâ€œWalkâ€ along this direction, that is p^(k+1) = operatornameretr_p^(k)(X^(k))\nIf f(p^(k+1))  f(q) set q = p^{(k+1)}$ as our new best visited point\nReturn q as the resulting best point we visited","category":"page"},{"location":"tutorials/ImplementASolver/#Preliminaries:-elements-a-solver-works-on","page":"Implement a solver","title":"Preliminaries: elements a solver works on","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"There are two main ingredients a solver needs: a problem to work on and the state of a solver, which â€œidentifiesâ€ the solver and stores intermediate results.","category":"page"},{"location":"tutorials/ImplementASolver/#Specifying-the-task:-an-AbstractManoptProblem","page":"Implement a solver","title":"Specifying the task: an AbstractManoptProblem","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"A problem in Manopt.jl usually consists of a manifold (an AbstractManifold) and an AbstractManifoldObjective describing the function we have and its features. In our case the objective is (just) a ManifoldCostObjective that stores cost function f(M,p) -> R. More generally, it might for example store a gradient function or the Hessian or any other information we have about our task.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"This is something independent of the solver itself, since it only identifies the problem we want to solve independent of how we want to solve it,Â or in other words, this type contains all information that is static and independent of the specific solver at hand.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Usually the problems variable is called mp.","category":"page"},{"location":"tutorials/ImplementASolver/#Specifying-a-solver:-an-AbstractManoptSolverState","page":"Implement a solver","title":"Specifying a solver: an AbstractManoptSolverState","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Everything that is needed by a solver during the iterations, all its parameters, interim values that are needed beyond just one iteration, is stored in a subtype of the AbstractManoptSolverState. This identifies the solver uniquely.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"In our case we want to store five things","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"the current iterate p=p^(k)\nthe best visited point q\nthe variable sigma  0\nthe retraction operatornameretr to use (cf.Â retractions and inverse retractions)\na criterion, when to stop: a StoppingCriterion","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We can defined this as","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"mutable struct RandomWalkState{\n    P,\n    R<:AbstractRetractionMethod,\n    S<:StoppingCriterion,\n} <: AbstractManoptSolverState\n  p::P\n  q::P\n  Ïƒ::Float64\n  retraction_method::R\n  stop::S\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"The stopping criterion is usually stored in the stateâ€™s stop field. If you have a reason to do otherwise, you have one more function to implement (see next section). For ease of use, a constructor can be provided, that for example chooses a good default for the retraction based on a given manifold.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"function RandomWalkState(M::AbstractManifold, p::P=rand(M);\n    Ïƒ = 0.1,\n    retraction_method::R=default_retraction_method(M, typeof(p)),\n    stopping_criterion::S=StopAfterIteration(200)\n) where {P, R<:AbstractRetractionMethod, S<:StoppingCriterion}\n    return RandomWalkState{P,R,S}(p, copy(M, p), Ïƒ, retraction_method, stopping_criterion)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Parametrising the state avoid that we have abstract typed fields. The keyword arguments for the retraction and stopping criterion are the ones usually used in Manopt.jl and provide an easy way to construct this state now.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"States usually have a shortened name as their variable, we use rws for our state here.","category":"page"},{"location":"tutorials/ImplementASolver/#Implementing-your-solver","page":"Implement a solver","title":"Implementing your solver","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"There is basically only two methods we need to implement for our solver","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"initialize_solver!(mp, rws) which initialises the solver before the first iteration\nstep_solver!(mp, rws, i) which implements the ith iteration, where i is given to you as the third parameter\nget_iterate(rws) which accesses the iterate from other places in the solver\nget_solver_result(rws) returning the solvers final (best) point we reached. By default this would return the last iterate rws.p (or more precisely calls get_iterate), but since we randomly walk and remember our best point in q, this has to return rws.q.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"The first two functions are in-place functions, that is they modify our solver state rws. You implement these by multiple dispatch on the types after importing said functions from Manopt:","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"import Manopt: initialize_solver!, step_solver!, get_iterate, get_solver_result","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"The state we defined before has two fields where we use the common names used in Manopt.jl, that is the StoppingCriterion is usually in stop and the iterate in p. If your choice is different, you need to reimplement","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"stop_solver!(mp, rws, i) to determine whether or not to stop after the ith iteration.\nget_iterate(rws) to access the current iterate","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We recommend to follow the general scheme with the stop field. If you have specific criteria when to stop, consider implementing your own stopping criterion instead.","category":"page"},{"location":"tutorials/ImplementASolver/#Initialization-and-iterate-access","page":"Implement a solver","title":"Initialization and iterate access","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"For our solver, there is not so much to initialize, just to be safe we should copy over the initial value in p we start with, to q. We do not have to care about remembering the iterate, that is done by Manopt.jl. For the iterate access we just have to pass p.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"function initialize_solver!(mp::AbstractManoptProblem, rws::RandomWalkState)\n    copyto!(M, rws.q, rws.p) # Set p^{(0)} = q\n    return rws\nend\nget_iterate(rws::RandomWalkState) = rws.p\nget_solver_result(rws::RandomWalkState) = rws.q","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"and similarly we implement the step. Here we make use of the fact that the problem (and also the objective in fact) have access functions for their elements, the one we need is get_cost.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"function step_solver!(mp::AbstractManoptProblem, rws::RandomWalkState, i)\n    M = get_manifold(mp) # for ease of use get the manifold from the problem\n    X = rand(M; vector_at=p)     # generate a direction\n    X .*= rws.Ïƒ/norm(M, p, X)\n    # Walk\n    retract!(M, rws.p, rws.p, X, rws.retraction_method)\n    # is the new point better? Then store it\n    if get_cost(mp, rws.p) < get_cost(mp, rws.q)\n        copyto!(M, rws.p, rws.q)\n    end\n    return rws\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Performance wise we could improve the number of allocations by making X also a field of our rws but letâ€™s keep it simple here. We could also store the cost of q in the state, but we shall see how to easily also enable this solver to allow for caching. In practice, however, it is preferable to cache intermediate values like cost of q in the state when it can be easily achieved. This way we do not have to deal with overheads of an external cache.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Now we can just run the solver already. We take the same example as for the other tutorials","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We first define our task, the Riemannian Center of Mass from the Get started: optimize tutorial.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Random.seed!(23)\nn = 100\nÏƒ = Ï€ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We can now generate the problem with its objective and the state","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"mp = DefaultManoptProblem(M, ManifoldCostObjective(f))\ns = RandomWalkState(M; Ïƒ = 0.2)\n\nsolve!(mp, s)\nget_solver_result(s)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"3-element Vector{Float64}:\n -0.2412674850987521\n  0.8608618657176527\n -0.44800317943876844","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"The function solve! works also in place of s, but the last line illustrates how to access the result in general; we could also just look at s.p, but the function get_iterate is also used in several other places.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We could for example easily set up a second solver to work from a specified starting point with a different Ïƒ like","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"s2 = RandomWalkState(M, [1.0, 0.0, 0.0];  Ïƒ = 0.1)\nsolve!(mp, s2)\nget_solver_result(s2)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"3-element Vector{Float64}:\n 1.0\n 0.0\n 0.0","category":"page"},{"location":"tutorials/ImplementASolver/#Ease-of-use-I:-a-high-level-interface","page":"Implement a solver","title":"Ease of use I: a high level interface","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Manopt.jl offers a few additional features for solvers in their high level interfaces, for example debug= for debug, record= keywords for debug and recording within solver states or count= and cache keywords for the objective.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We can introduce these here as well with just a few lines of code. There are usually two steps. We further need three internal function from Manopt.jl","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"using Manopt: get_solver_return, indicates_convergence, status_summary","category":"page"},{"location":"tutorials/ImplementASolver/#A-high-level-interface-using-the-objective","page":"Implement a solver","title":"A high level interface using the objective","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"This could be considered as an interim step to the high-level interface: if objective,Â a ManifoldCostObjective is already initialized, the high level interface consists of the steps","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"possibly decorate the objective\ngenerate the problem\ngenerate and possibly generate the state\ncall the solver\ndetermine the return value","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We illustrate the step with an in-place variant here. A variant that keeps the given start point unchanged would just add a copy(M, p) upfront. Manopt.jl provides both variants.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"function random_walk_algorithm!(\n    M::AbstractManifold,\n    mgo::ManifoldCostObjective,\n    p;\n    Ïƒ = 0.1,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n    stopping_criterion::StoppingCriterion=StopAfterIteration(200),\n    kwargs...,\n)\n    dmgo = decorate_objective!(M, mgo; kwargs...)\n    dmp = DefaultManoptProblem(M, dmgo)\n    s = RandomWalkState(M, [1.0, 0.0, 0.0];\n        Ïƒ=0.1,\n        retraction_method=retraction_method, stopping_criterion=stopping_criterion,\n    )\n    ds = decorate_state!(s; kwargs...)\n    solve!(dmp, ds)\n    return get_solver_return(get_objective(dmp), ds)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"random_walk_algorithm! (generic function with 1 method)","category":"page"},{"location":"tutorials/ImplementASolver/#The-high-level-interface","page":"Implement a solver","title":"The high level interface","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Starting from the last section, the usual call a user would prefer is just passing a manifold M the cost f and maybe a start point p.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"function random_walk_algorithm!(M::AbstractManifold, f, p=rand(M); kwargs...)\n    mgo = ManifoldCostObjective(f)\n    return random_walk_algorithm!(M, mgo, p; kwargs...)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"random_walk_algorithm! (generic function with 3 methods)","category":"page"},{"location":"tutorials/ImplementASolver/#Ease-of-Use-II:-the-state-summary","page":"Implement a solver","title":"Ease of Use II: the state summary","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"For the case that you set return_state=true the solver should return a summary of the run. When a show method is provided, users can easily read such summary in a terminal. It should reflect its main parameters, if they are not too verbose and provide information about the reason it stopped and whether this indicates convergence.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Here it would for example look like","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"import Base: show\nfunction show(io::IO, rws::RandomWalkState)\n    i = get_count(rws, :Iterations)\n    Iter = (i > 0) ? \"After $i iterations\\n\" : \"\"\n    Conv = indicates_convergence(rws.stop) ? \"Yes\" : \"No\"\n    s = \"\"\"\n    # Solver state for `Manopt.jl`s Tutorial Random Walk\n    $Iter\n    ## Parameters\n    * retraction method: $(rws.retraction_method)\n    * Ïƒ                : $(rws.Ïƒ)\n\n    ## Stopping criterion\n\n    $(status_summary(rws.stop))\n    This indicates convergence: $Conv\"\"\"\n    return print(io, s)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Now the algorithm can be easily called and provides all features of a Manopt.jl algorithm. For example to see the summary, we could now just call","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"q = random_walk_algorithm!(M, f; return_state=true)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"# Solver state for `Manopt.jl`s Tutorial Random Walk\nAfter 200 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n* Ïƒ                : 0.1\n\n## Stopping criterion\n\nMax Iteration 200:  reached\nThis indicates convergence: No","category":"page"},{"location":"tutorials/ImplementASolver/#Conclusion-and-beyond","page":"Implement a solver","title":"Conclusion & beyond","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"We saw in this tutorial how to implement a simple cost-based algorithm, to illustrate how optimization algorithms are covered in Manopt.jl.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"One feature we did not cover is that most algorithms allow for in-place and allocation functions, as soon as they work on more than just the cost, for example use gradients, proximal maps or Hessians. This is usually a keyword argument of the objective and hence also part of the high-level interfaces.","category":"page"},{"location":"tutorials/ImplementASolver/#Technical-details","page":"Implement a solver","title":"Technical details","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a solver","title":"Implement a solver","text":"2025-04-25T12:13:31.637","category":"page"},{"location":"solvers/FrankWolfe/#Frankâ€”Wolfe-method","page":"Frank-Wolfe","title":"Frankâ€”Wolfe method","text":"","category":"section"},{"location":"solvers/FrankWolfe/#Manopt.Frank_Wolfe_method","page":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method","text":"Frank_Wolfe_method(M, f, grad_f, p=rand(M))\nFrank_Wolfe_method(M, gradient_objective, p=rand(M); kwargs...)\nFrank_Wolfe_method!(M, f, grad_f, p; kwargs...)\nFrank_Wolfe_method!(M, gradient_objective, p; kwargs...)\n\nPerform the Frank-Wolfe algorithm to compute for mathcal C  mathcal M the constrained problem\n\n    operatorname*argmin_pmathcal C f(p)\n\nwhere the main step is a constrained optimisation is within the algorithm, that is the sub problem (Oracle)\n\n   operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq\n\nfor every iterate p_k together with a stepsize s_k1. The algorhtm can be performed in-place of p.\n\nThis algorithm is inspired by but slightly more general than [WS22].\n\nThe next iterate is then given by p_k+1 = Î³_p_kq_k(s_k), where by default Î³ is the shortest geodesic between the two points but can also be changed to use a retraction and its inverse.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldGradientObjective gradient_objective directly.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=DecreasingStepsize(; length=2.0, shift=2): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6)): a functor indicating that the stopping criterion is fulfilled\nsub_cost=FrankWolfeCost(p, X): the cost of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=FrankWolfeGradient(p, X): the gradient of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=ManifoldGradientObjective(sub_cost, sub_gradient): the objective for the Frank-Wolfe sub problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=GradientDescentState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\nsub_stopping_criterion=[StopAfterIteration](@ref)(300)[ | ](@ref StopWhenAny)[StopWhenStepsizeLess](@ref)(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define thesubstate=keyword and has hence no effect, if you setsubstate` directly.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/FrankWolfe/#Manopt.Frank_Wolfe_method!","page":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method!","text":"Frank_Wolfe_method(M, f, grad_f, p=rand(M))\nFrank_Wolfe_method(M, gradient_objective, p=rand(M); kwargs...)\nFrank_Wolfe_method!(M, f, grad_f, p; kwargs...)\nFrank_Wolfe_method!(M, gradient_objective, p; kwargs...)\n\nPerform the Frank-Wolfe algorithm to compute for mathcal C  mathcal M the constrained problem\n\n    operatorname*argmin_pmathcal C f(p)\n\nwhere the main step is a constrained optimisation is within the algorithm, that is the sub problem (Oracle)\n\n   operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq\n\nfor every iterate p_k together with a stepsize s_k1. The algorhtm can be performed in-place of p.\n\nThis algorithm is inspired by but slightly more general than [WS22].\n\nThe next iterate is then given by p_k+1 = Î³_p_kq_k(s_k), where by default Î³ is the shortest geodesic between the two points but can also be changed to use a retraction and its inverse.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldGradientObjective gradient_objective directly.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=DecreasingStepsize(; length=2.0, shift=2): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6)): a functor indicating that the stopping criterion is fulfilled\nsub_cost=FrankWolfeCost(p, X): the cost of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=FrankWolfeGradient(p, X): the gradient of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=ManifoldGradientObjective(sub_cost, sub_gradient): the objective for the Frank-Wolfe sub problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem=DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=GradientDescentState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\nsub_stopping_criterion=[StopAfterIteration](@ref)(300)[ | ](@ref StopWhenAny)[StopWhenStepsizeLess](@ref)(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define thesubstate=keyword and has hence no effect, if you setsubstate` directly.\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldGradientObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/FrankWolfe/#State","page":"Frank-Wolfe","title":"State","text":"","category":"section"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeState","page":"Frank-Wolfe","title":"Manopt.FrankWolfeState","text":"FrankWolfeState <: AbstractManoptSolverState\n\nA struct to store the current state of the Frank_Wolfe_method\n\nIt comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nThe sub task requires a method to solve\n\n   operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq\n\nConstructor\n\nFrankWolfeState(M, sub_problem, sub_state; kwargs...)\n\nInitialise the Frank Wolfe method state.\n\nFrankWolfeState(M, sub_problem; evaluation=AllocatingEvaluation(), kwargs...)\n\nInitialise the Frank Wolfe method state, where sub_problem is a closed form solution with evaluation as type of evaluation.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nsub_problem:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\np=rand(M): a point on the manifold mathcal Mto specify the initial value\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nstepsize=default_stepsize(M, FrankWolfeState): a functor inheriting from Stepsize to determine a step size\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nwhere the remaining fields from before are keyword arguments.\n\n\n\n\n\n","category":"type"},{"location":"solvers/FrankWolfe/#Helpers","page":"Frank-Wolfe","title":"Helpers","text":"","category":"section"},{"location":"solvers/FrankWolfe/","page":"Frank-Wolfe","title":"Frank-Wolfe","text":"For the inner sub-problem you can easily create the corresponding cost and gradient using","category":"page"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeCost","page":"Frank-Wolfe","title":"Manopt.FrankWolfeCost","text":"FrankWolfeCost{P,T}\n\nA structure to represent the oracle sub problem in the Frank_Wolfe_method. The cost function reads\n\nF(q) = X log_p q\n\nThe values p and X are stored within this functor and should be references to the iterate and gradient from within FrankWolfeState.\n\n\n\n\n\n","category":"type"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeGradient","page":"Frank-Wolfe","title":"Manopt.FrankWolfeGradient","text":"FrankWolfeGradient{P,T}\n\nA structure to represent the gradient of the oracle sub problem in the Frank_Wolfe_method, that is for a given point p and a tangent vector X the function reads\n\nF(q) = X log_p q\n\nIts gradient can be computed easily using adjoint_differential_log_argument.\n\nThe values p and X are stored within this functor and should be references to the iterate and gradient from within FrankWolfeState.\n\n\n\n\n\n","category":"type"},{"location":"solvers/FrankWolfe/","page":"Frank-Wolfe","title":"Frank-Wolfe","text":"M.Â Weber and S.Â Sra. Riemannian Optimization via Frank-Wolfe Methods. MathematicalÂ Programming 199, 525â€“556 (2022).\n\n\n\n","category":"page"},{"location":"tutorials/HowToDebug/#How-to-print-debug-output","page":"Print debug output","title":"How to print debug output","text":"","category":"section"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"This tutorial aims to illustrate how to perform debug output. For that we consider an example that includes a subsolver, to also consider their debug capabilities.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"The problem itself is hence not the main focus. We consider a nonnegative PCA which we can write as a constraint problem on the Sphere","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Letâ€™s first load the necessary packages.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"using Manopt, Manifolds, Random, LinearAlgebra\nRandom.seed!(42);","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"d = 4\nM = Sphere(d - 1)\nv0 = project(M, [ones(2)..., zeros(d - 2)...])\nZ = v0 * v0'\n#Cost and gradient\nf(M, p) = -tr(transpose(p) * Z * p) / 2\ngrad_f(M, p) = project(M, p, -transpose.(Z) * p / 2 - Z * p / 2)\n# Constraints\ng(M, p) = -p # now p â‰¥ 0\nmI = -Matrix{Float64}(I, d, d)\n# Vector of gradients of the constraint components\ngrad_g(M, p) = [project(M, p, mI[:, i]) for i in 1:d]","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Then we can take a starting point","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"p0 = project(M, [ones(2)..., zeros(d - 3)..., 0.1])","category":"page"},{"location":"tutorials/HowToDebug/#Simple-debug-output","page":"Print debug output","title":"Simple debug output","text":"","category":"section"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Any solver accepts the keyword debug=, which in the simplest case can be set to an array of strings, symbols and a number.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Strings are printed in every iteration as is (cf.Â DebugDivider) and should be used to finish the array with a line break.\nthe last number in the array is used with DebugEvery to print the debug only every ith iteration.\nAny Symbol is converted into certain debug prints","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Certain symbols starting with a capital letter are mapped to certain prints, for example :Cost is mapped to DebugCost() to print the current cost function value. A full list is provided in the DebugActionFactory. A special keyword is :Stop, which is only added to the final debug hook to print the stopping criterion.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Any symbol with a small letter is mapped to fields of the AbstractManoptSolverState which is used. This way you can easily print internal data, if you know their names.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Letâ€™s look at an example first: if we want to print the current iteration number, the current cost function value as well as the value Ïµ from the ExactPenaltyMethodState. To keep the amount of print at a reasonable level, we want to only print the debug every twenty-fifth iteration.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Then we can write","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"p1 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [:Iteration, :Cost, \" | \", (:Ïµ,\"Ïµ: %.8f\"), 25, \"\\n\", :Stop]\n);","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Initial f(x): -0.497512 | Ïµ: 0.00100000\n# 25    f(x): -0.499449 | Ïµ: 0.00017783\n# 50    f(x): -0.499996 | Ïµ: 0.00003162\n# 75    f(x): -0.500000 | Ïµ: 0.00000562\n# 100   f(x): -0.500000 | Ïµ: 0.00000100\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.","category":"page"},{"location":"tutorials/HowToDebug/#Specifying-when-to-print-something","page":"Print debug output","title":"Specifying when to print something","text":"","category":"section"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"While in the last step, we specified what to print, this can be extend to even specify when to print it. Currently the following four â€œplacesâ€ are available, ordered by when they appear in an algorithm run.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":":Start to print something at the start of the algorithm. At this place all other (the following) places are â€œresetâ€, by triggering each of them with an iteration number 0\n:BeforeIteration to print something before an iteration starts\n:Iteration to print something after an iteration. For example the group of prints from the last code block [:Iteration, :Cost, \" | \", :Ïµ, 25,] is added to this entry.\n:Stop to print something when the algorithm stops. In the example, the :Stop adds the DebugStoppingCriterion is added to this place.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Specifying something especially for one of these places is done by specifying a Pair, so for example :BeforeIteration => :Iteration would add the display of the iteration number to be printed before the iteration is performed.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Changing this in the run does not change the output. Being more precise for the other entries, we could also write","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"p1 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [\n        :BeforeIteration => [:Iteration],\n        :Iteration => [:Cost, \" | \", :Ïµ, \"\\n\"],\n        :Stop => DebugStoppingCriterion(),\n        25,\n    ],\n);","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Initial f(x): -0.497512 | Ïµ: 0.001\n# 25    f(x): -0.499449 | Ïµ: 0.0001778279410038921\n# 50    f(x): -0.499996 | Ïµ: 3.1622776601683734e-5\n# 75    f(x): -0.500000 | Ïµ: 5.623413251903474e-6\n# 100   f(x): -0.500000 | Ïµ: 1.0e-6\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"This also illustrates, that instead of Symbols we can also always pass down a DebugAction directly, for example when there is a reason to create or configure the action more individually than the default from the symbol. Note that the number (25) yields that all but :Start and :Stop are only displayed every twenty-fifth iteration.","category":"page"},{"location":"tutorials/HowToDebug/#Subsolver-debug","page":"Print debug output","title":"Subsolver debug","text":"","category":"section"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Sub solvers have a sub_kwargs keyword, such that you can pass keywords to the sub solver as well. This works well if you do not plan to change the subsolver. If you do you can wrap your own solver_state= argument in a decorate_state! and pass a debug= password to this function call. Keywords in a keyword have to be passed as pairs (:debug => [...]).","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"For most debugs, there further exists a longer form to specify the format to print. We want to use this to specify the format to print Ïµ. This is done by putting the corresponding symbol together with the string to use in formatting into a tuple like (:Ïµ,\" | Ïµ: %.8f\"), where we can already include the divider as well.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"A main problem now is, that this debug is issued every sub solver call or initialisation, as the following print of just a . per sub solver test/call illustrates","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"p3 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [\"\\n\",:Iteration, DebugCost(), (:Ïµ,\" | Ïµ: %.8f\"), 25, \"\\n\", :Stop],\n    sub_kwargs = [:debug => [\".\"]]\n);","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Initial f(x): -0.497512 | Ïµ: 0.00100000\n....................................................................................\n# 25    f(x): -0.499449 | Ïµ: 0.00017783\n.......................................................................\n# 50    f(x): -0.499996 | Ïµ: 0.00003162\n..................................................\n# 75    f(x): -0.500000 | Ïµ: 0.00000562\n..................................................\n# 100   f(x): -0.500000 | Ïµ: 0.00000100\n....The value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"The different lengths of the dotted lines come from the fact that â€”at least in the beginningâ€” the subsolver performs a few steps and each sub solvers step prints a dot.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"For this issue, there is the next symbol (similar to the :Stop) to indicate that a debug set is a subsolver set :WhenActive, which introduces a DebugWhenActive that is only activated when the outer debug is actually active, or another words DebugEvery is active itself. Furthermore, we want to print the iteration number before printing the sub solvers steps, so we put this into a Pair, but we can leave the remaining ones as single entries. Finally we also prefix :Stop with \" | \" and print the iteration number at the time we stop. We get","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"p4 = exact_penalty_method(\n    M,\n    f,\n    grad_f,\n    p0;\n    g=g,\n    grad_g=grad_g,\n    debug=[\n        :BeforeIteration => [:Iteration, \"\\n\"],\n        :Iteration => [DebugCost(), (:Ïµ, \" | Ïµ: %.8f\"), \"\\n\"],\n        :Stop,\n        25,\n    ],\n    sub_kwargs=[\n        :debug => [\n            \" | \",\n            :Iteration,\n            :Cost,\n            \"\\n\",\n            :WhenActive,\n            :Stop => [(:Stop, \" | \"), \" | stopped after iteration \", :Iteration, \"\\n\"],\n        ],\n    ],\n);","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Initial \nf(x): -0.497512 | Ïµ: 0.00100000\n | Initial f(x): -0.498944\n | # 1     f(x): -0.498969\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (3.4995246389869776e-5) is less than 0.001.\n | stopped after iteration # 1     \n# 25    \nf(x): -0.499449 | Ïµ: 0.00017783\n | Initial f(x): -0.499992\n | # 1     f(x): -0.499992\n | # 2     f(x): -0.499992\n | The algorithm reached approximately critical point after 2 iterations; the gradient norm (0.00027436723916614346) is less than 0.001.\n | stopped after iteration # 2     \n# 50    \nf(x): -0.499996 | Ïµ: 0.00003162\n | Initial f(x): -0.500000\n | # 1     f(x): -0.500000\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (5.000404403277298e-6) is less than 0.001.\n | stopped after iteration # 1     \n# 75    \nf(x): -0.500000 | Ïµ: 0.00000562\n | Initial f(x): -0.500000\n | # 1     f(x): -0.500000\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (4.202215558182483e-6) is less than 0.001.\n | stopped after iteration # 1     \n# 100   \nf(x): -0.500000 | Ïµ: 0.00000100\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"where we now see that the subsolver always only requires one step. Note that since debug of an iteration is happening after a step, we see the sub solver run before the debug for an iteration number.","category":"page"},{"location":"tutorials/HowToDebug/#Advanced-debug-output","page":"Print debug output","title":"Advanced debug output","text":"","category":"section"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"There is two more advanced variants that can be used. The first is a tuple of a symbol and a string, where the string is used as the format print, that most DebugActions have. The second is, to directly provide a DebugAction.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"We can for example change the way the :Ïµ is printed by adding a format string and use DebugCost() which is equivalent to using :Cost. Especially with the format change, the lines are more consistent in length.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"p2 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [:Iteration, DebugCost(), (:Ïµ,\" | Ïµ: %.8f\"), 25, \"\\n\", :Stop]\n);","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Initial f(x): -0.497512 | Ïµ: 0.00100000\n# 25    f(x): -0.499449 | Ïµ: 0.00017783\n# 50    f(x): -0.499996 | Ïµ: 0.00003162\n# 75    f(x): -0.500000 | Ïµ: 0.00000562\n# 100   f(x): -0.500000 | Ïµ: 0.00000100\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"You can also write your own DebugAction functor, where the function to implement has the same signature as the step function, that is an AbstractManoptProblem, an AbstractManoptSolverState, as well as the current iterate. For example the already mentionedDebugDivider(s) is given as","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"mutable struct DebugDivider{TIO<:IO} <: DebugAction\n    io::TIO\n    divider::String\n    DebugDivider(divider=\" | \"; io::IO=stdout) = new{typeof(io)}(io, divider)\nend\nfunction (d::DebugDivider)(::AbstractManoptProblem, ::AbstractManoptSolverState, k::Int)\n    (k >= 0) && (!isempty(d.divider)) && (print(d.io, d.divider))\n    return nothing\nend","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"or you could implement that of course just for your specific problem or state.","category":"page"},{"location":"tutorials/HowToDebug/#Technical-details","page":"Print debug output","title":"Technical details","text":"","category":"section"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/HowToDebug/","page":"Print debug output","title":"Print debug output","text":"2025-04-25T12:12:38.940","category":"page"},{"location":"solvers/particle_swarm/#Particle-swarm-optimization","page":"Particle Swarm Optimization","title":"Particle swarm optimization","text":"","category":"section"},{"location":"solvers/particle_swarm/#Manopt.particle_swarm","page":"Particle Swarm Optimization","title":"Manopt.particle_swarm","text":"patricle_swarm(M, f; kwargs...)\npatricle_swarm(M, f, swarm; kwargs...)\npatricle_swarm(M, mco::AbstractManifoldCostObjective; kwargs..)\npatricle_swarm(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\nparticle_swarm!(M, f, swarm; kwargs...)\nparticle_swarm!(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\n\nperform the particle swarm optimization algorithm (PSO) to solve\n\noperatorname*argmin_p  mathcal M f(p)\n\nPSO starts with an initial swarm [BIA10] of points on the manifold. If no swarm is provided, the swarm_size keyword is used to generate random points. The computation can be perfomed in-place of swarm.\n\nTo this end, a swarm S = s_1 ldots s_n of particles is moved around the manifold M in the following manner. For every particle s_k^(i) the new particle velocities X_k^(i) are computed in every step i of the algorithm by\n\nX_k^(i) = Ï‰ mathcal T_s_k^(i)s_k^(i-1) X_k^(i-1) + c r_1  operatornameretr^-1_s_k^(i)(p_k^(i)) + s r_2 operatornameretr^-1_s_k^(i)(p)\n\nwhere\n\ns_k^(i) is the current particle position,\nÏ‰ denotes the inertia,\nc and s are a cognitive and a social weight, respectively,\nr_j, j=12 are random factors which are computed new for each particle and step\n\\mathcal T_{â‹…â†â‹…} is a vector transport, and\n\\operatorname{retr}^{-1} is an inverse retraction\n\nThen the position of the particle is updated as\n\ns_k^(i+1) = operatornameretr_s_k^(i)(X_k^(i))\n\nThen the single particles best entries p_k^(i) are updated as\n\np_k^(i+1) = begincases\ns_k^(i+1)   textif  F(s_k^(i+1))F(p_k^(i))\np_k^(i)  textelse\nendcases\n\nand the global best position\n\ng^(i+1) = begincases\np_k^(i+1)   textif  F(p_k^(i+1))F(g_k^(i))\ng_k^(i)  textelse\nendcases\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nswarm = [rand(M) for _ in 1:swarm_size]: an initial swarm of points.\n\nInstead of a cost function f you can also provide an AbstractManifoldCostObjective mco.\n\nKeyword Arguments\n\ncognitive_weight=1.4: a cognitive weight factor\ninertia=0.65: the inertia of the particles\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nsocial_weight=1.4: a social weight factor\nswarm_size=100: swarm size, if it should be generated randomly\nstopping_criterion=StopAfterIteration(500)|StopWhenChangeLess(1e-4): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvelocity:                  a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles, per default a random tangent vector per initial position\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively. If you provide the objective directly, these decorations can still be specified\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/particle_swarm/#Manopt.particle_swarm!","page":"Particle Swarm Optimization","title":"Manopt.particle_swarm!","text":"patricle_swarm(M, f; kwargs...)\npatricle_swarm(M, f, swarm; kwargs...)\npatricle_swarm(M, mco::AbstractManifoldCostObjective; kwargs..)\npatricle_swarm(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\nparticle_swarm!(M, f, swarm; kwargs...)\nparticle_swarm!(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\n\nperform the particle swarm optimization algorithm (PSO) to solve\n\noperatorname*argmin_p  mathcal M f(p)\n\nPSO starts with an initial swarm [BIA10] of points on the manifold. If no swarm is provided, the swarm_size keyword is used to generate random points. The computation can be perfomed in-place of swarm.\n\nTo this end, a swarm S = s_1 ldots s_n of particles is moved around the manifold M in the following manner. For every particle s_k^(i) the new particle velocities X_k^(i) are computed in every step i of the algorithm by\n\nX_k^(i) = Ï‰ mathcal T_s_k^(i)s_k^(i-1) X_k^(i-1) + c r_1  operatornameretr^-1_s_k^(i)(p_k^(i)) + s r_2 operatornameretr^-1_s_k^(i)(p)\n\nwhere\n\ns_k^(i) is the current particle position,\nÏ‰ denotes the inertia,\nc and s are a cognitive and a social weight, respectively,\nr_j, j=12 are random factors which are computed new for each particle and step\n\\mathcal T_{â‹…â†â‹…} is a vector transport, and\n\\operatorname{retr}^{-1} is an inverse retraction\n\nThen the position of the particle is updated as\n\ns_k^(i+1) = operatornameretr_s_k^(i)(X_k^(i))\n\nThen the single particles best entries p_k^(i) are updated as\n\np_k^(i+1) = begincases\ns_k^(i+1)   textif  F(s_k^(i+1))F(p_k^(i))\np_k^(i)  textelse\nendcases\n\nand the global best position\n\ng^(i+1) = begincases\np_k^(i+1)   textif  F(p_k^(i+1))F(g_k^(i))\ng_k^(i)  textelse\nendcases\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nswarm = [rand(M) for _ in 1:swarm_size]: an initial swarm of points.\n\nInstead of a cost function f you can also provide an AbstractManifoldCostObjective mco.\n\nKeyword Arguments\n\ncognitive_weight=1.4: a cognitive weight factor\ninertia=0.65: the inertia of the particles\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nsocial_weight=1.4: a social weight factor\nswarm_size=100: swarm size, if it should be generated randomly\nstopping_criterion=StopAfterIteration(500)|StopWhenChangeLess(1e-4): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvelocity:                  a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles, per default a random tangent vector per initial position\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively. If you provide the objective directly, these decorations can still be specified\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/particle_swarm/#State","page":"Particle Swarm Optimization","title":"State","text":"","category":"section"},{"location":"solvers/particle_swarm/#Manopt.ParticleSwarmState","page":"Particle Swarm Optimization","title":"Manopt.ParticleSwarmState","text":"ParticleSwarmState{P,T} <: AbstractManoptSolverState\n\nDescribes a particle swarm optimizing algorithm, with\n\nFields\n\ncognitive_weight: a cognitive weight factor\ninertia:          the inertia of the particles\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nsocial_weight:    a social weight factor\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nvelocity:         a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles\n\nInternal and temporary fields\n\ncognitive_vector: temporary storage for a tangent vector related to cognitive_weight\np::P: a point on the manifold mathcal M storing the best point visited by all particles\npositional_best:  storing the best position p_i every single swarm participant visited\nq::P: a point on the manifold mathcal M serving as temporary storage for interims results; avoids allocations\nsocial_vec:       temporary storage for a tangent vector related to social_weight\nswarm:            a set of points (of type AbstractVector{P}) on a manifold a_i_i=1^N\n\nConstructor\n\nParticleSwarmState(M, initial_swarm, velocity; kawrgs...)\n\nconstruct a particle swarm solver state for the manifold M starting with the initial population initial_swarm with velocities. The p used in the following defaults is the type of one point from the swarm.\n\nKeyword arguments\n\ncognitive_weight=1.4\ninertia=0.65\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nsocial_weight=1.4\nstopping_criterion=StopAfterIteration(500)|StopWhenChangeLess(1e-4): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nparticle_swarm\n\n\n\n\n\n","category":"type"},{"location":"solvers/particle_swarm/#Stopping-criteria","page":"Particle Swarm Optimization","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/particle_swarm/#Manopt.StopWhenSwarmVelocityLess","page":"Particle Swarm Optimization","title":"Manopt.StopWhenSwarmVelocityLess","text":"StopWhenSwarmVelocityLess <: StoppingCriterion\n\nStopping criterion for particle_swarm, when the velocity of the swarm is less than a threshold.\n\nFields\n\nthreshold:      the threshold\nat_iteration:   store the iteration the stopping criterion was (last) fulfilled\nreason:         store the reason why the stopping criterion was fulfilled, see get_reason\nvelocity_norms: interim vector to store the norms of the velocities before computing its norm\n\nConstructor\n\nStopWhenSwarmVelocityLess(tolerance::Float64)\n\ninitialize the stopping criterion to a certain tolerance.\n\n\n\n\n\n","category":"type"},{"location":"solvers/particle_swarm/#sec-arc-technical-details","page":"Particle Swarm Optimization","title":"Technical details","text":"","category":"section"},{"location":"solvers/particle_swarm/","page":"Particle Swarm Optimization","title":"Particle Swarm Optimization","text":"The particle_swarm solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/particle_swarm/","page":"Particle Swarm Optimization","title":"Particle Swarm Optimization","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nTangent vectors storing the social and cognitive vectors are initialized calling zero_vector(M,p).\nA copyto!(M, q, p) and copy(M,p) for points.\nThe distance(M, p, q) when using the default stopping criterion, which uses StopWhenChangeLess.","category":"page"},{"location":"solvers/particle_swarm/#Literature","page":"Particle Swarm Optimization","title":"Literature","text":"","category":"section"},{"location":"solvers/particle_swarm/","page":"Particle Swarm Optimization","title":"Particle Swarm Optimization","text":"P.Â B.Â Borckmans, M.Â Ishteva and P.-A.Â Absil. A Modified Particle Swarm Optimization Algorithm for the Best Low Multilinear Rank Approximation of Higher-Order Tensors. In: 7th International Conference on Swarm INtelligence (Springer Berlin Heidelberg, 2010); pp.Â 13â€“23.\n\n\n\n","category":"page"},{"location":"solvers/stochastic_gradient_descent/#Stochastic-gradient-descent","page":"Stochastic Gradient Descent","title":"Stochastic gradient descent","text":"","category":"section"},{"location":"solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent","page":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent","text":"stochastic_gradient_descent(M, grad_f, p=rand(M); kwargs...)\nstochastic_gradient_descent(M, msgo; kwargs...)\nstochastic_gradient_descent!(M, grad_f, p; kwargs...)\nstochastic_gradient_descent!(M, msgo, p; kwargs...)\n\nperform a stochastic gradient descent. This can be perfomed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\ngrad_f: a gradient function, that either returns a vector of the gradients or is a vector of gradient functions\np: a point on the manifold mathcal M\n\nalternatively to the gradient you can provide an ManifoldStochasticGradientObjective msgo, then using the cost= keyword does not have any effect since if so, the cost is already within the objective.\n\nKeyword arguments\n\ncost=missing: you can provide a cost function for example to track the function value\ndirection=StochasticGradient([zerovector](@extrefManifoldsBase.zerovector-Tuple{AbstractManifold, Any})(M, p)`)\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Random: specify whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Linear) or the default :Random one.\norder_type=:RandomOder: a type of ordering of gradient evaluations. Possible values are :RandomOrder, a :FixedPermutation, :LinearOrder\nstopping_criterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize=default_stepsize(M, StochasticGradientDescentState): a functor inheriting from Stepsize to determine a step size\norder=[1:n]: the initial permutation, where n is the number of gradients in gradF.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent!","page":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent!","text":"stochastic_gradient_descent(M, grad_f, p=rand(M); kwargs...)\nstochastic_gradient_descent(M, msgo; kwargs...)\nstochastic_gradient_descent!(M, grad_f, p; kwargs...)\nstochastic_gradient_descent!(M, msgo, p; kwargs...)\n\nperform a stochastic gradient descent. This can be perfomed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\ngrad_f: a gradient function, that either returns a vector of the gradients or is a vector of gradient functions\np: a point on the manifold mathcal M\n\nalternatively to the gradient you can provide an ManifoldStochasticGradientObjective msgo, then using the cost= keyword does not have any effect since if so, the cost is already within the objective.\n\nKeyword arguments\n\ncost=missing: you can provide a cost function for example to track the function value\ndirection=StochasticGradient([zerovector](@extrefManifoldsBase.zerovector-Tuple{AbstractManifold, Any})(M, p)`)\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Random: specify whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Linear) or the default :Random one.\norder_type=:RandomOder: a type of ordering of gradient evaluations. Possible values are :RandomOrder, a :FixedPermutation, :LinearOrder\nstopping_criterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize=default_stepsize(M, StochasticGradientDescentState): a functor inheriting from Stepsize to determine a step size\norder=[1:n]: the initial permutation, where n is the number of gradients in gradF.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/#State","page":"Stochastic Gradient Descent","title":"State","text":"","category":"section"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradientDescentState","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradientDescentState","text":"StochasticGradientDescentState <: AbstractGradientDescentSolverState\n\nStore the following fields for a default stochastic gradient descent algorithm, see also ManifoldStochasticGradientObjective and stochastic_gradient_descent.\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\ndirection:  a direction update to use\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nevaluation_order: specify whether to use a randomly permuted sequence (:FixedRandom:), a per cycle permuted sequence (:Linear) or the default, a :Random sequence.\norder: stores the current permutation\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructor\n\nStochasticGradientDescentState(M::AbstractManifold; kwargs...)\n\nCreate a StochasticGradientDescentState with start point p.\n\nKeyword arguments\n\ndirection=StochasticGradientRule(M, [zerovector](@extrefManifoldsBase.zerovector-Tuple{AbstractManifold, Any})(M, p)`)\norder_type=:RandomOrder`\norder=Int[]: specify how to store the order of indices for the next epoche\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstopping_criterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize=default_stepsize(M, StochasticGradientDescentState): a functor inheriting from Stepsize to determine a step size\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{StochasticGradientDescentState}}","page":"Stochastic Gradient Descent","title":"Manopt.default_stepsize","text":"default_stepsize(M::AbstractManifold, ::Type{StochasticGradientDescentState})\n\nDeinfe the default step size computed for the StochasticGradientDescentState, which is ConstantStepsizeM.\n\n\n\n\n\n","category":"method"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"Additionally, the options share a DirectionUpdateRule, so you can also apply MomentumGradient and AverageGradient here. The most inner one should always be.","category":"page"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradient","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradient","text":"StochasticGradient(; kwargs...)\nStochasticGradient(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\ninitial_gradient=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\np=rand(M): a point on the manifold mathcal Mto specify the initial value\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for StochasticGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"which internally uses","category":"page"},{"location":"solvers/stochastic_gradient_descent/#Manopt.AbstractGradientGroupDirectionRule","page":"Stochastic Gradient Descent","title":"Manopt.AbstractGradientGroupDirectionRule","text":"AbstractStochasticGradientDescentSolverState <: AbstractManoptSolverState\n\nA generic type for all options related to gradient descent methods working with parts of the total gradient\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradientRule","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradientRule","text":"StochasticGradientRule<: AbstractGradientGroupDirectionRule\n\nCreate a functor (problem, state k) -> (s,X) to evaluate the stochatsic gradient, that is chose a random index from the state and use the internal field for evaluation of the gradient in-place.\n\nThe default gradient processor, which just evaluates the (stochastic) gradient or a subset thereof.\n\nFields\n\nX::T: a tangent vector at the point p on the manifold mathcal M\n\nConstructor\n\nStochasticGradientRule(M::AbstractManifold; p=rand(M), X=zero_vector(M, p))\n\nInitialize the stochastic gradient processor with tangent vector type of X, where both M and p are just help variables.\n\nSee also\n\nstochastic_gradient_descent, [StochasticGradient])@ref)\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/#sec-sgd-technical-details","page":"Stochastic Gradient Descent","title":"Technical details","text":"","category":"section"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"The stochastic_gradient_descent solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.","category":"page"},{"location":"solvers/proximal_bundle_method/#Proximal-bundle-method","page":"Proximal bundle method","title":"Proximal bundle method","text":"","category":"section"},{"location":"solvers/proximal_bundle_method/#Manopt.proximal_bundle_method","page":"Proximal bundle method","title":"Manopt.proximal_bundle_method","text":"proximal_bundle_method(M, f, âˆ‚f, p=rand(M), kwargs...)\nproximal_bundle_method!(M, f, âˆ‚f, p, kwargs...)\n\nperform a proximal bundle method p^(k+1) = operatornameretr_p^(k)(-d_k), where operatornameretr is a retraction and\n\nd_k = frac1mu_k sum_jin J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nwith X_q_j  f(q_j), p_k the last serious iterate, mu_k a proximal parameter, and the Î»_j^k as solutions to the quadratic subproblem provided by the sub solver, see for example the proximal_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details see [HNP23].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nâˆ‚f:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nÎ±â‚€=1.2:          initialization value for Î±, used to update Î·\nbundle_size=50:  the maximal size of the bundle\nÎ´=1.0:           parameter for updating Î¼: if Î´  0 then Î¼ = log(i + 1), else Î¼ += Î´ Î¼\nÎµ=1e-2:          stepsize-like parameter related to the injectivity radius of the manifold\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nm=0.0125:        a real number that controls the decrease of the cost function\nÎ¼=0.5:           initial proximal parameter for the subproblem\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nsub_problem=proximal_bundle_method_subsolver`:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_bundle_method/#Manopt.proximal_bundle_method!","page":"Proximal bundle method","title":"Manopt.proximal_bundle_method!","text":"proximal_bundle_method(M, f, âˆ‚f, p=rand(M), kwargs...)\nproximal_bundle_method!(M, f, âˆ‚f, p, kwargs...)\n\nperform a proximal bundle method p^(k+1) = operatornameretr_p^(k)(-d_k), where operatornameretr is a retraction and\n\nd_k = frac1mu_k sum_jin J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nwith X_q_j  f(q_j), p_k the last serious iterate, mu_k a proximal parameter, and the Î»_j^k as solutions to the quadratic subproblem provided by the sub solver, see for example the proximal_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details see [HNP23].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\nâˆ‚f:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nÎ±â‚€=1.2:          initialization value for Î±, used to update Î·\nbundle_size=50:  the maximal size of the bundle\nÎ´=1.0:           parameter for updating Î¼: if Î´  0 then Î¼ = log(i + 1), else Î¼ += Î´ Î¼\nÎµ=1e-2:          stepsize-like parameter related to the injectivity radius of the manifold\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nm=0.0125:        a real number that controls the decrease of the cost function\nÎ¼=0.5:           initial proximal parameter for the subproblem\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nsub_problem=proximal_bundle_method_subsolver`:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_bundle_method/#State","page":"Proximal bundle method","title":"State","text":"","category":"section"},{"location":"solvers/proximal_bundle_method/#Manopt.ProximalBundleMethodState","page":"Proximal bundle method","title":"Manopt.ProximalBundleMethodState","text":"ProximalBundleMethodState <: AbstractManoptSolverState\n\nstores option values for a proximal_bundle_method solver.\n\nFields\n\nÎ±:                        curvature-dependent parameter used to update Î·\nÎ±â‚€:                       initialization value for Î±, used to update Î·\napprox_errors:            approximation of the linearization errors at the last serious step\nbundle:                   bundle that collects each iterate with the computed subgradient at the iterate\nbundle_size:              the maximal size of the bundle\nc:                        convex combination of the approximation errors\nd:                        descent direction\nÎ´:                        parameter for updating Î¼: if Î´  0 then Î¼ = log(i + 1), else Î¼ += Î´ Î¼\nÎµ:                        stepsize-like parameter related to the injectivity radius of the manifold\nÎ·:                        curvature-dependent term for updating the approximation errors\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ»:                        convex coefficients that solve the subproblem\nm:                        the parameter to test the decrease of the cost\nÎ¼:                        (initial) proximal parameter for the subproblem\nÎ½:                        the stopping parameter given by Î½ = - Î¼ d^2 - c\np::P: a point on the manifold mathcal Mstoring the current iterate\np_last_serious:           last serious iterate\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\ntransported_subgradients: subgradients of the bundle that are transported to p_last_serious\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring a subgradient at the current iterate\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nConstructor\n\nProximalBundleMethodState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\nProximalBundleMethodState(M::AbstractManifold, sub_problem=proximal_bundle_method_subsolver; evaluation=AllocatingEvaluation(), kwargs...)\n\nGenerate the state for the proximal_bundle_method on the manifold M\n\nKeyword arguments\n\nÎ±â‚€=1.2\nbundle_size=50\nÎ´=1.0\nÎµ=1e-2\nÎ¼=0.5\nm=0.0125\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstopping_criterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nsub_problem=proximal_bundle_method_subsolver`:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state=AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX=zero_vector(M, p) specify the type of tangent vector to use.\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_bundle_method/#Helpers-and-internal-functions","page":"Proximal bundle method","title":"Helpers and internal functions","text":"","category":"section"},{"location":"solvers/proximal_bundle_method/#Manopt.proximal_bundle_method_subsolver","page":"Proximal bundle method","title":"Manopt.proximal_bundle_method_subsolver","text":"Î» = proximal_bundle_method_subsolver(M, p_last_serious, Î¼, approximation_errors, transported_subgradients)\nproximal_bundle_method_subsolver!(M, Î», p_last_serious, Î¼, approximation_errors, transported_subgradients)\n\nsolver for the subproblem of the proximal bundle method.\n\nThe subproblem for the proximal bundle method is\n\nbeginalign*\n    operatorname*argmin_Î»  â„^lvert L_lrvert \n    frac12 mu_l BigllVert sum_j  L_l Î»_j mathrmP_p_kq_j X_q_j BigrrVert^2\n    + sum_j  L_l Î»_j  c_j^k\n    \n    texts t quad \n    sum_j  L_l Î»_j = 1\n    quad Î»_j  0\n    quad textfor all  j  L_l\nendalign*\n\nwhere L_l = k if q_k is a serious iterate, and L_l = L_l-1 cup k otherwise. See [HNP23].\n\ntip: Tip\nA default subsolver based on RipQP.jl and QuadraticModels is available if these two packages are loaded.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_bundle_method/#Literature","page":"Proximal bundle method","title":"Literature","text":"","category":"section"},{"location":"solvers/proximal_bundle_method/","page":"Proximal bundle method","title":"Proximal bundle method","text":"N.Â Hoseini Monjezi, S.Â Nobakhtian and M.Â R.Â Pouryayevali. A proximal bundle algorithm for nonsmooth optimization on Riemannian manifolds. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 43, 293â€“325 (2023).\n\n\n\n","category":"page"},{"location":"solvers/cyclic_proximal_point/#Cyclic-proximal-point","page":"Cyclic Proximal Point","title":"Cyclic proximal point","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"The Cyclic Proximal Point (CPP) algorithm aims to minimize","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"F(x) = sum_i=1^c f_i(x)","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"assuming that the proximal maps operatornameprox_Î» f_i(x) are given in closed form or can be computed efficiently (at least approximately).","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"The algorithm then cycles through these proximal maps, where the type of cycle might differ and the proximal parameter Î»_k changes after each cycle k.","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"For a convergence result on Hadamard manifolds see BaÄÃ¡k [Bac14].","category":"page"},{"location":"solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point","page":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point","text":"cyclic_proximal_point(M, f, proxes_f, p; kwargs...)\ncyclic_proximal_point(M, mpo, p; kwargs...)\ncyclic_proximal_point!(M, f, proxes_f; kwargs...)\ncyclic_proximal_point!(M, mpo; kwargs...)\n\nperform a cyclic proximal point algorithm. This can be done in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf:        a cost function f mathcal Mâ„ to minimize\nproxes_f: an Array of proximal maps (Functions) (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nwhere f and the proximal maps proxes_f can also be given directly as a ManifoldProximalMapObjective mpo\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Random) or the default linear one.\nÎ»=iter -> 1/iter:         a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion=StopAfterIteration(5000)|StopWhenChangeLess(1e-12)): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point!","page":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point!","text":"cyclic_proximal_point(M, f, proxes_f, p; kwargs...)\ncyclic_proximal_point(M, mpo, p; kwargs...)\ncyclic_proximal_point!(M, f, proxes_f; kwargs...)\ncyclic_proximal_point!(M, mpo; kwargs...)\n\nperform a cyclic proximal point algorithm. This can be done in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf:        a cost function f mathcal Mâ„ to minimize\nproxes_f: an Array of proximal maps (Functions) (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nwhere f and the proximal maps proxes_f can also be given directly as a ManifoldProximalMapObjective mpo\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Random) or the default linear one.\nÎ»=iter -> 1/iter:         a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion=StopAfterIteration(5000)|StopWhenChangeLess(1e-12)): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cyclic_proximal_point/#sec-cppa-technical-details","page":"Cyclic Proximal Point","title":"Technical details","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"The cyclic_proximal_point solver requires no additional functions to be available for your manifold, besides the ones you use in the proximal maps.","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"By default, one of the stopping criteria is StopWhenChangeLess, which either requires","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"An inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.","category":"page"},{"location":"solvers/cyclic_proximal_point/#State","page":"Cyclic Proximal Point","title":"State","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/#Manopt.CyclicProximalPointState","page":"Cyclic Proximal Point","title":"Manopt.CyclicProximalPointState","text":"CyclicProximalPointState <: AbstractManoptSolverState\n\nstores options for the cyclic_proximal_point algorithm. These are the\n\nFields\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nÎ»:         a function for the values of Î»_k per iteration(cycle k\noder_type: whether to use a randomly permuted sequence (:FixedRandomOrder), a per cycle permuted sequence (:RandomOrder) or the default linear one.\n\nConstructor\n\nCyclicProximalPointState(M::AbstractManifold; kwargs...)\n\nGenerate the options\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\n\nKeyword arguments\n\nevaluation_order=:LinearOrder: soecify the order_type\nÎ»=i -> 1.0 / i a function to compute the Î»_k k  mathcal N,\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nstopping_criterion=StopAfterIteration(2000): a functor indicating that the stopping criterion is fulfilled\n\nSee also\n\ncyclic_proximal_point\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Debug-functions","page":"Cyclic Proximal Point","title":"Debug functions","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/#Manopt.DebugProximalParameter","page":"Cyclic Proximal Point","title":"Manopt.DebugProximalParameter","text":"DebugProximalParameter <: DebugAction\n\nprint the current iterates proximal point algorithm parameter given by AbstractManoptSolverStates o.Î».\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Record-functions","page":"Cyclic Proximal Point","title":"Record functions","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/#Manopt.RecordProximalParameter","page":"Cyclic Proximal Point","title":"Manopt.RecordProximalParameter","text":"RecordProximalParameter <: RecordAction\n\nrecord the current iterates proximal point algorithm parameter given by in AbstractManoptSolverStates o.Î».\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Literature","page":"Cyclic Proximal Point","title":"Literature","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"M.Â BaÄÃ¡k. Computing medians and means in Hadamard spaces. SIAMÂ JournalÂ onÂ Optimization 24, 1542â€“1566 (2014), arXiv:1210.2145.\n\n\n\n","category":"page"},{"location":"plans/objective/#A-manifold-objective","page":"Objective","title":"A manifold objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"The Objective describes that actual cost function and all its properties.","category":"page"},{"location":"plans/objective/#Manopt.AbstractManifoldObjective","page":"Objective","title":"Manopt.AbstractManifoldObjective","text":"AbstractManifoldObjective{E<:AbstractEvaluationType}\n\nDescribe the collection of the optimization function f mathcal M  â„ (or even a vectorial range) and its corresponding elements, which might for example be a gradient or (one or more) proximal maps.\n\nAll these elements should usually be implemented as functions (M, p) -> ..., or (M, X, p) -> ... that is\n\nthe first argument of these functions should be the manifold M they are defined on\nthe argument X is present, if the computation is performed in-place of X (see InplaceEvaluation)\nthe argument p is the place the function (f or one of its elements) is evaluated at.\n\nthe type T indicates the global AbstractEvaluationType.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractDecoratedManifoldObjective","page":"Objective","title":"Manopt.AbstractDecoratedManifoldObjective","text":"AbstractDecoratedManifoldObjective{E<:AbstractEvaluationType,O<:AbstractManifoldObjective}\n\nA common supertype for all decorators of AbstractManifoldObjectives to simplify dispatch.     The second parameter should refer to the undecorated objective (the most inner one).\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"Which has two main different possibilities for its containing functions concerning the evaluation mode, not necessarily the cost, but for example gradient in an AbstractManifoldGradientObjective.","category":"page"},{"location":"plans/objective/#Manopt.AbstractEvaluationType","page":"Objective","title":"Manopt.AbstractEvaluationType","text":"AbstractEvaluationType\n\nAn abstract type to specify the kind of evaluation a AbstractManifoldObjective supports.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AllocatingEvaluation","page":"Objective","title":"Manopt.AllocatingEvaluation","text":"AllocatingEvaluation <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem indicating that the problem uses functions that allocate memory for their result, they work out of place.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.InplaceEvaluation","page":"Objective","title":"Manopt.InplaceEvaluation","text":"InplaceEvaluation <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem indicating that the problem uses functions that do not allocate memory but work on their input, in place.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.evaluation_type","page":"Objective","title":"Manopt.evaluation_type","text":"evaluation_type(mp::AbstractManoptProblem)\n\nGet the AbstractEvaluationType of the objective in AbstractManoptProblem mp.\n\n\n\n\n\nevaluation_type(::AbstractManifoldObjective{Teval})\n\nGet the AbstractEvaluationType of the objective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Decorators-for-objectives","page":"Objective","title":"Decorators for objectives","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"An objective can be decorated using the following trait and function to initialize","category":"page"},{"location":"plans/objective/#Manopt.dispatch_objective_decorator","page":"Objective","title":"Manopt.dispatch_objective_decorator","text":"dispatch_objective_decorator(o::AbstractManoptSolverState)\n\nIndicate internally, whether an AbstractManifoldObjective o to be of decorating type, it stores (encapsulates) an object in itself, by default in the field o.objective.\n\nDecorators indicate this by returning Val{true} for further dispatch.\n\nThe default is Val{false}, so by default an state is not decorated.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.is_objective_decorator","page":"Objective","title":"Manopt.is_objective_decorator","text":"is_object_decorator(s::AbstractManifoldObjective)\n\nIndicate, whether AbstractManifoldObjective s are of decorator type.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.decorate_objective!","page":"Objective","title":"Manopt.decorate_objective!","text":"decorate_objective!(M, o::AbstractManifoldObjective)\n\ndecorate the AbstractManifoldObjectiveo with specific decorators.\n\nOptional arguments\n\noptional arguments provide necessary details on the decorators. A specific one is used to activate certain decorators.\n\ncache=missing: specify a cache. Currently :Simple is supported and :LRU if you load LRUCache.jl. For this case a tuple specifying what to cache and how many can be provided, has to be specified. For example (:LRU, [:Cost, :Gradient], 10) states that the last 10 used cost function evaluations and gradient evaluations should be stored. See objective_cache_factory for details.\ncount=missing: specify calls to the objective to be called, see ManifoldCountObjective for the full list\nobjective_type=:Riemannian: specify that an objective is :Riemannian or :Euclidean. The :Euclidean symbol is equivalent to specifying it as :Embedded, since in the end, both refer to converting an objective from the embedding (whether its Euclidean or not) to the Riemannian one.\n\nSee also\n\nobjective_cache_factory\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#subsection-embedded-objectives","page":"Objective","title":"Embedded objectives","text":"","category":"section"},{"location":"plans/objective/#Manopt.EmbeddedManifoldObjective","page":"Objective","title":"Manopt.EmbeddedManifoldObjective","text":"EmbeddedManifoldObjective{P, T, E, O2, O1<:AbstractManifoldObjective{E}} <:\n   AbstractDecoratedManifoldObjective{E,O2}\n\nDeclare an objective to be defined in the embedding. This also declares the gradient to be defined in the embedding, and especially being the Riesz representer with respect to the metric in the embedding. The types can be used to still dispatch on also the undecorated objective type O2.\n\nFields\n\nobjective: the objective that is defined in the embedding\np=nothing: a point in the embedding.\nX=nothing: a tangent vector in the embedding\n\nWhen a point in the embedding p is provided, embed! is used in place of this point to reduce memory allocations. Similarly X is used when embedding tangent vectors\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#subsection-scaled-objectives","page":"Objective","title":"Scaled objectives","text":"","category":"section"},{"location":"plans/objective/#Manopt.ScaledManifoldObjective","page":"Objective","title":"Manopt.ScaledManifoldObjective","text":"ScaledManifoldObjective{E, O2, O1<:AbstractManifoldObjective{E},F} <:\n   AbstractDecoratedManifoldObjective{E,O2}\n\nDeclare an objective to be defined as a scaled version of an existing objective.\n\nThis rescales all involved functions.\n\nFor now the functions rescaled are\n\nthe cost\nthe gradient\nthe Hessian\n\nFields\n\nobjective: the objective that is defined in the embedding\nscale=1: the scaling applied\n\nConstructors\n\nScaledManifoldObjective(objective, scale::Real=1)\n-objective\nscale*objective\n\nGenerate a scaled manifold objective based on objective with scale being 1 by default in the first, scale=-1 in the second case. The multiplication from the left with a scalar is also overloaded.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#subsection-cache-objective","page":"Objective","title":"Cache objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"Since single function calls, for example to the cost or the gradient, might be expensive, a simple cache objective exists as a decorator, that caches one cost value or gradient.","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"It can be activated/used with the cache= keyword argument available for every solver.","category":"page"},{"location":"plans/objective/#Manopt.reset_counters!","page":"Objective","title":"Manopt.reset_counters!","text":"reset_counters(co::ManifoldCountObjective, value::Integer=0)\n\nReset all values in the count objective to value.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.objective_cache_factory","page":"Objective","title":"Manopt.objective_cache_factory","text":"objective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Symbol)\n\nGenerate a cached variant of the AbstractManifoldObjective o on the AbstractManifold M based on the symbol cache.\n\nThe following caches are available\n\n:Simple generates a SimpleManifoldCachedObjective\n:LRU generates a ManifoldCachedObjective where you should use the form (:LRU, [:Cost, :Gradient]) to specify what should be cached or (:LRU, [:Cost, :Gradient], 100) to specify the cache size. Here this variant defaults to (:LRU, [:Cost, :Gradient], 100), caching up to 100 cost and gradient values.[1]\n\n[1]: This cache requires LRUCache.jl to be loaded as well.\n\n\n\n\n\nobjective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array, Array})\nobjective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array})\n\nGenerate a cached variant of the AbstractManifoldObjective o on the AbstractManifold M based on the symbol cache[1], where the second element cache[2] are further arguments to the cache and the optional third is passed down as keyword arguments.\n\nFor all available caches see the simpler variant with symbols.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#A-simple-cache","page":"Objective","title":"A simple cache","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"A first generic cache is always available, but it only caches one gradient and one cost function evaluation (for the same point).","category":"page"},{"location":"plans/objective/#Manopt.SimpleManifoldCachedObjective","page":"Objective","title":"Manopt.SimpleManifoldCachedObjective","text":" SimpleManifoldCachedObjective{O<:AbstractManifoldGradientObjective{E,TC,TG}, P, T,C} <: AbstractManifoldGradientObjective{E,TC,TG}\n\nProvide a simple cache for an AbstractManifoldGradientObjective that is for a given point p this cache stores a point p and a gradient operatornamegrad f(p) in X as well as a cost value f(p) in c.\n\nBoth X and c are accompanied by booleans to keep track of their validity.\n\nConstructor\n\nSimpleManifoldCachedObjective(M::AbstractManifold, obj::AbstractManifoldGradientObjective; kwargs...)\n\nKeyword arguments\n\np=rand(M): a point on the manifold to initialize the cache with\nX=get_gradient(M, obj, p) or zero_vector(M,p): a tangent vector to store the gradient in, see also initialize=\nc=[get_cost](@ref)(M, obj, p)or0.0: a value to store the cost function ininitialize`\ninitialized=true: whether to initialize the cached X and c or not.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#A-generic-cache","page":"Objective","title":"A generic cache","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"For the more advanced cache, you need to implement some type of cache yourself, that provides a get! and implement init_caches. This is for example provided if you load LRUCache.jl. Then you obtain","category":"page"},{"location":"plans/objective/#Manopt.ManifoldCachedObjective","page":"Objective","title":"Manopt.ManifoldCachedObjective","text":"ManifoldCachedObjective{E,P,O<:AbstractManifoldObjective{<:E},C<:NamedTuple{}} <: AbstractDecoratedManifoldObjective{E,P}\n\nCreate a cache for an objective, based on a NamedTuple that stores some kind of cache.\n\nConstructor\n\nManifoldCachedObjective(M, o::AbstractManifoldObjective, caches::Vector{Symbol}; kwargs...)\n\nCreate a cache for the AbstractManifoldObjective where the Symbols in caches indicate, which function evaluations to cache.\n\nSupported symbols\n\nSymbol Caches calls to (incl. ! variants) Comment\n:Cost get_cost \n:EqualityConstraint get_equality_constraint(M, p, i) \n:EqualityConstraints get_equality_constraint(M, p, :) \n:GradEqualityConstraint get_grad_equality_constraint tangent vector per (p,i)\n:GradInequalityConstraint get_inequality_constraint tangent vector per (p,i)\n:Gradient get_gradient(M,p) tangent vectors\n:Hessian get_hessian tangent vectors\n:InequalityConstraint get_inequality_constraint(M, p, j) \n:InequalityConstraints get_inequality_constraint(M, p, :) \n:Preconditioner get_preconditioner tangent vectors\n:ProximalMap get_proximal_map point per (p,Î»,i)\n:StochasticGradients get_gradients vector of tangent vectors\n:StochasticGradient get_gradient(M, p, i) tangent vector per (p,i)\n:SubGradient get_subgradient tangent vectors\n:SubtrahendGradient get_subtrahend_gradient tangent vectors\n\nKeyword arguments\n\np=rand(M): the type of the keys to be used in the caches. Defaults to the default representation on M.\nvalue=get_cost(M, objective, p): the type of values for numeric values in the cache\nX=zero_vector(M,p): the type of values to be cached for gradient and Hessian calls.\ncache=[:Cost]: a vector of symbols indicating which function calls should be cached.\ncache_size=10: number of (least recently used) calls to cache\ncache_sizes=Dict{Symbol,Int}(): a named tuple or dictionary specifying the sizes individually for each cache.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.init_caches","page":"Objective","title":"Manopt.init_caches","text":"init_caches(caches, T::Type{LRU}; kwargs...)\n\nGiven a vector of symbols caches, this function sets up the NamedTuple of caches, where T is the type of cache to use.\n\nKeyword arguments\n\np=rand(M): a point on a manifold, to both infer its type for keys and initialize caches\nvalue=0.0:  a value both typing and initialising number-caches, the default is for (Float) values like the cost.\nX=zero_vector(M, p): a tangent vector at p to both type and initialize tangent vector caches\ncache_size=10: a default cache size to use\ncache_sizes=Dict{Symbol,Int}(): a dictionary of sizes for the caches to specify different (non-default) sizes\n\n\n\n\n\ninit_caches(M::AbstractManifold, caches, T; kwargs...)\n\nGiven a vector of symbols caches, this function sets up the NamedTuple of caches for points/vectors on M, where T is the type of cache to use.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#subsection-count-objective","page":"Objective","title":"Count objective","text":"","category":"section"},{"location":"plans/objective/#Manopt.ManifoldCountObjective","page":"Objective","title":"Manopt.ManifoldCountObjective","text":"ManifoldCountObjective{E,P,O<:AbstractManifoldObjective,I<:Integer} <: AbstractDecoratedManifoldObjective{E,P}\n\nA wrapper for any AbstractManifoldObjective of type O to count different calls to parts of the objective.\n\nFields\n\ncounts a dictionary of symbols mapping to integers keeping the counted values\nobjective the wrapped objective\n\nSupported symbols\n\nSymbol Counts calls to (incl. ! variants) Comment\n:Cost get_cost \n:EqualityConstraint get_equality_constraint requires vector of counters\n:EqualityConstraints get_equality_constraint when evaluating all of them with :\n:GradEqualityConstraint get_grad_equality_constraint requires vector of counters\n:GradEqualityConstraints get_grad_equality_constraint when evaluating all of them with :\n:GradInequalityConstraint get_inequality_constraint requires vector of counters\n:GradInequalityConstraints get_inequality_constraint when evaluating all of them with :\n:Gradient get_gradient(M,p) \n:Hessian get_hessian \n:InequalityConstraint get_inequality_constraint requires vector of counters\n:InequalityConstraints get_inequality_constraint when evaluating all of them with :\n:Preconditioner get_preconditioner \n:ProximalMap get_proximal_map \n:StochasticGradients get_gradients \n:StochasticGradient get_gradient(M, p, i) \n:SubGradient get_subgradient \n:SubtrahendGradient get_subtrahend_gradient \n\nConstructors\n\nManifoldCountObjective(objective::AbstractManifoldObjective, counts::Dict{Symbol, <:Integer})\n\nInitialise the ManifoldCountObjective to wrap objective initializing the set of counts\n\nManifoldCountObjective(M::AbstractManifold, objective::AbstractManifoldObjective, count::AbstractVecor{Symbol}, init=0)\n\nCount function calls on objective using the symbols in count initialising all entries to init.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Internal-decorators","page":"Objective","title":"Internal decorators","text":"","category":"section"},{"location":"plans/objective/#Manopt.ReturnManifoldObjective","page":"Objective","title":"Manopt.ReturnManifoldObjective","text":"ReturnManifoldObjective{E,O2,O1<:AbstractManifoldObjective{E}} <:\n   AbstractDecoratedManifoldObjective{E,O2}\n\nA wrapper to indicate that get_solver_result should return the inner objective.\n\nThe types are such that one can still dispatch on the undecorated type O2 of the original objective as well.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Specific-Objective-typed-and-their-access-functions","page":"Objective","title":"Specific Objective typed and their access functions","text":"","category":"section"},{"location":"plans/objective/#Cost-objective","page":"Objective","title":"Cost objective","text":"","category":"section"},{"location":"plans/objective/#Manopt.AbstractManifoldCostObjective","page":"Objective","title":"Manopt.AbstractManifoldCostObjective","text":"AbstractManifoldCostObjective{T<:AbstractEvaluationType} <: AbstractManifoldObjective{T}\n\nRepresenting objectives on manifolds with a cost function implemented.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldCostObjective","page":"Objective","title":"Manopt.ManifoldCostObjective","text":"ManifoldCostObjective{T, TC} <: AbstractManifoldCostObjective{T, TC}\n\nspecify an AbstractManifoldObjective that does only have information about the cost function f  mathbb M  â„ implemented as a function (M, p) -> c to compute the cost value c at p on the manifold M.\n\ncost: a function f mathcal M  â„ to minimize\n\nConstructors\n\nManifoldCostObjective(f)\n\nGenerate a problem. While this Problem does not have any allocating functions, the type T can be set for consistency reasons with other problems.\n\nUsed with\n\nNelderMead, particle_swarm\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_cost","page":"Objective","title":"Manopt.get_cost","text":"get_cost(amp::AbstractManoptProblem, p)\n\nevaluate the cost function f stored within the AbstractManifoldObjective of an AbstractManoptProblem amp at the point p.\n\n\n\n\n\nget_cost(M::AbstractManifold, obj::AbstractManifoldObjective, p)\n\nevaluate the cost function f defined on M stored within the AbstractManifoldObjective at the point p.\n\n\n\n\n\nget_cost(M::AbstractManifold, mco::AbstractManifoldCostObjective, p)\n\nEvaluate the cost function from within the AbstractManifoldCostObjective on M at p.\n\nBy default this implementation assumed that the cost is stored within mco.cost.\n\n\n\n\n\nget_cost(TpM, trmo::TrustRegionModelObjective, X)\n\nEvaluate the tangent space TrustRegionModelObjective\n\nm(X) = f(p) + operatornamegrad f(p) X _p + frac12 operatornameHess f(p)X X_p\n\n\n\n\n\nget_cost(TpM, trmo::AdaptiveRagularizationWithCubicsModelObjective, X)\n\nEvaluate the tangent space AdaptiveRagularizationWithCubicsModelObjective\n\nm(X) = f(p) + operatornamegrad f(p) X _p + frac12 operatornameHess f(p)X X_p\n       +  fracÏƒ3 lVert X rVert^3\n\nat X, cf. Eq. (33) in [ABBC20].\n\n\n\n\n\nget_cost(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\n\nevaluate the cost\n\nf(X) = frac12 lVert mathcal AX + b rVert_p^2qquad X  T_pmathcal M\n\nat X.\n\n\n\n\n\nget_cost(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, i)\n\nEvaluate the ith summand of the cost.\n\nIf you use a single function for the stochastic cost, then only the index Ã¬=1` is available to evaluate the whole cost.\n\n\n\n\n\nget_cost(M::AbstractManifold,emo::EmbeddedManifoldObjective, p)\n\nEvaluate the cost function of an objective defined in the embedding by first embedding p before calling the cost function stored in the EmbeddedManifoldObjective.\n\n\n\n\n\nget_cost(M::AbstractManifold, scaled_objective::ScaledManifoldObjective, p)\n\nEvaluate the scaled objective. s*f(p)\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"and internally","category":"page"},{"location":"plans/objective/#Manopt.get_cost_function","page":"Objective","title":"Manopt.get_cost_function","text":"get_cost_function(amco::AbstractManifoldCostObjective)\n\nreturn the function to evaluate (just) the cost f(p)=c as a function (M,p) -> c.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Gradient-objectives","page":"Objective","title":"Gradient objectives","text":"","category":"section"},{"location":"plans/objective/#Manopt.AbstractManifoldGradientObjective","page":"Objective","title":"Manopt.AbstractManifoldGradientObjective","text":"AbstractManifoldGradientObjective{E<:AbstractEvaluationType, TC, TG} <: AbstractManifoldCostObjective{E, TC}\n\nAn abstract type for all objectives that provide a (full) gradient, where T is a AbstractEvaluationType for the gradient function.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldGradientObjective","page":"Objective","title":"Manopt.ManifoldGradientObjective","text":"ManifoldGradientObjective{T<:AbstractEvaluationType} <: AbstractManifoldGradientObjective{T}\n\nspecify an objective containing a cost and its gradient\n\nFields\n\ncost:       a function f mathcal M  â„\ngradient!!: the gradient operatornamegradf mathcal M  mathcal Tmathcal M of the cost function f.\n\nDepending on the AbstractEvaluationType T the gradient can have to forms\n\nas a function (M, p) -> X that allocates memory for X, an AllocatingEvaluation\nas a function (M, X, p) -> X that work in place of X, an InplaceEvaluation\n\nConstructors\n\nManifoldGradientObjective(cost, gradient; evaluation=AllocatingEvaluation())\n\nUsed with\n\ngradient_descent, conjugate_gradient_descent, quasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldAlternatingGradientObjective","page":"Objective","title":"Manopt.ManifoldAlternatingGradientObjective","text":"ManifoldAlternatingGradientObjective{E<:AbstractEvaluationType,TCost,TGradient} <: AbstractManifoldGradientObjective{E}\n\nAn alternating gradient objective consists of\n\na cost function F(x)\na gradient operatornamegradF that is either\ngiven as one function operatornamegradF returning a tangent vector X on M or\nan array of gradient functions operatornamegradF_i, Ã¬=1,â€¦,n s each returning a component of the gradient\nwhich might be allocating or mutating variants, but not a mix of both.\n\nnote: Note\nThis Objective is usually defined using the ProductManifold from Manifolds.jl, so Manifolds.jl to be loaded.\n\nConstructors\n\nManifoldAlternatingGradientObjective(F, gradF::Function;\n    evaluation=AllocatingEvaluation()\n)\nManifoldAlternatingGradientObjective(F, gradF::AbstractVector{<:Function};\n    evaluation=AllocatingEvaluation()\n)\n\nCreate a alternating gradient problem with an optional cost and the gradient either as one function (returning an array) or a vector of functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldStochasticGradientObjective","page":"Objective","title":"Manopt.ManifoldStochasticGradientObjective","text":"ManifoldStochasticGradientObjective{T<:AbstractEvaluationType} <: AbstractManifoldGradientObjective{T}\n\nA stochastic gradient objective consists of\n\na(n optional) cost function f(p) = displaystylesum_i=1^n f_i(p)\nan array of gradients, operatornamegradf_i(p) i=1ldotsn which can be given in two forms\nas one single function (mathcal M p)  (X_1X_n)  (T_pmathcal M)^n\nas a vector of functions bigl( (mathcal M p)  X_1  (mathcal M p)  X_nbigr).\n\nWhere both variants can also be provided as InplaceEvaluation functions (M, X, p) -> X, where X is the vector of X1,...,Xn and (M, X1, p) -> X1, ..., (M, Xn, p) -> Xn, respectively.\n\nConstructors\n\nManifoldStochasticGradientObjective(\n    grad_f::Function;\n    cost=Missing(),\n    evaluation=AllocatingEvaluation()\n)\nManifoldStochasticGradientObjective(\n    grad_f::AbstractVector{<:Function};\n    cost=Missing(), evaluation=AllocatingEvaluation()\n)\n\nCreate a Stochastic gradient problem with the gradient either as one function (returning an array of tangent vectors) or a vector of functions (each returning one tangent vector).\n\nThe optional cost can also be given as either a single function (returning a number) pr a vector of functions, each returning a value.\n\nUsed with\n\nstochastic_gradient_descent\n\nNote that this can also be used with a gradient_descent, since the (complete) gradient is just the sums of the single gradients.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.NonlinearLeastSquaresObjective","page":"Objective","title":"Manopt.NonlinearLeastSquaresObjective","text":"NonlinearLeastSquaresObjective{E<:AbstractEvaluationType} <: AbstractManifoldObjective{T}\n\nAn objective to model the nonlinear least squares problem\n\noperatorname*argmin_p  mathcal M frac12 sum_i=1^m lvert f_i(p) rvert^2\n\nwhere f mathcal M  â„^m is written with component functions f_i mathcal M  â„, i=1m, and each component function is continuously differentiable.\n\nSpecify a nonlinear least squares problem\n\nFields\n\nobjective: a AbstractVectorGradientFunction{E} containing both the vector of cost functions f_i (or a function returning a vector of costs) as well as their gradients operatornamegrad f_i (or Jacobian of the vector-valued function).\n\nThis NonlinearLeastSquaresObjective then has the same AbstractEvaluationType T as the (inner) objective.\n\nConstructors\n\nNonlinearLeastSquaresObjective(f, jacobian, range_dimension::Integer; kwargs...)\nNonlinearLeastSquaresObjective(vf::AbstractVectorGradientFunction)\n\nArguments\n\nf the vectorial cost function f mathcal M  â„^m\njacobian the Jacobian, might also be a vector of gradients of the component functions of f\nrange_dimension::Integer the number of dimensions m the function f maps into\n\nThese three can also be passed as a AbstractVectorGradientFunction vf already.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nfunction_type::AbstractVectorialType=FunctionVectorialType(): specify the format the residuals are given in. By default a function returning a vector.\njacobian_tangent_basis::AbstractBasis=DefaultOrthonormalBasis(); shortcut to specify the basis the Jacobian matrix is build with.\njacobian_type::AbstractVectorialType=CoordinateVectorialType(jacobian_tangent_basis): specify the format the Jacobian is given in. By default a matrix of the differential with respect to a certain basis of the tangent space.\n\nSee also\n\nLevenbergMarquardt, LevenbergMarquardtState\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"There is also a second variant, if just one function is responsible for computing the cost and the gradient","category":"page"},{"location":"plans/objective/#Manopt.ManifoldCostGradientObjective","page":"Objective","title":"Manopt.ManifoldCostGradientObjective","text":"ManifoldCostGradientObjective{T} <: AbstractManifoldObjective{T}\n\nspecify an objective containing one function to perform a combined computation of cost and its gradient\n\nFields\n\ncostgrad!!: a function that computes both the cost f mathcal M  â„ and its gradient operatornamegradf mathcal M  mathcal Tmathcal M\n\nDepending on the AbstractEvaluationType T the gradient can have to forms\n\nas a function (M, p) -> (c, X) that allocates memory for the gradient X, an AllocatingEvaluation\nas a function (M, X, p) -> (c, X) that work in place of X, an InplaceEvaluation\n\nConstructors\n\nManifoldCostGradientObjective(costgrad; evaluation=AllocatingEvaluation())\n\nUsed with\n\ngradient_descent, conjugate_gradient_descent, quasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-2","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_gradient","page":"Objective","title":"Manopt.get_gradient","text":"get_gradient(s::AbstractManoptSolverState)\n\nreturn the (last stored) gradient within AbstractManoptSolverStates`. By default also undecorates the state beforehand\n\n\n\n\n\nget_gradient(amp::AbstractManoptProblem, p)\nget_gradient!(amp::AbstractManoptProblem, X, p)\n\nevaluate the gradient of an AbstractManoptProblem amp at the point p.\n\nThe evaluation is done in place of X for the !-variant.\n\n\n\n\n\nget_gradient(M::AbstractManifold, mgo::AbstractManifoldGradientObjective{T}, p)\nget_gradient!(M::AbstractManifold, X, mgo::AbstractManifoldGradientObjective{T}, p)\n\nevaluate the gradient of a AbstractManifoldGradientObjective{T} mgo at p.\n\nThe evaluation is done in place of X for the !-variant. The T=AllocatingEvaluation problem might still allocate memory within. When the non-mutating variant is called with a T=InplaceEvaluation memory for the result is allocated.\n\nNote that the order of parameters follows the philosophy of Manifolds.jl, namely that even for the mutating variant, the manifold is the first parameter and the (in-place) tangent vector X comes second.\n\n\n\n\n\nget_gradient(agst::AbstractGradientSolverState)\n\nreturn the gradient stored within gradient options. THe default returns agst.X.\n\n\n\n\n\nget_gradient(M::AbstractManifold, vgf::VectorGradientFunction, p, i)\nget_gradient(M::AbstractManifold, vgf::VectorGradientFunction, p, i, range)\nget_gradient!(M::AbstractManifold, X, vgf::VectorGradientFunction, p, i)\nget_gradient!(M::AbstractManifold, X, vgf::VectorGradientFunction, p, i, range)\n\nEvaluate the gradients of the vector function vgf on the manifold M at p and the values given in range, specifying the representation of the gradients.\n\nSince i is assumed to be a linear index, you can provide\n\na single integer\na UnitRange to specify a range to be returned like 1:3\na BitVector specifying a selection\na AbstractVector{<:Integer} to specify indices\n: to return the vector of all gradients\n\n\n\n\n\nget_gradient(TpM, trmo::TrustRegionModelObjective, X)\n\nEvaluate the gradient of the TrustRegionModelObjective\n\noperatornamegrad m(X) = operatornamegrad f(p) + operatornameHess f(p)X\n\n\n\n\n\nget_gradient(TpM, trmo::AdaptiveRagularizationWithCubicsModelObjective, X)\n\nEvaluate the gradient of the AdaptiveRagularizationWithCubicsModelObjective\n\noperatornamegrad m(X) = operatornamegrad f(p) + operatornameHess f(p)X\n       + ÏƒlVert X rVert X\n\nat X, cf. Eq. (37) in [ABBC20].\n\n\n\n\n\nget_gradient(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\nget_gradient!(TpM::TangentSpace, Y, slso::SymmetricLinearSystemObjective, X)\n\nevaluate the gradient of\n\nf(X) = frac12 lVert mathcal AX + b rVert_p^2qquad X  T_pmathcal M\n\nWhich is operatornamegrad f(X) = mathcal AX+b. This can be computed in-place of Y.\n\n\n\n\n\nget_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, k)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, Y, p, k)\n\nEvaluate one of the summands gradients operatornamegradf_k, k1n, at x (in place of Y).\n\nIf you use a single function for the stochastic gradient, that works in-place, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\nget_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, X, p)\n\nEvaluate the complete gradient operatornamegrad f = displaystylesum_i=1^n operatornamegrad f_i(p) at p (in place of X).\n\nIf you use a single function for the stochastic gradient, that works in-place, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\nget_gradient(M::AbstractManifold, emo::EmbeddedManifoldObjective, p)\nget_gradient!(M::AbstractManifold, X, emo::EmbeddedManifoldObjective, p)\n\nEvaluate the gradient function of an objective defined in the embedding, that is embed p before calling the gradient function stored in the EmbeddedManifoldObjective.\n\nThe returned gradient is then converted to a Riemannian gradient calling riemannian_gradient.\n\n\n\n\n\nget_gradient(M::AbstractManifold, scaled_objective::ScaledManifoldObjective, p)\nget_gradient!(M::AbstractManifold, X, scaled_objective::ScaledManifoldObjective, p)\n\nEvaluate the scaled gradient. s*operatornamegradf(p)\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_gradients","page":"Objective","title":"Manopt.get_gradients","text":"get_gradients(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradients!(M::AbstractManifold, X, sgo::ManifoldStochasticGradientObjective, p)\n\nEvaluate all summands gradients operatornamegradf_i_i=1^n at p (in place of X).\n\nIf you use a single function for the stochastic gradient, that works in-place, then get_gradient is not available, since the length (or number of elements of the gradient) can not be determined.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_residuals","page":"Objective","title":"Manopt.get_residuals","text":"get_residuals(M::AbstractManifold, nlso::NonlinearLeastSquaresObjective, p)\nget_residuals!(M::AbstractManifold, V, nlso::NonlinearLeastSquaresObjective, p)\n\nCompute the vector of residuals f_i(p), i=1m given the manifold M, the NonlinearLeastSquaresObjective nlso and a current point p on M.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_residuals!","page":"Objective","title":"Manopt.get_residuals!","text":"get_residuals(M::AbstractManifold, nlso::NonlinearLeastSquaresObjective, p)\nget_residuals!(M::AbstractManifold, V, nlso::NonlinearLeastSquaresObjective, p)\n\nCompute the vector of residuals f_i(p), i=1m given the manifold M, the NonlinearLeastSquaresObjective nlso and a current point p on M.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"and internally","category":"page"},{"location":"plans/objective/#Manopt.get_gradient_function","page":"Objective","title":"Manopt.get_gradient_function","text":"get_gradient_function(amgo::AbstractManifoldGradientObjective, recursive=false)\n\nreturn the function to evaluate (just) the gradient operatornamegrad f(p), where either the gradient function using the decorator or without the decorator is used.\n\nBy default recursive is set to false, since usually to just pass the gradient function somewhere, one still wants for example the cached one or the one that still counts calls.\n\nDepending on the AbstractEvaluationType E this is a function\n\n(M, p) -> X for the AllocatingEvaluation case\n(M, X, p) -> X for the InplaceEvaluation working in-place of X.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Subgradient-objective","page":"Objective","title":"Subgradient objective","text":"","category":"section"},{"location":"plans/objective/#Manopt.ManifoldSubgradientObjective","page":"Objective","title":"Manopt.ManifoldSubgradientObjective","text":"ManifoldSubgradientObjective{T<:AbstractEvaluationType,C,S} <:AbstractManifoldCostObjective{T, C}\n\nA structure to store information about a objective for a subgradient based optimization problem\n\nFields\n\ncost:        the function f to be minimized\nsubgradient: a function returning a subgradient f of f\n\nConstructor\n\nManifoldSubgradientObjective(f, âˆ‚f)\n\nGenerate the ManifoldSubgradientObjective for a subgradient objective, consisting of a (cost) function f(M, p) and a function âˆ‚f(M, p) that returns a not necessarily deterministic element from the subdifferential at p on a manifold M.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-3","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_subgradient","page":"Objective","title":"Manopt.get_subgradient","text":"X = get_subgradient(M::AbstractManifold, sgo::AbstractManifoldGradientObjective, p)\nget_subgradient!(M::AbstractManifold, X, sgo::AbstractManifoldGradientObjective, p)\n\nEvaluate the subgradient, which for the case of a objective having a gradient, means evaluating the gradient itself.\n\nWhile in general, the result might not be deterministic, for this case it is.\n\n\n\n\n\nget_subgradient(amp::AbstractManoptProblem, p)\nget_subgradient!(amp::AbstractManoptProblem, X, p)\n\nevaluate the subgradient of an AbstractManoptProblem amp at point p.\n\nThe evaluation is done in place of X for the !-variant. The result might not be deterministic, one element of the subdifferential is returned.\n\n\n\n\n\nX = get_subgradient(M;;AbstractManifold, sgo::ManifoldSubgradientObjective, p)\nget_subgradient!(M;;AbstractManifold, X, sgo::ManifoldSubgradientObjective, p)\n\nEvaluate the (sub)gradient of a ManifoldSubgradientObjective sgo at the point p.\n\nThe evaluation is done in place of X for the !-variant. The result might not be deterministic, one element of the subdifferential is returned.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Proximal-map-objective","page":"Objective","title":"Proximal map objective","text":"","category":"section"},{"location":"plans/objective/#Manopt.ManifoldProximalMapObjective","page":"Objective","title":"Manopt.ManifoldProximalMapObjective","text":"ManifoldProximalMapObjective{E<:AbstractEvaluationType, TC, TP, V <: Vector{<:Integer}} <: AbstractManifoldCostObjective{E, TC}\n\nspecify a problem for solvers based on the evaluation of proximal maps, which represents proximal maps operatornameprox_Î»f_i for summands f = f_1 + f_2+  + f_N of the cost function f.\n\nFields\n\ncost: a function fmathcal Mâ„ to minimize\nproxes: proximal maps operatornameprox_Î»f_imathcal M  mathcal M as functions (M, Î», p) -> q or in-place (M, q, Î», p).\nnumber_of_proxes: number of proximal maps per function, to specify when one of the maps is a combined one such that the proximal maps functions return more than one entry per function, you have to adapt this value. if not specified, it is set to one prox per function.\n\nConstructor\n\nManifoldProximalMapObjective(f, proxes_f::Union{Tuple,AbstractVector}, numer_of_proxes=onex(length(proxes));\n   evaluation=Allocating)\n\nGenerate a proximal problem with a tuple or vector of funtions, where by default every function computes a single prox of one component of f.\n\nManifoldProximalMapObjective(f, prox_f); evaluation=Allocating)\n\nGenerate a proximal objective for f and its proxial map operatornameprox_Î»f\n\nSee also\n\ncyclic_proximal_point, get_cost, get_proximal_map\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-4","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_proximal_map","page":"Objective","title":"Manopt.get_proximal_map","text":"q = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Î», p)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Î», p)\nq = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Î», p, i)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Î», p, i)\n\nevaluate the (ith) proximal map of ManifoldProximalMapObjective p at the point p of p.M with parameter Î»0.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Hessian-objective","page":"Objective","title":"Hessian objective","text":"","category":"section"},{"location":"plans/objective/#Manopt.AbstractManifoldHessianObjective","page":"Objective","title":"Manopt.AbstractManifoldHessianObjective","text":"AbstractManifoldHessianObjective{T<:AbstractEvaluationType,TC,TG,TH} <: AbstractManifoldGradientObjective{T,TC,TG}\n\nAn abstract type for all objectives that provide a (full) Hessian, where T is a AbstractEvaluationType for the gradient and Hessian functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldHessianObjective","page":"Objective","title":"Manopt.ManifoldHessianObjective","text":"ManifoldHessianObjective{T<:AbstractEvaluationType,C,G,H,Pre} <: AbstractManifoldHessianObjective{T,C,G,H}\n\nspecify a problem for Hessian based algorithms.\n\nFields\n\ncost:           a function fmathcal Mâ„ to minimize\ngradient:       the gradient operatornamegradfmathcal M  mathcal Tmathcal M of the cost function f\nhessian:        the Hessian operatornameHessf(x) mathcal T_x mathcal M  mathcal T_x mathcal M of the cost function f\npreconditioner: the symmetric, positive definite preconditioner as an approximation of the inverse of the Hessian of f, a map with the same input variables as the hessian to numerically stabilize iterations when the Hessian is ill-conditioned\n\nDepending on the AbstractEvaluationType T the gradient and can have to forms\n\nas a function (M, p) -> X  and (M, p, X) -> Y, resp., an AllocatingEvaluation\nas a function (M, X, p) -> X and (M, Y, p, X), resp., an InplaceEvaluation\n\nConstructor\n\nManifoldHessianObjective(f, grad_f, Hess_f, preconditioner = (M, p, X) -> X;\n    evaluation=AllocatingEvaluation())\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-5","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_hessian","page":"Objective","title":"Manopt.get_hessian","text":"Y = get_hessian(amp::AbstractManoptProblem{T}, p, X)\nget_hessian!(amp::AbstractManoptProblem{T}, Y, p, X)\n\nevaluate the Hessian of an AbstractManoptProblem amp at p applied to a tangent vector X, computing operatornameHessf(q)X, which can also happen in-place of Y.\n\n\n\n\n\nget_hessian(M::AbstractManifold, vgf::VectorHessianFunction, p, X, i)\nget_hessian(M::AbstractManifold, vgf::VectorHessianFunction, p, X, i, range)\nget_hessian!(M::AbstractManifold, X, vgf::VectorHessianFunction, p, X, i)\nget_hessian!(M::AbstractManifold, X, vgf::VectorHessianFunction, p, X, i, range)\n\nEvaluate the Hessians of the vector function vgf on the manifold M at p in direction X and the values given in range, specifying the representation of the gradients.\n\nSince i is assumed to be a linear index, you can provide\n\na single integer\na UnitRange to specify a range to be returned like 1:3\na BitVector specifying a selection\na AbstractVector{<:Integer} to specify indices\n: to return the vector of all Hessian evaluations\n\n\n\n\n\nget_hessian(TpM, trmo::TrustRegionModelObjective, X)\n\nEvaluate the Hessian of the TrustRegionModelObjective\n\noperatornameHess m(X)Y = operatornameHess f(p)Y\n\n\n\n\n\nget_Hessian(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X, V)\nget_Hessian!(TpM::TangentSpace, W, slso::SymmetricLinearSystemObjective, X, V)\n\nevaluate the Hessian of\n\nf(X) = frac12 lVert mathcal AX + b rVert_p^2qquad X  T_pmathcal M\n\nWhich is operatornameHess f(X)Y = mathcal AV. This can be computed in-place of W.\n\n\n\n\n\nget_hessian(M::AbstractManifold, emo::EmbeddedManifoldObjective, p, X)\nget_hessian!(M::AbstractManifold, Y, emo::EmbeddedManifoldObjective, p, X)\n\nEvaluate the Hessian of an objective defined in the embedding, that is embed p and X before calling the Hessian function stored in the EmbeddedManifoldObjective.\n\nThe returned Hessian is then converted to a Riemannian Hessian calling  riemannian_Hessian.\n\n\n\n\n\nget_hessian(M::AbstractManifold, scaled_objective::ScaledManifoldObjective, p, X)\nget_hessian!(M::AbstractManifold, Y, scaled_objective::ScaledManifoldObjective, p, X)\n\nEvaluate the scaled Hessian s*operatornameHessf(p)\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_preconditioner","page":"Objective","title":"Manopt.get_preconditioner","text":"get_preconditioner(amp::AbstractManoptProblem, p, X)\n\nevaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function f) of a AbstractManoptProblem amps objective at the point p applied to a tangent vector X.\n\n\n\n\n\nget_preconditioner(M::AbstractManifold, mho::ManifoldHessianObjective, p, X)\n\nevaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function F) of a ManifoldHessianObjective mho at the point p applied to a tangent vector X.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"and internally","category":"page"},{"location":"plans/objective/#Manopt.get_hessian_function","page":"Objective","title":"Manopt.get_hessian_function","text":"get_gradient_function(amgo::AbstractManifoldGradientObjective{E<:AbstractEvaluationType})\n\nreturn the function to evaluate (just) the Hessian operatornameHess f(p). Depending on the AbstractEvaluationType E this is a function\n\n(M, p, X) -> Y for the AllocatingEvaluation case\n(M, Y, p, X) -> X for the InplaceEvaluation, working in-place of Y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Primal-dual-based-objectives","page":"Objective","title":"Primal-dual based objectives","text":"","category":"section"},{"location":"plans/objective/#Manopt.AbstractPrimalDualManifoldObjective","page":"Objective","title":"Manopt.AbstractPrimalDualManifoldObjective","text":"AbstractPrimalDualManifoldObjective{E<:AbstractEvaluationType,C,P} <: AbstractManifoldCostObjective{E,C}\n\nA common abstract super type for objectives that consider primal-dual problems.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.PrimalDualManifoldObjective","page":"Objective","title":"Manopt.PrimalDualManifoldObjective","text":"PrimalDualManifoldObjective{T<:AbstractEvaluationType} <: AbstractPrimalDualManifoldObjective{T}\n\nDescribes an Objective linearized or exact Chambolle-Pock algorithm, cf. [BHS+21], [CP11]\n\nFields\n\nAll fields with !! can either be in-place or allocating functions, which should be set depending on the evaluation= keyword in the constructor and stored in T <: AbstractEvaluationType.\n\ncost:                          F + G(Î›()) to evaluate interim cost function values\nlinearized_forward_operator!!: linearized operator for the forward operation in the algorithm DÎ›\nlinearized_adjoint_operator!!: the adjoint differential (DÎ›)^*  mathcal N  Tmathcal M\nprox_f!!:                      the proximal map belonging to f\nprox_G_dual!!:                 the proximal map belonging to g_n^*\nÎ›!!:                           the  forward operator (if given) Î› mathcal M  mathcal N\n\nEither the linearized operator DÎ› or Î› are required usually.\n\nConstructor\n\nPrimalDualManifoldObjective(cost, prox_f, prox_G_dual, adjoint_linearized_operator;\n    linearized_forward_operator::Union{Function,Missing}=missing,\n    Î›::Union{Function,Missing}=missing,\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n)\n\nThe last optional argument can be used to provide the 4 or 5 functions as allocating or mutating (in place computation) ones. Note that the first argument is always the manifold under consideration, the mutated one is the second.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.PrimalDualManifoldSemismoothNewtonObjective","page":"Objective","title":"Manopt.PrimalDualManifoldSemismoothNewtonObjective","text":"PrimalDualManifoldSemismoothNewtonObjective{E<:AbstractEvaluationType, TC, LO, ALO, PF, DPF, PG, DPG, L} <: AbstractPrimalDualManifoldObjective{E, TC, PF}\n\nDescribes a Problem for the Primal-dual Riemannian semismooth Newton algorithm. [DL21]\n\nFields\n\ncost:                        F + G(Î›()) to evaluate interim cost function values\nlinearized_operator:         the linearization DÎ›() of the operator Î›().\nlinearized_adjoint_operator: the adjoint differential (DÎ›)^*  mathcal N  Tmathcal M\nprox_F:                      the proximal map belonging to F\ndiff_prox_F:                 the (Clarke Generalized) differential of the proximal maps of F\nprox_G_dual:                 the proximal map belonging to G^\\ast_n`\ndiff_prox_dual_G:            the (Clarke Generalized) differential of the proximal maps of G^ast_n\nÎ›:                           the exact forward operator. This operator is required if Î›(m)=n does not hold.\n\nConstructor\n\nPrimalDualManifoldSemismoothNewtonObjective(cost, prox_F, prox_G_dual, forward_operator, adjoint_linearized_operator,Î›)\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-6","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.adjoint_linearized_operator","page":"Objective","title":"Manopt.adjoint_linearized_operator","text":"X = adjoint_linearized_operator(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y)\nadjoint_linearized_operator(N::AbstractManifold, X, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y)\n\nEvaluate the adjoint of the linearized forward operator of (DÎ›(m))^*Y stored within the AbstractPrimalDualManifoldObjective (in place of X). Since YT_nmathcal N, both m and n=Î›(m) are necessary arguments, mainly because the forward operator Î› might be missing in p.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.forward_operator","page":"Objective","title":"Manopt.forward_operator","text":"q = forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, p)\nforward_operator!(M::AbstractManifold, N::AbstractManifold, q, apdmo::AbstractPrimalDualManifoldObjective, p)\n\nEvaluate the forward operator of Î›(x) stored within the TwoManifoldProblem (in place of q).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential_dual_prox","page":"Objective","title":"Manopt.get_differential_dual_prox","text":"Î· = get_differential_dual_prox(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, n, Ï„, X, Î¾)\nget_differential_dual_prox!(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, Î·, n, Ï„, X, Î¾)\n\nEvaluate the differential proximal map of G_n^* stored within PrimalDualManifoldSemismoothNewtonObjective\n\nDoperatornameprox_Ï„G_n^*(X)Î¾\n\nwhich can also be computed in place of Î·.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential_primal_prox","page":"Objective","title":"Manopt.get_differential_primal_prox","text":"y = get_differential_primal_prox(M::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective Ïƒ, x)\nget_differential_primal_prox!(p::TwoManifoldProblem, y, Ïƒ, x)\n\nEvaluate the differential proximal map of F stored within AbstractPrimalDualManifoldObjective\n\nDoperatornameprox_ÏƒF(x)X\n\nwhich can also be computed in place of y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_dual_prox","page":"Objective","title":"Manopt.get_dual_prox","text":"Y = get_dual_prox(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, n, Ï„, X)\nget_dual_prox!(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, Y, n, Ï„, X)\n\nEvaluate the proximal map of g_n^* stored within AbstractPrimalDualManifoldObjective\n\n  Y = operatornameprox_Ï„G_n^*(X)\n\nwhich can also be computed in place of Y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_primal_prox","page":"Objective","title":"Manopt.get_primal_prox","text":"q = get_primal_prox(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, Ïƒ, p)\nget_primal_prox!(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, q, Ïƒ, p)\n\nEvaluate the proximal map of F stored within AbstractPrimalDualManifoldObjective\n\noperatornameprox_ÏƒF(x)\n\nwhich can also be computed in place of y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.linearized_forward_operator","page":"Objective","title":"Manopt.linearized_forward_operator","text":"Y = linearized_forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, X, n)\nlinearized_forward_operator!(M::AbstractManifold, N::AbstractManifold, Y, apdmo::AbstractPrimalDualManifoldObjective, m, X, n)\n\nEvaluate the linearized operator (differential) DÎ›(m)X stored within the AbstractPrimalDualManifoldObjective (in place of Y), where n = Î›(m).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Constrained-objective","page":"Objective","title":"Constrained objective","text":"","category":"section"},{"location":"plans/objective/#Manopt.ConstrainedManifoldObjective","page":"Objective","title":"Manopt.ConstrainedManifoldObjective","text":"ConstrainedManifoldObjective{T<:AbstractEvaluationType, C<:ConstraintType} <: AbstractManifoldObjective{T}\n\nDescribes the constrained objective\n\nbeginaligned\n operatorname*argmin_p mathcalM  f(p)\n textsubject to  g_i(p)leq0 quad text for all  i=1m\n quad h_j(p)=0 quad text for all  j=1n\nendaligned\n\nFields\n\nobjective: an AbstractManifoldObjective representing the unconstrained objective, that is containing cost f, the gradient of the cost f and maybe the Hessian.\nequality_constraints: an AbstractManifoldObjective representing the equality constraints\n\nh mathcal M  mathbb R^n also possibly containing its gradient and/or Hessian\n\nequality_constraints: an AbstractManifoldObjective representing the equality constraints\n\nh mathcal M  mathbb R^n also possibly containing its gradient and/or Hessian\n\nConstructors\n\nConstrainedManifoldObjective(M::AbstractManifold, f, grad_f;\n    g=nothing,\n    grad_g=nothing,\n    h=nothing,\n    grad_h=nothing;\n    hess_f=nothing,\n    hess_g=nothing,\n    hess_h=nothing,\n    equality_constraints=nothing,\n    inequality_constraints=nothing,\n    evaluation=AllocatingEvaluation(),\n    M = nothing,\n    p = isnothing(M) ? nothing : rand(M),\n)\n\nGenerate the constrained objective based on all involved single functions f, grad_f, g, grad_g, h, grad_h, and optionally a Hessian for each of these. With equality_constraints and inequality_constraints you have to provide the dimension of the ranges of h and g, respectively. You can also provide a manifold M and a point p to use one evaluation of the constraints to automatically try to determine these sizes.\n\nConstrainedManifoldObjective(M::AbstractManifold, mho::AbstractManifoldObjective;\n    equality_constraints = nothing,\n    inequality_constraints = nothing\n)\n\nGenerate the constrained objective either with explicit constraints g and h, and their gradients, or in the form where these are already encapsulated in VectorGradientFunctions.\n\nBoth variants require that at least one of the constraints (and its gradient) is provided. If any of the three parts provides a Hessian, the corresponding object, that is a ManifoldHessianObjective for f or a VectorHessianFunction for g or h, respectively, is created.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldConstrainedSetObjective","page":"Objective","title":"Manopt.ManifoldConstrainedSetObjective","text":"ManifoldConstrainedSetObjective{E, MO, PF, IF} <: AbstractManifoldObjective{E}\n\nModel a constrained objective restricted to a set\n\noperatorname*argmin_p  mathcal C f(p)\n\nwhere mathcal C  mathcal M is a convex closed subset.\n\nFields\n\nobjective::AbstractManifoldObjective the (unconstrained) objective, which contains f and for example ist gradient operatornamegrad f.\nproject!!::PF a projection function operatornameproj_mathcal C mathcal M  mathcal C that projects onto the set mathcal C.\nindicator::IF the indicator function ``Î¹_{\\mathcal C}(p) = \\begin{cases}   0 &\\text{ for }pâˆˆ\\mathcal C\\\\    âˆž &\\text{ else.}\\end{cases}\n\nConstructor\n\nManifoldConstrainedSetObjective(f, grad_f, project!!; kwargs...)\n\nGenerate the constrained objective for a given function f its gradient grad_f and a projection project!! operatornameproj_mathcal C.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nindicator=nothing: the indicator function Î¹_mathcal C(p). If not provided a test, whether the projection yields the same point is performed. For the InplaceEvaluation this required one allocation.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"It might be beneficial to use the adapted problem to specify different ranges for the gradients of the constraints","category":"page"},{"location":"plans/objective/#Manopt.ConstrainedManoptProblem","page":"Objective","title":"Manopt.ConstrainedManoptProblem","text":"ConstrainedProblem{\n    TM <: AbstractManifold,\n    O <: AbstractManifoldObjective\n    HR<:Union{AbstractPowerRepresentation,Nothing},\n    GR<:Union{AbstractPowerRepresentation,Nothing},\n    HHR<:Union{AbstractPowerRepresentation,Nothing},\n    GHR<:Union{AbstractPowerRepresentation,Nothing},\n} <: AbstractManoptProblem{TM}\n\nA constrained problem might feature different ranges for the (vectors of) gradients of the equality and inequality constraints.\n\nThe ranges are required in a few places to allocate memory and access elements correctly, they work as follows:\n\nAssume the objective is\n\nbeginaligned\n operatorname*argmin_p mathcalM  f(p)\n textsubject to  g_i(p)leq0 quad text for all  i=1m\n quad h_j(p)=0 quad text for all  j=1n\nendaligned\n\nthen the gradients can (classically) be considered as vectors of the components gradients, for example bigl(operatornamegrad g_1(p) operatornamegrad g_2(p)  operatornamegrad g_m(p) bigr).\n\nIn another interpretation, this can be considered a point on the tangent space at P = (pp) in mathcal M^m, so in the tangent space to the PowerManifold mathcal M^m. The case where this is a NestedPowerRepresentation this agrees with the interpretation from before, but on power manifolds, more efficient representations exist.\n\nTo then access the elements, the range has to be specified. That is what this problem is for.\n\nConstructor\n\nConstrainedManoptProblem(\n    M::AbstractManifold,\n    co::ConstrainedManifoldObjective;\n    range=NestedPowerRepresentation(),\n    gradient_equality_range=range,\n    gradient_inequality_range=range\n    hessian_equality_range=range,\n    hessian_inequality_range=range\n)\n\nCreates a constrained Manopt problem specifying an AbstractPowerRepresentation for both the gradient_equality_range and the gradient_inequality_range, respectively.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"as well as the helper functions","category":"page"},{"location":"plans/objective/#Manopt.AbstractConstrainedFunctor","page":"Objective","title":"Manopt.AbstractConstrainedFunctor","text":"AbstractConstrainedFunctor{T}\n\nA common supertype for fucntors that model constraint functions.\n\nThis supertype provides access for the fields Î» and Î¼, the dual variables of constraintsnof type T.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractConstrainedSlackFunctor","page":"Objective","title":"Manopt.AbstractConstrainedSlackFunctor","text":"AbstractConstrainedSlackFunctor{T,R}\n\nA common supertype for fucntors that model constraint functions with slack.\n\nThis supertype additionally provides access for the fields\n\nÎ¼::T the dual for the inequality constraints\ns::T the slack parameter, and\nÎ²::R the  the barrier parameter\n\nwhich is also of type T.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.LagrangianCost","page":"Objective","title":"Manopt.LagrangianCost","text":"LagrangianCost{CO,T} <: AbstractConstrainedFunctor{T}\n\nImplement the Lagrangian of a ConstrainedManifoldObjective co.\n\nmathcal L(p Î¼ Î»)\n= f(p) +  sum_i=1^m Î¼_ig_i(p) + sum_j=1^n Î»_jh_j(p)\n\nFields\n\nco::CO, Î¼::T, Î»::T as mentioned, where T represents a vector type.\n\nConstructor\n\nLagrangianCost(co, Î¼, Î»)\n\nCreate a functor for the Lagrangian with fixed dual variables.\n\nExample\n\nWhen you directly want to evaluate the Lagrangian mathcal L you can also call\n\nLagrangianCost(co, Î¼, Î»)(M,p)\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.LagrangianGradient","page":"Objective","title":"Manopt.LagrangianGradient","text":"LagrangianGradient{CO,T}\n\nThe gradient of the Lagrangian of a ConstrainedManifoldObjective co with respect to the variable p. The formula reads\n\noperatornamegrad_p mathcal L(p Î¼ Î»)\n= operatornamegrad f(p) +  sum_i=1^m Î¼_i operatornamegrad g_i(p) + sum_j=1^n Î»_j operatornamegrad h_j(p)\n\nFields\n\nco::CO, Î¼::T, Î»::T as mentioned, where T represents a vector type.\n\nConstructor\n\nLagrangianGradient(co, Î¼, Î»)\n\nCreate a functor for the Lagrangian with fixed dual variables.\n\nExample\n\nWhen you directly want to evaluate the gradient of the Lagrangian operatornamegrad_p mathcal L you can also call LagrangianGradient(co, Î¼, Î»)(M,p) or LagrangianGradient(co, Î¼, Î»)(M,X,p) for the in-place variant.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.LagrangianHessian","page":"Objective","title":"Manopt.LagrangianHessian","text":"LagrangianHessian{CO, V, T}\n\nThe Hesian of the Lagrangian of a ConstrainedManifoldObjective co with respect to the variable p. The formula reads\n\noperatornameHess_p mathcal L(p Î¼ Î»)X\n= operatornameHess f(p) +  sum_i=1^m Î¼_i operatornameHess g_i(p)X + sum_j=1^n Î»_j operatornameHess h_j(p)X\n\nFields\n\nco::CO, Î¼::T, Î»::T as mentioned, where T represents a vector type.\n\nConstructor\n\nLagrangianHessian(co, Î¼, Î»)\n\nCreate a functor for the Lagrangian with fixed dual variables.\n\nExample\n\nWhen you directly want to evaluate the Hessian of the Lagrangian operatornameHess_p mathcal L you can also call LagrangianHessian(co, Î¼, Î»)(M, p, X) or LagrangianHessian(co, Î¼, Î»)(M, Y, p, X) for the in-place variant.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-7","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.equality_constraints_length","page":"Objective","title":"Manopt.equality_constraints_length","text":"equality_constraints_length(co::ConstrainedManifoldObjective)\n\nReturn the number of equality constraints of an ConstrainedManifoldObjective. This acts transparently through AbstractDecoratedManifoldObjectives\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.inequality_constraints_length","page":"Objective","title":"Manopt.inequality_constraints_length","text":"inequality_constraints_length(cmo::ConstrainedManifoldObjective)\n\nReturn the number of inequality constraints of an ConstrainedManifoldObjective cmo. This acts transparently through AbstractDecoratedManifoldObjectives\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_equality_constraint","page":"Objective","title":"Manopt.get_equality_constraint","text":"get_equality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_equality_constraint(M::AbstractManifold, objective, p, j=:)\n\nEvaluate equality constraints of a ConstrainedManifoldObjective objective at point p and indices j (by default : which corresponds to all indices).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_equality_constraint","page":"Objective","title":"Manopt.get_grad_equality_constraint","text":"get_grad_equality_constraint(amp::AbstractManoptProblem, p, j)\nget_grad_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\nget_grad_equality_constraint!(amp::AbstractManoptProblem, X, p, j)\nget_grad_equality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\n\nEvaluate the gradient or gradients  of the equality constraint (operatornamegrad h(p))_j or operatornamegrad h_j(p),\n\nSee also the ConstrainedManoptProblem to specify the range of the gradient.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_inequality_constraint","page":"Objective","title":"Manopt.get_grad_inequality_constraint","text":"get_grad_inequality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_grad_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\nget_grad_inequality_constraint!(amp::AbstractManoptProblem, X, p, j=:)\nget_grad_inequality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\n\nEvaluate the gradient or gradients of the inequality constraint (operatornamegrad g(p))_j or operatornamegrad g_j(p),\n\nSee also the ConstrainedManoptProblem to specify the range of the gradient.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_hess_equality_constraint","page":"Objective","title":"Manopt.get_hess_equality_constraint","text":"get_hess_equality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_hess_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\nget_hess_equality_constraint!(amp::AbstractManoptProblem, X, p, j=:)\nget_hess_equality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\n\nEvaluate the Hessian or Hessians of the equality constraint (operatornameHess h(p))_j or operatornameHess h_j(p),\n\nSee also the ConstrainedManoptProblem to specify the range of the Hessian.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_hess_inequality_constraint","page":"Objective","title":"Manopt.get_hess_inequality_constraint","text":"get_hess_inequality_constraint(amp::AbstractManoptProblem, p, X, j=:)\nget_hess_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\nget_hess_inequality_constraint!(amp::AbstractManoptProblem, Y, p, j=:)\nget_hess_inequality_constraint!(M::AbstractManifold, Y, co::ConstrainedManifoldObjective, p, X, j=:, range=NestedPowerRepresentation())\n\nEvaluate the Hessian or Hessians of the inequality constraint (operatornameHess g(p)X)_j or operatornameHess g_j(p)X,\n\nSee also the ConstrainedManoptProblem to specify the range of the Hessian.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_inequality_constraint","page":"Objective","title":"Manopt.get_inequality_constraint","text":"get_inequality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\n\nEvaluate inequality constraints of a ConstrainedManifoldObjective objective at point p and indices j (by default : which corresponds to all indices).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_projected_point","page":"Objective","title":"Manopt.get_projected_point","text":"get_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\nget_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_projected_point!","page":"Objective","title":"Manopt.get_projected_point!","text":"get_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\nget_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_unconstrained_objective","page":"Objective","title":"Manopt.get_unconstrained_objective","text":"get_unconstrained_objective(co::ConstrainedManifoldObjective)\n\nReturns the internally stored unconstrained AbstractManifoldObjective within the ConstrainedManifoldObjective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.is_feasible","page":"Objective","title":"Manopt.is_feasible","text":"is_feasible(M::AbstractManifold, cmo::ConstrainedManifoldObjective, p, kwargs...)\n\nEvaluate whether a boint p on M is feasible with respect to the ConstrainedManifoldObjective cmo. That is for the provided inequality constaints g mathcal M  â„^m and equality constaints h mathcal M to â„^m from within cmo, the point p  mathcal M is feasible if\n\ng_i(p)  0 text for all  i=1mquadtext and quad h_j(p) = 0 text for all  j=1n\n\nKeyword arguments\n\ncheck_point::Bool=true: whether to also verify that `pâˆˆ\\mathcal M holds, using is_point\nerror::Symbol=:none: if the point is not feasible, this symbol determines how to report the error.\n:error: throws an error\n:info: displays the error message as an @info\n:none: (default) the function just returns true/false\n:warn: displays the error message as a @warning.\n\nThe keyword error= and all other kwargs... are passed on to is_point if the point is verfied (see check_point).\n\nAll other keywords are passed on to is_poi\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Internal-functions","page":"Objective","title":"Internal functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_feasibility_status","page":"Objective","title":"Manopt.get_feasibility_status","text":"get_feasibility_status(\n    M::AbstractManifold,\n    cmo::ConstrainedManifoldObjective,\n    g = get_inequality_constraints(M, cmo, p),\n    h = get_equality_constraints(M, cmo, p),\n)\n\nGenerate a message about the feasibiliy of p with respect to the ConstrainedManifoldObjective. You can also provide the evaluated vectors for the values of g and h as keyword arguments, in case you had them evaluated before.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Vectorial-objectives","page":"Objective","title":"Vectorial objectives","text":"","category":"section"},{"location":"plans/objective/#Manopt.AbstractVectorFunction","page":"Objective","title":"Manopt.AbstractVectorFunction","text":"AbstractVectorFunction{E, FT} <: Function\n\nRepresent an abstract vectorial function fmathcal M  â„^n with an AbstractEvaluationType E and an AbstractVectorialType to specify the format f is implemented as.\n\nRepresentations of f\n\nThere are three different representations of f, which might be beneficial in one or the other situation:\n\nthe FunctionVectorialType storing a single function f that returns a vector,\nthe ComponentVectorialType storing a vector of functions f_i that return a single value each,\nthe CoordinateVectorialType storing functions with respect to a specific basis of the tangent space for gradients and Hessians. Gradients of this type are usually referred to as Jacobians.\n\nFor the ComponentVectorialType imagine that f could also be written using its component functions,\n\nf(p) = bigl( f_1(p) f_2(p) ldots f_n(p) bigr)^mathrmT\n\nIn this representation f is given as a vector [f1(M,p), f2(M,p), ..., fn(M,p)] of its component functions. An advantage is that the single components can be evaluated and from this representation one even can directly read of the number n. A disadvantage might be, that one has to implement a lot of individual (component) functions.\n\nFor the  FunctionVectorialType f is implemented as a single function f(M, p), that returns an AbstractArray. And advantage here is, that this is a single function. A disadvantage might be, that if this is expensive even to compute a single component, all of f has to be evaluated\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractVectorGradientFunction","page":"Objective","title":"Manopt.AbstractVectorGradientFunction","text":"VectorGradientFunction{E, FT, JT, F, J, I} <: AbstractManifoldObjective{E}\n\nRepresent an abstract vectorial function fmathcal M  â„^n that provides a (component wise) gradient. The AbstractEvaluationType E indicates the evaluation type, and the AbstractVectorialTypes FT and JT the formats in which the function and the gradient are provided, see AbstractVectorFunction for an explanation.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.VectorGradientFunction","page":"Objective","title":"Manopt.VectorGradientFunction","text":"VectorGradientFunction{E, FT, JT, F, J, I} <: AbstractVectorGradientFunction{E, FT, JT}\n\nRepresent a function fmathcal M  â„^n including it first derivative, either as a vector of gradients of a Jacobian\n\nAnd hence has a gradient `\\operatorname{grad} f_i(p) âˆˆ T_{p}\\mathcal M. Putting these gradients into a vector the same way as the functions, yields a ComponentVectorialType\n\noperatornamegrad f(p) = Bigl( operatornamegrad f_1(p) operatornamegrad f_2(p)  operatornamegrad f_n(p) Bigr)^mathrmT\n (T_pmathcal M)^n\n\nAnd advantage here is, that again the single components can be evaluated individually\n\nFields\n\nvalue!!::F:          the cost function f, which can take different formats\ncost_type::AbstractVectorialType:     indicating / storing data for the type of f\njacobian!!::G:     the Jacobian of f\njacobian_type::AbstractVectorialType: indicating / storing data for the type of J_f\nparameters:    the number n from, the size of the vector f returns.\n\nConstructor\n\nVectorGradientFunction(f, Jf, range_dimension;\n    evaluation::AbstractEvaluationType=AllocatingEvaluation(),\n    function_type::AbstractVectorialType=FunctionVectorialType(),\n    jacobian_type::AbstractVectorialType=FunctionVectorialType(),\n)\n\nCreate a VectorGradientFunction of f  and its Jacobian (vector of gradients) Jf, where f maps into the Euclidean space of dimension range_dimension. Their types are specified by the function_type, and jacobian_type, respectively. The Jacobian can further be given as an allocating variant or an in-place variant, specified by the evaluation= keyword.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.VectorHessianFunction","page":"Objective","title":"Manopt.VectorHessianFunction","text":"VectorHessianFunction{E, FT, JT, HT, F, J, H, I} <: AbstractVectorGradientFunction{E, FT, JT}\n\nRepresent a function fmathcal M M  â„^n including it first derivative, either as a vector of gradients of a Jacobian, and the Hessian, as a vector of Hessians of the component functions.\n\nBoth the Jacobian and the Hessian can map into either a sequence of tangent spaces or a single tangent space of the power manifold of length n.\n\nFields\n\nvalue!!::F:          the cost function f, which can take different formats\ncost_type::AbstractVectorialType:     indicating / string data for the type of f\njacobian!!::G:     the Jacobian J_f of f\njacobian_type::AbstractVectorialType: indicating / storing data for the type of J_f\nhessians!!::H:     the Hessians of f (in a component wise sense)\nhessian_type::AbstractVectorialType:  indicating / storing data for the type of H_f\nrange_dimension:    the number n from, the size of the vector f returns.\n\nConstructor\n\nVectorHessianFunction(f, Jf, Hess_f, range_dimension;\n    evaluation::AbstractEvaluationType=AllocatingEvaluation(),\n    function_type::AbstractVectorialType=FunctionVectorialType(),\n    jacobian_type::AbstractVectorialType=FunctionVectorialType(),\n    hessian_type::AbstractVectorialType=FunctionVectorialType(),\n)\n\nCreate a VectorHessianFunction of f  and its Jacobian (vector of gradients) Jf and (vector of) Hessians, where f maps into the Euclidean space of dimension range_dimension. Their types are specified by the function_type, and jacobian_type, and hessian_type, respectively. The Jacobian and Hessian can further be given as an allocating variant or an inplace-variant, specified by the evaluation= keyword.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractVectorialType","page":"Objective","title":"Manopt.AbstractVectorialType","text":"AbstractVectorialType\n\nAn abstract type for different representations of a vectorial function f mathcal M  â„^m and its (component-wise) gradient/Jacobian\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.CoordinateVectorialType","page":"Objective","title":"Manopt.CoordinateVectorialType","text":"CoordinateVectorialType{B<:AbstractBasis} <: AbstractVectorialType\n\nA type to indicate that gradient of the constraints is implemented as a Jacobian matrix with respect to a certain basis, that is if the vector function is f mathcal M  â„^m and we have a basis mathcal B of T_pmathcal M, at p mathcal M This can be written as J_g(p) = (c_1^mathrmTc_m^mathrmT)^mathrmT in â„^md, that is, every row c_i of this matrix is a set of coefficients such that get_coefficients(M, p, c, B) is the tangent vector oepratornamegrad g_i(p) for example g_i(p)  â„^m or operatornamegrad g_i(p)  T_pmathcal M,     i=1m.\n\nFields\n\nbasis an AbstractBasis to indicate the basis in which Jacobian is expressed.\n\nConstructor\n\nCoordinateVectorialType(basis=DefaultOrthonormalBasis())\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ComponentVectorialType","page":"Objective","title":"Manopt.ComponentVectorialType","text":"ComponentVectorialType <: AbstractVectorialType\n\nA type to indicate that constraints are implemented as component functions, for example g_i(p)  â„^m or operatornamegrad g_i(p)  T_pmathcal M, i=1m.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.FunctionVectorialType","page":"Objective","title":"Manopt.FunctionVectorialType","text":"FunctionVectorialType{P<:AbstractPowerRepresentation} <: AbstractVectorialType\n\nA type to indicate that constraints are implemented one whole functions, for example g(p)  â„^m or operatornamegrad g(p)  (T_pmathcal M)^m.\n\nThis type internally stores the AbstractPowerRepresentation, when it makes sense, especially for Hessian and gradient functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-8","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_jacobian","page":"Objective","title":"Manopt.get_jacobian","text":"get_jacobian(M::AbstractManifold, vgf::AbstractVectorGradientFunction, p; kwargs...)\nget_jacobian(M::AbstractManifold, J, vgf::AbstractVectorGradientFunction, p; kwargs...)\n\nCompute the Jacobian J_F  â„^mn of the AbstractVectorGradientFunction F at p on the M.\n\nThere are two interpretations of the Jacobian of a vectorial function F mathcal M  â„^m on a manifold. Both depend on choosing a basis on the tangent space T_pmathcal M which we denote by Y_1Y_n, where n is the manifold_dimension(M)(M). We can write any tangent vector X = displaystylesum_i c_iY_i\n\nThe Jacobian J_F is the matrix with respect to the basis Y_1Y_n such that\n\nfor any XT_pmathcal M we have the equality of the differential DF(p)X = Jc.   In other words, the jth column of J is given by DF(p)Y_j\n\nGiven the gradients operatornamegrad F_i(p) of the component functions F_i mathcal M  â„,\n\nwe define the jacobian function as\n\nmath   J(X) = beginpmatrix operatornamegrad F_1 X_p operatornamegrad F_1 X_p  operatornamegrad F_1 X_pendpmatrix\n\nThen either the jth column of J_F is given by J(Y_i) or the ith row is given by all inner products operatornamegrad F_1 Y_j_p of the ith gradient function with all basis vectors Y_j.\n\nThe computation can be computed in-place of J.\n\nKeyword arguments\n\nbasis::AbstractBasis =get_basis(vgf) for the CoordinateVectorialType of the vectorial functions gradient, this might lead to a change of basis, if this basis and the one the coordinates are given in do not agree.\nrange::AbstractPowerRepresentation =get_range(vgf.jacobian_type) specify the range of the gradients in the case of a FunctionVectorialType, that is, on which type of power manifold the gradient is given on.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_jacobian!","page":"Objective","title":"Manopt.get_jacobian!","text":"get_jacobian(M::AbstractManifold, vgf::AbstractVectorGradientFunction, p; kwargs...)\nget_jacobian(M::AbstractManifold, J, vgf::AbstractVectorGradientFunction, p; kwargs...)\n\nCompute the Jacobian J_F  â„^mn of the AbstractVectorGradientFunction F at p on the M.\n\nThere are two interpretations of the Jacobian of a vectorial function F mathcal M  â„^m on a manifold. Both depend on choosing a basis on the tangent space T_pmathcal M which we denote by Y_1Y_n, where n is the manifold_dimension(M)(M). We can write any tangent vector X = displaystylesum_i c_iY_i\n\nThe Jacobian J_F is the matrix with respect to the basis Y_1Y_n such that\n\nfor any XT_pmathcal M we have the equality of the differential DF(p)X = Jc.   In other words, the jth column of J is given by DF(p)Y_j\n\nGiven the gradients operatornamegrad F_i(p) of the component functions F_i mathcal M  â„,\n\nwe define the jacobian function as\n\nmath   J(X) = beginpmatrix operatornamegrad F_1 X_p operatornamegrad F_1 X_p  operatornamegrad F_1 X_pendpmatrix\n\nThen either the jth column of J_F is given by J(Y_i) or the ith row is given by all inner products operatornamegrad F_1 Y_j_p of the ith gradient function with all basis vectors Y_j.\n\nThe computation can be computed in-place of J.\n\nKeyword arguments\n\nbasis::AbstractBasis =get_basis(vgf) for the CoordinateVectorialType of the vectorial functions gradient, this might lead to a change of basis, if this basis and the one the coordinates are given in do not agree.\nrange::AbstractPowerRepresentation =get_range(vgf.jacobian_type) specify the range of the gradients in the case of a FunctionVectorialType, that is, on which type of power manifold the gradient is given on.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_value","page":"Objective","title":"Manopt.get_value","text":"get_value(M::AbstractManifold, vgf::AbstractVectorFunction, p[, i=:])\nget_value!(M::AbstractManifold, V, vgf::AbstractVectorFunction, p[, i=:])\n\nEvaluate the vector function VectorGradientFunction vgf at p. The range can be used to specify a potential range, but is currently only present for consistency.\n\nThe i can be a linear index, you can provide\n\na single integer\na UnitRange to specify a range to be returned like 1:3\na BitVector specifying a selection\na AbstractVector{<:Integer} to specify indices\n: to return the vector of all gradients, which is also the default\n\nThis function can perform the evaluation inplace of V.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_value_function","page":"Objective","title":"Manopt.get_value_function","text":"get_value_function(vgf::VectorGradientFunction, recursive=false)\n\nreturn the internally stored function computing get_value.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Base.length-Tuple{VectorGradientFunction}","page":"Objective","title":"Base.length","text":"length(vgf::AbstractVectorFunction)\n\nReturn the length of the vector the function f mathcal M  â„^n maps into, that is the number n.\n\n\n\n\n\n","category":"method"},{"location":"plans/objective/#Internal-functions-2","page":"Objective","title":"Internal functions","text":"","category":"section"},{"location":"plans/objective/#Manopt._to_iterable_indices","page":"Objective","title":"Manopt._to_iterable_indices","text":"_to_iterable_indices(A::AbstractVector, i)\n\nConvert index i (integer, colon, vector of indices, etc.) for array A into an iterable structure of indices.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt._change_basis!","page":"Objective","title":"Manopt._change_basis!","text":"_change_basis!(M::AbstractManifold, JF, p, from_basis::B1, to_basis::B; X=zero_vector(M,p))\n\nGiven a jacobian matrix JF on a manifold M at p with respect to the from_basis in the tangent space of p on M. Change the basis of the Jacobian to to_basis in place of JF.\n\nKeyword Arguments\n\nX a temporary vector to store a generated vector, before decomposing it again with respect to the new basis\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#ManifoldsBase.get_basis","page":"Objective","title":"ManifoldsBase.get_basis","text":"get_basis(::AbstractVectorialType)\n\nReturn a basis that fits a vector function representation.\n\nFor the case, where some vectorial data is stored with respect to a basis, this function returns the corresponding basis, most prominently for the CoordinateVectorialType.\n\nIf a type is not with respect to a certain basis, the DefaultOrthonormalBasis is returned.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_range","page":"Objective","title":"Manopt.get_range","text":"get_range(::AbstractVectorialType)\n\nReturn an abstract power manifold representation that fits a vector function's range. Most prominently a FunctionVectorialType returns its internal range.\n\nOtherwise the default NestedPowerRepresentation() is used to work on a vector of data.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Subproblem-objective","page":"Objective","title":"Subproblem objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"This objective can be use when the objective of a sub problem solver still needs access to the (outer/main) objective.","category":"page"},{"location":"plans/objective/#Manopt.AbstractManifoldSubObjective","page":"Objective","title":"Manopt.AbstractManifoldSubObjective","text":"AbstractManifoldSubObjective{O<:AbstractManifoldObjective} <: AbstractManifoldObjective\n\nAn abstract type for objectives of sub problems within a solver but still store the original objective internally to generate generic objectives for sub solvers.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-9","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Manopt.get_objective_cost","page":"Objective","title":"Manopt.get_objective_cost","text":"get_objective_cost(M, amso::AbstractManifoldSubObjective, p)\n\nEvaluate the cost of the (original) objective stored within the sub objective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_objective_gradient","page":"Objective","title":"Manopt.get_objective_gradient","text":"X = get_objective_gradient(M, amso::AbstractManifoldSubObjective, p)\nget_objective_gradient!(M, X, amso::AbstractManifoldSubObjective, p)\n\nEvaluate the gradient of the (original) objective stored within the sub objective amso.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_objective_hessian","page":"Objective","title":"Manopt.get_objective_hessian","text":"Y = get_objective_Hessian(M, amso::AbstractManifoldSubObjective, p, X)\nget_objective_Hessian!(M, Y, amso::AbstractManifoldSubObjective, p, X)\n\nEvaluate the Hessian of the (original) objective stored within the sub objective amso.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_objective_preconditioner","page":"Objective","title":"Manopt.get_objective_preconditioner","text":"Y = get_objective_preconditioner(M, amso::AbstractManifoldSubObjective, p, X)\nget_objective_preconditioner(M, Y, amso::AbstractManifoldSubObjective, p, X)\n\nEvaluate the Hessian of the (original) objective stored within the sub objective amso.\n\n\n\n\n\n","category":"function"},{"location":"plans/stopping_criteria/#sec-stopping-criteria","page":"Stopping Criteria","title":"Stopping criteria","text":"","category":"section"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Stopping criteria are implemented as a functor and inherit from the base type","category":"page"},{"location":"plans/stopping_criteria/#Manopt.StoppingCriterion","page":"Stopping Criteria","title":"Manopt.StoppingCriterion","text":"StoppingCriterion\n\nAn abstract type for the functors representing stopping criteria, so they are callable structures. The naming Scheme follows functions, see for example StopAfterIteration.\n\nEvery StoppingCriterion has to provide a constructor and its function has to have the interface (p,o,i) where a AbstractManoptProblem as well as AbstractManoptSolverState and the current number of iterations are the arguments and returns a boolean whether to stop or not.\n\nBy default each StoppingCriterion should provide a fields reason to provide details when a criterion is met (and that is empty otherwise).\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"They can also be grouped, which is summarized in the type of a set of criteria","category":"page"},{"location":"plans/stopping_criteria/#Manopt.StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.StoppingCriterionSet","text":"StoppingCriterionGroup <: StoppingCriterion\n\nAn abstract type for a Stopping Criterion that itself consists of a set of Stopping criteria. In total it acts as a stopping criterion itself. Examples are StopWhenAny and StopWhenAll that can be used to combine stopping criteria.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"The stopping criteria s might have certain internal values/fields it uses to verify against. This is done when calling them as a function s(amp::AbstractManoptProblem, ams::AbstractManoptSolverState), where the AbstractManoptProblem and the AbstractManoptSolverState together represent the current state of the solver. The functor returns either false when the stopping criterion is not fulfilled or true otherwise. One field all criteria should have is the s.at_iteration, to indicate at which iteration the stopping criterion (last) indicated to stop. 0 refers to an indication before starting the algorithm, while any negative number meant the stopping criterion is not (yet) fulfilled. To can access a string giving the reason of stopping see get_reason.","category":"page"},{"location":"plans/stopping_criteria/#Generic-stopping-criteria","page":"Stopping Criteria","title":"Generic stopping criteria","text":"","category":"section"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"The following generic stopping criteria are available. Some require that, for example, the corresponding AbstractManoptSolverState have a field gradient when the criterion should access that.","category":"page"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Further stopping criteria might be available for individual solvers.","category":"page"},{"location":"plans/stopping_criteria/#Manopt.StopAfter","page":"Stopping Criteria","title":"Manopt.StopAfter","text":"StopAfter <: StoppingCriterion\n\nstore a threshold when to stop looking at the complete runtime. It uses time_ns() to measure the time and you provide a Period as a time limit, for example Minute(15).\n\nFields\n\nthreshold stores the Period after which to stop\nstart stores the starting time when the algorithm is started, that is a call with i=0.\ntime stores the elapsed time\nat_iteration indicates at which iteration (including i=0) the stopping criterion was fulfilled and is -1 while it is not fulfilled.\n\nConstructor\n\nStopAfter(t)\n\ninitialize the stopping criterion to a Period t to stop after.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopAfterIteration","page":"Stopping Criteria","title":"Manopt.StopAfterIteration","text":"StopAfterIteration <: StoppingCriterion\n\nA functor for a stopping criterion to stop after a maximal number of iterations.\n\nFields\n\nmax_iterations  stores the maximal iteration number where to stop at\nat_iteration indicates at which iteration (including i=0) the stopping criterion was fulfilled and is -1 while it is not fulfilled.\n\nConstructor\n\nStopAfterIteration(maxIter)\n\ninitialize the functor to indicate to stop after maxIter iterations.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenAll","page":"Stopping Criteria","title":"Manopt.StopWhenAll","text":"StopWhenAll <: StoppingCriterionSet\n\nstore an array of StoppingCriterion elements and indicates to stop, when all indicate to stop. The reason is given by the concatenation of all reasons.\n\nConstructor\n\nStopWhenAll(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAll(c::StoppingCriterion,...)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenAny","page":"Stopping Criteria","title":"Manopt.StopWhenAny","text":"StopWhenAny <: StoppingCriterionSet\n\nstore an array of StoppingCriterion elements and indicates to stop, when any single one indicates to stop. The reason is given by the concatenation of all reasons (assuming that all non-indicating return \"\").\n\nConstructor\n\nStopWhenAny(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAny(c::StoppingCriterion...)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenChangeLess","text":"StopWhenChangeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the norm of the change of the optimization variable from within a AbstractManoptSolverState s. That ism by accessing get_iterate(s) and comparing successive iterates. For the storage a StoreStateAction is used.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nlast_change::Real: the last change recorded in this stopping criterion\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstorage::StoreStateAction: a storage to access the previous iterate\nat_iteration::Int: indicate at which iteration this stopping criterion was last active.\ninverse_retraction: An AbstractInverseRetractionMethod that can be passed to approximate the distance by this inverse retraction and a norm on the tangent space. This can be used if neither the distance nor the logarithmic map are availannle on M.\nlast_change: store the last change\nstorage: A StoreStateAction to access the previous iterate.\nthreshold: the threshold for the change to check (run under to stop)\nouter_norm: if M is a manifold with components, this can be used to specify the norm, that is used to compute the overall distance based on the element-wise distance. You can deactivate this, but setting this value to missing.\n\nExample\n\nOn an AbstractPowerManifold like mathcal M = mathcal N^n any point p = (p_1p_n)  mathcal M is a vector of length n with of points p_i  mathcal N. Then, denoting the outer_norm by r, the distance of two points pq  mathcal M is given by\n\n\\mathrm{d}(p,q) = \\Bigl( \\sum_{k=1}^n \\mathrm{d}(p_k,q_k)^r \\Bigr)^{\\frac{1}{r}},\n\nwhere the sum turns into a maximum for the case r=. The outer_norm has no effect on manifolds that do not consist of components.\n\nIf the manifold does not have components, the outer norm is ignored.\n\nConstructor\n\nStopWhenChangeLess(\n    M::AbstractManifold,\n    threshold::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    inverse_retraction_method::IRT=default_inverse_retraction_method(M)\n    outer_norm::Union{Missing,Real}=missing\n)\n\ninitialize the stopping criterion to a threshold Îµ using the StoreStateAction a, which is initialized to just store :Iterate by default. You can also provide an inverseretractionmethod for the distance or a manifold to use its default inverse retraction.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenCostLess","page":"Stopping Criteria","title":"Manopt.StopWhenCostLess","text":"StopWhenCostLess <: StoppingCriterion\n\nstore a threshold when to stop looking at the cost function of the optimization problem from within a AbstractManoptProblem, i.e get_cost(p,get_iterate(o)).\n\nConstructor\n\nStopWhenCostLess(Îµ)\n\ninitialize the stopping criterion to a threshold Îµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenCostNaN","page":"Stopping Criteria","title":"Manopt.StopWhenCostNaN","text":"StopWhenCostNaN <: StoppingCriterion\n\nstop looking at the cost function of the optimization problem from within a AbstractManoptProblem, i.e get_cost(p,get_iterate(o)).\n\nConstructor\n\nStopWhenCostNaN()\n\ninitialize the stopping criterion to NaN.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenEntryChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenEntryChangeLess","text":"StopWhenEntryChangeLess\n\nEvaluate whether a certain fields change is less than a certain threshold\n\nFields\n\nfield:     a symbol addressing the corresponding field in a certain subtype of AbstractManoptSolverState to track\ndistance:  a function (problem, state, v1, v2) -> R that computes the distance between two possible values of the field\nstorage:   a StoreStateAction to store the previous value of the field\nthreshold: the threshold to indicate to stop when the distance is below this value\n\nInternal fields\n\nat_iteration: store the iteration at which the stop indication happened\n\nstores a threshold when to stop looking at the norm of the change of the optimization variable from within a AbstractManoptSolverState, i.e get_iterate(o). For the storage a StoreStateAction is used\n\nConstructor\n\nStopWhenEntryChangeLess(\n    field::Symbol\n    distance,\n    threshold;\n    storage::StoreStateAction=StoreStateAction([field]),\n)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenGradientChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenGradientChangeLess","text":"StopWhenGradientChangeLess <: StoppingCriterion\n\nA stopping criterion based on the change of the gradient.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nlast_change::Real: the last change recorded in this stopping criterion\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nstorage::StoreStateAction: a storage to access the previous iterate\nthreshold: the threshold for the change to check (run under to stop)\nouter_norm: if M is a manifold with components, this can be used to specify the norm, that is used to compute the overall distance based on the element-wise distance. You can deactivate this, but setting this value to missing.\n\nExample\n\nOn an AbstractPowerManifold like mathcal M = mathcal N^n any point p = (p_1p_n)  mathcal M is a vector of length n with of points p_i  mathcal N. Then, denoting the outer_norm by r, the norm of the difference of tangent vectors like the last and current gradien XY  mathcal M is given by\n\n\\lVert X-Y \\rVert_{p} = \\Bigl( \\sum_{k=1}^n \\lVert X_k-Y_k \\rVert_{p_k}^r \\Bigr)^{\\frac{1}{r}},\n\nwhere the sum turns into a maximum for the case r=. The outer_norm has no effect on manifols, that do not consist of components.\n\nConstructor\n\nStopWhenGradientChangeLess(\n    M::AbstractManifold,\n    Îµ::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    vector_transport_method::IRT=default_vector_transport_method(M),\n    outer_norm::N=missing\n)\n\nCreate a stopping criterion with threshold Îµ for the change gradient, that is, this criterion indicates to stop when get_gradient is in (norm of) its change less than Îµ, where vector_transport_method denotes the vector transport mathcal T used.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenGradientNormLess","page":"Stopping Criteria","title":"Manopt.StopWhenGradientNormLess","text":"StopWhenGradientNormLess <: StoppingCriterion\n\nA stopping criterion based on the current gradient norm.\n\nFields\n\nnorm:      a function (M::AbstractManifold, p, X) -> â„ that computes a norm of the gradient X in the tangent space at p on M. For manifolds with components provide(M::AbstractManifold, p, X, r) -> â„`.\nthreshold: the threshold to indicate to stop when the distance is below this value\nouter_norm: if M is a manifold with components, this can be used to specify the norm, that is used to compute the overall distance based on the element-wise distance.\n\nInternal fields\n\nlast_change store the last change\nat_iteration store the iteration at which the stop indication happened\n\nExample\n\nOn an AbstractPowerManifold like mathcal M = mathcal N^n any point p = (p_1p_n)  mathcal M is a vector of length n with of points p_i  mathcal N. Then, denoting the outer_norm by r, the norm of a tangent vector like the current gradient X  mathcal M is given by\n\n\\lVert X \\rVert_{p} = \\Bigl( \\sum_{k=1}^n \\lVert X_k \\rVert_{p_k}^r \\Bigr)^{\\frac{1}{r}},\n\nwhere the sum turns into a maximum for the case r=. The outer_norm has no effect on manifolds that do not consist of components.\n\nIf you pass in your individual norm, this can be deactivated on such manifolds by passing missing to outer_norm.\n\nConstructor\n\nStopWhenGradientNormLess(Îµ; norm=ManifoldsBase.norm, outer_norm=missing)\n\nCreate a stopping criterion with threshold Îµ for the gradient, that is, this criterion indicates to stop when get_gradient returns a gradient vector of norm less than Îµ, where the norm to use can be specified in the norm= keyword.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenIterateNaN","page":"Stopping Criteria","title":"Manopt.StopWhenIterateNaN","text":"StopWhenIterateNaN <: StoppingCriterion\n\nstop looking at the cost function of the optimization problem from within a AbstractManoptProblem, i.e get_cost(p,get_iterate(o)).\n\nConstructor\n\nStopWhenIterateNaN()\n\ninitialize the stopping criterion to NaN.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenSmallerOrEqual","page":"Stopping Criteria","title":"Manopt.StopWhenSmallerOrEqual","text":"StopWhenSmallerOrEqual <: StoppingCriterion\n\nA functor for an stopping criterion, where the algorithm if stopped when a variable is smaller than or equal to its minimum value.\n\nFields\n\nvalue    stores the variable which has to fall under a threshold for the algorithm to stop\nminValue stores the threshold where, if the value is smaller or equal to this threshold, the algorithm stops\n\nConstructor\n\nStopWhenSmallerOrEqual(value, minValue)\n\ninitialize the functor to indicate to stop after value is smaller than or equal to minValue.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenStepsizeLess","page":"Stopping Criteria","title":"Manopt.StopWhenStepsizeLess","text":"StopWhenStepsizeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the last step size determined or found during the last iteration from within a AbstractManoptSolverState.\n\nConstructor\n\nStopWhenStepsizeLess(Îµ)\n\ninitialize the stopping criterion to a threshold Îµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenSubgradientNormLess","page":"Stopping Criteria","title":"Manopt.StopWhenSubgradientNormLess","text":"StopWhenSubgradientNormLess <: StoppingCriterion\n\nA stopping criterion based on the current subgradient norm.\n\nConstructor\n\nStopWhenSubgradientNormLess(Îµ::Float64)\n\nCreate a stopping criterion with threshold Îµ for the subgradient, that is, this criterion indicates to stop when get_subgradient returns a subgradient vector of norm less than Îµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Functions-for-stopping-criteria","page":"Stopping Criteria","title":"Functions for stopping criteria","text":"","category":"section"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"There are a few functions to update, combine, and modify stopping criteria, especially to update internal values even for stopping criteria already being used within an AbstractManoptSolverState structure.","category":"page"},{"location":"plans/stopping_criteria/#Base.:&-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","page":"Stopping Criteria","title":"Base.:&","text":"&(s1,s2)\ns1 & s2\n\nCombine two StoppingCriterion within an StopWhenAll. If either s1 (or s2) is already an StopWhenAll, then s2 (or s1) is appended to the list of StoppingCriterion within s1 (or s2).\n\nExample\n\na = StopAfterIteration(200) & StopWhenChangeLess(M, 1e-6)\nb = a & StopWhenGradientNormLess(1e-6)\n\nIs the same as\n\na = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6))\nb = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6), StopWhenGradientNormLess(1e-6))\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Base.:|-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","page":"Stopping Criteria","title":"Base.:|","text":"|(s1,s2)\ns1 | s2\n\nCombine two StoppingCriterion within an StopWhenAny. If either s1 (or s2) is already an StopWhenAny, then s2 (or s1) is appended to the list of StoppingCriterion within s1 (or s2)\n\nExample\n\na = StopAfterIteration(200) | StopWhenChangeLess(M, 1e-6)\nb = a | StopWhenGradientNormLess(1e-6)\n\nIs the same as\n\na = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6))\nb = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6), StopWhenGradientNormLess(1e-6))\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_active_stopping_criteria-Tuple{sCS} where sCS<:StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.get_active_stopping_criteria","text":"get_active_stopping_criteria(c)\n\nreturns all active stopping criteria, if any, that are within a StoppingCriterion c, and indicated a stop, that is their reason is nonempty. To be precise for a simple stopping criterion, this returns either an empty array if no stop is indicated or the stopping criterion as the only element of an array. For a StoppingCriterionSet all internal (even nested) criteria that indicate to stop are returned.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_reason-Tuple{AbstractManoptSolverState}","page":"Stopping Criteria","title":"Manopt.get_reason","text":"get_reason(s::AbstractManoptSolverState)\n\nreturn the current reason stored within the StoppingCriterion from within the AbstractManoptSolverState. This reason is empty (\"\") if the criterion has never been met.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_stopping_criteria-Tuple{S} where S<:StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.get_stopping_criteria","text":"get_stopping_criteria(c)\n\nreturn the array of internally stored StoppingCriterions for a StoppingCriterionSet c.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.indicates_convergence-Tuple{StoppingCriterion}","page":"Stopping Criteria","title":"Manopt.indicates_convergence","text":"indicates_convergence(c::StoppingCriterion)\n\nReturn whether (true) or not (false) a StoppingCriterion does always mean that, when it indicates to stop, the solver has converged to a minimizer or critical point.\n\nNote that this is independent of the actual state of the stopping criterion, whether some of them indicate to stop, but a purely type-based, static decision.\n\nExamples\n\nWith s1=StopAfterIteration(20) and s2=StopWhenGradientNormLess(1e-7) the indicator yields\n\nindicates_convergence(s1) is false\nindicates_convergence(s2) is true\nindicates_convergence(s1 | s2) is false, since this might also stop after 20 iterations\nindicates_convergence(s1 & s2) is true, since s2 is fulfilled if this stops.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopAfter, Val{:MaxTime}, Dates.Period}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopAfter, :MaxTime, v::Period)\n\nUpdate the time period after which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopAfterIteration, Val{:MaxIteration}, Int64}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopAfterIteration, :;MaxIteration, v::Int)\n\nUpdate the number of iterations after which the algorithm should stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenChangeLess, Val{:MinIterateChange}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenChangeLess, :MinIterateChange, v::Int)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenCostLess, Val{:MinCost}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenCostLess, :MinCost, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenEntryChangeLess, Val{:Threshold}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenEntryChangeLess, :Threshold, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenGradientChangeLess, Val{:MinGradientChange}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenGradientChangeLess, :MinGradientChange, v)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenGradientNormLess, Val{:MinGradNorm}, Float64}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenGradientNormLess, :MinGradNorm, v::Float64)\n\nUpdate the minimal gradient norm when an algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenStepsizeLess, Val{:MinStepsize}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenStepsizeLess, :MinStepsize, v)\n\nUpdate the minimal step size below which the algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenSubgradientNormLess, Val{:MinSubgradNorm}, Float64}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenSubgradientNormLess, :MinSubgradNorm, v::Float64)\n\nUpdate the minimal subgradient norm when an algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"tutorials/HowToRecord/#How-to-record-data-during-the-iterations","page":"Record values","title":"How to record data during the iterations","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"The recording and debugging features make it possible to record nearly any data during the iterations. This tutorial illustrates how to:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"record one value during the iterations;\nrecord multiple values during the iterations and access them afterwards;\nrecord within a subsolver\ndefine an own RecordAction to perform individual recordings.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Several predefined recordings exist, for example RecordCost or RecordGradient, if the problem the solver uses provides a gradient. For fields of the State the recording can also be done RecordEntry. For other recordings, for example more advanced computations before storing a value, an own RecordAction can be defined.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We illustrate these using the gradient descent from the Get started: optimize tutorial.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Here the focus is put on ways to investigate the behaviour during iterations by using Recording techniques.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Letâ€™s first load the necessary packages.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"using Manopt, Manifolds, Random, ManifoldDiff, LinearAlgebra\nusing ManifoldDiff: grad_distance\nRandom.seed!(42);","category":"page"},{"location":"tutorials/HowToRecord/#The-objective","page":"Record values","title":"The objective","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We generate data and define our cost and gradient:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Random.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nÏƒ = Ï€ / 8\nx = zeros(Float64, m + 1)\nx[2] = 1.0\ndata = [exp(M, x, Ïƒ * rand(M; vector_at=x)) for i in 1:n]\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"grad_f (generic function with 1 method)","category":"page"},{"location":"tutorials/HowToRecord/#First-examples","page":"Record values","title":"First examples","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"For the high level interfaces of the solvers, like gradient_descent we have to set return_state to true to obtain the whole solver state and not only the resulting minimizer.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Then we can easily use the record= option to add recorded values. This keyword accepts RecordActions as well as several symbols as shortcuts, for example :Cost to record the cost, or if your options have a field f, :f would record that entry. An overview of the symbols that can be used is given here.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We first just record the cost after every iteration","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R = gradient_descent(M, f, grad_f, data[1]; record=:Cost, return_state=true)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 58 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordCost(),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"From the returned state, we see that the GradientDescentState are encapsulated (decorated) within a RecordSolverState.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"For such a state, one can attach different recorders to some operations, currently to :Start. :Stop, and :Iteration, where :Iteration is the default when using the record= keyword with a RecordAction or a Symbol as we just did. We can access all values recorded during the iterations by calling get_record(R, :Iteation) or since this is the default even shorter","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"58-element Vector{Float64}:\n 0.6870172325261714\n 0.6239221496686211\n 0.5900244338953802\n 0.569312079535616\n 0.551804825865545\n 0.5429045359832491\n 0.5383847696671529\n 0.5360322830268692\n 0.5348144739486789\n 0.5341773307679919\n 0.5338452512001082\n 0.5336712822308554\n 0.533580331120935\n â‹®\n 0.5334801024530476\n 0.5334801024530282\n 0.5334801024530178\n 0.5334801024530125\n 0.5334801024530096\n 0.5334801024530081\n 0.5334801024530073\n 0.5334801024530066\n 0.5334801024530061\n 0.5334801024530059\n 0.5334801024530059\n 0.5334801024530059","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"To record more than one value, you can pass an array of a mix of symbols and RecordActions which formally introduces RecordGroup. Such a group records a tuple of values in every iteration:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R2 = gradient_descent(M, f, grad_f, data[1]; record=[:Iteration, :Cost], return_state=true)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 58 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Here, the symbol :Cost is mapped to using the RecordCost action. The same holds for :Iteration obviously records the current iteration number i. To access these you can first extract the group of records (that is where the :Iterations are recorded; note the plural) and then access the :Cost â€œâ€œâ€","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record_action(R2, :Iteration)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"RecordGroup([RecordIteration(), RecordCost()])","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Since iteration is the default, we can also omit it here again. To access single recorded values, one can use","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record_action(R2)[:Cost]","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"58-element Vector{Float64}:\n 0.6870172325261714\n 0.6239221496686211\n 0.5900244338953802\n 0.569312079535616\n 0.551804825865545\n 0.5429045359832491\n 0.5383847696671529\n 0.5360322830268692\n 0.5348144739486789\n 0.5341773307679919\n 0.5338452512001082\n 0.5336712822308554\n 0.533580331120935\n â‹®\n 0.5334801024530476\n 0.5334801024530282\n 0.5334801024530178\n 0.5334801024530125\n 0.5334801024530096\n 0.5334801024530081\n 0.5334801024530073\n 0.5334801024530066\n 0.5334801024530061\n 0.5334801024530059\n 0.5334801024530059\n 0.5334801024530059","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"This can be also done by using a the high level interface get_record","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R2, :Iteration, :Cost)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"58-element Vector{Float64}:\n 0.6870172325261714\n 0.6239221496686211\n 0.5900244338953802\n 0.569312079535616\n 0.551804825865545\n 0.5429045359832491\n 0.5383847696671529\n 0.5360322830268692\n 0.5348144739486789\n 0.5341773307679919\n 0.5338452512001082\n 0.5336712822308554\n 0.533580331120935\n â‹®\n 0.5334801024530476\n 0.5334801024530282\n 0.5334801024530178\n 0.5334801024530125\n 0.5334801024530096\n 0.5334801024530081\n 0.5334801024530073\n 0.5334801024530066\n 0.5334801024530061\n 0.5334801024530059\n 0.5334801024530059\n 0.5334801024530059","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Note that the first symbol again refers to the point where we record (not to the thing we record). We can also pass a tuple as second argument to have our own order within the tuples returned. Switching the order of recorded cost and Iteration can be done using â€œâ€œâ€","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R2, :Iteration, (:Iteration, :Cost))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"58-element Vector{Tuple{Int64, Float64}}:\n (1, 0.6870172325261714)\n (2, 0.6239221496686211)\n (3, 0.5900244338953802)\n (4, 0.569312079535616)\n (5, 0.551804825865545)\n (6, 0.5429045359832491)\n (7, 0.5383847696671529)\n (8, 0.5360322830268692)\n (9, 0.5348144739486789)\n (10, 0.5341773307679919)\n (11, 0.5338452512001082)\n (12, 0.5336712822308554)\n (13, 0.533580331120935)\n â‹®\n (47, 0.5334801024530476)\n (48, 0.5334801024530282)\n (49, 0.5334801024530178)\n (50, 0.5334801024530125)\n (51, 0.5334801024530096)\n (52, 0.5334801024530081)\n (53, 0.5334801024530073)\n (54, 0.5334801024530066)\n (55, 0.5334801024530061)\n (56, 0.5334801024530059)\n (57, 0.5334801024530059)\n (58, 0.5334801024530059)","category":"page"},{"location":"tutorials/HowToRecord/#A-more-complex-example","page":"Record values","title":"A more complex example","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"To illustrate a complicated example letâ€™s record:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"the iteration number, cost and gradient field, but only every sixth iteration;\nthe iteration at which we stop.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We first generate the problem and the state, to also illustrate the low-level works when not using the high-level interface gradient_descent.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"p = DefaultManoptProblem(M, ManifoldGradientObjective(f, grad_f))\ns = GradientDescentState(\n    M;\n    p=copy(data[1]),\n    stopping_criterion=StopAfterIteration(200) | StopWhenGradientNormLess(10.0^-9),\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We now first build a RecordGroup to group the three entries we want to record per iteration. We then put this into a RecordEvery to only record this every sixth iteration","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"rI = RecordEvery(\n    RecordGroup([\n        RecordIteration() => :Iteration,\n        RecordCost() => :Cost,\n        RecordEntry(similar(data[1]), :X) => :Gradient,\n    ]),\n    6,\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"where the notation as a pair with the symbol can be read as â€œIs accessible byâ€. The record= keyword with the symbol :Iteration is actually the same as we specified here for the first group entry. For recording the final iteration number","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"sI = RecordIteration()","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"RecordIteration()","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We now combine both into the RecordSolverState decorator. It acts completely the same as any AbstractManoptSolverState but records something in every iteration additionally. This is stored in a dictionary of RecordActions, where :Iteration is the action (here the only every sixth iteration group) and the sI which is executed at stop.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Note that the keyword record= in the high level interface gradient_descent only would fill the :Iteration symbol of said dictionary, but we could also pass pairs like in the following, that is in the form Symbol => RecordAction into that keyword to obtain the same as in","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"r = RecordSolverState(s, Dict(:Iteration => rI, :Stop => sI))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration())","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We now call the solver","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"res = solve!(p, r)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 63 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration())","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"And we can look at the recorded value at :Stop to see how many iterations were performed","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(res, :Stop)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"1-element Vector{Int64}:\n 63","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"and the other values during the iterations are","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(res, :Iteration, (:Iteration, :Cost))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"10-element Vector{Tuple{Int64, Float64}}:\n (6, 0.5429045359832491)\n (12, 0.5336712822308554)\n (18, 0.5334840986243338)\n (24, 0.5334801877032023)\n (30, 0.5334801043129838)\n (36, 0.5334801024945817)\n (42, 0.5334801024539585)\n (48, 0.5334801024530282)\n (54, 0.5334801024530066)\n (60, 0.5334801024530057)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"where the last tuple contains the names from the pairs when we generated the record group. So similarly we can use :Gradient as specified before to access the recorded gradient.","category":"page"},{"location":"tutorials/HowToRecord/#Recording-from-a-Subsolver","page":"Record values","title":"Recording from a Subsolver","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"One can also record from a subsolver. For that we need a problem that actually requires a subsolver. We take the constraint example from the How to print debug tutorial. Maybe read that part for more details on the problem","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"d = 4\nM2 = Sphere(d - 1)\nv0 = project(M2, [ones(2)..., zeros(d - 2)...])\nZ = v0 * v0'\n#Cost and gradient\nf2(M, p) = -tr(transpose(p) * Z * p) / 2\ngrad_f2(M, p) = project(M, p, -transpose.(Z) * p / 2 - Z * p / 2)\n# Constraints\ng(M, p) = -p # now p â‰¥ 0\nmI = -Matrix{Float64}(I, d, d)\n# Vector of gradients of the constraint components\ngrad_g(M, p) = [project(M, p, mI[:, i]) for i in 1:d]\np0 = project(M2, [ones(2)..., zeros(d - 3)..., 0.1])","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We directly start with recording the sub solvers Iteration. We can specify what to record in the subsolver using the sub_kwargs keyword argument with a Symbol => value pair. Here we specify to record the iteration and the cost in every sub solvers step.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Furthermore, we have to â€œcollectâ€ this recording after every sub solver run. This is done with the :Subsolver keyword in the main record= keyword.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"s1 = exact_penalty_method(\n    M2,\n    f2,\n    grad_f2,\n    p0;\n    g = g,\n    grad_g = grad_g,\n    record = [:Iteration, :Cost, :Subsolver],\n    sub_kwargs = [:record => [:Iteration, :Cost]],\n    return_state=true,\n);","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Then the first entry of the record contains the iterate, the (main solvers) cost, and the third entry is the recording of the subsolver.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(s1)[1]","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"(1, -0.4733019623455375, [(1, -0.4288382393589549), (2, -0.43669534259556914), (3, -0.4374036673499917), (4, -0.43744087180862923)])","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"When adding a number to not record on every iteration, the :Subsolver keyword of course still also only â€œcopies overâ€ the subsolver recordings when active. But one could avoid allocations on the other runs. This is done, by specifying the sub solver as :WhenActive","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"s2 = exact_penalty_method(\n    M2,\n    f2,\n    grad_f2,\n    p0;\n    g = g,\n    grad_g = grad_g,\n    record = [:Iteration, :Cost, :Subsolver, 25],\n    sub_kwargs = [:record => [:Iteration, :Cost, :WhenActive]],\n    return_state=true,\n);","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Then","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(s2)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"4-element Vector{Tuple{Int64, Float64, Vector{Tuple{Int64, Float64}}}}:\n (25, -0.4994494108530985, [(1, -0.4991469152295235)])\n (50, -0.49999564261147317, [(1, -0.49999366842932896)])\n (75, -0.49999997420136083, [(1, -0.4999999614701454)])\n (100, -0.4999999998337046, [(1, -0.49999999981081666)])","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Finally, instead of recording iterations, we can also specify to record the stopping criterion and final cost by adding that to :Stop of the sub solvers record. Then we can specify, as usual in a tuple, that the :Subsolver should record :Stop (by default it takes over :Iteration)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"s3 = exact_penalty_method(\n    M2,\n    f2,\n    grad_f2,\n    p0;\n    g = g,\n    grad_g = grad_g,\n    record = [:Iteration, :Cost, (:Subsolver, :Stop), 25],\n    sub_kwargs = [:record => [:Stop => [:Stop, :Cost]]],\n    return_state=true,\n);","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Then the following displays also the reasons why each of the recorded sub solvers stopped and the corresponding cost","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(s3)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"4-element Vector{Tuple{Int64, Float64, Vector{Tuple{String, Float64}}}}:\n (25, -0.4994494108530985, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (0.00031307624887101047) is less than 0.001.\\n\", -0.4991469152295235)])\n (50, -0.49999564261147317, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (0.0009767910400237622) is less than 0.001.\\n\", -0.49999366842932896)])\n (75, -0.49999997420136083, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (0.0002239629119661262) is less than 0.001.\\n\", -0.4999999614701454)])\n (100, -0.4999999998337046, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (3.8129640908105967e-6) is less than 0.001.\\n\", -0.49999999981081666)])","category":"page"},{"location":"tutorials/HowToRecord/#Writing-an-own-[RecordAction](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s","page":"Record values","title":"Writing an own RecordActions","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Letâ€™s investigate where we want to count the number of function evaluations, again just to illustrate, since for the gradient this is just one evaluation per iteration. We first define a cost, that counts its own calls.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"mutable struct MyCost{T}\n    data::T\n    count::Int\nend\nMyCost(data::T) where {T} = MyCost{T}(data, 0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    return sum(1 / (2 * length(c.data)) * distance.(Ref(M), Ref(x), c.data) .^ 2)\nend","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"and we define an own, new RecordAction, which is a functor, that is a struct that is also a function. The function we have to implement is similar to a single solver step in signature, since it might get called every iteration:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"mutable struct RecordCount <: RecordAction\n    recorded_values::Vector{Int}\n    RecordCount() = new(Vector{Int}())\nend\nfunction (r::RecordCount)(p::AbstractManoptProblem, ::AbstractManoptSolverState, i)\n    if i > 0\n        push!(r.recorded_values, Manopt.get_cost_function(get_objective(p)).count)\n    elseif i < 0 # reset if negative\n        r.recorded_values = Vector{Int}()\n    end\nend","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Now we can initialize the new cost and call the gradient descent. Note that this illustrates also the last use case since you can pass symbol-action pairs into the record=array.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"f3 = MyCost(data)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Now for the plain gradient descent, we have to modify the step (to a constant stepsize) and remove the default debug verification whether the cost increases (setting debug to []). We also only look at the first 20 iterations to keep this example small in recorded values. We call","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R3 = gradient_descent(\n    M,\n    f3,\n    grad_f,\n    data[1];\n    record=[:Iteration => [\n        :Iteration,\n        RecordCount() => :Count,\n        :Cost],\n    ],\n    stepsize = ConstantLength(1.0),\n    stopping_criterion=StopAfterIteration(20),\n    debug=[],\n    return_state=true,\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 20 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nConstantLength(1.0; type=:relative)\n\n## Stopping criterion\n\nMax Iteration 20:   reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCount([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]), RecordCost()]),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"For :Cost we already learned how to access them, the => :Count introduces an action to obtain the :Count symbol as its access. We can again access the whole sets of records","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R3)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"20-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 1, 0.5823814423113639)\n (2, 2, 0.540804980234004)\n (3, 3, 0.5345550944722898)\n (4, 4, 0.5336375289938887)\n (5, 5, 0.5335031591890169)\n (6, 6, 0.5334834802310252)\n (7, 7, 0.5334805973984544)\n (8, 8, 0.5334801749902928)\n (9, 9, 0.5334801130855078)\n (10, 10, 0.5334801040117543)\n (11, 11, 0.5334801026815558)\n (12, 12, 0.5334801024865219)\n (13, 13, 0.5334801024579218)\n (14, 14, 0.5334801024537273)\n (15, 15, 0.5334801024531121)\n (16, 16, 0.5334801024530218)\n (17, 17, 0.5334801024530087)\n (18, 18, 0.5334801024530067)\n (19, 19, 0.5334801024530065)\n (20, 20, 0.5334801024530064)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"this is equivalent to calling R[:Iteration]. Note that since we introduced :Count we can also access a single recorded value using","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R3[:Iteration, :Count]","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"20-element Vector{Int64}:\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n 10\n 11\n 12\n 13\n 14\n 15\n 16\n 17\n 18\n 19\n 20","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"and we see that the cost function is called once per iteration.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"If we use this counting cost and run the default gradient descent with Armijo line search, we can infer how many Armijo line search backtracks are preformed:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"f4 = MyCost(data)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"MyCost{Vector{Vector{Float64}}}([[-0.054658825167894595, -0.5592077846510423, -0.04738273828111257, -0.04682080720921302, 0.12279468849667038, 0.07171438895366239, -0.12930045409417057, -0.22102081626380404, -0.31805333254577767, 0.0065859500152017645  â€¦  -0.21999168261518043, 0.19570142227077295, 0.340909965798364, -0.0310802190082894, -0.04674431076254687, -0.006088297671169996, 0.01576037011323387, -0.14523596850249543, 0.14526158060820338, 0.1972125856685378], [-0.08192376929745249, -0.5097715132187676, -0.008339904915541005, 0.07289741328038676, 0.11422036270613797, -0.11546739299835748, 0.2296996932628472, 0.1490467170835958, -0.11124820565850364, -0.11790721606521781  â€¦  -0.16421249630470344, -0.2450575844467715, -0.07570080850379841, -0.07426218324072491, -0.026520181327346338, 0.11555341205250205, -0.0292955762365121, -0.09012096853677576, -0.23470556634911574, -0.026214242996704013], [-0.22951484264859257, -0.6083825348640186, 0.14273766477054015, -0.11947823367023377, 0.05984293499234536, 0.058820835498203126, 0.07577331705863266, 0.1632847202946857, 0.20244385489915745, 0.04389826920203656  â€¦  0.3222365119325929, 0.009728730325524067, -0.12094785371632395, -0.36322323926212824, -0.0689253407939657, 0.23356953371702974, 0.23489531397909744, 0.078303336494718, -0.14272984135578806, 0.07844539956202407], [-0.0012588500237817606, -0.29958740415089763, 0.036738459489123514, 0.20567651907595125, -0.1131046432541904, -0.06032435985370224, 0.3366633723165895, -0.1694687746143405, -0.001987171245125281, 0.04933779858684409  â€¦  -0.2399584473006256, 0.19889267065775063, 0.22468755918787048, 0.1780090580180643, 0.023703860700539356, -0.10212737517121755, 0.03807004103115319, -0.20569120952458983, -0.03257704254233959, 0.06925473452536687], [-0.035534309946938375, -0.06645560787329002, 0.14823972268208874, -0.23913346587232426, 0.038347027875883496, 0.10453333143286662, 0.050933995140290705, -0.12319549375687473, 0.12956684644537844, -0.23540367869989412  â€¦  -0.41471772859912864, -0.1418984610380257, 0.0038321446836859334, 0.23655566917750157, -0.17500681300994742, -0.039189751036839374, -0.08687860620942896, -0.11509948162959047, 0.11378233994840942, 0.38739450723013735], [-0.3122539912469438, -0.3101935557860296, 0.1733113629107006, 0.08968593616209351, -0.1836344261367962, -0.06480023695256802, 0.18165070013886545, 0.19618275767992124, -0.07956460275570058, 0.0325997354656551  â€¦  0.2845492418767769, 0.17406455870721682, -0.053101230371568706, -0.1382082812981627, 0.005830071475508364, 0.16739264037923055, 0.034365814374995335, 0.09107702398753297, -0.1877250428700409, 0.05116494897806923], [-0.04159442361185588, -0.7768029783272633, 0.06303616666722486, 0.08070518925253539, -0.07396265237309446, -0.06008109299719321, 0.07977141629715745, 0.019511027129056415, 0.08629917589924847, -0.11156298867318722  â€¦  0.0792587504128044, -0.016444383900170008, -0.181746064577005, -0.01888129512990984, -0.13523922089388968, 0.11358102175659832, 0.07929049608459493, 0.1689565359083833, 0.07673657951723721, -0.1128480905648813], [-0.21221814304651335, -0.5031823821503253, 0.010326342133992458, -0.12438192100961257, 0.04004758695231872, 0.2280527500843805, -0.2096243232022162, -0.16564828762420294, -0.28325749481138984, 0.17033534605245823  â€¦  -0.13599096505924074, 0.28437770540525625, 0.08424426798544583, -0.1266207606984139, 0.04917635557603396, -0.00012608938533809706, -0.04283220254770056, -0.08771365647566572, 0.14750169103093985, 0.11601120086036351], [0.10683290707435536, -0.17680836277740156, 0.23767458301899405, 0.12011180867097299, -0.029404774462600154, 0.11522028383799933, -0.3318174480974519, -0.17859266746938374, 0.04352373642537759, 0.2530382802667988  â€¦  0.08879861736692073, -0.004412506987801729, 0.19786810509925895, -0.1397104682727044, 0.09482328498485094, 0.05108149065160893, -0.14578343506951633, 0.3167479772660438, 0.10422673169182732, 0.21573150015891313], [-0.024895624707466164, -0.7473912016432697, -0.1392537238944721, -0.14948896791465557, -0.09765393283580377, 0.04413059403279867, -0.13865379004720355, -0.071032040283992, 0.15604054722246585, -0.10744260463413555  â€¦  -0.14748067081342833, -0.14743635071251024, 0.0643591937981352, 0.16138827697852615, -0.12656652133603935, -0.06463635704869083, 0.14329582429103488, -0.01113113793821713, 0.29295387893749997, 0.06774523575259782]  â€¦  [0.011874845316569967, -0.6910596618389588, 0.21275741439477827, -0.014042545524367437, -0.07883613103495014, -0.0021900966696246776, -0.033836430464220496, 0.2925813113264835, -0.04718187201980008, 0.03949680289730036  â€¦  0.0867736586603294, 0.0404682510051544, -0.24779813848587257, -0.28631514602877145, -0.07211767532456789, -0.15072898498180473, 0.017855923621826746, -0.09795357710255254, -0.14755229203084924, 0.1305005778855436], [0.013457629515450426, -0.3750353654626534, 0.12349883726772073, 0.3521803555005319, 0.2475921439420274, 0.006088649842999206, 0.31203183112392907, -0.036869203979483754, -0.07475746464056504, -0.029297797064479717  â€¦  0.16867368684091563, -0.09450564983271922, -0.0587273302122711, -0.1326667940553803, -0.25530237980444614, 0.37556905374043376, 0.04922612067677609, 0.2605362549983866, -0.21871556587505667, -0.22915883767386164], [0.03295085436260177, -0.971861604433394, 0.034748713521512035, -0.0494065013245799, -0.01767479281403355, 0.0465459739459587, 0.007470494722096038, 0.003227960072276129, 0.0058328596338402365, -0.037591237446692356  â€¦  0.03205152122876297, 0.11331109854742015, 0.03044900529526686, 0.017971704993311105, -0.009329252062960229, -0.02939354719650879, 0.022088835776251863, -0.02546111553658854, -0.0026257225461427582, 0.005702111697172774], [0.06968243992532257, -0.7119502191435176, -0.18136614593117445, -0.1695926215673451, 0.01725015359973796, -0.00694164951158388, -0.34621134287344574, 0.024709256792651912, -0.1632255805999673, -0.2158226433583082  â€¦  -0.14153772108081458, -0.11256850346909901, 0.045109821764180706, -0.1162754336222613, -0.13221711766357983, 0.005365354776191061, 0.012750671705879105, -0.018208207549835407, 0.12458753932455452, -0.31843587960340897], [-0.19830349374441875, -0.6086693423968884, 0.08552341811170468, 0.35781519334042255, 0.15790663648524367, 0.02712571268324985, 0.09855601327331667, -0.05840653973421127, -0.09546429767790429, -0.13414717696055448  â€¦  -0.0430935804718714, 0.2678584478951765, 0.08780994289014614, 0.01613469379498457, 0.0516187906322884, -0.07383067566731401, -0.1481272738354552, -0.010532317187265649, 0.06555344745952187, -0.1506167863762911], [-0.04347524125197773, -0.6327981074196994, -0.221116680035191, 0.0282207467940456, -0.0855024881522933, 0.12821801740178346, 0.1779499563280024, -0.10247384887512365, 0.0396432464100116, -0.0582580338112627  â€¦  0.1253893207083573, 0.09628202269764763, 0.3165295473947355, -0.14915034201394833, -0.1376727867817772, -0.004153096613530293, 0.09277957650773738, 0.05917264554031624, -0.12230262590034507, -0.19655728521529914], [-0.10173946348675116, -0.6475660153977272, 0.1260284619729566, -0.11933160462857616, -0.04774310633937567, 0.09093928358804217, 0.041662676324043114, -0.1264739543938265, 0.09605293126911392, -0.16790474428001648  â€¦  -0.04056684573478108, 0.09351665120940456, 0.15259195558799882, 0.0009949298312580497, 0.09461980828206303, 0.3067004514287283, 0.16129258773733715, -0.18893664085007542, -0.1806865244492513, 0.029319680436405825], [-0.251780954320053, -0.39147463259941456, -0.24359579328578626, 0.30179309757665723, 0.21658893985206484, 0.12304585275893232, 0.28281133086451704, 0.029187615341955325, 0.03616243507191924, 0.029375588909979152  â€¦  -0.08071746662465404, -0.2176101928258658, 0.20944684921170825, 0.043033273425352715, -0.040505542460853576, 0.17935596149079197, -0.08454569418519972, 0.0545941597033932, 0.12471741052450099, -0.24314124407858329], [0.28156471341150974, -0.6708572780452595, -0.1410302363738465, -0.08322589397277698, -0.022772599832907418, -0.04447265789199677, -0.016448068022011157, -0.07490911512503738, 0.2778432295769144, -0.10191899088372378  â€¦  -0.057272155080983836, 0.12817478092201395, 0.04623814480781884, -0.12184190164369117, 0.1987855635987229, -0.14533603246124993, -0.16334072868597016, -0.052369977381939437, 0.014904286931394959, -0.2440882678882144], [0.12108727495744157, -0.714787344982596, 0.01632521838262752, 0.04437570556908449, -0.041199280304144284, 0.052984488452616, 0.03796520200156107, 0.2791785910964288, 0.11530429924056099, 0.12178223160398421  â€¦  -0.07621847481721669, 0.18353870423743013, -0.19066653731436745, -0.09423224997242206, 0.14596847781388494, -0.09747986927777111, 0.16041150122587072, -0.02296513951256738, 0.06786878373578588, 0.15296635978447756]], 0)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"To not get too many entries letâ€™s just look at the first 20 iterations again","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R4 = gradient_descent(\n    M,\n    f4,\n    grad_f,\n    data[1];\n    record=[RecordCount(),],\n    return_state=true,\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 58 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0\n    retraction_method=ExponentialRetraction()\n    contraction_factor=0.95\n    sufficient_decrease=0.1\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordCount([25, 29, 33, 37, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 229, 232, 237, 241, 245, 247, 249]),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R4)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"58-element Vector{Int64}:\n  25\n  29\n  33\n  37\n  40\n  44\n  48\n  52\n  56\n  60\n  64\n  68\n  72\n   â‹®\n 208\n 212\n 216\n 220\n 224\n 229\n 232\n 237\n 241\n 245\n 247\n 249","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We can see that the number of cost function calls varies, depending on how many line search backtrack steps were required to obtain a good stepsize.","category":"page"},{"location":"tutorials/HowToRecord/#Technical-details","page":"Record values","title":"Technical details","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"2025-04-25T12:13:12.482","category":"page"},{"location":"solvers/ChambollePock/#The-Riemannian-Chambolle-Pock-algorithm","page":"Chambolle-Pock","title":"The Riemannian Chambolle-Pock algorithm","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"The Riemannian Chambolleâ€”Pock is a generalization of the Chambolleâ€”Pock algorithm Chambolle and Pock [CP11] It is also known as primal-dual hybrid gradient (PDHG) or primal-dual proximal splitting (PDPS) algorithm.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"In order to minimize over pmathcal M the cost function consisting of In order to minimize a cost function consisting of","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"F(p) + G(Î›(p))","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"over pmathcal M","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"where Fmathcal M  overlineâ„, Gmathcal N  overlineâ„, and Î›mathcal M mathcal N. If the manifolds mathcal M or mathcal N are not Hadamard, it has to be considered locally only, that is on geodesically convex sets mathcal C subset mathcal M and mathcal D subsetmathcal N such that Î›(mathcal C) subset mathcal D.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"The algorithm is available in four variants: exact versus linearized (see variant) as well as with primal versus dual relaxation (see relax). For more details, see Bergmann, Herzog, Silva Louzeiro, Tenbrinck and Vidal-NÃºÃ±ez [BHS+21]. In the following description is the case of the exact, primal relaxed Riemannian Chambolleâ€”Pock algorithm.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Given base points mmathcal C, n=Î›(m)mathcal D, initial primal and dual values p^(0) mathcal C, Î¾_n^(0) T_n^*mathcal N, and primal and dual step sizes sigma_0, tau_0, relaxation theta_0, as well as acceleration gamma.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"As an initialization, perform bar p^(0) gets p^(0).","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"The algorithms performs the steps k=1 (until a StoppingCriterion is fulfilled with)","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Î¾^(k+1)_n = operatornameprox_tau_k G_n^*Bigl(Î¾_n^(k) + tau_k bigl(log_n Î› (bar p^(k))bigr)^flatBigr)\np^(k+1) = operatornameprox_sigma_k Fbiggl(exp_p^(k)Bigl( operatornamePT_p^(k)gets mbigl(-sigma_k DÎ›(m)^*Î¾_n^(k+1)bigr)^sharpBigr)biggr)\nUpdate\ntheta_k = (1+2gammasigma_k)^-frac12\nsigma_k+1 = sigma_ktheta_k\ntau_k+1 =  fractau_ktheta_k\nbar p^(k+1)  = exp_p^(k+1)bigl(-theta_k log_p^(k+1) p^(k)bigr)","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Furthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction, and a vector transport.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Finally you can also update the base points m and n during the iterations. This introduces a few additional vector transports. The same holds for the case Î›(m^(k))neq n^(k) at some point. All these cases are covered in the algorithm.","category":"page"},{"location":"solvers/ChambollePock/#Manopt.ChambollePock","page":"Chambolle-Pock","title":"Manopt.ChambollePock","text":"ChambollePock(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\nChambollePock!(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\n\nPerform the Riemannian Chambolleâ€”Pock algorithm.\n\nGiven a cost function mathcal Emathcal M  â„ of the form\n\nmathcal f(p) = F(p) + G( Î›(p) )\n\nwhere Fmathcal M  â„, Gmathcal N  â„, and Î›mathcal M  mathcal N.\n\nThis can be done inplace of p.\n\nInput parameters\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nN::AbstractManifold: a Riemannian manifold mathcal M\np: a point on the manifold mathcal M\nX: a tangent vector at the point p on the manifold mathcal M\nm: a point on the manifold mathcal M\nn: a point on the manifold mathcal N\nadjoint_linearized_operator:  the adjoint DÎ›^* of the linearized operator DÎ› T_mmathcal M  T_Î›(m)mathcal N)\nprox_F, prox_G_Dual:          the proximal maps of F and G^ast_n\n\nnote that depending on the AbstractEvaluationType evaluation the last three parameters as well as the forward operator Î› and the linearized_forward_operator can be given as allocating functions (Manifolds, parameters) -> result  or as mutating functions (Manifold, result, parameters) -> result` to spare allocations.\n\nBy default, this performs the exact Riemannian Chambolle Pock algorithm, see the optional parameter DÎ› for their linearized variant.\n\nFor more details on the algorithm, see [BHS+21].\n\nKeyword Arguments\n\nacceleration=0.05: acceleration parameter\ndual_stepsize=1/sqrt(8): proximal parameter of the primal prox\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual=default_inverse_retraction_method(N, typeof(n)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the (forward) operator Î›() (required for the :exact variant)\nlinearized_forward_operator=missing: its linearization DÎ›() (required for the :linearized variant)\nprimal_stepsize=1/sqrt(8): proximal parameter of the dual prox\nrelaxation=1.: the relaxation parameter Î³\nrelax=:primal: whether to relax the primal or dual\nvariant=:exact if Î› is missing, otherwise :linearized: variant to use. Note that this changes the arguments the forward_operator is called with.\nstopping_criterion=StopAfterIteration`(100): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual=default_vector_transport_method(N, typeof(n)): a vector transport mathcal T_ to use, see the section on vector transports\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.ChambollePock!","page":"Chambolle-Pock","title":"Manopt.ChambollePock!","text":"ChambollePock(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\nChambollePock!(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\n\nPerform the Riemannian Chambolleâ€”Pock algorithm.\n\nGiven a cost function mathcal Emathcal M  â„ of the form\n\nmathcal f(p) = F(p) + G( Î›(p) )\n\nwhere Fmathcal M  â„, Gmathcal N  â„, and Î›mathcal M  mathcal N.\n\nThis can be done inplace of p.\n\nInput parameters\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nN::AbstractManifold: a Riemannian manifold mathcal M\np: a point on the manifold mathcal M\nX: a tangent vector at the point p on the manifold mathcal M\nm: a point on the manifold mathcal M\nn: a point on the manifold mathcal N\nadjoint_linearized_operator:  the adjoint DÎ›^* of the linearized operator DÎ› T_mmathcal M  T_Î›(m)mathcal N)\nprox_F, prox_G_Dual:          the proximal maps of F and G^ast_n\n\nnote that depending on the AbstractEvaluationType evaluation the last three parameters as well as the forward operator Î› and the linearized_forward_operator can be given as allocating functions (Manifolds, parameters) -> result  or as mutating functions (Manifold, result, parameters) -> result` to spare allocations.\n\nBy default, this performs the exact Riemannian Chambolle Pock algorithm, see the optional parameter DÎ› for their linearized variant.\n\nFor more details on the algorithm, see [BHS+21].\n\nKeyword Arguments\n\nacceleration=0.05: acceleration parameter\ndual_stepsize=1/sqrt(8): proximal parameter of the primal prox\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual=default_inverse_retraction_method(N, typeof(n)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the (forward) operator Î›() (required for the :exact variant)\nlinearized_forward_operator=missing: its linearization DÎ›() (required for the :linearized variant)\nprimal_stepsize=1/sqrt(8): proximal parameter of the dual prox\nrelaxation=1.: the relaxation parameter Î³\nrelax=:primal: whether to relax the primal or dual\nvariant=:exact if Î› is missing, otherwise :linearized: variant to use. Note that this changes the arguments the forward_operator is called with.\nstopping_criterion=StopAfterIteration`(100): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual=default_vector_transport_method(N, typeof(n)): a vector transport mathcal T_ to use, see the section on vector transports\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#State","page":"Chambolle-Pock","title":"State","text":"","category":"section"},{"location":"solvers/ChambollePock/#Manopt.ChambollePockState","page":"Chambolle-Pock","title":"Manopt.ChambollePockState","text":"ChambollePockState <: AbstractPrimalDualSolverState\n\nstores all options and variables within a linearized or exact Chambolle Pock.\n\nFields\n\nacceleration::R:    acceleration factor\ndual_stepsize::R:   proximal parameter of the dual prox\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nm::P:               base point on mathcal M\nn::Q:               base point on mathcal N\np::P:               an initial point on p^(0)  mathcal M\npbar::P:            the relaxed iterate used in the next dual update step (when using :primal relaxation)\nprimal_stepsize::R: proximal parameter of the primal prox\nX::T:               an initial tangent vector X^(0)  T_p^(0)mathcal M\nXbar::T:            the relaxed iterate used in the next primal update step (when using :dual relaxation)\nrelaxation::R:      relaxation in the primal relaxation step (to compute pbar:\nrelax::Symbol:       which variable to relax (:primalor:dual`:\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nvariant:            whether to perform an :exact or :linearized Chambolle-Pock\nupdate_primal_base: function (pr, st, k) -> m to update the primal base\nupdate_dual_base:  function (pr, st, k) -> n to update the dual base\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nHere, P is a point type on mathcal M, T its tangent vector type, Q a point type on mathcal N, and R<:Real is a real number type\n\nwhere for the last two the functions a AbstractManoptProblemp, AbstractManoptSolverStateo and the current iterate i are the arguments. If you activate these to be different from the default identity, you have to provide p.Î› for the algorithm to work (which might be missing in the linearized case).\n\nConstructor\n\nChambollePockState(M::AbstractManifold, N::AbstractManifold;\n    kwargs...\n) where {P, Q, T, R <: Real}\n\nKeyword arguments\n\nn=[rand](@extref Base.rand-Tuple{AbstractManifold})(N)`\np=rand(M)\nm=rand(M)\nX=zero_vector(M, p)\nacceleration=0.0\ndual_stepsize=1/sqrt(8)\nprimal_stepsize=1/sqrt(8)\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual=default_inverse_retraction_method(N, typeof(n)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nrelaxation=1.0\nrelax=:primal: relax the primal variable by default\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(300): a functor indicating that the stopping criterion is fulfilled\nvariant=:exact: run the exact Chambolle Pock by default\nupdate_primal_base=missing\nupdate_dual_base=missing\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual=default_vector_transport_method(N, typeof(n)): a vector transport mathcal T_ to use, see the section on vector transports\n\nif Manifolds.jl is loaded, N is also a keyword argument and set to TangentBundle(M) by default.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Useful-terms","page":"Chambolle-Pock","title":"Useful terms","text":"","category":"section"},{"location":"solvers/ChambollePock/#Manopt.primal_residual","page":"Chambolle-Pock","title":"Manopt.primal_residual","text":"primal_residual(p, o, x_old, X_old, n_old)\n\nCompute the primal residual at current iterate k given the necessary values x_k-1 X_k-1, and n_k-1 from the previous iterate.\n\nBigllVert\nfrac1Ïƒoperatornameretr^-1_x_kx_k-1 -\nV_x_kgets m_kbigl(DÎ›^*(m_k)biglV_n_kgets n_k-1X_k-1 - X_k bigr\nBigrrVert\n\nwhere V_gets is the vector transport used in the ChambollePockState\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.dual_residual","page":"Chambolle-Pock","title":"Manopt.dual_residual","text":"dual_residual(p, o, x_old, X_old, n_old)\n\nCompute the dual residual at current iterate k given the necessary values x_k-1 X_k-1, and n_k-1 from the previous iterate. The formula is slightly different depending on the o.variant used:\n\nFor the :linearized it reads\n\nBigllVert\nfrac1Ï„bigl(\nV_n_kgets n_k-1(X_k-1)\n- X_k\nbigr)\n-\nDÎ›(m_k)bigl\nV_m_kgets x_koperatornameretr^-1_x_kx_k-1\nbigr\nBigrrVert\n\nand for the :exact variant\n\nBigllVert\nfrac1Ï„ V_n_kgets n_k-1(X_k-1)\n-\noperatornameretr^-1_n_kbigl(\nÎ›(operatornameretr_m_k(V_m_kgets x_koperatornameretr^-1_x_kx_k-1))\nbigr)\nBigrrVert\n\nwhere in both cases V_gets is the vector transport used in the ChambollePockState.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Debug","page":"Chambolle-Pock","title":"Debug","text":"","category":"section"},{"location":"solvers/ChambollePock/#Manopt.DebugDualBaseIterate","page":"Chambolle-Pock","title":"Manopt.DebugDualBaseIterate","text":"DebugDualBaseIterate(io::IO=stdout)\n\nPrint the dual base variable by using DebugEntry, see their constructors for detail. This method is further set display o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualBaseChange","page":"Chambolle-Pock","title":"Manopt.DebugDualBaseChange","text":"DebugDualChange(; storage=StoreStateAction([:n]), io::IO=stdout)\n\nPrint the change of the dual base variable by using DebugEntryChange, see their constructors for detail, on o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalBaseIterate","page":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseIterate","text":"DebugPrimalBaseIterate()\n\nPrint the primal base variable by using DebugEntry, see their constructors for detail. This method is further set display o.m.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalBaseChange","page":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseChange","text":"DebugPrimalBaseChange(a::StoreStateAction=StoreStateAction([:m]),io::IO=stdout)\n\nPrint the change of the primal base variable by using DebugEntryChange, see their constructors for detail, on o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualChange","page":"Chambolle-Pock","title":"Manopt.DebugDualChange","text":"DebugDualChange(opts...)\n\nPrint the change of the dual variable, similar to DebugChange, see their constructors for detail, but with a different calculation of the change, since the dual variable lives in (possibly different) tangent spaces.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugDualIterate","page":"Chambolle-Pock","title":"Manopt.DebugDualIterate","text":"DebugDualIterate(e)\n\nPrint the dual variable by using DebugEntry, see their constructors for detail. This method is further set display o.X.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualResidual","page":"Chambolle-Pock","title":"Manopt.DebugDualResidual","text":"DebugDualResidual <: DebugAction\n\nA Debug action to print the dual residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugDualResidual(; kwargs...)\n\nKeyword warguments\n\nio=stdout`: stream to perform the debug to\nformat=\"$prefix%s\": format to print the dual residual, using the\nprefix=\"Dual Residual: \": short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalChange","page":"Chambolle-Pock","title":"Manopt.DebugPrimalChange","text":"DebugPrimalChange(opts...)\n\nPrint the change of the primal variable by using DebugChange, see their constructors for detail.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalIterate","page":"Chambolle-Pock","title":"Manopt.DebugPrimalIterate","text":"DebugPrimalIterate(opts...;kwargs...)\n\nPrint the change of the primal variable by using DebugIterate, see their constructors for detail.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalResidual","page":"Chambolle-Pock","title":"Manopt.DebugPrimalResidual","text":"DebugPrimalResidual <: DebugAction\n\nA Debug action to print the primal residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugPrimalResidual(; kwargs...)\n\nKeyword warguments\n\nio=stdout`: stream to perform the debug to\nformat=\"$prefix%s\": format to print the dual residual, using the\nprefix=\"Primal Residual: \": short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalDualResidual","page":"Chambolle-Pock","title":"Manopt.DebugPrimalDualResidual","text":"DebugPrimalDualResidual <: DebugAction\n\nA Debug action to print the primal dual residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugPrimalDualResidual()\n\nwith the keywords\n\nKeyword warguments\n\nio=stdout`: stream to perform the debug to\nformat=\"$prefix%s\": format to print the dual residual, using the\nprefix=\"PD Residual: \": short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Record","page":"Chambolle-Pock","title":"Record","text":"","category":"section"},{"location":"solvers/ChambollePock/#Manopt.RecordDualBaseIterate","page":"Chambolle-Pock","title":"Manopt.RecordDualBaseIterate","text":"RecordDualBaseIterate(n)\n\nCreate an RecordAction that records the dual base point, an RecordEntry of o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualBaseChange","page":"Chambolle-Pock","title":"Manopt.RecordDualBaseChange","text":"RecordDualBaseChange(e)\n\nCreate an RecordAction that records the dual base point change, an RecordEntryChange of o.n with distance to the last value to store a value.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualChange","page":"Chambolle-Pock","title":"Manopt.RecordDualChange","text":"RecordDualChange()\n\nCreate the action either with a given (shared) Storage, which can be set to the values Tuple, if that is provided).\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualIterate","page":"Chambolle-Pock","title":"Manopt.RecordDualIterate","text":"RecordDualIterate(X)\n\nCreate an RecordAction that records the dual base point, an RecordEntry of o.X.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalBaseIterate","page":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseIterate","text":"RecordPrimalBaseIterate(x)\n\nCreate an RecordAction that records the primal base point, an RecordEntry of o.m.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalBaseChange","page":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseChange","text":"RecordPrimalBaseChange()\n\nCreate an RecordAction that records the primal base point change, an RecordEntryChange of o.m with distance to the last value to store a value.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalChange","page":"Chambolle-Pock","title":"Manopt.RecordPrimalChange","text":"RecordPrimalChange(a)\n\nCreate an RecordAction that records the primal value change, RecordChange, to record the change of o.x.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalIterate","page":"Chambolle-Pock","title":"Manopt.RecordPrimalIterate","text":"RecordDualBaseIterate(x)\n\nCreate an RecordAction that records the dual base point, an RecordIterate of o.x.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Internals","page":"Chambolle-Pock","title":"Internals","text":"","category":"section"},{"location":"solvers/ChambollePock/#Manopt.update_prox_parameters!","page":"Chambolle-Pock","title":"Manopt.update_prox_parameters!","text":"update_prox_parameters!(o)\n\nupdate the prox parameters as described in Algorithm 2 of [CP11],\n\nÎ¸_n = frac1sqrt1+2Î³Ï„_n\nÏ„_n+1 = Î¸_nÏ„_n\nÏƒ_n+1 = fracÏƒ_nÎ¸_n\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#sec-cp-technical-details","page":"Chambolle-Pock","title":"Technical details","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"The ChambollePock solver requires the following functions of a manifold to be available for both the manifold mathcal Mand mathcal N","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= or retraction_method_dual= (for mathcal N) does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= or vector_transport_method_dual= (for mathcal N) does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points.","category":"page"},{"location":"solvers/ChambollePock/#Literature","page":"Chambolle-Pock","title":"Literature","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"R.Â Bergmann, R.Â Herzog, M.Â Silva Louzeiro, D.Â Tenbrinck and J.Â Vidal-NÃºÃ±ez. Fenchel duality theory and a primal-dual algorithm on Riemannian manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 21, 1465â€“1504 (2021), arXiv:1908.02022.\n\n\n\nA.Â Chambolle and T.Â Pock. A first-order primal-dual algorithm for convex problems with applications to imaging. JournalÂ ofÂ MathematicalÂ ImagingÂ andÂ Vision 40, 120â€“145 (2011).\n\n\n\n","category":"page"},{"location":"solvers/conjugate_residual/#Conjugate-residual-solver-in-a-Tangent-space","page":"Conjugate Residual","title":"Conjugate residual solver in a Tangent space","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Manopt.conjugate_residual","page":"Conjugate Residual","title":"Manopt.conjugate_residual","text":"conjugate_residual(TpM::TangentSpace, A, b, X=zero_vector(TpM))\nconjugate_residual(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X=zero_vector(TpM))\nconjugate_residual!(TpM::TangentSpace, A, b, X)\nconjugate_residual!(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\n\nCompute the solution of mathcal A(p)X + b(p) = 0_p, where\n\nmathcal A is a linear, symmetric operator on T_pmathcal M\nb is a vector field on the manifold\nX  T_pmathcal M is a tangent vector\n0_p is the zero vector T_pmathcal M.\n\nThis implementation follows Algorithm 3 in [LY24] and is initalised with X^(0) as the zero vector and\n\nthe initial residual r^(0) = -b(p) - mathcal A(p)X^(0)\nthe initial conjugate direction d^(0) = r^(0)\ninitialize Y^(0) = mathcal A(p)X^(0)\n\nperformed the following steps at iteration k=0 until the stopping_criterion is fulfilled.\n\ncompute a step size Î±_k = displaystylefrac r^(k) mathcal A(p)r^(k) _p mathcal A(p)d^(k) mathcal A(p)d^(k) _p\ndo a step X^(k+1) = X^(k) + Î±_kd^(k)\nupdate the residual r^(k+1) = r^(k) + Î±_k Y^(k)\ncompute Z = mathcal A(p)r^(k+1)\nUpdate the conjugate coefficient Î²_k = displaystylefrac r^(k+1) mathcal A(p)r^(k+1) _p r^(k) mathcal A(p)r^(k) _p\nUpdate the conjugate direction d^(k+1) = r^(k+1) + Î²_kd^(k)\nUpdate  Y^(k+1) = -Z + Î²_k Y^(k)\n\nNote that the right hand side of Step 7 is the same as evaluating mathcal Ad^(k+1), but avoids the actual evaluation\n\nInput\n\nTpM the TangentSpace as the domain\nA a symmetric linear operator on the tangent space (M, p, X) -> Y\nb a vector field on the tangent space (M, p) -> X\nX the initial tangent vector\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nstopping_criterion=StopAfterIteration(manifold_dimension(M)|StopWhenRelativeResidualLess(c,1e-8),  where c is lVert b rVert_: a functor indicating that the stopping criterion is fulfilled\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_residual/#Manopt.conjugate_residual!","page":"Conjugate Residual","title":"Manopt.conjugate_residual!","text":"conjugate_residual(TpM::TangentSpace, A, b, X=zero_vector(TpM))\nconjugate_residual(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X=zero_vector(TpM))\nconjugate_residual!(TpM::TangentSpace, A, b, X)\nconjugate_residual!(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\n\nCompute the solution of mathcal A(p)X + b(p) = 0_p, where\n\nmathcal A is a linear, symmetric operator on T_pmathcal M\nb is a vector field on the manifold\nX  T_pmathcal M is a tangent vector\n0_p is the zero vector T_pmathcal M.\n\nThis implementation follows Algorithm 3 in [LY24] and is initalised with X^(0) as the zero vector and\n\nthe initial residual r^(0) = -b(p) - mathcal A(p)X^(0)\nthe initial conjugate direction d^(0) = r^(0)\ninitialize Y^(0) = mathcal A(p)X^(0)\n\nperformed the following steps at iteration k=0 until the stopping_criterion is fulfilled.\n\ncompute a step size Î±_k = displaystylefrac r^(k) mathcal A(p)r^(k) _p mathcal A(p)d^(k) mathcal A(p)d^(k) _p\ndo a step X^(k+1) = X^(k) + Î±_kd^(k)\nupdate the residual r^(k+1) = r^(k) + Î±_k Y^(k)\ncompute Z = mathcal A(p)r^(k+1)\nUpdate the conjugate coefficient Î²_k = displaystylefrac r^(k+1) mathcal A(p)r^(k+1) _p r^(k) mathcal A(p)r^(k) _p\nUpdate the conjugate direction d^(k+1) = r^(k+1) + Î²_kd^(k)\nUpdate  Y^(k+1) = -Z + Î²_k Y^(k)\n\nNote that the right hand side of Step 7 is the same as evaluating mathcal Ad^(k+1), but avoids the actual evaluation\n\nInput\n\nTpM the TangentSpace as the domain\nA a symmetric linear operator on the tangent space (M, p, X) -> Y\nb a vector field on the tangent space (M, p) -> X\nX the initial tangent vector\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nstopping_criterion=StopAfterIteration(manifold_dimension(M)|StopWhenRelativeResidualLess(c,1e-8),  where c is lVert b rVert_: a functor indicating that the stopping criterion is fulfilled\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_residual/#State","page":"Conjugate Residual","title":"State","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Manopt.ConjugateResidualState","page":"Conjugate Residual","title":"Manopt.ConjugateResidualState","text":"ConjugateResidualState{T,R,TStop<:StoppingCriterion} <: AbstractManoptSolverState\n\nA state for the conjugate_residual solver.\n\nFields\n\nX::T: the iterate\nr::T: the residual r = -b(p) - mathcal A(p)X\nd::T: the conjugate direction\nAr::T, Ad::T: storages for mathcal A(p)d, mathcal A(p)r\nrAr::R: internal field for storing  r mathcal A(p)r \nÎ±::R: a step length\nÎ²::R: the conjugate coefficient\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nConstructor\n\nConjugateResidualState(TpM::TangentSpace,slso::SymmetricLinearSystemObjective; kwargs...)\n\nInitialise the state with default values.\n\nKeyword arguments\n\nr=-get_gradient(TpM, slso, X)\nd=copy(TpM, r)\nAr=get_hessian(TpM, slso, X, r)\nAd=copy(TpM, Ar)\nÎ±::R=0.0\nÎ²::R=0.0\nstopping_criterion=StopAfterIteration(manifold_dimension(M))|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nSee also\n\nconjugate_residual\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_residual/#Objective","page":"Conjugate Residual","title":"Objective","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Manopt.SymmetricLinearSystemObjective","page":"Conjugate Residual","title":"Manopt.SymmetricLinearSystemObjective","text":"SymmetricLinearSystemObjective{E<:AbstractEvaluationType,TA,T} <: AbstractManifoldObjective{E}\n\nModel the objective\n\nf(X) = frac12 lVert mathcal AX + b rVert_p^2qquad X  T_pmathcal M\n\ndefined on the tangent space T_pmathcal M at p on the manifold mathcal M.\n\nIn other words this is an objective to solve mathcal A = -b(p) for some linear symmetric operator and a vector function. Note the minus on the right hand side, which makes this objective especially tailored for (iteratively) solving Newton-like equations.\n\nFields\n\nA!!: a symmetric, linear operator on the tangent space\nb!!: a gradient function\n\nwhere A!! can work as an allocating operator (M, p, X) -> Y or an in-place one (M, Y, p, X) -> Y, and similarly b!! can either be a function (M, p) -> X or (M, X, p) -> X. The first variants allocate for the result, the second variants work in-place.\n\nConstructor\n\nSymmetricLinearSystemObjective(A, b; evaluation=AllocatingEvaluation())\n\nGenerate the objective specifying whether the two parts work allocating or in-place.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_residual/#Additional-stopping-criterion","page":"Conjugate Residual","title":"Additional stopping criterion","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Manopt.StopWhenRelativeResidualLess","page":"Conjugate Residual","title":"Manopt.StopWhenRelativeResidualLess","text":"StopWhenRelativeResidualLess <: StoppingCriterion\n\nStop when re relative residual in the conjugate_residual is below a certain threshold, i.e.\n\ndisplaystylefraclVert r^(k) rVert_c  Îµ\n\nwhere c = lVert b rVert_ of the initial vector from the vector field in mathcal A(p)X + b(p) = 0_p, from the conjugate_residual\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nc: the initial norm\nÎµ: the threshold\nnorm_rk: the last computed norm of the residual\n\nConstructor\n\nStopWhenRelativeResidualLess(c, Îµ; norm_r = 2*c*Îµ)\n\nInitialise the stopping criterion.\n\nnote: Note\nThe initial norm of the vector field c = lVert b rVert_ that is stored internally is updated on initialisation, that is, if this stopping criterion is called with k<=0.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_residual/#Internal-functions","page":"Conjugate Residual","title":"Internal functions","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Manopt.get_b","page":"Conjugate Residual","title":"Manopt.get_b","text":"get_b(TpM::TangentSpace, slso::SymmetricLinearSystemObjective)\n\nevaluate the stored value for computing the right hand side b in mathcal A=-b.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_residual/#Literature","page":"Conjugate Residual","title":"Literature","text":"","category":"section"},{"location":"solvers/conjugate_residual/","page":"Conjugate Residual","title":"Conjugate Residual","text":"Z.Â Lai and A.Â Yoshise. Riemannian Interior Point Methods for Constrained Optimization on Manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 201, 433â€“469 (2024), arXiv:2203.09762.\n\n\n\n","category":"page"},{"location":"tutorials/EmbeddingObjectives/#How-to-define-the-cost-in-the-embedding","page":"Define objectives in the embedding","title":"How to define the cost in the embedding","text":"","category":"section"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Specifying a cost function f  mathcal M  â„ on a manifold is usually the model one starts with. Specifying its gradient operatornamegrad f mathcal M  Tmathcal M, or more precisely operatornamegradf(p)  T_pmathcal M, and eventually a Hessian operatornameHess f  T_pmathcal M  T_pmathcal M are then necessary to perform optimization. Since these might be challenging to compute, especially when manifolds and differential geometry are not the main area of a user,Â easier to use methods might be welcome.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"This tutorial discusses how to specify f in the embedding as tilde f, maybe only locally around the manifold, and use the Euclidean gradient  tilde f and Hessian ^2 tilde f within Manopt.jl.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"For the theoretical background see convert an Euclidean to an Riemannian Gradient, or Section 4.7 of [Bou23] for the gradient part or Section 5.11 as well as [Ngu23] for the background on converting Hessians.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Here we use the Examples 9.40 and 9.49 of [Bou23] and compare the different methods, one can call the solver, depending on which gradient and/or Hessian one provides.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"using Manifolds, Manopt, ManifoldDiff\nusing LinearAlgebra, Random, Colors, Plots\nRandom.seed!(123)","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"We consider the cost function on the Grassmann manifold given by","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"n = 5\nk = 2\nM = Grassmann(5,2)\nA = Symmetric(rand(n,n));","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"f(M, p) = 1 / 2 * tr(p' * A * p)","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Note that this implementation is already also a valid implementation / continuation of f into the (lifted) embedding of the Grassmann manifold. In the implementation we can use f for both the Euclidean tilde f and the Grassmann case f.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Its Euclidean gradient nabla f and Hessian nabla^2f are easy to compute as","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"âˆ‡f(M, p) = A * p\nâˆ‡Â²f(M,p,X) = A*X","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"On the other hand, from the aforementioned Example 9.49 we can also state the Riemannian gradient and Hessian for comparison as","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"grad_f(M, p) = A * p - p * (p' * A * p)\nHess_f(M, p, X) = A * X - p * p' * A * X - X * p' * A * p","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"We can verify that these are the correct at least numerically by calling the check_gradient","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"check_gradient(M, f, grad_f; plot=true)","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"(Image: )","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"and the check_Hessian, which requires a bit more tolerance in its linearity verification","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"check_Hessian(M, f, grad_f, Hess_f; plot=true, error=:error, atol=1e-15)","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"(Image: )","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"While they look reasonable here and were already derived, for the general case this derivation might be more complicated.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Luckily there exist two functions in ManifoldDiff.jl that are implemented for several manifolds from Manifolds.jl, namely riemannian_gradient(M, p, eG) that converts a Riemannian gradient eG=nabla tilde f(p) into a the Riemannian one operatornamegrad f(p) and riemannian_Hessian(M, p, eG, eH, X) which converts the Euclidean Hessian eH=nabla^2 tilde f(p)X into operatornameHess f(p)X, where we also require the Euclidean gradient eG=nabla tilde f(p).","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"So we can define","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"grad2_f(M, p) = riemannian_gradient(M, p, âˆ‡f(get_embedding(M), embed(M, p)))","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"where only formally we here call embed(M,p) before passing p to the Euclidean gradient, though here (for the Grassmann manifold with Stiefel representation) the embedding function is the identity.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Similarly for the Hessian, where in our example the embeddings of both the points and tangent vectors are the identity.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"function Hess2_f(M, p, X)\n    return riemannian_Hessian(\n        M,\n        p,\n        âˆ‡f(get_embedding(M), embed(M, p)),\n        âˆ‡Â²f(get_embedding(M), embed(M, p), embed(M, p, X)),\n        X\n    )\nend","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"And we can again verify these numerically,","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"check_gradient(M, f, grad2_f; plot=true)","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"(Image: )","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"and","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"check_Hessian(M, f, grad2_f, Hess2_f; plot=true, error=:error, atol=1e-14)","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"(Image: )","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"which yields the same result, but we see that the Euclidean conversion might be a bit less stable.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Now if we want to use these in optimization we would require these two functions to call e.g.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"p0 = [1.0 0.0; 0.0 1.0; 0.0 0.0; 0.0 0.0; 0.0 0.0]\nr1 = adaptive_regularization_with_cubics(\n    M,\n    f,\n    grad_f,\n    Hess_f,\n    p0;\n    debug=[:Iteration, :Cost, \"\\n\"],\n    return_objective=true,\n    return_state=true,\n)\nq1 = get_solver_result(r1)\nr1","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Initial f(x): 0.666814\n# 1     f(x): 0.329582\n# 2     f(x): -0.251913\n# 3     f(x): -0.451908\n# 4     f(x): -0.604753\n# 5     f(x): -0.608791\n# 6     f(x): -0.608797\n# 7     f(x): -0.608797\n\n# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)\nAfter 7 iterations\n\n## Parameters\n* Î·1 | Î·2              : 0.1 | 0.9\n* Î³1 | Î³2              : 0.1 | 2.0\n* Ïƒ (Ïƒmin)             : 0.0004082482904638632 (1.0e-10)\n* Ï (Ï_regularization) : 1.0002163851951777 (1000.0)\n* retraction method    : ExponentialRetraction()\n* sub solver state     :\n    | # Solver state for `Manopt.jl`s Lanczos Iteration\n    | After 6 iterations\n    | \n    | ## Parameters\n    | * Ïƒ                         : 0.0040824829046386315\n    | * # of Lanczos vectors used : 6\n    | \n    | ## Stopping criteria\n    | (a) For the Lanczos Iteration\n    | Stop When _one_ of the following are fulfilled:\n    |   * Max Iteration 6:  reached\n    |   * First order progress with Î¸=0.5:  not reached\n    | Overall: reached\n    | (b) For the Newton sub solver\n    | Max Iteration 200:    not reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 40:   not reached\n  * |grad f| < 1.0e-9: reached\n  * All Lanczos vectors (5) used:   not reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [ (:Iteration, \"# %-6d\"), (:Cost, \"f(x): %f\"), \"\\n\" ]","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"but if you choose to go for the conversions, then, thinking of the embedding and defining two new functions might be tedious. There is a shortcut for these, which performs the change internally, when necessary by specifying objective_type=:Euclidean.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"r2 = adaptive_regularization_with_cubics(\n    M,\n    f,\n    âˆ‡f,\n    âˆ‡Â²f,\n    p0;\n    # The one line different to specify our grad/Hess are Eucldiean:\n    objective_type=:Euclidean,\n    debug=[:Iteration, :Cost, \"\\n\"],\n    return_objective=true,\n    return_state=true,\n)\nq2 = get_solver_result(r2)\nr2","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Initial f(x): 0.666814\n# 1     f(x): 0.329582\n# 2     f(x): -0.251913\n# 3     f(x): -0.451908\n# 4     f(x): -0.604753\n# 5     f(x): -0.608791\n# 6     f(x): -0.608797\n# 7     f(x): -0.608797\n\n# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)\nAfter 7 iterations\n\n## Parameters\n* Î·1 | Î·2              : 0.1 | 0.9\n* Î³1 | Î³2              : 0.1 | 2.0\n* Ïƒ (Ïƒmin)             : 0.0004082482904638632 (1.0e-10)\n* Ï (Ï_regularization) : 1.000409105075989 (1000.0)\n* retraction method    : ExponentialRetraction()\n* sub solver state     :\n    | # Solver state for `Manopt.jl`s Lanczos Iteration\n    | After 6 iterations\n    | \n    | ## Parameters\n    | * Ïƒ                         : 0.0040824829046386315\n    | * # of Lanczos vectors used : 6\n    | \n    | ## Stopping criteria\n    | (a) For the Lanczos Iteration\n    | Stop When _one_ of the following are fulfilled:\n    |   * Max Iteration 6:  reached\n    |   * First order progress with Î¸=0.5:  not reached\n    | Overall: reached\n    | (b) For the Newton sub solver\n    | Max Iteration 200:    not reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 40:   not reached\n  * |grad f| < 1.0e-9: reached\n  * All Lanczos vectors (5) used:   not reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Debug\n    :Iteration = [ (:Iteration, \"# %-6d\"), (:Cost, \"f(x): %f\"), \"\\n\" ]","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"which returns the same result, see","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"distance(M, q1, q2)","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"5.599906634890012e-16","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"This conversion also works for the gradients of constraints, and is passed down to sub solvers by default when these are created using the Euclidean objective f, nabla f and nabla^2 f.","category":"page"},{"location":"tutorials/EmbeddingObjectives/#Summary","page":"Define objectives in the embedding","title":"Summary","text":"","category":"section"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"If you have the Euclidean gradient (or Hessian) available for a solver call, all you need to provide is objective_type=:Euclidean to convert the objective to a Riemannian one.","category":"page"},{"location":"tutorials/EmbeddingObjectives/#Literature","page":"Define objectives in the embedding","title":"Literature","text":"","category":"section"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"N.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nD.Â Nguyen. Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 198, 135â€“164 (2023), arXiv:2009.10159.\n\n\n\n","category":"page"},{"location":"tutorials/EmbeddingObjectives/#Technical-details","page":"Define objectives in the embedding","title":"Technical details","text":"","category":"section"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/EmbeddingObjectives/","page":"Define objectives in the embedding","title":"Define objectives in the embedding","text":"2025-04-25T12:12:14.038","category":"page"},{"location":"solvers/alternating_gradient_descent/#solver-alternating-gradient-descent","page":"Alternating Gradient Descent","title":"Alternating gradient descent","text":"","category":"section"},{"location":"solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent","page":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent","text":"alternating_gradient_descent(M::ProductManifold, f, grad_f, p=rand(M))\nalternating_gradient_descent(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\nalternating_gradient_descent!(M::ProductManifold, f, grad_f, p)\nalternating_gradient_descent!(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\n\nperform an alternating gradient descent. This can be done in-place of the start point p\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: a gradient, that can be of two cases\nis a single function returning an ArrayPartition from RecursiveArrayTools.jl or\nis a vector functions each returning a component part of the whole gradient\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Random) or the default :Linear one.\ninner_iterations=5:  how many gradient steps to take in a component before alternating to the next\nstopping_criterion=StopAfterIteration(1000)): a functor indicating that the stopping criterion is fulfilled\nstepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\norder=[1:n]:         the initial permutation, where n is the number of gradients in gradF.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nOutput\n\nusually the obtained (approximate) minimizer, see get_solver_return for details\n\nnote: Note\nThe input of each of the (component) gradients is still the whole vector X, just that all other then the ith input component are assumed to be fixed and just the ith components gradient is computed / returned.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent!","page":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent!","text":"alternating_gradient_descent(M::ProductManifold, f, grad_f, p=rand(M))\nalternating_gradient_descent(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\nalternating_gradient_descent!(M::ProductManifold, f, grad_f, p)\nalternating_gradient_descent!(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\n\nperform an alternating gradient descent. This can be done in-place of the start point p\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: a gradient, that can be of two cases\nis a single function returning an ArrayPartition from RecursiveArrayTools.jl or\nis a vector functions each returning a component part of the whole gradient\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Random) or the default :Linear one.\ninner_iterations=5:  how many gradient steps to take in a component before alternating to the next\nstopping_criterion=StopAfterIteration(1000)): a functor indicating that the stopping criterion is fulfilled\nstepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\norder=[1:n]:         the initial permutation, where n is the number of gradients in gradF.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nOutput\n\nusually the obtained (approximate) minimizer, see get_solver_return for details\n\nnote: Note\nThe input of each of the (component) gradients is still the whole vector X, just that all other then the ith input component are assumed to be fixed and just the ith components gradient is computed / returned.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#State","page":"Alternating Gradient Descent","title":"State","text":"","category":"section"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradientDescentState","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradientDescentState","text":"AlternatingGradientDescentState <: AbstractGradientDescentSolverState\n\nStore the fields for an alternating gradient descent algorithm, see also alternating_gradient_descent.\n\nFields\n\ndirection::DirectionUpdateRule\nevaluation_order::Symbol: whether to use a randomly permuted sequence (:FixedRandom), a per cycle newly permuted sequence (:Random) or the default :Linear evaluation order.\ninner_iterations: how many gradient steps to take in a component before alternating to the next\norder: the current permutation\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\np::P: a point on the manifold mathcal Mstoring the current iterate\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\nk, Ã¬`:              internal counters for the outer and inner iterations, respectively.\n\nConstructors\n\nAlternatingGradientDescentState(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\ninner_iterations=5\np=rand(M): a point on the manifold mathcal M\norder_type::Symbol=:Linear\norder::Vector{<:Int}=Int[]\nstopping_criterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize=default_stepsize(M, AlternatingGradientDescentState): a functor inheriting from Stepsize to determine a step size\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nGenerate the options for point p and where inner_iterations, order_type, order, retraction_method, stopping_criterion, and stepsize` are keyword arguments\n\n\n\n\n\n","category":"type"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"Additionally, the options share a DirectionUpdateRule, which chooses the current component, so they can be decorated further; The most inner one should always be the following one though.","category":"page"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradient","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradient","text":"AlternatingGradient(; kwargs...)\nAlternatingGradient(M::AbstractManifold; kwargs...)\n\nSpecify that a gradient based method should only update parts of the gradient in order to do a alternating gradient descent.\n\nKeyword arguments\n\ninitial_gradient=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\np=rand(M): a point on the manifold mathcal Mto specify the initial value\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for AlternatingGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradientRule","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradientRule","text":"AlternatingGradientRule <: AbstractGradientGroupDirectionRule\n\nCreate a functor (problem, state k) -> (s,X) to evaluate the alternating gradient, that is alternating between the components of the gradient and has an field for partial evaluation of the gradient in-place.\n\nFields\n\nX::T: a tangent vector at the point p on the manifold mathcal M\n\nConstructor\n\nAlternatingGradientRule(M::AbstractManifold; p=rand(M), X=zero_vector(M, p))\n\nInitialize the alternating gradient processor with tangent vector type of X, where both M and p are just help variables.\n\nSee also\n\nalternating_gradient_descent, [AlternatingGradient])@ref)\n\n\n\n\n\n","category":"type"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"which internally uses","category":"page"},{"location":"solvers/alternating_gradient_descent/#sec-agd-technical-details","page":"Alternating Gradient Descent","title":"Technical details","text":"","category":"section"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"The alternating_gradient_descent solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"The problem has to be phrased on a ProductManifold, to be able to","category":"page"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"alternate between parts of the input.","category":"page"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nBy default alternating gradient descent uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#tCG","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint truncated conjugate gradient method","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"Solve the constraint optimization problem on the tangent space","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"beginalign*\noperatorname*argmin_Y    T_pmathcalM m_p(Y) = f(p) +\noperatornamegradf(p) Y_p + frac12 mathcalH_pY Y_p\ntextsuch that  lVert Y rVert_p  Î”\nendalign*","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"on the tangent space T_pmathcal M of a Riemannian manifold mathcal M by using the Steihaug-Toint truncated conjugate-gradient (tCG) method, see [ABG06], Algorithm 2, and [CGT00]. Here mathcal H_p is either the Hessian operatornameHess f(p) or a linear symmetric operator on the tangent space approximating the Hessian.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Interface","page":"Steihaug-Toint TCG Method","title":"Interface","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent","page":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent","text":"truncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p=rand(M), X=rand(M); vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, mho::ManifoldHessianObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, trmo::TrustRegionModelObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\n\nsolve the trust-region subproblem\n\nbeginalign*\noperatorname*argmin_Y    T_pmathcalM m_p(Y) = f(p) +\noperatornamegradf(p) Y_p + frac12 mathcalH_pY Y_p\ntextsuch that  lVert Y rVert_p  Î”\nendalign*\n\non a manifold mathcal M by using the Steihaug-Toint truncated conjugate-gradient (tCG) method. This can be done inplace of X.\n\nFor a description of the algorithm and theorems offering convergence guarantees, see [ABG06, CGT00].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\nX: a tangent vector at the point p on the manifold mathcal M\n\nInstead of the three functions, you either provide a ManifoldHessianObjective mho which is then used to build the trust region model, or a TrustRegionModelObjective trmo directly.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸\nÎº=0.1:                the linear convergence target rate.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(manifold_dimension(base_manifold(Tpm)))|StopWhenResidualIsReducedByFactorOrPower(; Îº=Îº, Î¸=Î¸)|StopWhenTrustRegionIsExceeded()|StopWhenCurvatureIsNegative()|StopWhenModelIncreased(): a functor indicating that the stopping criterion is fulfilled\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntrust_regions\n\n\n\n\n\n","category":"function"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent!","page":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent!","text":"truncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p=rand(M), X=rand(M); vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, mho::ManifoldHessianObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, trmo::TrustRegionModelObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\n\nsolve the trust-region subproblem\n\nbeginalign*\noperatorname*argmin_Y    T_pmathcalM m_p(Y) = f(p) +\noperatornamegradf(p) Y_p + frac12 mathcalH_pY Y_p\ntextsuch that  lVert Y rVert_p  Î”\nendalign*\n\non a manifold mathcal M by using the Steihaug-Toint truncated conjugate-gradient (tCG) method. This can be done inplace of X.\n\nFor a description of the algorithm and theorems offering convergence guarantees, see [ABG06, CGT00].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcal M  T_pmathcal M of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np: a point on the manifold mathcal M\nX: a tangent vector at the point p on the manifold mathcal M\n\nInstead of the three functions, you either provide a ManifoldHessianObjective mho which is then used to build the trust region model, or a TrustRegionModelObjective trmo directly.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸\nÎº=0.1:                the linear convergence target rate.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(manifold_dimension(base_manifold(Tpm)))|StopWhenResidualIsReducedByFactorOrPower(; Îº=Îº, Î¸=Î¸)|StopWhenTrustRegionIsExceeded()|StopWhenCurvatureIsNegative()|StopWhenModelIncreased(): a functor indicating that the stopping criterion is fulfilled\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntrust_regions\n\n\n\n\n\n","category":"function"},{"location":"solvers/truncated_conjugate_gradient_descent/#State","page":"Steihaug-Toint TCG Method","title":"State","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.TruncatedConjugateGradientState","page":"Steihaug-Toint TCG Method","title":"Manopt.TruncatedConjugateGradientState","text":"TruncatedConjugateGradientState <: AbstractHessianSolverState\n\ndescribe the Steihaug-Toint truncated conjugate-gradient method, with\n\nFields\n\nLet T denote the type of a tangent vector and R <: Real.\n\nÎ´::T:                     the conjugate gradient search direction\nÎ´HÎ´, YPÎ´, Î´PÎ´, YPÎ´: temporary inner products with HÎ´ and preconditioned inner products.\nHÎ´, HY:                 temporary results of the Hessian applied to Î´ and Y, respectively.\nÎº::R:                     the linear convergence target rate.\nproject!:                 for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize:          indicate whether X is initialised to a random vector or not\nresidual::T:                 the gradient of the model m(Y)\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nÎ¸::R:                     the superlinear convergence target rate of 1+Î¸\ntrust_region_radius::R:   the trust-region radius\nX::T:                     the gradient operatornamegradf(p)\nY::T:                     current iterate tangent vector\nz::T:                     the preconditioned residual\nz_r::R:                   inner product of the residual and z\n\nConstructor\n\nTruncatedConjugateGradientState(TpM::TangentSpace, Y=rand(TpM); kwargs...)\n\nInitialise the TCG state.\n\nInput\n\nTpM: a TangentSpace\n\nKeyword arguments\n\nÎº=0.1\nproject!::F=copyto!: initialise the numerical stabilisation to just copy the result\nrandomize=false\nÎ¸=1.0\ntrust_region_radius=injectivity_radius(base_manifold(TpM)) / 4\nstopping_criterion=StopAfterIteration(manifold_dimension(base_manifold(Tpm)))|StopWhenResidualIsReducedByFactorOrPower(; Îº=Îº, Î¸=Î¸)|StopWhenTrustRegionIsExceeded()|StopWhenCurvatureIsNegative()|StopWhenModelIncreased(): a functor indicating that the stopping criterion is fulfilled\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal M\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Stopping-criteria","page":"Steihaug-Toint TCG Method","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenResidualIsReducedByFactorOrPower","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenResidualIsReducedByFactorOrPower","text":"StopWhenResidualIsReducedByFactorOrPower <: StoppingCriterion\n\nA functor for testing if the norm of residual at the current iterate is reduced either by a power of 1+Î¸ or by a factor Îº compared to the norm of the initial residual. The criterion hence reads\n\nlVert r_k rVert_p  lVert r_0 rVert_p^(0) min bigl( Îº lVert r_0 rVert_p^(0)  bigr).\n\nFields\n\nÎº:      the reduction factor\nÎ¸:      part of the reduction power\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\n\nConstructor\n\nStopWhenResidualIsReducedByFactorOrPower(; Îº=0.1, Î¸=1.0)\n\nInitialize the StopWhenResidualIsReducedByFactorOrPower functor to indicate to stop after the norm of the current residual is lesser than either the norm of the initial residual to the power of 1+Î¸ or the norm of the initial residual times Îº.\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenTrustRegionIsExceeded","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenTrustRegionIsExceeded","text":"StopWhenTrustRegionIsExceeded <: StoppingCriterion\n\nA functor for testing if the norm of the next iterate in the Steihaug-Toint truncated conjugate gradient method is larger than the trust-region radius Î¸  lVert Y^(k)^* rVert_p^(k) and to end the algorithm when the trust region has been left.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\ntrr the trust region radius\nYPY the computed norm of Y.\n\nConstructor\n\nStopWhenTrustRegionIsExceeded()\n\ninitialize the StopWhenTrustRegionIsExceeded functor to indicate to stop after the norm of the next iterate is greater than the trust-region radius.\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenCurvatureIsNegative","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenCurvatureIsNegative","text":"StopWhenCurvatureIsNegative <: StoppingCriterion\n\nA functor for testing if the curvature of the model is negative, Î´_k operatornameHess F(p)Î´_k_p  0. In this case, the model is not strictly convex, and the stepsize as computed does not yield a reduction of the model.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nvalue store the value of the inner product.\nreason: stores a reason of stopping if the stopping criterion has been reached, see get_reason.\n\nConstructor\n\nStopWhenCurvatureIsNegative()\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenModelIncreased","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenModelIncreased","text":"StopWhenModelIncreased <: StoppingCriterion\n\nA functor for testing if the curvature of the model value increased.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nmodel_valuestre the last model value\ninc_model_value store the model value that increased\n\nConstructor\n\nStopWhenModelIncreased()\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.set_parameter!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualPower}, Any}","page":"Steihaug-Toint TCG Method","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualPower, v)\n\nUpdate the residual Power Î¸  to v.\n\n\n\n\n\n","category":"method"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.set_parameter!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualFactor}, Any}","page":"Steihaug-Toint TCG Method","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualFactor, v)\n\nUpdate the residual Factor Îº to v.\n\n\n\n\n\n","category":"method"},{"location":"solvers/truncated_conjugate_gradient_descent/#Trust-region-model","page":"Steihaug-Toint TCG Method","title":"Trust region model","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.TrustRegionModelObjective","page":"Steihaug-Toint TCG Method","title":"Manopt.TrustRegionModelObjective","text":"TrustRegionModelObjective{O<:AbstractManifoldHessianObjective} <: AbstractManifoldSubObjective{O}\n\nA trust region model of the form\n\n    m(X) = f(p) + operatornamegrad f(p) X_p + frac1(2 operatornameHess f(p)X X_p\n\nFields\n\nobjective: an AbstractManifoldHessianObjective proving f, its gradient and Hessian\n\nConstructors\n\nTrustRegionModelObjective(objective)\n\nwith either an AbstractManifoldHessianObjective objective or an decorator containing such an objective\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#sec-tr-technical-details","page":"Steihaug-Toint TCG Method","title":"Technical details","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"The trust_regions solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"if you do not provide a trust_region_radius=, then injectivity_radius on the manifold M is required.\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nA zero_vector!(M,X,p).\nA copyto!(M, q, p) and copy(M,p) for points.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Literature","page":"Steihaug-Toint TCG Method","title":"Literature","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"P.-A.Â Absil, C.Â Baker and K.Â Gallivan. Trust-Region Methods on Riemannian Manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 7, 303â€“330 (2006).\n\n\n\nA.Â R.Â Conn, N.Â I.Â Gould and P.Â L.Â Toint. Trust Region Methods (Society for Industrial and Applied Mathematics, 2000).\n\n\n\n","category":"page"},{"location":"solvers/LevenbergMarquardt/#Levenberg-Marquardt","page":"Levenbergâ€“Marquardt","title":"Levenberg-Marquardt","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt","page":"Levenbergâ€“Marquardt","title":"Manopt.LevenbergMarquardt","text":"LevenbergMarquardt(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt(M, vgf, p; kwargs...)\nLevenbergMarquardt(M, nlso, p; kwargs...)\nLevenbergMarquardt!(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, vgf, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, nlso, p, num_components=-1; kwargs...)\n\ncompute the the Riemannian Levenberg-Marquardt algorithm [Pee93, AOT22] to solve\n\noperatorname*argmin_p  mathcal M frac12 sum_i=1^m lvert f_i(p) rvert^2\n\nwhere f mathcal M  â„^m is written with component functions f_i mathcal M  â„, i=1m, and each component function is continuously differentiable.\n\nThe second block of signatures perform the optimization in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal Mâ„^m. The cost function can be provided in two different ways\nas a single function returning a vector f(p)  â„^m\nas a vector of functions, where each single function returns a scalar f_i(p)  â„\nThe type is determined by the function_type= keyword argument.\njacobian_f:   the Jacobian of f. The Jacobian can be provided in three different ways\nas a single function returning a vector of gradient vectors bigl(operatornamegrad f_i(p)bigr)_i=1^m\nas a vector of functions, where each single function returns a gradient vector operatornamegrad f_i(p), i=1m\nas a single function returning a (coefficient) matrix J  â„^md, where d is the dimension of the manifold.\nThese coefficients are given with respect to an AbstractBasis of the tangent space at p. The type is determined by the jacobian_type= keyword argument.\np: a point on the manifold mathcal M\nnum_components: length m of the vector returned by the cost function. By default its value is -1 which means that it is determined automatically by calling f one additional time. This is only possible when evaluation is AllocatingEvaluation, for mutating evaluation this value must be explicitly specified.\n\nYou can also provide the cost and its Jacobian already as aVectorGradientFunction vgf, Alternatively, passing a NonlinearLeastSquaresObjective nlso.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎ·=0.2:                   scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range: 0 < Î· < 1.\nexpect_zero_residual=false: whether or not the algorithm might expect that the value of residual (objective) at minimum is equal to 0.\ndamping_term_min=0.1:      initial (and also minimal) value of the damping term\nÎ²=5.0:                     parameter by which the damping term is multiplied when the current new point is rejected\nfunction_type=FunctionVectorialType: an AbstractVectorialType specifying the type of cost function provided.\ninitial_jacobian_f:      the initial Jacobian of the cost function f. By default this is a matrix of size num_components times the manifold dimension of similar type as p.\ninitial_residual_values: the initial residual vector of the cost function f. By default this is a vector of length num_components of similar type as p.\njacobian_type=FunctionVectorialType: an AbstractVectorialType specifying the type of Jacobian provided.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt!","page":"Levenbergâ€“Marquardt","title":"Manopt.LevenbergMarquardt!","text":"LevenbergMarquardt(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt(M, vgf, p; kwargs...)\nLevenbergMarquardt(M, nlso, p; kwargs...)\nLevenbergMarquardt!(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, vgf, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, nlso, p, num_components=-1; kwargs...)\n\ncompute the the Riemannian Levenberg-Marquardt algorithm [Pee93, AOT22] to solve\n\noperatorname*argmin_p  mathcal M frac12 sum_i=1^m lvert f_i(p) rvert^2\n\nwhere f mathcal M  â„^m is written with component functions f_i mathcal M  â„, i=1m, and each component function is continuously differentiable.\n\nThe second block of signatures perform the optimization in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal Mâ„^m. The cost function can be provided in two different ways\nas a single function returning a vector f(p)  â„^m\nas a vector of functions, where each single function returns a scalar f_i(p)  â„\nThe type is determined by the function_type= keyword argument.\njacobian_f:   the Jacobian of f. The Jacobian can be provided in three different ways\nas a single function returning a vector of gradient vectors bigl(operatornamegrad f_i(p)bigr)_i=1^m\nas a vector of functions, where each single function returns a gradient vector operatornamegrad f_i(p), i=1m\nas a single function returning a (coefficient) matrix J  â„^md, where d is the dimension of the manifold.\nThese coefficients are given with respect to an AbstractBasis of the tangent space at p. The type is determined by the jacobian_type= keyword argument.\np: a point on the manifold mathcal M\nnum_components: length m of the vector returned by the cost function. By default its value is -1 which means that it is determined automatically by calling f one additional time. This is only possible when evaluation is AllocatingEvaluation, for mutating evaluation this value must be explicitly specified.\n\nYou can also provide the cost and its Jacobian already as aVectorGradientFunction vgf, Alternatively, passing a NonlinearLeastSquaresObjective nlso.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎ·=0.2:                   scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range: 0 < Î· < 1.\nexpect_zero_residual=false: whether or not the algorithm might expect that the value of residual (objective) at minimum is equal to 0.\ndamping_term_min=0.1:      initial (and also minimal) value of the damping term\nÎ²=5.0:                     parameter by which the damping term is multiplied when the current new point is rejected\nfunction_type=FunctionVectorialType: an AbstractVectorialType specifying the type of cost function provided.\ninitial_jacobian_f:      the initial Jacobian of the cost function f. By default this is a matrix of size num_components times the manifold dimension of similar type as p.\ninitial_residual_values: the initial residual vector of the cost function f. By default this is a vector of length num_components of similar type as p.\njacobian_type=FunctionVectorialType: an AbstractVectorialType specifying the type of Jacobian provided.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Options","page":"Levenbergâ€“Marquardt","title":"Options","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardtState","page":"Levenbergâ€“Marquardt","title":"Manopt.LevenbergMarquardtState","text":"LevenbergMarquardtState{P,T} <: AbstractGradientSolverState\n\nDescribes a Gradient based descent algorithm, with\n\nFields\n\nA default value is given in brackets if a parameter can be left out in initialization.\n\np::P: a point on the manifold mathcal Mstoring the current iterate\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nresidual_values:      value of F calculated in the solver setup or the previous iteration\nresidual_values_temp: value of F for the current proposal point\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\njacobian:                 the current Jacobian of F\ngradient:             the current gradient of F\nstep_vector:          the tangent vector at x that is used to move to the next point\nlast_stepsize:        length of step_vector\nÎ·:                    Scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range: 0 < Î· < 1.\ndamping_term:         current value of the damping term\ndamping_term_min:     initial (and also minimal) value of the damping term\nÎ²:                    parameter by which the damping term is multiplied when the current new point is rejected\nexpect_zero_residual: if true, the algorithm expects that the value of the residual (objective) at minimum is equal to 0.\nlinear_subsolver!:    a function with three arguments sk, JJ, grad_f_cthat solves the linear subproblemsk .= JJ \\ gradfc, whereJJis (up to numerical issues) a symmetric positive definite matrix. Default value is [defaultlmlin_solve!`](@ref).\n\nConstructor\n\nLevenbergMarquardtState(M, initial_residual_values, initial_jacobian; kwargs...)\n\nGenerate the Levenberg-Marquardt solver state.\n\nKeyword arguments\n\nThe following fields are keyword arguments\n\nÎ²=5.0\ndamping_term_min=0.1\nÎ·=0.2,\nexpect_zero_residual=false\ninitial_gradient=zero_vector(M, p)\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-12)|StopWhenStepsizeLess(1e-12): a functor indicating that the stopping criterion is fulfilled\n\nSee also\n\ngradient_descent, LevenbergMarquardt\n\n\n\n\n\n","category":"type"},{"location":"solvers/LevenbergMarquardt/#sec-lm-technical-details","page":"Levenbergâ€“Marquardt","title":"Technical details","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/","page":"Levenbergâ€“Marquardt","title":"Levenbergâ€“Marquardt","text":"The LevenbergMarquardt solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/LevenbergMarquardt/","page":"Levenbergâ€“Marquardt","title":"Levenbergâ€“Marquardt","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nA copyto!(M, q, p) and copy(M,p) for points.","category":"page"},{"location":"solvers/LevenbergMarquardt/#Internals","page":"Levenbergâ€“Marquardt","title":"Internals","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/#Manopt.default_lm_lin_solve!","page":"Levenbergâ€“Marquardt","title":"Manopt.default_lm_lin_solve!","text":"default_lm_lin_solve!(sk, JJ, grad_f_c)\n\nSolve the system JJ \\ grad_f_c where JJ is (mathematically) a symmetric positive definite matrix and save the result to sk. In case of numerical errors the PosDefException is caught and the default symmetric solver (Symmetric(JJ) \\ grad_f_c) is used.\n\nThe function is intended to be used with LevenbergMarquardt.\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Literature","page":"Levenbergâ€“Marquardt","title":"Literature","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/","page":"Levenbergâ€“Marquardt","title":"Levenbergâ€“Marquardt","text":"S.Â Adachi, T.Â Okuno and A.Â Takeda. Riemannian Levenberg-Marquardt Method with Global and Local Convergence Properties. ArXivÂ Preprint (2022).\n\n\n\nR.Â Peeters. On a Riemannian version of the Levenberg-Marquardt algorithm. Serie Research MemorandaÂ 0011 (VU University Amsterdam, Faculty of Economics, Business Administration and Econometrics, 1993).\n\n\n\n","category":"page"},{"location":"solvers/exact_penalty_method/#Exact-penalty-method","page":"Exact Penalty Method","title":"Exact penalty method","text":"","category":"section"},{"location":"solvers/exact_penalty_method/#Manopt.exact_penalty_method","page":"Exact Penalty Method","title":"Manopt.exact_penalty_method","text":"exact_penalty_method(M, f, grad_f, p=rand(M); kwargs...)\nexact_penalty_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\nexact_penalty_method!(M, f, grad_f, p; kwargs...)\nexact_penalty_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the exact penalty method (EPM) [LB19] The aim of the EPM is to find a solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. For that a weighted L_1-penalty term for the violation of the constraints is added to the objective\n\nf(x) + Ïbiggl( sum_i=1^m maxbigl0 g_i(x)bigr + sum_j=1^n vert h_j(x)vertbiggr)\n\nwhere Ï0 is the penalty parameter.\n\nSince this is non-smooth, a SmoothingTechnique with parameter u is applied, see the ExactPenaltyCost.\n\nIn every step k of the exact penalty method, the smoothed objective is then minimized over all p mathcal M. Then, the accuracy tolerance Ïµ and the smoothing parameter u are updated by setting\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_min is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor, and\n\nu^(k) = max u_min theta_u u^(k-1) \n\nwhere u_min is the lowest value u is allowed to become and Î¸_u  (01) is constant scaling factor.\n\nFinally, the penalty parameter Ï is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  displaystyle max_j  mathcalEi  mathcalI Bigl vert h_j(x^(k)) vert g_i(x^(k))Bigr geq u^(k-1) Bigr) \nÏ^(k-1)  textelse\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nif not called with the ConstrainedManifoldObjective cmo\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nFurther keyword arguments\n\nÏµ=1eâ€“3: the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor;\nÏµ_min=1e-6: the lower bound for the accuracy tolerance\nu=1eâ€“1: the smoothing parameter and threshold for violation of the constraints\nu_exponent=1/100: exponent of the u update factor;\nu_min=1e-6: the lower bound for the smoothing parameter and threshold for violation of the constraints\nÏ=1.0: the penalty parameter\nequality_constraints=nothing: the number n of equality constraints. If not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nmin_stepsize=1e-10: the minimal step size\nsmoothing=LogarithmicSumOfExponentials: a SmoothingTechnique to use\nsub_cost=ExactPenaltyCost(problem, Ï, u; smoothing=smoothing): cost to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=ExactPenaltyGrad(problem, Ï, u; smoothing=smoothing): gradient to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-10): a stopping cirterion for the sub solver This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_state=DefaultManoptProblem(M,ManifoldGradientObjective`(subcost, subgrad; evaluation=evaluation):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_state=QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\nstopping_criterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) ): a functor indicating that the stopping criterion is fulfilled\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/exact_penalty_method/#Manopt.exact_penalty_method!","page":"Exact Penalty Method","title":"Manopt.exact_penalty_method!","text":"exact_penalty_method(M, f, grad_f, p=rand(M); kwargs...)\nexact_penalty_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\nexact_penalty_method!(M, f, grad_f, p; kwargs...)\nexact_penalty_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the exact penalty method (EPM) [LB19] The aim of the EPM is to find a solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcal M  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. For that a weighted L_1-penalty term for the violation of the constraints is added to the objective\n\nf(x) + Ïbiggl( sum_i=1^m maxbigl0 g_i(x)bigr + sum_j=1^n vert h_j(x)vertbiggr)\n\nwhere Ï0 is the penalty parameter.\n\nSince this is non-smooth, a SmoothingTechnique with parameter u is applied, see the ExactPenaltyCost.\n\nIn every step k of the exact penalty method, the smoothed objective is then minimized over all p mathcal M. Then, the accuracy tolerance Ïµ and the smoothing parameter u are updated by setting\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_min is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor, and\n\nu^(k) = max u_min theta_u u^(k-1) \n\nwhere u_min is the lowest value u is allowed to become and Î¸_u  (01) is constant scaling factor.\n\nFinally, the penalty parameter Ï is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  displaystyle max_j  mathcalEi  mathcalI Bigl vert h_j(x^(k)) vert g_i(x^(k))Bigr geq u^(k-1) Bigr) \nÏ^(k-1)  textelse\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nif not called with the ConstrainedManifoldObjective cmo\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nFurther keyword arguments\n\nÏµ=1eâ€“3: the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor;\nÏµ_min=1e-6: the lower bound for the accuracy tolerance\nu=1eâ€“1: the smoothing parameter and threshold for violation of the constraints\nu_exponent=1/100: exponent of the u update factor;\nu_min=1e-6: the lower bound for the smoothing parameter and threshold for violation of the constraints\nÏ=1.0: the penalty parameter\nequality_constraints=nothing: the number n of equality constraints. If not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nmin_stepsize=1e-10: the minimal step size\nsmoothing=LogarithmicSumOfExponentials: a SmoothingTechnique to use\nsub_cost=ExactPenaltyCost(problem, Ï, u; smoothing=smoothing): cost to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=ExactPenaltyGrad(problem, Ï, u; smoothing=smoothing): gradient to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_kwargs=(;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-10): a stopping cirterion for the sub solver This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_state=DefaultManoptProblem(M,ManifoldGradientObjective`(subcost, subgrad; evaluation=evaluation):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_state=QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\nstopping_criterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) ): a functor indicating that the stopping criterion is fulfilled\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/exact_penalty_method/#State","page":"Exact Penalty Method","title":"State","text":"","category":"section"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyMethodState","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyMethodState","text":"ExactPenaltyMethodState{P,T} <: AbstractManoptSolverState\n\nDescribes the exact penalty method, with\n\nFields\n\nÏµ: the accuracy tolerance\nÏµ_min: the lower bound for the accuracy tolerance\np::P: a point on the manifold mathcal Mstoring the current iterate\nÏ: the penalty parameter\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nu: the smoothing parameter and threshold for violation of the constraints\nu_min: the lower bound for the smoothing parameter and threshold for violation of the constraints\nÎ¸_Ïµ: the scaling factor of the tolerance parameter\nÎ¸_Ï: the scaling factor of the penalty parameter\nÎ¸_u: the scaling factor of the smoothing parameter\n\nConstructor\n\nExactPenaltyMethodState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\n\nconstruct the exact penalty state.\n\nExactPenaltyMethodState(M::AbstractManifold, sub_problem;\n    evaluation=AllocatingEvaluation(), kwargs...\n\n)\n\nconstruct the exact penalty state, where sub_problem is a closed form solution with evaluation as type of evaluation.\n\nKeyword arguments\n\nÏµ=1e-3\nÏµ_min=1e-6\nÏµ_exponent=1 / 100: a shortcut for the scaling factor Î¸_Ïµ\nÎ¸_Ïµ=(Ïµ_min / Ïµ)^(Ïµ_exponent)\nu=1e-1\nu_min=1e-6\nu_exponent=1 / 100:  a shortcut for the scaling factor Î¸_u.\nÎ¸_u=(u_min / u)^(u_exponent)\np=rand(M): a point on the manifold mathcal Mto specify the initial value\nÏ=1.0\nÎ¸_Ï=0.3\nstopping_criterion=StopAfterIteration(300)|(: a functor indicating that the stopping criterion is fulfilled StopWhenSmallerOrEqual(:Ïµ, Ïµ_min)|StopWhenChangeLess(1e-10) )\n\nSee also\n\nexact_penalty_method\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Helping-functions","page":"Exact Penalty Method","title":"Helping functions","text":"","category":"section"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyCost","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyCost","text":"ExactPenaltyCost{S, Pr, R}\n\nRepresent the cost of the exact penalty method based on a ConstrainedManifoldObjective P and a parameter Ï given by\n\nf(p) + ÏBigl(\n    sum_i=0^m max0g_i(p) + sum_j=0^n lvert h_j(p)rvert\nBigr)\n\nwhere an additional parameter u is used as well as a smoothing technique, for example LogarithmicSumOfExponentials or LinearQuadraticHuber to obtain a smooth cost function. This struct is also a functor (M,p) -> v of the cost v.\n\nFields\n\nÏ, u: as described in the mathematical formula, .\nco:     the original cost\n\nConstructor\n\nExactPenaltyCost(co::ConstrainedManifoldObjective, Ï, u; smoothing=LinearQuadraticHuber())\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyGrad","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyGrad","text":"ExactPenaltyGrad{S, CO, R}\n\nRepresent the gradient of the ExactPenaltyCost based on a ConstrainedManifoldObjective co and a parameter Ï and a smoothing technique, which uses an additional parameter u.\n\nThis struct is also a functor in both formats\n\n(M, p) -> X to compute the gradient in allocating fashion.\n(M, X, p) to compute the gradient in in-place fashion.\n\nFields\n\nÏ, u as stated before\nco the nonsmooth objective\n\nConstructor\n\nExactPenaltyGradient(co::ConstrainedManifoldObjective, Ï, u; smoothing=LinearQuadraticHuber())\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.SmoothingTechnique","page":"Exact Penalty Method","title":"Manopt.SmoothingTechnique","text":"abstract type SmoothingTechnique\n\nSpecify a smoothing technique, see for example ExactPenaltyCost and ExactPenaltyGrad.\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber","page":"Exact Penalty Method","title":"Manopt.LinearQuadraticHuber","text":"LinearQuadraticHuber <: SmoothingTechnique\n\nSpecify a smoothing based on max0x  mathcal P(xu) for some u, where\n\nmathcal P(x u) = begincases\n  0  text if  x leq 0\n  fracx^22u  text if  0 leq x leq u\n  x-fracu2  text if  x geq u\nendcases\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials","page":"Exact Penalty Method","title":"Manopt.LogarithmicSumOfExponentials","text":"LogarithmicSumOfExponentials <: SmoothingTechnique\n\nSpecify a smoothing based on maxab  u log(mathrme^fracau+mathrme^fracbu) for some u.\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#sec-dr-technical-details","page":"Exact Penalty Method","title":"Technical details","text":"","category":"section"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"The exact_penalty_method solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"A copyto!(M, q, p) and copy(M,p) for points.\nEverything the subsolver requires, which by default is the quasi_Newton method\nA zero_vector(M,p).","category":"page"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"The stopping criteria involves StopWhenChangeLess and StopWhenGradientNormLess which require","category":"page"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"An inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.","category":"page"},{"location":"solvers/exact_penalty_method/#Literature","page":"Exact Penalty Method","title":"Literature","text":"","category":"section"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"C.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\n","category":"page"},{"location":"plans/#sec-plan","page":"Specify a Solver","title":"Plans for solvers","text":"","category":"section"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"For any optimisation performed in Manopt.jl information is required about both the optimisation task or â€œproblemâ€ at hand as well as the solver and all its parameters. This together is called a plan in Manopt.jl and it consists of two data structures:","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"The Manopt Problem describes all static data of a task, most prominently the manifold and the objective.\nThe Solver State describes all varying data and parameters for the solver that is used. This also means that each solver has its own data structure for the state.","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"By splitting these two parts, one problem can be define an then be solved  using different solvers.","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"Still there might be the need to set certain parameters within any of these structures. For that there is","category":"page"},{"location":"plans/#Manopt.set_parameter!","page":"Specify a Solver","title":"Manopt.set_parameter!","text":"set_parameter!(f, element::Symbol , args...)\n\nFor any f and a Symbol e, dispatch on its value so by default, to set some args... in f or one of uts sub elements.\n\n\n\n\n\nset_parameter!(element::Symbol, value::Union{String,Bool,<:Number})\n\nSet global Manopt parameters addressed by a symbol element. W This first dispatches on the value of element.\n\nThe parameters are stored to the global settings using Preferences.jl.\n\nPassing a value of \"\" deletes the corresponding entry from the preferences. Whenever the LocalPreferences.toml is modified, this is also issued as an @info.\n\n\n\n\n\nset_parameter!(amo::AbstractManifoldObjective, element::Symbol, args...)\n\nSet a certain args... from the AbstractManifoldObjective amo to value. This function should dispatch onVal(element)`.\n\nCurrently supported\n\n:Cost passes to the get_cost_function\n:Gradient passes to the get_gradient_function\n\n\n\n\n\nset_parameter!(ams::AbstractManoptProblem, element::Symbol, field::Symbol , value)\n\nSet a certain field/element from the AbstractManoptProblem ams to value. This function usually dispatches on Val(element). Instead of a single field, also a chain of elements can be provided, allowing to access encapsulated parts of the problem.\n\nMain values for element are :Manifold and :Objective.\n\n\n\n\n\nset_parameter!(ams::DebugSolverState, ::Val{:Debug}, args...)\n\nSet certain values specified by args... into the elements of the debugDictionary\n\n\n\n\n\nset_parameter!(ams::RecordSolverState, ::Val{:Record}, args...)\n\nSet certain values specified by args... into the elements of the recordDictionary\n\n\n\n\n\nset_parameter!(c::StopAfter, :MaxTime, v::Period)\n\nUpdate the time period after which an algorithm shall stop.\n\n\n\n\n\nset_parameter!(c::StopAfterIteration, :;MaxIteration, v::Int)\n\nUpdate the number of iterations after which the algorithm should stop.\n\n\n\n\n\nset_parameter!(c::StopWhenChangeLess, :MinIterateChange, v::Int)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\nset_parameter!(c::StopWhenCostLess, :MinCost, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenEntryChangeLess, :Threshold, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenGradientChangeLess, :MinGradientChange, v)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\nset_parameter!(c::StopWhenGradientNormLess, :MinGradNorm, v::Float64)\n\nUpdate the minimal gradient norm when an algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenStepsizeLess, :MinStepsize, v)\n\nUpdate the minimal step size below which the algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenSubgradientNormLess, :MinSubgradNorm, v::Float64)\n\nUpdate the minimal subgradient norm when an algorithm shall stop\n\n\n\n\n\nset_parameter!(ams::AbstractManoptSolverState, element::Symbol, args...)\n\nSet a certain field or semantic element from the AbstractManoptSolverState ams to value. This function passes to Val(element) and specific setters should dispatch on Val{element}.\n\nBy default, this function just does nothing.\n\n\n\n\n\nset_parameter!(ams::DebugSolverState, ::Val{:SubProblem}, args...)\n\nSet certain values specified by args... to the sub problem.\n\n\n\n\n\nset_parameter!(ams::DebugSolverState, ::Val{:SubState}, args...)\n\nSet certain values specified by args... to the sub state.\n\n\n\n\n\nset_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualPower, v)\n\nUpdate the residual Power Î¸  to v.\n\n\n\n\n\nset_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualFactor, v)\n\nUpdate the residual Factor Îº to v.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.get_parameter","page":"Specify a Solver","title":"Manopt.get_parameter","text":"get_parameter(f, element::Symbol, args...)\n\nAccess arbitrary parameters from f addressed by a symbol element.\n\nFor any f and a Symbol e dispatch on its value by default, to get some element from f potentially further qualified by args....\n\nThis functions returns nothing if f does not have the property element\n\n\n\n\n\nget_parameter(element::Symbol; default=nothing)\n\nAccess global Manopt parameters addressed by a symbol element. This first dispatches on the value of element.\n\nIf the value is not set, default is returned.\n\nThe parameters are queried from the global settings using Preferences.jl, so they are persistent within your activated Environment.\n\nCurrently used settings\n\n:Mode the mode can be set to \"Tutorial\" to get several hints especially in scenarios, where the optimisation on manifolds is different from the usual â€œexperienceâ€ in (classical, Euclidean) optimization. Any other value has the same effect as not setting it.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.status_summary","page":"Specify a Solver","title":"Manopt.status_summary","text":"status_summary(e)\n\nReturn a string reporting about the current status of e, where e is a type from Manopt.\n\nThis method is similar to show but just returns a string. It might also be more verbose in explaining, or hide internal information.\n\n\n\n\n\n","category":"function"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"The following symbols are used.","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"Symbol Used in Description\n:Activity DebugWhenActive activity of the debug action stored within\n:Basepoint TangentSpace the point the tangent space is at\n:Cost generic the cost function (within an objective, as pass down)\n:Debug DebugSolverState the stored debugDictionary\n:Gradient generic the gradient function (within an objective, as pass down)\n:Iterate generic the (current) iterate,Â similar to set_iterate!,Â within a state\n:Manifold generic the manifold (within a problem, as pass down)\n:Objective generic the objective (within a problem, as pass down)\n:SubProblem generic the sub problem (within a state, as pass down)\n:SubState generic the sub state (within a state, as pass down)\n:Î» ProximalDCCost, ProximalDCGrad set the proximal parameter within the proximal sub objective elements\n:Population ParticleSwarmState a certain population of points, for example particle_swarms swarm\n:Record RecordSolverState \n:TrustRegionRadius TrustRegionsState the trust region radius, equivalent to :Ïƒ\n:Ï, :u ExactPenaltyCost, ExactPenaltyGrad Parameters within the exact penalty objective\n:Ï, :Î¼, :Î» AugmentedLagrangianCost, AugmentedLagrangianGrad Parameters of the Lagrangian function\n:p, :X LinearizedDCCost, LinearizedDCGrad Parameters withing the linearized functional used for the sub problem of the difference of convex algorithm","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"Any other lower case name or letter as well as single upper case letters access fields of the corresponding first argument. for example :p could be used to access the field s.p of a state. This is often, where the iterate is stored, so the recommended way is to use :Iterate from before.","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"Since the iterate is often stored in the states fields s.p one could access the iterate often also with :p and similarly the gradient with :X. This is discouraged for both readability as well as to stay more generic, and it is recommended to use :Iterate and :Gradient instead in generic settings.","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"You can further activate a â€œTutorialâ€ mode by set_parameter!(:Mode, \"Tutorial\"). Internally, the following convenience function is available.","category":"page"},{"location":"plans/#Manopt.is_tutorial_mode","page":"Specify a Solver","title":"Manopt.is_tutorial_mode","text":"is_tutorial_mode()\n\nA small internal helper to indicate whether tutorial mode is active.\n\nYou can set the mode by calling set_parameter!(:Mode, \"Tutorial\") or deactivate it by set_parameter!(:Mode, \"\").\n\n\n\n\n\n","category":"function"},{"location":"plans/#A-factory-for-providing-manifold-defaults","page":"Specify a Solver","title":"A factory for providing manifold defaults","text":"","category":"section"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"In several cases a manifold might not yet be known at the time a (keyword) argument should be provided. Therefore, any type with a manifold default can be wrapped into a factory.","category":"page"},{"location":"plans/#Manopt.ManifoldDefaultsFactory","page":"Specify a Solver","title":"Manopt.ManifoldDefaultsFactory","text":"ManifoldDefaultsFactory{M,T,A,K}\n\nA generic factory to postpone the instantiation of certain types from within Manopt.jl, in order to be able to adapt it to defaults from different manifolds and/or postpone the decission on which manifold to use to a later point\n\nFor now this is established for\n\nDirectionUpdateRules\nStepsize\nStoppingCriterion\n\nThis factory stores necessary and optional parameters as well as keyword arguments provided by the user to later produce the type this factory is for.\n\nBesides a manifold as a fallback, the factory can also be used for the (maybe simpler) types from the list of types that do not require the manifold.\n\nFields\n\nM::Union{Nothing,AbstractManifold}:  provide a manifold for defaults\nargs::A:                             arguments (args...) that are passed to the type constructor\nkwargs::K:                           keyword arguments (kwargs...) that are passed to the type constructor\nconstructor_requires_manifold::Bool: indicate whether the type construtor requires the manifold or not\n\nConstructor\n\nManifoldDefaultsFactory(T, args...; kwargs...)\nManifoldDefaultsFactory(T, M, args...; kwargs...)\n\nInput\n\nT a subtype of types listed above that this factory is to produce\nM (optional) a manifold used for the defaults in case no manifold is provided.\nargs... arguments to pass to the constructor of T\nkwargs... keyword arguments to pass (overwrite) when constructing T.\n\nKeyword arguments\n\nrequires_manifold=true: indicate whether the type constructor this factory wraps requires the manifold as first argument or not.\n\nAll other keyword arguments are internally stored to be used in the type constructor\n\nas well as arguments and keyword arguments for the update rule.\n\nsee also\n\n_produce_type\n\n\n\n\n\n","category":"type"},{"location":"plans/#Manopt._produce_type","page":"Specify a Solver","title":"Manopt._produce_type","text":"_produce_type(t::T, M::AbstractManifold)\n_produce_type(t::ManifoldDefaultsFactory{T}, M::AbstractManifold)\n\nUse the ManifoldDefaultsFactory{T} to produce an instance of type T. This acts transparent in the way that if you provide an instance t::T already, this will just be returned.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/ConstrainedOptimization/#How-to-do-constrained-optimization","page":"Do constrained optimization","title":"How to do constrained optimization","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"This tutorial is a short introduction to using solvers for constraint optimisation in Manopt.jl.","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Introduction","page":"Do constrained optimization","title":"Introduction","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"A constraint optimisation problem is given by","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"tagP\nbeginalign*\noperatorname*argmin_pmathcal M  f(p)\ntextsuch that quad g(p) leq 0\nquad h(p) = 0\nendalign*","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"where f  mathcal M  â„ is a cost function, and g  mathcal M  â„^m and h  mathcal M  â„^n are the inequality and equality constraints, respectively. The leq and = in (P) are meant element-wise.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"This can be seen as a balance between moving constraints into the geometry of a manifold mathcal M and keeping some, since they can be handled well in algorithms, see [BH19], [LB19] for details.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"using Distributions, LinearAlgebra, Manifolds, Manopt, Random\nRandom.seed!(42);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"In this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrate the different available forms.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"We consider the problem of a Nonnegative PCA, cf.Â Section 5.1.2 in [LB19]","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"let v_0  â„^d, lVert v_0 rVert=1 be given spike signal, that is a signal that is sparse with only s=lfloor Î´d rfloor nonzero entries.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Z = sqrtÏƒ v_0v_0^mathrmT+N","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"where sigma is a signal-to-noise ratio and N is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation 1d on the off-diagonals and 2d on the diagonal","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"d = 150; # dimension of v0\nÏƒ = 0.1^2; # SNR\nÎ´ = 0.1; sp = Int(floor(Î´ * d)); # Sparsity\nS = sample(1:d, sp; replace=false);\nv0 =  [i âˆˆ S ? 1 / sqrt(sp) : 0.0 for i in 1:d];\nN = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);\nZ = Z = sqrt(Ïƒ) * v0 * transpose(v0) + N;","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"In order to recover v_0 we consider the constrained optimisation problem on the sphere mathcal S^d-1 given by","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"beginalign*\noperatorname*argmin_pmathcal S^d-1  -p^mathrmTZp^mathrmT\ntextsuch that quad p geq 0\nendalign*","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"or in the previous notation f(p) = -p^mathrmTZp^mathrmT and g(p) = -p. We first initialize the manifold under consideration","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"M = Sphere(d - 1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Sphere(149, â„)","category":"page"},{"location":"tutorials/ConstrainedOptimization/#A-first-augmented-Lagrangian-run","page":"Do constrained optimization","title":"A first augmented Lagrangian run","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"We first defined f and g as usual functions","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"f(M, p) = -transpose(p) * Z * p;\ng(M, p) = -p;","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"since f is a functions defined in the embedding â„^d as well, we obtain its gradient by projection.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"grad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"For the constraints this is a little more involved, since each function g_i=g(p)_i=p_i has to return its own gradient. These are again in the embedding just operatornamegrad g_i(p) = -e_i the i th unit vector. We can project these again onto the tangent space at p:","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"grad_g(M, p) = project.(\n    Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"We further start in a random point:","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"p0 = rand(M);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Letâ€™s verify a few things for the initial point","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"f(M, p0)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"0.005667399180991248","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"How much the function g is positive","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"maximum(g(M, p0))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"0.17885478285466855","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Now as a first method we can just call the Augmented Lagrangian Method with a simple call:","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"@time v1 = augmented_Lagrangian_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Î”p : %1.5e\"), 20, \"\\n\"],\n    stopping_criterion = StopAfterIteration(300) | (\n        StopWhenSmallerOrEqual(:Ïµ, 1e-5) & StopWhenChangeLess(M, 1e-8)\n    )\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Initial f(x): 0.005667 | \n# 20    f(x): -0.123557 | Î”p : 1.00133e+00\n# 40    f(x): -0.123557 | Î”p : 3.77088e-08\n# 60    f(x): -0.123557 | Î”p : 2.40619e-05\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-5).\nAt iteration 68 the algorithm performed a step with a change (7.600544776224794e-11) less than 9.77237220955808e-6.\n  5.690243 seconds (18.85 M allocations: 1.493 GiB, 2.95% gc time, 97.61% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Now we have both a lower function value and the point is nearly within the constraints, namely up to numerical inaccuracies","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"f(M, v1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"-0.12353580883894738","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"maximum( g(M, v1) )","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"4.577229036010474e-12","category":"page"},{"location":"tutorials/ConstrainedOptimization/#A-faster-augmented-Lagrangian-run","page":"Do constrained optimization","title":"A faster augmented Lagrangian run","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Now this is a little slow, so we can modify two things:","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Gradients should be evaluated in place, so for example","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"grad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"The constraints are currently always evaluated all together, since the function grad_g always returns a vector of gradients.  We first change the constraints function into a vector of functions.  We further change the gradient both into a vector of gradient functions operatornamegrad g_ii=1ldotsd, as well as gradients that are computed in place.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"g2 = [(M, p) -> -p[i] for i in 1:d];\ngrad_g2! = [\n    (M, X, p) -> project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d\n];","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"We obtain","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"@time v2 = augmented_Lagrangian_method(\n        M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n        debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Î”p : %1.5e\"), 20, \"\\n\"],\n        stopping_criterion = StopAfterIteration(300) | (\n          StopWhenSmallerOrEqual(:Ïµ, 1e-5) & StopWhenChangeLess(M, 1e-8)\n        )\n    );","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Initial f(x): 0.005667 | \n# 20    f(x): -0.123557 | Î”p : 1.00133e+00\n# 40    f(x): -0.123557 | Î”p : 3.77088e-08\n# 60    f(x): -0.123557 | Î”p : 2.40619e-05\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-5).\nAt iteration 68 the algorithm performed a step with a change (7.600544776224794e-11) less than 9.77237220955808e-6.\n  2.347736 seconds (7.49 M allocations: 753.774 MiB, 2.96% gc time, 95.25% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"As a technical remark: note that (by default) the change to InplaceEvaluations affects both the constrained solver as well as the inner solver of the subproblem in each iteration.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"f(M, v2)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"-0.12353580883894738","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"maximum(g(M, v2))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"4.577229036010474e-12","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"These are the very similar to the previous values but the solver took much less time and less memory allocations.","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Exact-penalty-method","page":"Do constrained optimization","title":"Exact penalty method","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"As a second solver, we have the Exact Penalty Method, which currently is available with two smoothing variants, which make an inner solver for smooth optimization, that is by default again [quasi Newton] possible: LogarithmicSumOfExponentials and LinearQuadraticHuber. We compare both here as well. The first smoothing technique is the default, so we can just call","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"@time v3 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Initial f(x): 0.005667 | \n# 50    f(x): -0.122792 | Last Change: 0.982159\n# 100   f(x): -0.123555 | Last Change: 0.013515\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (3.0244885037602495e-7) less than 1.0e-6.\n  2.397207 seconds (14.29 M allocations: 4.753 GiB, 7.13% gc time, 69.62% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"We obtain a similar cost value as for the Augmented Lagrangian Solver from before, but here the constraint is actually fulfilled and not just numerically â€œon the boundaryâ€.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"f(M, v3)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"-0.12355544268449432","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"maximum(g(M, v3))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"-3.589798060999793e-6","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"The second smoothing technique is often beneficial, when we have a lot of constraints (in the previously mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"@time v4 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!,\n    evaluation=InplaceEvaluation(),\n    smoothing=LinearQuadraticHuber(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Initial f(x): 0.005667 | \n# 50    f(x): -0.123559 | Last Change: 0.008024\n# 100   f(x): -0.123557 | Last Change: 0.000026\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 101 the algorithm performed a step with a change (1.0069976577931588e-8) less than 1.0e-6.\n  2.004572 seconds (9.40 M allocations: 2.174 GiB, 5.66% gc time, 85.63% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"For the result we see the same behaviour as for the other smoothing.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"f(M, v4)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"-0.12355667846565418","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"maximum(g(M, v4))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"2.6974802196316014e-8","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Comparing-to-the-unconstrained-solver","page":"Do constrained optimization","title":"Comparing to the unconstrained solver","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"We can compare this to the global optimum on the sphere, which is the unconstrained optimisation problem, where we can just use Quasi Newton.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Note that this is much faster, since every iteration of the algorithm does a quasi-Newton call as well.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"@time w1 = quasi_Newton(\n    M, f, grad_f!, p0; evaluation=InplaceEvaluation()\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"  0.715850 seconds (1.92 M allocations: 115.760 MiB, 2.13% gc time, 97.04% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"f(M, w1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"-0.13990874034056555","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"But for sure here the constraints here are not fulfilled and we have quite positive entries in g(w_1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"maximum(g(M, w1))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"0.11803200739746737","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Technical-details","page":"Do constrained optimization","title":"Technical details","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"This tutorial is cached. It was last run on the following package versions.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"using Pkg\nPkg.status()","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.0.3\n  [0fc0a36d] Manopt v0.5.13 `~/work/Manopt.jl/Manopt.jl`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"using Dates\nnow()","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"2025-04-25T12:11:03.946","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Literature","page":"Do constrained optimization","title":"Literature","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do constrained optimization","title":"Do constrained optimization","text":"R.Â Bergmann and R.Â Herzog. Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds. SIAMÂ JournalÂ onÂ Optimization 29, 2423â€“2444 (2019), arXiv:1804.06214.\n\n\n\nC.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\n","category":"page"},{"location":"helpers/exports/#sec-exports","page":"Exports","title":"Exports","text":"","category":"section"},{"location":"helpers/exports/","page":"Exports","title":"Exports","text":"Exports aim to provide a consistent generation of images of your results. For example if you record the trace your algorithm walks on the Sphere, you can easily export this trace to a rendered image using asymptote_export_S2_signals and render the result with Asymptote. Despite these, you can always record values during your iterations, and export these, for example to csv.","category":"page"},{"location":"helpers/exports/#Asymptote","page":"Exports","title":"Asymptote","text":"","category":"section"},{"location":"helpers/exports/","page":"Exports","title":"Exports","text":"The following functions provide exports both in graphics and/or raw data using Asymptote.","category":"page"},{"location":"helpers/exports/#Manopt.asymptote_export_S2_data-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_S2_data","text":"asymptote_export_S2_data(filename)\n\nExport given data as an array of points on the 2-sphere, which might be one-, two- or three-dimensional data with points on the Sphere mathbb S^2.\n\nInput\n\nfilename                a file to store the Asymptote code in.\n\nOptional arguments for the data\n\ndata                    a point representing the 1D,2D, or 3D array of points\nelevation_color_scheme  A ColorScheme for elevation\nscale_axes=(1/3,1/3,1/3): move spheres closer to each other by a factor per direction\n\nOptional arguments for asymptote\n\narrow_head_size=1.8: size of the arrowheads of the vectors (in mm)\ncamera_position  position of the camera scene (default: atop the center of the data in the xy-plane)\ntarget           position the camera points at (default: center of xy-plane within data).\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.asymptote_export_S2_signals-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_S2_signals","text":"asymptote_export_S2_signals(filename; points, curves, tangent_vectors, colors, kwargs...)\n\nExport given points, curves, and tangent_vectors on the sphere mathbb S^2 to Asymptote.\n\nInput\n\nfilename          a file to store the Asymptote code in.\n\nKeywaord arguments for the data\n\ncolors=Dict{Symbol,Array{RGBA{Float64},1}}(): dictionary of color arrays, indexed by symbols :points, :curves and :tvector, where each entry has to provide as least as many colors as the length of the corresponding sets.\ncurves=Array{Array{Float64,1},1}(undef, 0): an Array of Arrays of points on the sphere, where each inner array is interpreted as a curve and is accompanied by an entry within colors.\npoints=Array{Array{Float64,1},1}(undef, 0): an Array of Arrays of points on the sphere where each inner array is interpreted as a set of points and is accompanied by an entry within colors.\ntangent_vectors=Array{Array{Tuple{Float64,Float64},1},1}(undef, 0): an Array of Arrays of tuples, where the first is a points, the second a tangent vector and each set of vectors is accompanied by an entry from within colors.\n\nKeyword arguments for asymptote\n\narrow_head_size=6.0: size of the arrowheads of the tangent vectors\narrow_head_sizes  overrides the previous value to specify a value per tVector` set.\ncamera_position=(1., 1., 0.): position of the camera in the Asymptote scene\nline_width=1.0: size of the lines used to draw the curves.\nline_widths       overrides the previous value to specify a value per curve and tVector` set.\ndot_size=1.0: size of the dots used to draw the points.\ndot_sizes         overrides the previous value to specify a value per point set.\nsize=nothing: a tuple for the image size, otherwise a relative size 4cm is used.\nsphere_color=RGBA{Float64}(0.85, 0.85, 0.85, 0.6): color of the sphere the data is drawn on\nsphere_line_color=RGBA{Float64}(0.75, 0.75, 0.75, 0.6): color of the lines on the sphere\nsphere_line_width=0.5: line width of the lines on the sphere\ntarget=(0.,0.,0.): position the camera points at\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.asymptote_export_SPD-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_SPD","text":"asymptote_export_SPD(filename)\n\nexport given data as a point on a Power(SymmetricPOsitiveDefinnite(3))} manifold of one-, two- or three-dimensional data with points on the manifold of symmetric positive definite matrices.\n\nInput\n\nfilename        a file to store the Asymptote code in.\n\nOptional arguments for the data\n\ndata            a point representing the 1D, 2D, or 3D array of SPD matrices\ncolor_scheme    a ColorScheme for Geometric Anisotropy Index\nscale_axes=(1/3,1/3,1/3): move symmetric positive definite matrices closer to each other by a factor per direction compared to the distance estimated by the maximal eigenvalue of all involved SPD points\n\nOptional arguments for asymptote\n\ncamera_position  position of the camera scene (default: atop the center of the data in the xy-plane)\ntarget           position the camera points at (default: center of xy-plane within data).\n\nBoth values camera_position and target are scaled by scaledAxes*EW, where EW is the maximal eigenvalue in the data.\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.render_asymptote-Tuple{Any}","page":"Exports","title":"Manopt.render_asymptote","text":"render_asymptote(filename; render=4, format=\"png\", ...)\n\nrender an exported asymptote file specified in the filename, which can also be given as a relative or full path\n\nInput\n\nfilename    filename of the exported asy and rendered image\n\nKeyword arguments\n\nthe default values are given in brackets\n\nrender=4: render level of asymptote passed to its -render option.  This can be removed from the command by setting it to nothing.\nformat=\"png\": final rendered format passed to the -f option\nexport_file: (the filename with format as ending) specify the export filename\n\n\n\n\n\n","category":"method"},{"location":"plans/problem/#sec-problem","page":"Problem","title":"A Manopt problem","text":"","category":"section"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"A problem describes all static data of an optimisation task and has as a super type","category":"page"},{"location":"plans/problem/#Manopt.AbstractManoptProblem","page":"Problem","title":"Manopt.AbstractManoptProblem","text":"AbstractManoptProblem{M<:AbstractManifold}\n\nDescribe a Riemannian optimization problem with all static (not-changing) properties.\n\nThe most prominent features that should always be stated here are\n\nthe AbstractManifold mathcal M\nthe cost function f  mathcal M  â„\n\nUsually the cost should be within an AbstractManifoldObjective.\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/#Manopt.get_objective","page":"Problem","title":"Manopt.get_objective","text":"get_objective(o::AbstractManifoldObjective, recursive=true)\n\nreturn the (one step) undecorated AbstractManifoldObjective of the (possibly) decorated o. As long as your decorated objective stores the objective within o.objective and the dispatch_objective_decorator is set to Val{true}, the internal state are extracted automatically.\n\nBy default the objective that is stored within a decorated objective is assumed to be at o.objective. Overwrite _get_objective(o, ::Val{true}, recursive) to change this behaviour for your objectiveo` for both the recursive and the direct case.\n\nIf recursive is set to false, only the most outer decorator is taken away instead of all.\n\n\n\n\n\nget_objective(mp::AbstractManoptProblem, recursive=false)\n\nreturn the objective AbstractManifoldObjective stored within an AbstractManoptProblem. If recursive is set to true, it additionally unwraps all decorators of the objective\n\n\n\n\n\nget_objective(amso::AbstractManifoldSubObjective)\n\nReturn the (original) objective stored the sub objective is build on.\n\n\n\n\n\n","category":"function"},{"location":"plans/problem/#Manopt.get_manifold","page":"Problem","title":"Manopt.get_manifold","text":"get_manifold(amp::AbstractManoptProblem)\n\nreturn the manifold stored within an AbstractManoptProblem\n\n\n\n\n\n","category":"function"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"Usually, such a problem is determined by the manifold or domain of the optimisation and the objective with all its properties used within an algorithm, see The Objective. For that one can just use","category":"page"},{"location":"plans/problem/#Manopt.DefaultManoptProblem","page":"Problem","title":"Manopt.DefaultManoptProblem","text":"DefaultManoptProblem{TM <: AbstractManifold, Objective <: AbstractManifoldObjective}\n\nModel a default manifold problem, that (just) consists of the domain of optimisation, that is an AbstractManifold and an AbstractManifoldObjective\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"For the constraint optimisation, there are different possibilities to represent the gradients of the constraints. This can be done with a","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"ConstraintProblem","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"The primal dual-based solvers (Chambolle-Pock and the PD Semi-smooth Newton), both need two manifolds as their domains, hence there also exists a","category":"page"},{"location":"plans/problem/#Manopt.TwoManifoldProblem","page":"Problem","title":"Manopt.TwoManifoldProblem","text":"TwoManifoldProblem{\n    MT<:AbstractManifold,NT<:AbstractManifold,O<:AbstractManifoldObjective\n} <: AbstractManoptProblem{MT}\n\nAn abstract type for primal-dual-based problems.\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"From the two ingredients here, you can find more information about","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"the ManifoldsBase.AbstractManifold in ManifoldsBase.jl\nthe AbstractManifoldObjective on the page about the objective.","category":"page"},{"location":"solvers/quasi_Newton/#Riemannian-quasi-Newton-methods","page":"Quasi-Newton","title":"Riemannian quasi-Newton methods","text":"","category":"section"},{"location":"solvers/quasi_Newton/#Manopt.quasi_Newton","page":"Quasi-Newton","title":"Manopt.quasi_Newton","text":"quasi_Newton(M, f, grad_f, p; kwargs...)\nquasi_Newton!(M, f, grad_f, p; kwargs...)\n\nPerform a quasi Newton iteration to solve\n\noperatorname*argmin_p  mathcal M f(p)\n\nwith start point p. The iterations can be done in-place of p=p^(0). The kth iteration consists of\n\nCompute the search direction Î·^(k) = -mathcal B_k operatornamegradf (p^(k)) or solve mathcal H_k Î·^(k) = -operatornamegradf (p^(k)).\nDetermine a suitable stepsize Î±_k along the curve Î³(Î±) = R_p^(k)(Î± Î·^(k)), usually by using WolfePowellLinesearch.\nCompute p^(k+1) = R_p^(k)(Î±_k Î·^(k)).\nDefine s_k = mathcal T_p^(k) Î±_k Î·^(k)(Î±_k Î·^(k)) and y_k = operatornamegradf(p^(k+1)) - mathcal T_p^(k) Î±_k Î·^(k)(operatornamegradf(p^(k))), where mathcal T denotes a vector transport.\nCompute the new approximate Hessian H_k+1 or its inverse B_k+1.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nbasis=DefaultOrthonormalBasis(): basis to use within each of the the tangent spaces to represent the Hessian (inverse) for the cases where it is stored in full (matrix) form.\ncautious_update=false:  whether or not to use the QuasiNewtonCautiousDirectionUpdate  which wraps the direction_upate.\ncautious_function=(x) -> x * 1e-4: a monotone increasing function for the cautious update that is zero at x=0 and strictly increasing at 0\ndirection_update=InverseBFGS(): the AbstractQuasiNewtonUpdateRule to use.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\ninitial_operator= initial_scale*Matrix{Float64}(I, n, n):  initial matrix to use in case the Hessian (inverse) approximation is stored as a full matrix,  that is n=manifold_dimension(M). This matrix is only allocated for the full matrix case.  See also initial_scale.\ninitial_scale=1.0: scale initial s to use in with fracss_ky_k_p_klVert y_krVert_p_k in the computation of the limited memory approach. see also initial_operator\nmemory_size=20: limited memory, number of s_k y_k to store.  Set to a negative value to use a full memory (matrix) representation\nnondescent_direction_behavior=:reinitialize_direction_update: specify how non-descent direction is handled. This can be\n:step_towards_negative_gradient: the direction is replaced with negative gradient, a message is stored.\n:ignore: the verification is not performed, so any computed direction is accepted. No message is stored.\n:reinitialize_direction_update: discards operator state stored in direction update rules.\nany other value performs the verification, keeps the direction but stores a message.\nA stored message can be displayed using DebugMessages.\npreconditioner=nothing specify a preconditioner, either\nthe default nothing does not activate a preconditioning\na function of the form (M, p, X) -> Y or mutating (M, Y, p, X) -> Y depending on the evaluation\na PreconditionedDirection. See also their docs for mor details on the preconditioner.\nNote that the preconditioner is applied to the gradient, i.e. the right hand side before solving the linear system.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=WolfePowellLinesearch(retraction_method, vector_transport_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(max(1000, memory_size))|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Manopt.quasi_Newton!","page":"Quasi-Newton","title":"Manopt.quasi_Newton!","text":"quasi_Newton(M, f, grad_f, p; kwargs...)\nquasi_Newton!(M, f, grad_f, p; kwargs...)\n\nPerform a quasi Newton iteration to solve\n\noperatorname*argmin_p  mathcal M f(p)\n\nwith start point p. The iterations can be done in-place of p=p^(0). The kth iteration consists of\n\nCompute the search direction Î·^(k) = -mathcal B_k operatornamegradf (p^(k)) or solve mathcal H_k Î·^(k) = -operatornamegradf (p^(k)).\nDetermine a suitable stepsize Î±_k along the curve Î³(Î±) = R_p^(k)(Î± Î·^(k)), usually by using WolfePowellLinesearch.\nCompute p^(k+1) = R_p^(k)(Î±_k Î·^(k)).\nDefine s_k = mathcal T_p^(k) Î±_k Î·^(k)(Î±_k Î·^(k)) and y_k = operatornamegradf(p^(k+1)) - mathcal T_p^(k) Î±_k Î·^(k)(operatornamegradf(p^(k))), where mathcal T denotes a vector transport.\nCompute the new approximate Hessian H_k+1 or its inverse B_k+1.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcal M  T_pmathcal M of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np: a point on the manifold mathcal M\n\nKeyword arguments\n\nbasis=DefaultOrthonormalBasis(): basis to use within each of the the tangent spaces to represent the Hessian (inverse) for the cases where it is stored in full (matrix) form.\ncautious_update=false:  whether or not to use the QuasiNewtonCautiousDirectionUpdate  which wraps the direction_upate.\ncautious_function=(x) -> x * 1e-4: a monotone increasing function for the cautious update that is zero at x=0 and strictly increasing at 0\ndirection_update=InverseBFGS(): the AbstractQuasiNewtonUpdateRule to use.\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\ninitial_operator= initial_scale*Matrix{Float64}(I, n, n):  initial matrix to use in case the Hessian (inverse) approximation is stored as a full matrix,  that is n=manifold_dimension(M). This matrix is only allocated for the full matrix case.  See also initial_scale.\ninitial_scale=1.0: scale initial s to use in with fracss_ky_k_p_klVert y_krVert_p_k in the computation of the limited memory approach. see also initial_operator\nmemory_size=20: limited memory, number of s_k y_k to store.  Set to a negative value to use a full memory (matrix) representation\nnondescent_direction_behavior=:reinitialize_direction_update: specify how non-descent direction is handled. This can be\n:step_towards_negative_gradient: the direction is replaced with negative gradient, a message is stored.\n:ignore: the verification is not performed, so any computed direction is accepted. No message is stored.\n:reinitialize_direction_update: discards operator state stored in direction update rules.\nany other value performs the verification, keeps the direction but stores a message.\nA stored message can be displayed using DebugMessages.\npreconditioner=nothing specify a preconditioner, either\nthe default nothing does not activate a preconditioning\na function of the form (M, p, X) -> Y or mutating (M, Y, p, X) -> Y depending on the evaluation\na PreconditionedDirection. See also their docs for mor details on the preconditioner.\nNote that the preconditioner is applied to the gradient, i.e. the right hand side before solving the linear system.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=WolfePowellLinesearch(retraction_method, vector_transport_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion=StopAfterIteration(max(1000, memory_size))|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Background","page":"Quasi-Newton","title":"Background","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"The aim is to minimize a real-valued function on a Riemannian manifold, that is","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"min f(p) quad p  mathcalM","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Riemannian quasi-Newtonian methods are as generalizations of their Euclidean counterparts Riemannian line search methods. These methods determine a search direction Î·_k  T_p_k mathcalM at the current iterate p_k and a suitable stepsize Î±_k along gamma(Î±) = R_p_k(Î± Î·_k), where R T mathcalM mathcalM is a retraction. The next iterate is obtained by","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"p_k+1 = R_p_k(Î±_k Î·_k)","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"In quasi-Newton methods, the search direction is given by","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Î·_k = -mathcalH_k^-1operatornamegradf (p_k) = -mathcalB_k operatornamegrad (p_k)","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where mathcalH_k  T_p_k mathcalM T_p_k mathcalM is a positive definite self-adjoint operator, which approximates the action of the Hessian operatornameHess f (p_k) and mathcalB_k = mathcalH_k^-1. The idea of quasi-Newton methods is instead of creating a complete new approximation of the Hessian operator operatornameHess f(p_k+1) or its inverse at every iteration, the previous operator mathcalH_k or mathcalB_k is updated by a convenient formula using the obtained information about the curvature of the objective function during the iteration. The resulting operator mathcalH_k+1 or mathcalB_k+1 acts on the tangent space T_p_k+1 mathcalM of the freshly computed iterate p_k+1. In order to get a well-defined method, the following requirements are placed on the new operator mathcalH_k+1 or mathcalB_k+1 that is created by an update. Since the Hessian operatornameHess f(p_k+1) is a self-adjoint operator on the tangent space T_p_k+1 mathcalM, and mathcalH_k+1 approximates it, one requirement is, that mathcalH_k+1 or mathcalB_k+1 is also self-adjoint on T_p_k+1 mathcalM. In order to achieve a steady descent, the next requirement is that Î·_k is a descent direction in each iteration. Hence a further requirement is that mathcalH_k+1 or mathcalB_k+1 is a positive definite operator on T_p_k+1 mathcalM. In order to get information about the curvature of the objective function into the new operator mathcalH_k+1 or mathcalB_k+1, the last requirement is a form of a Riemannian quasi-Newton equation:","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"mathcalH_k+1 T_p_k rightarrow p_k+1(R_p_k^-1(p_k+1)) = operatornamegrad(p_k+1) - T_p_k rightarrow p_k+1(operatornamegradf(p_k))","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"or","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"mathcalB_k+1 operatornamegradf(p_k+1) - T_p_k rightarrow p_k+1(operatornamegradf(p_k)) = T_p_k rightarrow p_k+1(R_p_k^-1(p_k+1))","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where T_p_k rightarrow p_k+1  T_p_k mathcalM T_p_k+1 mathcalM and the chosen retraction R is the associated retraction of T. Note that, of course, not all updates in all situations meet these conditions in every iteration. For specific quasi-Newton updates, the fulfilment of the Riemannian curvature condition, which requires that","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"g_p_k+1(s_k y_k)  0","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"holds, is a requirement for the inheritance of the self-adjointness and positive definiteness of the mathcalH_k or mathcalB_k to the operator mathcalH_k+1 or mathcalB_k+1. Unfortunately, the fulfilment of the Riemannian curvature condition is not given by a step size alpha_k  0 that satisfies the generalized Wolfe conditions. However, to create a positive definite operator mathcalH_k+1 or mathcalB_k+1 in each iteration, the so-called locking condition was introduced in [HGA15], which requires that the isometric vector transport T^S, which is used in the update formula, and its associate retraction R fulfil","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"T^Sp Î¾_p(Î¾_p) = Î² T^Rp Î¾_p(Î¾_p) quad Î² = fraclVert Î¾_p rVert_plVert T^Rp Î¾_p(Î¾_p) rVert_R_p(Î¾_p)","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where T^R is the vector transport by differentiated retraction. With the requirement that the isometric vector transport T^S and its associated retraction R satisfies the locking condition and using the tangent vector","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"y_k = Î²_k^-1 operatornamegradf(p_k+1) - T^Sp_k Î±_k Î·_k(operatornamegradf(p_k))","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Î²_k = fraclVert Î±_k Î·_k rVert_p_klVert T^Rp_k Î±_k Î·_k(Î±_k Î·_k) rVert_p_k+1","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"in the update, it can be shown that choosing a stepsize Î±_k  0 that satisfies the Riemannian Wolfe conditions leads to the fulfilment of the Riemannian curvature condition, which in turn implies that the operator generated by the updates is positive definite. In the following the specific operators are denoted in matrix notation and hence use H_k and B_k, respectively.","category":"page"},{"location":"solvers/quasi_Newton/#Direction-updates","page":"Quasi-Newton","title":"Direction updates","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"In general there are different ways to compute a fixed AbstractQuasiNewtonUpdateRule. In general these are represented by","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonDirectionUpdate","page":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonDirectionUpdate","text":"AbstractQuasiNewtonDirectionUpdate\n\nAn abstract representation of an Quasi Newton Update rule to determine the next direction given current QuasiNewtonState.\n\nAll subtypes should be functors, they should be callable as H(M,x,d) to compute a new direction update.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonMatrixDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonMatrixDirectionUpdate","text":"QuasiNewtonMatrixDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThe QuasiNewtonMatrixDirectionUpdate represent a quasi-Newton update rule, where the operator is stored as a matrix. A distinction is made between the update of the approximation of the Hessian, H_k mapsto H_k+1, and the update of the approximation of the Hessian inverse, B_k mapsto B_k+1. For the first case, the coordinates of the search direction Î·_k with respect to a basis b_i_i=1^n are determined by solving a linear system of equations\n\ntextSolve quad hatÎ·_k = - H_k widehatoperatornamegradf(x_k)\n\nwhere H_k is the matrix representing the operator with respect to the basis b_i_i=1^n and widehatoperatornamegrad f(p_k) represents the coordinates of the gradient of the objective function f in x_k with respect to the basis b_i_i=1^n. If a method is chosen where Hessian inverse is approximated, the coordinates of the search direction Î·_k with respect to a basis b_i_i=1^n are obtained simply by matrix-vector multiplication\n\nhatÎ·_k = - B_k widehatoperatornamegradf(x_k)\n\nwhere B_k is the matrix representing the operator with respect to the basis b_i_i=1^n and widehatoperatornamegrad f(p_k). In the end, the search direction Î·_k is generated from the coordinates hateta_k and the vectors of the basis b_i_i=1^n in both variants. The AbstractQuasiNewtonUpdateRule indicates which quasi-Newton update rule is used. In all of them, the Euclidean update formula is used to generate the matrix H_k+1 and B_k+1, and the basis b_i_i=1^n is transported into the upcoming tangent space T_p_k+1 mathcal M, preferably with an isometric vector transport, or generated there.\n\nProvided functors\n\n(mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction\n(Î·, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction in-place of Î·\n\nFields\n\nbasis:                  an AbstractBasis to use in the tangent spaces\nmatrix:                 the matrix which represents the approximating operator.\ninitial_scale:          when initialising the update, a unit matrix is used as initial approximation, scaled by this factor\nupdate:                 a AbstractQuasiNewtonUpdateRule.\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nQuasiNewtonMatrixDirectionUpdate(\n    M::AbstractManifold,\n    update,\n    basis::B=DefaultOrthonormalBasis(),\n    m=Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M));\n    kwargs...\n)\n\nKeyword arguments\n\ninitial_scale=1.0 â€“ this can also be deactivated by passing nothing.\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nGenerate the Update rule with defaults from a manifold and the names corresponding to the fields.\n\nSee also\n\nQuasiNewtonLimitedMemoryDirectionUpdate, QuasiNewtonCautiousDirectionUpdate, AbstractQuasiNewtonDirectionUpdate,\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","text":"QuasiNewtonLimitedMemoryDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThis AbstractQuasiNewtonDirectionUpdate represents the limited-memory Riemannian BFGS update, where the approximating operator is represented by m stored pairs of tangent vectors widehats_i_i=k-m^k-1 and widehaty_i_i=k-m^k-1 in the k-th iteration. For the calculation of the search direction X_k, the generalisation of the two-loop recursion is used (see [HGA15]), since it only requires inner products and linear combinations of tangent vectors in T_p_kmathcal M. For that the stored pairs of tangent vectors widehats_i  widehaty_i, the gradient operatornamegrad f(p_k) of the objective function f in p_k and the positive definite self-adjoint operator\n\nmathcalB^(0)_k = fracg_p_k(s_k-1 y_k-1)g_p_k(y_k-1 y_k-1)  mathrmid_T_p_k mathcalM\n\nare used. The two-loop recursion can be understood as that the InverseBFGS update is executed m times in a row on mathcal B^(0)_k using the tangent vectors widehats_iwidehaty_i, and in the same time the resulting operator mathcal B^LRBFGS_k  is directly applied on operatornamegradf(x_k). When updating there are two cases: if there is still free memory, k  m, the previously stored vector pairs widehats_iwidehaty_i have to be transported into the upcoming tangent space T_p_k+1mathcal M. If there is no free memory, the oldest pair widehats_iwidehaty_i has to be discarded and then all the remaining vector pairs widehats_iwidehaty_i are transported into the tangent space T_p_k+1mathcal M. After that the new values s_k = widehats_k = T^S_x_k Î±_k Î·_k(Î±_k Î·_k) and y_k = widehaty_k are stored at the beginning. This process ensures that new information about the objective function is always included and the old, probably no longer relevant, information is discarded.\n\nProvided functors\n\n(mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction\n(Î·, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction in-place of Î·\n\nFields\n\nmemory_s:                the set of the stored (and transported) search directions times step size widehats_i_i=k-m^k-1.\nmemory_y:                set of the stored gradient differences widehaty_i_i=k-m^k-1.\nÎ¾:                       a variable used in the two-loop recursion.\nÏL                       a variable used in the two-loop recursion.\ninitial_scale:           initial scaling of the Hessian, deactivate (e.g. when using a preconditioner) by passing nothing\nvector_transport_method::AbstractVectorTransportMethodP: a vector transport mathcal T_ to use, see the section on vector transports\nmessage:                 a string containing a potential warning that might have appeared\nproject!:                a function to stabilize the update by projecting on the tangent space\n\nConstructor\n\nQuasiNewtonLimitedMemoryDirectionUpdate(\n    M::AbstractManifold,\n    x,\n    update::AbstractQuasiNewtonUpdateRule,\n    memory_size::Int;\n    initial_vector=zero_vector(M,x),\n    initial_scale::Real=1.0\n    project!=copyto!\n)\n\nSee also\n\nInverseBFGS QuasiNewtonCautiousDirectionUpdate AbstractQuasiNewtonDirectionUpdate\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonCautiousDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonCautiousDirectionUpdate","text":"QuasiNewtonCautiousDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThese AbstractQuasiNewtonDirectionUpdates represent any quasi-Newton update rule, which are based on the idea of a so-called cautious update. The search direction is calculated as given in QuasiNewtonMatrixDirectionUpdate or QuasiNewtonLimitedMemoryDirectionUpdate, butut the update  then is only executed if\n\nfracg_x_k+1(y_ks_k)lVert s_k rVert^2_x_k+1  Î¸(lVert operatornamegradf(x_k) rVert_x_k)\n\nis satisfied, where Î¸ is a monotone increasing function satisfying Î¸(0) = 0 and Î¸ is strictly increasing at 0. If this is not the case, the corresponding update is skipped, which means that for QuasiNewtonMatrixDirectionUpdate the matrix H_k or B_k is not updated. The basis b_i^n_i=1 is nevertheless transported into the upcoming tangent space T_x_k+1 mathcalM, and for QuasiNewtonLimitedMemoryDirectionUpdate neither the oldest vector pair  widetildes_km widetildey_km is discarded nor the newest vector pair  widetildes_k widetildey_k is added into storage, but all stored vector pairs  widetildes_i widetildey_i_i=k-m^k-1 are transported into the tangent space T_x_k+1 mathcalM. If InverseBFGS or InverseBFGS is chosen as update, then the resulting method follows the method of [HAG18], taking into account that the corresponding step size is chosen.\n\nProvided functors\n\n(mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction\n(Î·, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction in-place of Î·\n\nFields\n\nupdate: an AbstractQuasiNewtonDirectionUpdate\nÎ¸:      a monotone increasing function satisfying Î¸(0) = 0 and Î¸ is strictly increasing at 0.\n\nConstructor\n\nQuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonMatrixDirectionUpdate; Î¸ = identity)\nQuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonLimitedMemoryDirectionUpdate; Î¸ = identity)\n\nGenerate a cautious update for either a matrix based or a limited memory based update rule.\n\nSee also\n\nQuasiNewtonMatrixDirectionUpdate QuasiNewtonLimitedMemoryDirectionUpdate\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.initialize_update!","page":"Quasi-Newton","title":"Manopt.initialize_update!","text":"initialize_update!(s::AbstractQuasiNewtonDirectionUpdate)\n\nInitialize direction update. By default no change is made.\n\n\n\n\n\ninitialize_update!(d::QuasiNewtonLimitedMemoryDirectionUpdate)\n\nInitialize the limited memory direction update by emptying the memory buffers.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonPreconditioner","page":"Quasi-Newton","title":"Manopt.QuasiNewtonPreconditioner","text":"QuasiNewtonPreconditioner{E<:AbstractEvaluationType, F}\n\nAdd a preconditioning\n\nFields\n\npreconditioner::F: the preconditioner function\n\nConstructors\n\nQuasiNewtonPreconditioner(\n    preconditioner;\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n)\n\nAdd preconditioning to a gradient problem.\n\nInput\n\npreconditioner:   preconditioner function, either as a (M, p, X) -> Y allocating or (M, Y, p, X) -> Y mutating function\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Hessian-update-rules","page":"Quasi-Newton","title":"Hessian update rules","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Using","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.update_hessian!","page":"Quasi-Newton","title":"Manopt.update_hessian!","text":"update_hessian!(d::AbstractQuasiNewtonDirectionUpdate, amp, st, p_old, k)\n\nupdate the Hessian within the QuasiNewtonState st given a AbstractManoptProblem amp as well as the an AbstractQuasiNewtonDirectionUpdate d and the last iterate p_old. Note that the current (kth) iterate is already stored in get_iterate(st).\n\nSee also AbstractQuasiNewtonUpdateRule and its subtypes for the different rules that are available within d.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"the following update formulae for either H_k+1 or B_k+1 are available.","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonUpdateRule","page":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonUpdateRule","text":"AbstractQuasiNewtonUpdateRule\n\nSpecify a type for the different AbstractQuasiNewtonDirectionUpdates, that is for a QuasiNewtonMatrixDirectionUpdate there are several different updates to the matrix, while the default for QuasiNewtonLimitedMemoryDirectionUpdate the most prominent is InverseBFGS.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.BFGS","page":"Quasi-Newton","title":"Manopt.BFGS","text":"BFGS <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian BFGS update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeH_k^mathrmBFGS the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmBFGS_k+1 = widetildeH^mathrmBFGS_k  + fracy_k y^mathrmT_k s^mathrmT_k y_k - fracwidetildeH^mathrmBFGS_k s_k s^mathrmT_k widetildeH^mathrmBFGS_k s^mathrmT_k widetildeH^mathrmBFGS_k s_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.DFP","page":"Quasi-Newton","title":"Manopt.DFP","text":"DFP <: AbstractQuasiNewtonUpdateRule\n\nindicates in an AbstractQuasiNewtonDirectionUpdate that the Riemannian DFP update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeH_k^mathrmDFP the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmDFP_k+1 = Bigl(\n  mathrmid_T_x_k+1 mathcalM - fracy_k s^mathrmT_ks^mathrmT_k y_k\nBigr)\nwidetildeH^mathrmDFP_k\nBigl(\n  mathrmid_T_x_k+1 mathcalM - fracs_k y^mathrmT_ks^mathrmT_k y_k\nBigr) + fracy_k y^mathrmT_ks^mathrmT_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.Broyden","page":"Quasi-Newton","title":"Manopt.Broyden","text":"Broyden <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of BFGS and DFP.\n\nDenote by widetildeH_k^mathrmBr the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmBr_k+1 = widetildeH^mathrmBr_k\n  - fracwidetildeH^mathrmBr_k s_k s^mathrmT_k widetildeH^mathrmBr_ks^mathrmT_k widetildeH^mathrmBr_k s_k + fracy_k y^mathrmT_ks^mathrmT_k y_k\n  + Ï†_k s^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigl(\n        fracy_ks^mathrmT_k y_k - fracwidetildeH^mathrmBr_k s_ks^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigr)\n  Bigl(\n        fracy_ks^mathrmT_k y_k - fracwidetildeH^mathrmBr_k s_ks^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigr)^mathrmT\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively, and Ï†_k is the Broyden factor which is :constant by default but can also be set to :Davidon.\n\nConstructor\n\nBroyden(Ï†, update_rule::Symbol = :constant)\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.SR1","page":"Quasi-Newton","title":"Manopt.SR1","text":"SR1 <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian SR1 update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeH_k^mathrmSR1 the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmSR1_k+1 = widetildeH^mathrmSR1_k\n+ frac\n  (y_k - widetildeH^mathrmSR1_k s_k) (y_k - widetildeH^mathrmSR1_k s_k)^mathrmT\n\n(y_k - widetildeH^mathrmSR1_k s_k)^mathrmT s_k\n\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\nThis method can be stabilized by only performing the update if denominator is larger than rlVert s_krVert_x_k+1lVert y_k - widetildeH^mathrmSR1_k s_k rVert_x_k+1 for some r0. For more details, see Section 6.2 in [NW06].\n\nConstructor\n\nSR1(r::Float64=-1.0)\n\nGenerate the SR1 update.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseBFGS","page":"Quasi-Newton","title":"Manopt.InverseBFGS","text":"InverseBFGS <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemannian BFGS update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeB_k^mathrmBFGS the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmBFGS_k+1  = Bigl(\n  mathrmid_T_x_k+1 mathcalM - fracs_k y^mathrmT_k s^mathrmT_k y_k\nBigr)\nwidetildeB^mathrmBFGS_k\nBigl(\n  mathrmid_T_x_k+1 mathcalM - fracy_k s^mathrmT_k s^mathrmT_k y_k\nBigr) + fracs_k s^mathrmT_ks^mathrmT_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseDFP","page":"Quasi-Newton","title":"Manopt.InverseDFP","text":"InverseDFP <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemannian DFP update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeB_k^mathrmDFP the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmDFP_k+1 = widetildeB^mathrmDFP_k + fracs_k s^mathrmT_ks^mathrmT_k y_k\n  - fracwidetildeB^mathrmDFP_k y_k y^mathrmT_k widetildeB^mathrmDFP_ky^mathrmT_k widetildeB^mathrmDFP_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseBroyden","page":"Quasi-Newton","title":"Manopt.InverseBroyden","text":"InverseBroyden <: AbstractQuasiNewtonUpdateRule\n\nIndicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of InverseBFGS and InverseDFP.\n\nDenote by widetildeH_k^mathrmBr the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmBr_k+1 = widetildeB^mathrmBr_k\n - fracwidetildeB^mathrmBr_k y_k y^mathrmT_k widetildeB^mathrmBr_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n   + fracs_k s^mathrmT_ks^mathrmT_k y_k\n + Ï†_k y^mathrmT_k widetildeB^mathrmBr_k y_k\n Bigl(\n     fracs_ks^mathrmT_k y_k - fracwidetildeB^mathrmBr_k y_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n    Bigr) Bigl(\n        fracs_ks^mathrmT_k y_k - fracwidetildeB^mathrmBr_k y_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n Bigr)^mathrmT\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively, and Ï†_k is the Broyden factor which is :constant by default but can also be set to :Davidon.\n\nConstructor\n\nInverseBroyden(Ï†, update_rule::Symbol = :constant)\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseSR1","page":"Quasi-Newton","title":"Manopt.InverseSR1","text":"InverseSR1 <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemannian SR1 update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeB_k^mathrmSR1 the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmSR1_k+1 = widetildeB^mathrmSR1_k\n+ frac\n  (s_k - widetildeB^mathrmSR1_k y_k) (s_k - widetildeB^mathrmSR1_k y_k)^mathrmT\n\n  (s_k - widetildeB^mathrmSR1_k y_k)^mathrmT y_k\n\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Î±_k Î·_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\nThis method can be stabilized by only performing the update if denominator is larger than rlVert y_krVert_x_k+1lVert s_k - widetildeH^mathrmSR1_k y_k rVert_x_k+1 for some r0. For more details, see Section 6.2 in [NW06].\n\nConstructor\n\nInverseSR1(r::Float64=-1.0)\n\nGenerate the InverseSR1.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#State","page":"Quasi-Newton","title":"State","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"The quasi Newton algorithm is based on a DefaultManoptProblem.","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonState","page":"Quasi-Newton","title":"Manopt.QuasiNewtonState","text":"QuasiNewtonState <: AbstractManoptSolverState\n\nThe AbstractManoptSolverState represent any quasi-Newton based method and stores all necessary fields.\n\nFields\n\ndirection_update:              an AbstractQuasiNewtonDirectionUpdate rule.\nÎ·:                             the current update direction\nnondescent_direction_behavior: a Symbol to specify how to handle direction that are not descent ones.\nnondescent_direction_value:    the value from the last inner product from checking for descent directions\np::P: a point on the manifold mathcal Mstoring the current iterate\np_old:                         the last iterate\npreconditioner                 an QuasiNewtonPreconditioner\nsk:                            the current step\nyk:                            the current gradient difference\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nX::T: a tangent vector at the point p on the manifold mathcal Mstoring the gradient at the current iterate\nX_old:                         the last gradient\n\nConstructor\n\nQuasiNewtonState(M::AbstractManifold, p; kwargs...)\n\nGenerate the Quasi Newton state on the manifold M with start point p.\n\nKeyword arguments\n\ndirection_update=QuasiNewtonLimitedMemoryDirectionUpdate(M, p, InverseBFGS(), memory_size; vector_transport_method=vector_transport_method)\nstopping_criterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\ninitial_scale=1.0: a realtive initial scale. By default deactivated when using a preconditioner.\nmemory_size=20: a shortcut to set the memory in the default direction update\npreconditioner::Union{QuasiNewtonPreconditioner, Nothing} = nothing specify a preconditioner or deactivate by passing nothing.\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize=default_stepsize(M, QuasiNewtonState): a functor inheriting from Stepsize to determine a step size\nvector_transport_method=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX=zero_vector(M, p): a tangent vector at the point p on the manifold mathcal Mto specify the representation of a tangent vector\n\nSee also\n\nquasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#sec-qn-technical-details","page":"Quasi-Newton","title":"Technical details","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"The quasi_Newton solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= or vector_transport_method_dual= (for mathcal N) does not have to be specified.\nBy default quasi Newton uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nA copyto!(M, q, p) and copy(M,p) for points and similarly copy(M, p, X) for tangent vectors.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Most Hessian approximations further require get_coordinates(M, p, X, b) with respect to the AbstractBasis b provided, which is DefaultOrthonormalBasis by default from the basis= keyword.","category":"page"},{"location":"solvers/quasi_Newton/#Literature","page":"Quasi-Newton","title":"Literature","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"W.Â Huang, P.-A.Â Absil and K.Â A.Â Gallivan. A Riemannian BFGS method without differentiated retraction for nonconvex optimization problems. SIAMÂ JournalÂ onÂ Optimization 28, 470â€“495 (2018).\n\n\n\nW.Â Huang, K.Â A.Â Gallivan and P.-A.Â Absil. A Broyden class of quasi-Newton methods for Riemannian optimization. SIAMÂ JournalÂ onÂ Optimization 25, 1660â€“1685 (2015).\n\n\n\nJ.Â Nocedal and S.Â J.Â Wright. Numerical Optimization. 2Â Edition (Springer, New York, 2006).\n\n\n\n","category":"page"},{"location":"solvers/NelderMead/#sec-nelder-meadSolver","page":"Nelderâ€“Mead","title":"Nelder Mead method","text":"","category":"section"},{"location":"solvers/NelderMead/#Manopt.NelderMead","page":"Nelderâ€“Mead","title":"Manopt.NelderMead","text":"NelderMead(M::AbstractManifold, f, population=NelderMeadSimplex(M))\nNelderMead(M::AbstractManifold, mco::AbstractManifoldCostObjective, population=NelderMeadSimplex(M))\nNelderMead!(M::AbstractManifold, f, population)\nNelderMead!(M::AbstractManifold, mco::AbstractManifoldCostObjective, population)\n\nSolve a Nelder-Mead minimization problem for the cost function f mathcal M  â„ on the manifold M. If the initial NelderMeadSimplex is not provided, a random set of points is chosen. The compuation can be performed in-place of the population.\n\nThe algorithm consists of the following steps. Let d denote the dimension of the manifold mathcal M.\n\nOrder the simplex vertices p_i i=1d+1 by increasing cost, such that we have f(p_1)  f(p_2)    f(p_d+1).\nCompute the Riemannian center of mass [Kar77], cf. mean, p_textm  of the simplex vertices p_1p_d+1.\nReflect the point with the worst point at the mean p_textr = operatornameretr_p_textmbigl( - Î±operatornameretr^-1_p_textm (p_d+1) bigr)  If f(p_1)  f(p_textr)  f(p_d) then set p_d+1 = p_textr and go to step 1.\nExpand the simplex if f(p_textr)  f(p_1) by computing the expantion point p_texte = operatornameretr_p_textmbigl( - Î³Î±operatornameretr^-1_p_textm (p_d+1) bigr),  which in this formulation allows to reuse the tangent vector from the inverse retraction from before.  If f(p_texte)  f(p_textr) then set p_d+1 = p_texte otherwise set set p_d+1 = p_textr. Then go to Step 1.\nContract the simplex if f(p_textr)  f(p_d).\nIf f(p_textr)  f(p_d+1) set the step s = -Ï\notherwise set s=Ï.\nCompute the contraction point p_textc = operatornameretr_p_textmbigl(soperatornameretr^-1_p_textm p_d+1 bigr).\nin this case if f(p_textc)  f(p_textr) set p_d+1 = p_textc and go to step 1\nin this case if f(p_textc)  f(p_d+1) set p_d+1 = p_textc and go to step 1\nShrink all points (closer to p_1). For all i=2d+1 set  p_i = operatornameretr_p_1bigl( Ïƒoperatornameretr^-1_p_1 p_i bigr)\n\nFor more details, see The Euclidean variant in the Wikipedia https://en.wikipedia.org/wiki/Nelder-Mead_method or Algorithm 4.1 in http://www.optimization-online.org/DB_FILE/2007/08/1742.pdf.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\npopulation::NelderMeadSimplex=NelderMeadSimplex(M): an initial simplex of d+1 points, where d is the manifold_dimension of M.\n\nKeyword arguments\n\nstopping_criterion=StopAfterIteration(2000)|StopWhenPopulationConcentrated()): a functor indicating that the stopping criterion is fulfilled a StoppingCriterion\nÎ±=1.0: reflection parameter Î±  0:\nÎ³=2.0 expansion parameter Î³:\nÏ=1/2: contraction parameter, 0  Ï  frac12,\nÏƒ=1/2: shrink coefficient, 0  Ïƒ  1\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/NelderMead/#Manopt.NelderMead!","page":"Nelderâ€“Mead","title":"Manopt.NelderMead!","text":"NelderMead(M::AbstractManifold, f, population=NelderMeadSimplex(M))\nNelderMead(M::AbstractManifold, mco::AbstractManifoldCostObjective, population=NelderMeadSimplex(M))\nNelderMead!(M::AbstractManifold, f, population)\nNelderMead!(M::AbstractManifold, mco::AbstractManifoldCostObjective, population)\n\nSolve a Nelder-Mead minimization problem for the cost function f mathcal M  â„ on the manifold M. If the initial NelderMeadSimplex is not provided, a random set of points is chosen. The compuation can be performed in-place of the population.\n\nThe algorithm consists of the following steps. Let d denote the dimension of the manifold mathcal M.\n\nOrder the simplex vertices p_i i=1d+1 by increasing cost, such that we have f(p_1)  f(p_2)    f(p_d+1).\nCompute the Riemannian center of mass [Kar77], cf. mean, p_textm  of the simplex vertices p_1p_d+1.\nReflect the point with the worst point at the mean p_textr = operatornameretr_p_textmbigl( - Î±operatornameretr^-1_p_textm (p_d+1) bigr)  If f(p_1)  f(p_textr)  f(p_d) then set p_d+1 = p_textr and go to step 1.\nExpand the simplex if f(p_textr)  f(p_1) by computing the expantion point p_texte = operatornameretr_p_textmbigl( - Î³Î±operatornameretr^-1_p_textm (p_d+1) bigr),  which in this formulation allows to reuse the tangent vector from the inverse retraction from before.  If f(p_texte)  f(p_textr) then set p_d+1 = p_texte otherwise set set p_d+1 = p_textr. Then go to Step 1.\nContract the simplex if f(p_textr)  f(p_d).\nIf f(p_textr)  f(p_d+1) set the step s = -Ï\notherwise set s=Ï.\nCompute the contraction point p_textc = operatornameretr_p_textmbigl(soperatornameretr^-1_p_textm p_d+1 bigr).\nin this case if f(p_textc)  f(p_textr) set p_d+1 = p_textc and go to step 1\nin this case if f(p_textc)  f(p_d+1) set p_d+1 = p_textc and go to step 1\nShrink all points (closer to p_1). For all i=2d+1 set  p_i = operatornameretr_p_1bigl( Ïƒoperatornameretr^-1_p_1 p_i bigr)\n\nFor more details, see The Euclidean variant in the Wikipedia https://en.wikipedia.org/wiki/Nelder-Mead_method or Algorithm 4.1 in http://www.optimization-online.org/DB_FILE/2007/08/1742.pdf.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcal M\nf: a cost function f mathcal M â„ implemented as (M, p) -> v\npopulation::NelderMeadSimplex=NelderMeadSimplex(M): an initial simplex of d+1 points, where d is the manifold_dimension of M.\n\nKeyword arguments\n\nstopping_criterion=StopAfterIteration(2000)|StopWhenPopulationConcentrated()): a functor indicating that the stopping criterion is fulfilled a StoppingCriterion\nÎ±=1.0: reflection parameter Î±  0:\nÎ³=2.0 expansion parameter Î³:\nÏ=1/2: contraction parameter, 0  Ï  frac12,\nÏƒ=1/2: shrink coefficient, 0  Ïƒ  1\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/NelderMead/#State","page":"Nelderâ€“Mead","title":"State","text":"","category":"section"},{"location":"solvers/NelderMead/#Manopt.NelderMeadState","page":"Nelderâ€“Mead","title":"Manopt.NelderMeadState","text":"NelderMeadState <: AbstractManoptSolverState\n\nDescribes all parameters and the state of a Nelder-Mead heuristic based optimization algorithm.\n\nFields\n\nThe naming of these parameters follows the Wikipedia article of the Euclidean case. The default is given in brackets, the required value range after the description\n\npopulation::NelderMeadSimplex: a population (set) of d+1 points x_i, i=1n+1, where d is the manifold_dimension of M.\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nÎ±: the reflection parameter Î±  0:\nÎ³ the expansion parameter Î³  0:\nÏ: the contraction parameter, 0  Ï  frac12,\nÏƒ: the shrinkage coefficient, 0  Ïƒ  1\np::P: a point on the manifold mathcal M storing the current best point\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructors\n\nNelderMeadState(M::AbstractManifold; kwargs...)\n\nConstruct a Nelder-Mead Option with a default population (if not provided) of set of dimension(M)+1 random points stored in NelderMeadSimplex.\n\nKeyword arguments\n\npopulation=NelderMeadSimplex(M)\nstopping_criterion=StopAfterIteration(2000)|StopWhenPopulationConcentrated()): a functor indicating that the stopping criterion is fulfilled a StoppingCriterion\nÎ±=1.0: reflection parameter Î±  0:\nÎ³=2.0 expansion parameter Î³:\nÏ=1/2: contraction parameter, 0  Ï  frac12,\nÏƒ=1/2: shrink coefficient, 0  Ïƒ  1\ninverse_retraction_method=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\np=copy(M, population.pts[1]): initialise the storage for the best point (iterate)Â¨\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#Simplex","page":"Nelderâ€“Mead","title":"Simplex","text":"","category":"section"},{"location":"solvers/NelderMead/#Manopt.NelderMeadSimplex","page":"Nelderâ€“Mead","title":"Manopt.NelderMeadSimplex","text":"NelderMeadSimplex\n\nA simplex for the Nelder-Mead algorithm.\n\nConstructors\n\nNelderMeadSimplex(M::AbstractManifold)\n\nConstruct a  simplex using d+1 random points from manifold M, where d is the manifold_dimension of M.\n\nNelderMeadSimplex(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis=DefaultOrthonormalBasis();\n    a::Real=0.025,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n)\n\nConstruct a simplex from a basis B with one point being p and other points constructed by moving by a in each principal direction defined by basis B of the tangent space at point p using retraction retraction_method. This works similarly to how the initial simplex is constructed in the Euclidean Nelder-Mead algorithm, just in the tangent space at point p.\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#Additional-stopping-criteria","page":"Nelderâ€“Mead","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/NelderMead/#Manopt.StopWhenPopulationConcentrated","page":"Nelderâ€“Mead","title":"Manopt.StopWhenPopulationConcentrated","text":"StopWhenPopulationConcentrated <: StoppingCriterion\n\nA stopping criterion for NelderMead to indicate to stop when both\n\nthe maximal distance of the first to the remaining the cost values and\nthe maximal distance of the first to the remaining the population points\n\ndrops below a certain tolerance tol_f and tol_p, respectively.\n\nConstructor\n\nStopWhenPopulationConcentrated(tol_f::Real=1e-8, tol_x::Real=1e-8)\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#Technical-details","page":"Nelderâ€“Mead","title":"Technical details","text":"","category":"section"},{"location":"solvers/NelderMead/","page":"Nelderâ€“Mead","title":"Nelderâ€“Mead","text":"The NelderMead solver requires the following functions of a manifold to be available","category":"page"},{"location":"solvers/NelderMead/","page":"Nelderâ€“Mead","title":"Nelderâ€“Mead","text":"A retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nThe distance(M, p, q) when using the default stopping criterion, which includes StopWhenPopulationConcentrated.\nWithin the default initialization rand(M) is used to generate the initial population\nA mean(M, population) has to be available, for example by loading Manifolds.jl and its statistics tools","category":"page"}]
}
