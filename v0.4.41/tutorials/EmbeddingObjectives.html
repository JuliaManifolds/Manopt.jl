<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Define Objectives in the Embedding · Manopt.jl</title><meta name="title" content="Define Objectives in the Embedding · Manopt.jl"/><meta property="og:title" content="Define Objectives in the Embedding · Manopt.jl"/><meta property="twitter:title" content="Define Objectives in the Embedding · Manopt.jl"/><meta name="description" content="Documentation for Manopt.jl."/><meta property="og:description" content="Documentation for Manopt.jl."/><meta property="twitter:description" content="Documentation for Manopt.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img src="../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">Manopt.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><a class="tocitem" href="../about.html">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="Optimize!.html">Get started: Optimize!</a></li><li><a class="tocitem" href="InplaceGradient.html">Speedup using Inplace computations</a></li><li><a class="tocitem" href="AutomaticDifferentiation.html">Use Automatic Differentiation</a></li><li class="is-active"><a class="tocitem" href="EmbeddingObjectives.html">Define Objectives in the Embedding</a><ul class="internal"><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li><li><a class="tocitem" href="#Technical-Details"><span>Technical Details</span></a></li></ul></li><li><a class="tocitem" href="CountAndCache.html">Count and use a Cache</a></li><li><a class="tocitem" href="HowToDebug.html">Print Debug Output</a></li><li><a class="tocitem" href="HowToRecord.html">Record values</a></li><li><a class="tocitem" href="ImplementASolver.html">Implement a Solver</a></li><li><a class="tocitem" href="ConstrainedOptimization.html">Do Constrained Optimization</a></li><li><a class="tocitem" href="GeodesicRegression.html">Do Geodesic Regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../solvers/index.html">Introduction</a></li><li><a class="tocitem" href="../solvers/adaptive-regularization-with-cubics.html">Adaptive Regularization with Cubics</a></li><li><a class="tocitem" href="../solvers/alternating_gradient_descent.html">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../solvers/augmented_Lagrangian_method.html">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../solvers/ChambollePock.html">Chambolle-Pock</a></li><li><a class="tocitem" href="../solvers/conjugate_gradient_descent.html">Conjugate gradient descent</a></li><li><a class="tocitem" href="../solvers/cyclic_proximal_point.html">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../solvers/difference_of_convex.html">Difference of Convex</a></li><li><a class="tocitem" href="../solvers/DouglasRachford.html">Douglas–Rachford</a></li><li><a class="tocitem" href="../solvers/exact_penalty_method.html">Exact Penalty Method</a></li><li><a class="tocitem" href="../solvers/FrankWolfe.html">Frank-Wolfe</a></li><li><a class="tocitem" href="../solvers/gradient_descent.html">Gradient Descent</a></li><li><a class="tocitem" href="../solvers/LevenbergMarquardt.html">Levenberg–Marquardt</a></li><li><a class="tocitem" href="../solvers/NelderMead.html">Nelder–Mead</a></li><li><a class="tocitem" href="../solvers/particle_swarm.html">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../solvers/primal_dual_semismooth_Newton.html">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../solvers/quasi_Newton.html">Quasi-Newton</a></li><li><a class="tocitem" href="../solvers/stochastic_gradient_descent.html">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../solvers/subgradient.html">Subgradient method</a></li><li><a class="tocitem" href="../solvers/truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../solvers/trust_regions.html">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../plans/index.html">Specify a Solver</a></li><li><a class="tocitem" href="../plans/problem.html">Problem</a></li><li><a class="tocitem" href="../plans/objective.html">Objective</a></li><li><a class="tocitem" href="../plans/state.html">Solver State</a></li><li><a class="tocitem" href="../plans/stepsize.html">Stepsize</a></li><li><a class="tocitem" href="../plans/stopping_criteria.html">Stopping Criteria</a></li><li><a class="tocitem" href="../plans/debug.html">Debug Output</a></li><li><a class="tocitem" href="../plans/record.html">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../functions/index.html">Introduction</a></li><li><a class="tocitem" href="../functions/bezier.html">Bézier curves</a></li><li><a class="tocitem" href="../functions/costs.html">Cost functions</a></li><li><a class="tocitem" href="../functions/differentials.html">Differentials</a></li><li><a class="tocitem" href="../functions/adjoint_differentials.html">Adjoint Differentials</a></li><li><a class="tocitem" href="../functions/gradients.html">Gradients</a></li><li><a class="tocitem" href="../functions/proximal_maps.html">Proximal Maps</a></li><li><a class="tocitem" href="../functions/manifold.html">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../helpers/checks.html">Checks</a></li><li><a class="tocitem" href="../helpers/data.html">Data</a></li><li><a class="tocitem" href="../helpers/errorMeasures.html">Error Measures</a></li><li><a class="tocitem" href="../helpers/exports.html">Exports</a></li></ul></li><li><a class="tocitem" href="../contributing.html">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../extensions.html">Extensions</a></li><li><a class="tocitem" href="../notation.html">Notation</a></li><li><a class="tocitem" href="../changelog.html">Changelog</a></li><li><a class="tocitem" href="../references.html">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to...</a></li><li class="is-active"><a href="EmbeddingObjectives.html">Define Objectives in the Embedding</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="EmbeddingObjectives.html">Define Objectives in the Embedding</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/tutorials/EmbeddingObjectives.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="How-to-define-the-cost-in-the-embedding"><a class="docs-heading-anchor" href="#How-to-define-the-cost-in-the-embedding">How to define the cost in the embedding</a><a id="How-to-define-the-cost-in-the-embedding-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-define-the-cost-in-the-embedding" title="Permalink"></a></h1><p>Ronny Bergmann</p><p>Specifying a cost function <span>$f\colon \mathcal M \to \mathbb R$</span> on a manifold is usually the model one starts with. Specifying its gradient <span>$\operatorname{grad} f\colon\mathcal M \to T\mathcal M$</span>, or more precisely <span>$\operatorname{grad}f(p) \in T_p\mathcal M$</span>, and eventually a Hessian <span>$\operatorname{Hess} f\colon T_p\mathcal M \to T_p\mathcal M$</span> are then necessary to perform optimization. Since these might be challenging to compute, especially when manifolds and differential geometry are not the main area of a user – easier to use methods might be welcome.</p><p>This tutorial discusses how to specify <span>$f$</span> in the embedding as <span>$\tilde f$</span>, maybe only locally around the manifold, and use the Euclidean gradient <span>$∇ \tilde f$</span> and Hessian <span>$∇^2 \tilde f$</span> within <code>Manopt.jl</code>.</p><p>For the theoretical background see <a href="AutomaticDifferentiation.html#EmbeddedGradient">convert an Euclidean to an Riemannian Gradient</a>, or Section 4.7 of [<a href="../references.html#Boumal:2023">Bou23</a>] for the gradient part or Section 5.11 as well as [<a href="../references.html#Nguyen:2023">Ngu23</a>] for the background on converting Hessians.</p><p>Here we use the Examples 9.40 and 9.49 of [<a href="../references.html#Boumal:2023">Bou23</a>] and compare the different methods, one can call the solver, depending on which gradient and/or Hessian one provides.</p><pre><code class="language-julia hljs">using Manifolds, Manopt, ManifoldDiff
using LinearAlgebra, Random, Colors, Plots
Random.seed!(123)</code></pre><p>We consider the cost function on the <a href="https://juliamanifolds.github.io/Manifolds.jl/latest/manifolds/grassmann.html"><code>Grassmann</code></a> manifold given by</p><pre><code class="language-julia hljs">n = 5
k = 2
M = Grassmann(5,2)
A = Symmetric(rand(n,n));</code></pre><pre><code class="language-julia hljs">f(M, p) = 1 / 2 * tr(p&#39; * A * p)</code></pre><p>Note that this implementation is already also a valid implementation / continuation of <span>$f$</span> into the (lifted) embedding of the Grassmann manifold. In the implementation we can use <code>f</code> for both the Euclidean <span>$\tilde f$</span> and the Grassmann case <span>$f$</span>.</p><p>Its Euclidean gradient <span>$\nabla f$</span> and Hessian <span>$\nabla^2f$</span> are easy to compute as</p><pre><code class="language-julia hljs">∇f(M, p) = A * p
∇²f(M,p,X) = A*X</code></pre><p>On the other hand, from the aforementioned Example 9.49 we can also state the Riemannian gradient and Hessian for comparison as</p><pre><code class="language-julia hljs">grad_f(M, p) = A * p - p * (p&#39; * A * p)
Hess_f(M, p, X) = A * X - p * p&#39; * A * X - X * p&#39; * A * p</code></pre><p>We can check that these are the correct at least numerically by calling the <a href="../helpers/checks.html#Manopt.check_gradient"><code>check_gradient</code></a></p><pre><code class="language-julia hljs">check_gradient(M, f, grad_f; plot=true)</code></pre><p><img src="EmbeddingObjectives_files/figure-commonmark/cell-8-output-1.svg" alt/></p><p>and the <a href="../helpers/checks.html#Manopt.check_Hessian"><code>check_Hessian</code></a>, which requires a bit more tolerance in its linearity check</p><pre><code class="language-julia hljs">check_Hessian(M, f, grad_f, Hess_f; plot=true, throw_error=true, atol=1e-15)</code></pre><p><img src="EmbeddingObjectives_files/figure-commonmark/cell-9-output-1.svg" alt/></p><p>While they look reasonable here and were already derived – for the general case this derivation might be more complicated.</p><p>Luckily there exist two functions in <a href="https://juliamanifolds.github.io/ManifoldDiff.jl/stable/"><code>ManifoldDiff.jl</code></a> that are implemented for several manifolds from <a href="https://github.com/JuliaManifolds/Manifolds.jl"><code>Manifolds.jl</code></a>, namely <a href="https://juliamanifolds.github.io/ManifoldDiff.jl/stable/library/#ManifoldDiff.riemannian_gradient-Tuple%7BAbstractManifold,%20Any,%20Any%7D"><code>riemannian_gradient</code></a><code>(M, p, eG)</code> that converts a Riemannian gradient <code>eG=</code><span>$\nabla \tilde f(p)$</span> into a the Riemannain one <span>$\operatorname{grad} f(p)$</span> and <a href="https://juliamanifolds.github.io/ManifoldDiff.jl/stable/library/#ManifoldDiff.riemannian_Hessian-Tuple%7BAbstractManifold,%20Any,%20Any,%20Any,%20Any%7D"><code>riemannian_Hessian</code></a><code>(M, p, eG, eH, X)</code> which converts the Euclidean Hessian <code>eH=</code><span>$\nabla^2 \tilde f(p)[X]$</span> into <span>$\operatorname{Hess} f(p)[X]$</span>, where we also require the Euclidean gradient <code>eG=</code><span>$\nabla \tilde f(p)$</span>.</p><p>So we can define</p><pre><code class="language-julia hljs">grad2_f(M, p) = riemannian_gradient(M, p, ∇f(get_embedding(M), embed(M, p)))</code></pre><p>where only formally we here call <code>embed(M,p)</code> before passing <code>p</code> to the Euclidean gradient, though here (for the Grassmann manifold with Stiefel representation) the embedding function is the identity.</p><p>Similarly for the Hessian, where in our example the embeddings of both the points and tangent vectors are the identity.</p><pre><code class="language-julia hljs">function Hess2_f(M, p, X)
    return riemannian_Hessian(
        M,
        p,
        ∇f(get_embedding(M), embed(M, p)),
        ∇²f(get_embedding(M), embed(M, p), embed(M, p, X)),
        X
    )
end</code></pre><p>And we can again check these numerically,</p><pre><code class="language-julia hljs">check_gradient(M, f, grad2_f; plot=true)</code></pre><p><img src="EmbeddingObjectives_files/figure-commonmark/cell-12-output-1.svg" alt/></p><p>and</p><pre><code class="language-julia hljs">check_Hessian(M, f, grad2_f, Hess2_f; plot=true, throw_error=true, atol=1e-14)</code></pre><p><img src="EmbeddingObjectives_files/figure-commonmark/cell-13-output-1.svg" alt/></p><p>which yields the same result, but we see that the Euclidean conversion might be a bit less stable.</p><p>Now if we want to use these in optimization we would require these two functions to call e.g.</p><pre><code class="language-julia hljs">p0 = [1.0 0.0; 0.0 1.0; 0.0 0.0; 0.0 0.0; 0.0 0.0]
r1 = adaptive_regularization_with_cubics(
    M,
    f,
    grad_f,
    Hess_f,
    p0;
    debug=[:Iteration, :Cost, &quot;\n&quot;],
    return_objective=true,
    return_state=true,
)
q1 = get_solver_result(r1)
r1</code></pre><pre><code class="nohighlight hljs">Initial f(x): 0.666814
# 1     f(x): 0.333500
# 2     f(x): -0.233216
# 3     f(x): -0.440390
# 4     f(x): -0.607973
# 5     f(x): -0.608796
# 6     f(x): -0.608797
# 7     f(x): -0.608797

# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)
After 7 iterations

## Parameters
* η1 | η2              : 0.1 | 0.9
* γ1 | γ2              : 0.1 | 2.0
* σ (σmin)             : 0.0004082482904638632 (1.0e-10)
* ρ (ρ_regularization) : 1.0012847829562384 (1000.0)
* retraction method    : PolarRetraction()
* sub solver state     :
    | # Solver state for `Manopt.jl`s Lanczos Iteration
    | After 6 iterations
    | 
    | ## Parameters
    | * σ                         : 0.0040824829046386315
    | * # of Lanczos vectors used : 6
    | 
    | ## Stopping Criteria
    | (a) For the Lanczos Iteration
    | Stop When _one_ of the following are fulfilled:
    |     Max Iteration 6:  reached
    |     First order progress with θ=0.5:  not reached
    | Overall: reached
    | (b) For the Newton sub solver
    | Max Iteration 200:    not reached
    | This indicates convergence: No

## Stopping Criterion
Stop When _one_ of the following are fulfilled:
    Max Iteration 40:   not reached
    |grad f| &lt; 1.0e-9: reached
    All Lanczos vectors (5) used:   not reached
Overall: reached
This indicates convergence: Yes

## Debug
    [ (:Iteration, &quot;# %-6d&quot;), (:Cost, &quot;f(x): %f&quot;), &quot;\n&quot; ]</code></pre><p>but if you choose to go for the conversions, then, thinking of the embedding and defining two new functions might be tedious. There is a shortcut for these, which performs the change internally, when necessary by specifying <code>objective_type=:Euclidean</code>.</p><pre><code class="language-julia hljs">r2 = adaptive_regularization_with_cubics(
    M,
    f,
    ∇f,
    ∇²f,
    p0;
    # The one line different to specify our grad/Hess are Eucldiean:
    objective_type=:Euclidean,
    debug=[:Iteration, :Cost, &quot;\n&quot;],
    return_objective=true,
    return_state=true,
)
q2 = get_solver_result(r2)
r2</code></pre><pre><code class="nohighlight hljs">Initial f(x): 0.666814
# 1     f(x): 0.333500
# 2     f(x): -0.233216
# 3     f(x): -0.440390
# 4     f(x): -0.607973
# 5     f(x): -0.608796
# 6     f(x): -0.608797
# 7     f(x): -0.608797

# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)
After 7 iterations

## Parameters
* η1 | η2              : 0.1 | 0.9
* γ1 | γ2              : 0.1 | 2.0
* σ (σmin)             : 0.0004082482904638632 (1.0e-10)
* ρ (ρ_regularization) : 0.9997999315462104 (1000.0)
* retraction method    : PolarRetraction()
* sub solver state     :
    | # Solver state for `Manopt.jl`s Lanczos Iteration
    | After 6 iterations
    | 
    | ## Parameters
    | * σ                         : 0.0040824829046386315
    | * # of Lanczos vectors used : 6
    | 
    | ## Stopping Criteria
    | (a) For the Lanczos Iteration
    | Stop When _one_ of the following are fulfilled:
    |     Max Iteration 6:  reached
    |     First order progress with θ=0.5:  not reached
    | Overall: reached
    | (b) For the Newton sub solver
    | Max Iteration 200:    not reached
    | This indicates convergence: No

## Stopping Criterion
Stop When _one_ of the following are fulfilled:
    Max Iteration 40:   not reached
    |grad f| &lt; 1.0e-9: reached
    All Lanczos vectors (5) used:   not reached
Overall: reached
This indicates convergence: Yes

## Debug
    [ (:Iteration, &quot;# %-6d&quot;), (:Cost, &quot;f(x): %f&quot;), &quot;\n&quot; ]</code></pre><p>which returns the same result, see</p><pre><code class="language-julia hljs">distance(M, q1, q2)</code></pre><pre><code class="nohighlight hljs">4.1244122288879254e-16</code></pre><p>This conversion also works for the gradients of constraints, and is passed down to subsolvers by deault when these are created using the Euclidean objective <span>$f$</span>, <span>$\nabla f$</span> and <span>$\nabla^2 f$</span>.</p><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>If you have the Euclidean gradient (or Hessian) available for a solver call, all you need to provide is <code>objective_type=:Euclidean</code> to convert the objective to a Riemannian one.</p><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[Bou23]</dt><dd><div>N. Boumal. <a href="https://doi.org/10.1017/9781009166164"><em>An Introduction to Optimization on Smooth Manifolds</em></a>. First Edition (Cambridge University Press, 2023). Homepage to the book: <a href="https://www.nicolasboumal.net/book/index.html">nicolasboumal.net/book/index.html</a>.</div></dd><dt>[Ngu23]</dt><dd><div>D. Nguyen. <em>Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization</em>. <a href="https://doi.org/10.1007/s10957-023-02242-z">Journal of Optimization Theory and Applications <strong>198</strong>, 135–164</a> (2023), <a href="https://arxiv.org/abs/2009.10159">arXiv:2009.10159</a>.</div></dd></dl></div><h2 id="Technical-Details"><a class="docs-heading-anchor" href="#Technical-Details">Technical Details</a><a id="Technical-Details-1"></a><a class="docs-heading-anchor-permalink" href="#Technical-Details" title="Permalink"></a></h2><p>This notebook was rendered with the following environment</p><pre><code class="language-julia hljs">Pkg.status()</code></pre><pre><code class="nohighlight hljs">Status `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`
  [6e4b80f9] BenchmarkTools v1.3.2
  [5ae59095] Colors v0.12.10
  [31c24e10] Distributions v0.25.102
  [26cc04aa] FiniteDifferences v0.12.31
  [7073ff75] IJulia v1.24.2
  [8ac3fa9e] LRUCache v1.5.0
  [af67fdf4] ManifoldDiff v0.3.8
  [1cead3c2] Manifolds v0.9.3
  [3362f125] ManifoldsBase v0.15.1
  [0fc0a36d] Manopt v0.4.41 `~/work/Manopt.jl/Manopt.jl`
  [91a5bcdd] Plots v1.39.0</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="AutomaticDifferentiation.html">« Use Automatic Differentiation</a><a class="docs-footer-nextpage" href="CountAndCache.html">Count and use a Cache »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.2 on <span class="colophon-date" title="Thursday 2 November 2023 11:23">Thursday 2 November 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
