<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Adaptive Regularization with Cubics · Manopt.jl</title><meta name="title" content="Adaptive Regularization with Cubics · Manopt.jl"/><meta property="og:title" content="Adaptive Regularization with Cubics · Manopt.jl"/><meta property="twitter:title" content="Adaptive Regularization with Cubics · Manopt.jl"/><meta name="description" content="Documentation for Manopt.jl."/><meta property="og:description" content="Documentation for Manopt.jl."/><meta property="twitter:description" content="Documentation for Manopt.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img src="../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">Manopt.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><a class="tocitem" href="../about.html">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../tutorials/Optimize!.html">Get started: Optimize!</a></li><li><a class="tocitem" href="../tutorials/InplaceGradient.html">Speedup using Inplace computations</a></li><li><a class="tocitem" href="../tutorials/AutomaticDifferentiation.html">Use Automatic Differentiation</a></li><li><a class="tocitem" href="../tutorials/EmbeddingObjectives.html">Define Objectives in the Embedding</a></li><li><a class="tocitem" href="../tutorials/CountAndCache.html">Count and use a Cache</a></li><li><a class="tocitem" href="../tutorials/HowToDebug.html">Print Debug Output</a></li><li><a class="tocitem" href="../tutorials/HowToRecord.html">Record values</a></li><li><a class="tocitem" href="../tutorials/ImplementASolver.html">Implement a Solver</a></li><li><a class="tocitem" href="../tutorials/ConstrainedOptimization.html">Do Constrained Optimization</a></li><li><a class="tocitem" href="../tutorials/GeodesicRegression.html">Do Geodesic Regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="index.html">Introduction</a></li><li class="is-active"><a class="tocitem" href="adaptive-regularization-with-cubics.html">Adaptive Regularization with Cubics</a><ul class="internal"><li><a class="tocitem" href="#State"><span>State</span></a></li><li><a class="tocitem" href="#Sub-solvers"><span>Sub solvers</span></a></li><li><a class="tocitem" href="#Lanczos-Iteration"><span>Lanczos Iteration</span></a></li><li><a class="tocitem" href="#(Conjugate)-Gradient-Descent"><span>(Conjugate) Gradient Descent</span></a></li><li><a class="tocitem" href="#Additional-Stopping-Criteria"><span>Additional Stopping Criteria</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="alternating_gradient_descent.html">Alternating Gradient Descent</a></li><li><a class="tocitem" href="augmented_Lagrangian_method.html">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="ChambollePock.html">Chambolle-Pock</a></li><li><a class="tocitem" href="conjugate_gradient_descent.html">Conjugate gradient descent</a></li><li><a class="tocitem" href="cyclic_proximal_point.html">Cyclic Proximal Point</a></li><li><a class="tocitem" href="difference_of_convex.html">Difference of Convex</a></li><li><a class="tocitem" href="DouglasRachford.html">Douglas–Rachford</a></li><li><a class="tocitem" href="exact_penalty_method.html">Exact Penalty Method</a></li><li><a class="tocitem" href="FrankWolfe.html">Frank-Wolfe</a></li><li><a class="tocitem" href="gradient_descent.html">Gradient Descent</a></li><li><a class="tocitem" href="LevenbergMarquardt.html">Levenberg–Marquardt</a></li><li><a class="tocitem" href="NelderMead.html">Nelder–Mead</a></li><li><a class="tocitem" href="particle_swarm.html">Particle Swarm Optimization</a></li><li><a class="tocitem" href="primal_dual_semismooth_Newton.html">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="quasi_Newton.html">Quasi-Newton</a></li><li><a class="tocitem" href="stochastic_gradient_descent.html">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="subgradient.html">Subgradient method</a></li><li><a class="tocitem" href="truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="trust_regions.html">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../plans/index.html">Specify a Solver</a></li><li><a class="tocitem" href="../plans/problem.html">Problem</a></li><li><a class="tocitem" href="../plans/objective.html">Objective</a></li><li><a class="tocitem" href="../plans/state.html">Solver State</a></li><li><a class="tocitem" href="../plans/stepsize.html">Stepsize</a></li><li><a class="tocitem" href="../plans/stopping_criteria.html">Stopping Criteria</a></li><li><a class="tocitem" href="../plans/debug.html">Debug Output</a></li><li><a class="tocitem" href="../plans/record.html">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../functions/index.html">Introduction</a></li><li><a class="tocitem" href="../functions/bezier.html">Bézier curves</a></li><li><a class="tocitem" href="../functions/costs.html">Cost functions</a></li><li><a class="tocitem" href="../functions/differentials.html">Differentials</a></li><li><a class="tocitem" href="../functions/adjoint_differentials.html">Adjoint Differentials</a></li><li><a class="tocitem" href="../functions/gradients.html">Gradients</a></li><li><a class="tocitem" href="../functions/proximal_maps.html">Proximal Maps</a></li><li><a class="tocitem" href="../functions/manifold.html">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../helpers/checks.html">Checks</a></li><li><a class="tocitem" href="../helpers/data.html">Data</a></li><li><a class="tocitem" href="../helpers/errorMeasures.html">Error Measures</a></li><li><a class="tocitem" href="../helpers/exports.html">Exports</a></li></ul></li><li><a class="tocitem" href="../contributing.html">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../extensions.html">Extensions</a></li><li><a class="tocitem" href="../notation.html">Notation</a></li><li><a class="tocitem" href="../changelog.html">Changelog</a></li><li><a class="tocitem" href="../references.html">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href="adaptive-regularization-with-cubics.html">Adaptive Regularization with Cubics</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="adaptive-regularization-with-cubics.html">Adaptive Regularization with Cubics</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/solvers/adaptive-regularization-with-cubics.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="ARSSection"><a class="docs-heading-anchor" href="#ARSSection">Adaptive regularization with Cubics</a><a id="ARSSection-1"></a><a class="docs-heading-anchor-permalink" href="#ARSSection" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.adaptive_regularization_with_cubics" href="#Manopt.adaptive_regularization_with_cubics"><code>Manopt.adaptive_regularization_with_cubics</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">adaptive_regularization_with_cubics(M, f, grad_f, Hess_f, p=rand(M); kwargs...)
adaptive_regularization_with_cubics(M, f, grad_f, p=rand(M); kwargs...)
adaptive_regularization_with_cubics(M, mho, p=rand(M); kwargs...)</code></pre><p>Solve an optimization problem on the manifold <code>M</code> by iteratively minimizing</p><p class="math-container">\[m_k(X) = f(p_k) + ⟨X, \operatorname{grad} f(p_k)⟩ + \frac{1}{2}⟨X, \operatorname{Hess} f(p_k)[X]⟩ + \frac{σ_k}{3}\lVert X \rVert^3\]</p><p>on the tangent space at the current iterate <span>$p_k$</span>, i.e. <span>$X ∈ T_{p_k}\mathcal M$</span> and where <span>$σ_k &gt; 0$</span> is a regularization parameter.</p><p>Let <span>$X_k$</span> denote the minimizer of the model <span>$m_k$</span>, then we use the model improvement</p><p class="math-container">\[ρ_k = \frac{f(p_k) - f(\operatorname{retr}_{p_k}(X_k))}{m_k(0) - m_k(s) + \frac{σ_k}{3}\lVert X_k\rVert^3}.\]</p><p>We use two thresholds <span>$η_2 ≥ η_1 &gt; 0$</span> and set <span>$p_{k+1} = \operatorname{retr}_{p_k}(X_k)$</span> if <span>$ρ ≥ η_1$</span> and reject the candidate otherwise, i.e. set <span>$p_{k+1} = p_k$</span>.</p><p>We further update the regularization parameter using factors <span>$0 &lt; γ_1 &lt; 1 &lt; γ_2$</span></p><p class="math-container">\[σ_{k+1} =
\begin{cases}
    \max\{σ_{\min}, γ_1σ_k\} &amp; \text{ if } ρ \geq η_2 &amp;\text{   (the model was very successful)},\\
    σ_k &amp; \text{ if } ρ \in [η_1, η_2)&amp;\text{   (the model was successful)},\\
    γ_2σ_k &amp; \text{ if } ρ &lt; η_1&amp;\text{   (the model was unsuccessful)}.
\end{cases}\]</p><p>For more details see <a href="../references.html#AgarwalBoumalBullinsCartis:2020">Agarwal, Boumal, Bullins, Cartis, Math. Prog., 2020</a>.</p><p><strong>Input</strong></p><ul><li><code>M</code> – a manifold <span>$\mathcal M$</span></li><li><code>f</code> – a cost function <span>$F: \mathcal M → ℝ$</span> to minimize</li><li><code>grad_f</code>- the gradient <span>$\operatorname{grad}F: \mathcal M → T \mathcal M$</span> of <span>$F$</span></li><li><code>Hess_f</code> – (optional) the hessian <span>$H( \mathcal M, x, ξ)$</span> of <span>$F$</span></li><li><code>p</code> – an initial value <span>$p  ∈  \mathcal M$</span></li></ul><p>For the case that no hessian is provided, the Hessian is computed using finite difference, see <a href="trust_regions.html#Manopt.ApproxHessianFiniteDifference"><code>ApproxHessianFiniteDifference</code></a>.</p><p>the cost <code>f</code> and its gradient and hessian might also be provided as a <a href="../plans/objective.html#Manopt.ManifoldHessianObjective"><code>ManifoldHessianObjective</code></a></p><p><strong>Keyword arguments</strong></p><p>the default values are given in brackets</p><ul><li><code>σ</code>                      - (<code>100.0 / sqrt(manifold_dimension(M)</code>) initial regularization parameter</li><li><code>σmin</code>                   - (<code>1e-10</code>) minimal regularization value <span>$σ_{\min}$</span></li><li><code>η1</code>                     - (<code>0.1</code>) lower model success threshold</li><li><code>η2</code>                     - (<code>0.9</code>) upper model success threshold</li><li><code>γ1</code>                     - (<code>0.1</code>) regularization reduction factor (for the success case)</li><li><code>γ2</code>                     - (<code>2.0</code>) regularization increment factor (for the non-success case)</li><li><code>evaluation</code>             – (<a href="../plans/objective.html#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>) specify whether the gradient works by allocation (default) form <code>grad_f(M, p)</code>                            or <a href="../plans/objective.html#Manopt.InplaceEvaluation"><code>InplaceEvaluation</code></a> in place, i.e. is of the form <code>grad_f!(M, X, p)</code> and analogously for the hessian.</li><li><code>retraction_method</code>      – (<code>default_retraction_method(M, typeof(p))</code>) a retraction to use</li><li><code>initial_tangent_vector</code> - (<code>zero_vector(M, p)</code>) initialize any tangent vector data,</li><li><code>maxIterLanczos</code>         - (<code>200</code>) a shortcut to set the stopping criterion in the sub_solver,</li><li><code>ρ_regularization</code>       - (<code>1e3</code>) a regularization to avoid dividing by zero for small values of cost and model</li><li><code>stopping_criterion</code>     - (<a href="../plans/stopping_criteria.html#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(40) |</code><a href="../plans/stopping_criteria.html#Manopt.StopWhenGradientNormLess"><code>StopWhenGradientNormLess</code></a><code>(1e-9) |</code><a href="adaptive-regularization-with-cubics.html#Manopt.StopWhenAllLanczosVectorsUsed"><code>StopWhenAllLanczosVectorsUsed</code></a><code>(maxIterLanczos)</code>)</li><li><code>sub_state</code>              - <a href="adaptive-regularization-with-cubics.html#Manopt.LanczosState"><code>LanczosState</code></a><code>(M, copy(M, p); maxIterLanczos=maxIterLanczos, σ=σ)                            a state for the subproblem or an [</code>AbstractEvaluationType`](@ref) if the problem is a function.</li><li><code>sub_objective</code>               - a shortcut to modify the objective of the subproblem used within in the</li><li><code>sub_problem</code>            - <a href="../plans/problem.html#Manopt.DefaultManoptProblem"><code>DefaultManoptProblem</code></a><code>(M, sub_objective)</code> the problem (or a function) for the sub problem</li></ul><p>All other keyword arguments are passed to <a href="../plans/state.html#Manopt.decorate_state!"><code>decorate_state!</code></a> for state decorators or <a href="../plans/objective.html#Manopt.decorate_objective!"><code>decorate_objective!</code></a> for objective, respectively. If you provide the <a href="../plans/objective.html#Manopt.ManifoldGradientObjective"><code>ManifoldGradientObjective</code></a> directly, these decorations can still be specified</p><p>By default the <code>debug=</code> keyword is set to <a href="../plans/debug.html#Manopt.DebugIfEntry"><code>DebugIfEntry</code></a><code>(:ρ_denominator, &gt;(0); message=&quot;Denominator nonpositive&quot;, type=:error)</code><code>to avoid that by rounding errors the denominator in the computation of</code>ρ` gets nonpositive.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/ee354f95d8c819b2cc757e5fc73c187ea47b6484/src/solvers/adaptive_regularization_with_cubics.jl#L162-L238">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.adaptive_regularization_with_cubics!" href="#Manopt.adaptive_regularization_with_cubics!"><code>Manopt.adaptive_regularization_with_cubics!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">adaptive_regularization_with_cubics!(M, f, grad_f, Hess_f, p; kwargs...)
adaptive_regularization_with_cubics!(M, f, grad_f, p; kwargs...)
adaptive_regularization_with_cubics!(M, mho, p; kwargs...)</code></pre><p>evaluate the Riemannian adaptive regularization with cubics solver in place of <code>p</code>.</p><p><strong>Input</strong></p><ul><li><code>M</code> – a manifold <span>$\mathcal M$</span></li><li><code>f</code> – a cost function <span>$F: \mathcal M → ℝ$</span> to minimize</li><li><code>grad_f</code>- the gradient <span>$\operatorname{grad}F: \mathcal M → T \mathcal M$</span> of <span>$F$</span></li><li><code>Hess_f</code> – (optional) the hessian <span>$H( \mathcal M, x, ξ)$</span> of <span>$F$</span></li><li><code>p</code> – an initial value <span>$p  ∈  \mathcal M$</span></li></ul><p>For the case that no hessian is provided, the Hessian is computed using finite difference, see <a href="trust_regions.html#Manopt.ApproxHessianFiniteDifference"><code>ApproxHessianFiniteDifference</code></a>.</p><p>the cost <code>f</code> and its gradient and hessian might also be provided as a <a href="../plans/objective.html#Manopt.ManifoldHessianObjective"><code>ManifoldHessianObjective</code></a></p><p>for more details and all options, see <a href="adaptive-regularization-with-cubics.html#Manopt.adaptive_regularization_with_cubics"><code>adaptive_regularization_with_cubics</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/ee354f95d8c819b2cc757e5fc73c187ea47b6484/src/solvers/adaptive_regularization_with_cubics.jl#L317-L337">source</a></section></article><h2 id="State"><a class="docs-heading-anchor" href="#State">State</a><a id="State-1"></a><a class="docs-heading-anchor-permalink" href="#State" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.AdaptiveRegularizationState" href="#Manopt.AdaptiveRegularizationState"><code>Manopt.AdaptiveRegularizationState</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AdaptiveRegularizationState{P,T} &lt;: AbstractHessianSolverState</code></pre><p>A state for the <a href="adaptive-regularization-with-cubics.html#Manopt.adaptive_regularization_with_cubics"><code>adaptive_regularization_with_cubics</code></a> solver.</p><p><strong>Fields</strong></p><p>a default value is given in brackets if a parameter can be left out in initialization.</p><ul><li><code>η1</code>, <code>η2</code>           – (<code>0.1</code>, <code>0.9</code>) bounds for evaluating the regularization parameter</li><li><code>γ1</code>, <code>γ2</code>           – (<code>0.1</code>, <code>2.0</code>) shrinking and expansion factors for regularization parameter <code>σ</code></li><li><code>p</code>                  – (<code>rand(M)</code> the current iterate</li><li><code>X</code>                  – (<code>zero_vector(M,p)</code>) the current gradient <span>$\operatorname{grad}f(p)$</span></li><li><code>s</code>                  - (<code>zero_vector(M,p)</code>) the tangent vector step resulting from minimizing the model problem in the tangent space <span>$\mathcal T_{p} \mathcal M$</span></li><li><code>σ</code>                 – the current cubic regularization parameter</li><li><code>σmin</code>               – (<code>1e-7</code>) lower bound for the cubic regularization parameter</li><li><code>ρ_regularization</code>   – (1e3) regularization parameter for computing ρ. As we approach convergence the ρ may be difficult to compute with numerator and denominator approaching zero. Regularizing the the ratio lets ρ go to 1 near convergence.</li><li><code>evaluation</code>         - (<code>AllocatingEvaluation()</code>) if you provide a</li><li><code>retraction_method</code>  – (<code>default_retraction_method(M)</code>) the retraction to use</li><li><code>stopping_criterion</code> – (<a href="../plans/stopping_criteria.html#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(100)</code>) a <a href="../plans/stopping_criteria.html#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a></li><li><code>sub_problem</code>        - sub problem solved in each iteration</li><li><code>sub_state</code>          - sub state for solving the sub problem – either a solver state if                        the problem is an <a href="../plans/problem.html#Manopt.AbstractManoptProblem"><code>AbstractManoptProblem</code></a> or an <a href="../plans/objective.html#Manopt.AbstractEvaluationType"><code>AbstractEvaluationType</code></a> if it is a function,                        where it defaults to <a href="../plans/objective.html#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>.</li></ul><p>Furthermore the following integral fields are defined</p><ul><li><code>q</code>                  - (<code>copy(M,p)</code>) a point for the candidates to evaluate model and ρ</li><li><code>H</code>                  – (<code>copy(M, p, X)</code>) the current hessian, <span>$\operatorname{Hess}F(p)[⋅]$</span></li><li><code>S</code>                  – (<code>copy(M, p, X)</code>) the current solution from the subsolver</li><li><code>ρ</code>                  – the current regularized ratio of actual improvement and model improvement.</li><li><code>ρ_denominator</code>      – (<code>one(ρ)</code>) a value to store the denominator from the computation of ρ                        to allow for a warning or error when this value is non-positive.</li></ul><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">AdaptiveRegularizationState(M, p=rand(M); X=zero_vector(M, p); kwargs...)</code></pre><p>Construct the solver state with all fields stated above as keyword arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/ee354f95d8c819b2cc757e5fc73c187ea47b6484/src/solvers/adaptive_regularization_with_cubics.jl#L1-L40">source</a></section></article><h2 id="Sub-solvers"><a class="docs-heading-anchor" href="#Sub-solvers">Sub solvers</a><a id="Sub-solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Sub-solvers" title="Permalink"></a></h2><p>There are several ways to approach the subsolver. The default is the first one.</p><h2 id="Lanczos-Iteration"><a class="docs-heading-anchor" href="#Lanczos-Iteration">Lanczos Iteration</a><a id="Lanczos-Iteration-1"></a><a class="docs-heading-anchor-permalink" href="#Lanczos-Iteration" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.LanczosState" href="#Manopt.LanczosState"><code>Manopt.LanczosState</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LanczosState{P,T,SC,B,I,R,TM,V,Y} &lt;: AbstractManoptSolverState</code></pre><p>Solve the adaptive regularized subproblem with a Lanczos iteration</p><p><strong>Fields</strong></p><ul><li><code>stop</code> – the stopping criterion</li><li><code>σ</code> – the current regularization parameter</li><li><code>X</code> the Iterate</li><li><code>Lanczos_vectors</code> – the obtained Lanczos vectors</li><li><code>tridig_matrix</code> the tridiagonal coefficient matrix T</li><li><code>coefficients</code> the coefficients <code>y_1,...y_k</code>` that determine the solution</li><li><code>Hp</code> – a temporary vector containing the evaluation of the Hessian</li><li><code>Hp_residual</code> – a temporary vector containing the residual to the Hessian</li><li><code>S</code> – the current obtained / approximated solution</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/ee354f95d8c819b2cc757e5fc73c187ea47b6484/src/solvers/Lanczos.jl#L5-L21">source</a></section></article><h2 id="(Conjugate)-Gradient-Descent"><a class="docs-heading-anchor" href="#(Conjugate)-Gradient-Descent">(Conjugate) Gradient Descent</a><a id="(Conjugate)-Gradient-Descent-1"></a><a class="docs-heading-anchor-permalink" href="#(Conjugate)-Gradient-Descent" title="Permalink"></a></h2><p>There is a generic objective, that implements the sub problem</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.AdaptiveRagularizationWithCubicsModelObjective" href="#Manopt.AdaptiveRagularizationWithCubicsModelObjective"><code>Manopt.AdaptiveRagularizationWithCubicsModelObjective</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AdaptiveRagularizationWithCubicsModelObjective</code></pre><p>A model for the adaptive regularization with Cubics</p><p class="math-container">\[m(X) = f(p) + ⟨\operatorname{grad} f(p), X ⟩_p + \frac{1}{2} ⟨\operatorname{Hess} f(p)[X], X⟩_p
       +  \frac{σ}{3} \lVert X \rVert^3,\]</p><p>cf. Eq. (33) in [<a href="../references.html#AgarwalBoumalBullinsCartis:2020">ABBC20</a>]</p><p><strong>Fields</strong></p><ul><li><code>objective</code> – an <a href="../plans/objective.html#Manopt.AbstractManifoldHessianObjective"><code>AbstractManifoldHessianObjective</code></a> proving <span>$f$</span>, its gradient and Hessian</li><li><code>σ</code> – the current (cubic) regularization parameter</li></ul><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AdaptiveRagularizationWithCubicsModelObjective(mho, σ=1.0)</code></pre><p>with either an <a href="../plans/objective.html#Manopt.AbstractManifoldHessianObjective"><code>AbstractManifoldHessianObjective</code></a> <code>objective</code> or an decorator containing such an objective.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/ee354f95d8c819b2cc757e5fc73c187ea47b6484/src/plans/adabtive_regularization_with_cubics_plan.jl#L1-L23">source</a></section></article><p>Since the sub problem is given on the tangent space, you have to provide</p><pre><code class="nohighlight hljs">arc_obj = AdaptiveRagularizationWithCubicsModelObjective(mho, σ)
sub_problem = DefaultProblem(TangentSpaceAt(M,p), arc_obj)</code></pre><p>where <code>mho</code> is the hessian objective of <code>f</code> to solve. Then use this for the <code>sub_problem</code> keyword and use your favourite gradient based solver for the <code>sub_state</code> keyword, for example a <a href="conjugate_gradient_descent.html#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a></p><h2 id="Additional-Stopping-Criteria"><a class="docs-heading-anchor" href="#Additional-Stopping-Criteria">Additional Stopping Criteria</a><a id="Additional-Stopping-Criteria-1"></a><a class="docs-heading-anchor-permalink" href="#Additional-Stopping-Criteria" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.StopWhenAllLanczosVectorsUsed" href="#Manopt.StopWhenAllLanczosVectorsUsed"><code>Manopt.StopWhenAllLanczosVectorsUsed</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">StopWhenAllLanczosVectorsUsed &lt;: StoppingCriterion</code></pre><p>When an inner iteration has used up all Lanczos vectors, then this stopping criterion is a fallback / security stopping criterion in order to not access a non-existing field in the array allocated for vectors.</p><p>Note that this stopping criterion (for now) is only implemented for the case that an <a href="adaptive-regularization-with-cubics.html#Manopt.AdaptiveRegularizationState"><code>AdaptiveRegularizationState</code></a> when using a <a href="adaptive-regularization-with-cubics.html#Manopt.LanczosState"><code>LanczosState</code></a> subsolver</p><p><strong>Fields</strong></p><ul><li><code>maxLanczosVectors</code> – maximal number of Lanczos vectors</li><li><code>reason</code> – a String indicating the reason if the criterion indicated to stop</li></ul><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">StopWhenAllLanczosVectorsUsed(maxLancosVectors::Int)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/ee354f95d8c819b2cc757e5fc73c187ea47b6484/src/solvers/Lanczos.jl#L302-L321">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.StopWhenFirstOrderProgress" href="#Manopt.StopWhenFirstOrderProgress"><code>Manopt.StopWhenFirstOrderProgress</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">StopWhenFirstOrderProgress &lt;: StoppingCriterion</code></pre><p>A stopping criterion related to the Riemannian adaptive regularization with cubics (ARC) solver indicating that the model function at the current (outer) iterate, i.e.</p><p class="math-container">\[    m(X) = f(p) + &lt;X, \operatorname{grad}f(p)&gt;
      + \frac{1}{2} &lt;X, \operatorname{Hess} f(p)[X]&gt; +  \frac{σ}{3} \lVert X \rVert^3,\]</p><p>defined on the tangent space <span>$T_{p}\mathcal M$</span> fulfills at the current iterate <span>$X_k$</span> that</p><p class="math-container">\[m(X_k) \leq m(0)
\quad\text{ and }\quad
\lVert \operatorname{grad} m(X_k) \rVert ≤ θ \lVert X_k \rVert^2\]</p><p><strong>Fields</strong></p><ul><li><code>θ</code> – the factor <span>$θ$</span> in the second condition above</li><li><code>reason</code> – a String indicating the reason if the criterion indicated to stop</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/ee354f95d8c819b2cc757e5fc73c187ea47b6484/src/solvers/Lanczos.jl#L223-L247">source</a></section></article><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[ABBC20]</dt><dd><div>N. Agarwal, N. Boumal, B. Bullins and C. Cartis. <em>Adaptive regularization with cubics on manifolds</em>. <a href="https://doi.org/10.1007/s10107-020-01505-1">Mathematical Programming</a> (2020).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="index.html">« Introduction</a><a class="docs-footer-nextpage" href="alternating_gradient_descent.html">Alternating Gradient Descent »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.2 on <span class="colophon-date" title="Thursday 2 November 2023 11:23">Thursday 2 November 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
