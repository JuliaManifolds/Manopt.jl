---
title: "Implementing your own solver"
author: Ronny Bergmann
---

When you have used a few solvers from `Manopt.jl` for example like in the opening
tutorial [Get Started: Optimize!](https://manoptjl.org/stable/tutorials/Optimize!.html)
you might come to the idea of implementing a solver yourself.

After a short introduction of the algorithm we will implement,
this tutorial first discusses the structural details, i.e. what a solver consists of and “works with”.
Afterwards, we will show how to implement the algorithm.
Finally, we will discuss how to make the algorithm both nice for the user as well as
initiliased in a way, that it can benefit from features already available in `Manopt.jl`.

::: {.callout-tip}
If you have implemented your own solver, we would be very happy to have that within `Manopt.jl`
as well, so maybe consider [opening a Pull Request](https://github.com/JuliaManifolds/Manopt.jl)
:::

```{julia}
#| echo: false
#| code-fold: true
#| output: false
using Pkg;
cd(@__DIR__)
Pkg.activate("."); # for reproducibility use the local tutorial environment.
```

## Our Guiding Example: A random walk Minimization

Since most serious algorithms should be implemented in `Manopt.jl` themselves directly,
we will implement a solver that randomly walks on the manifold and keeps track of the lowest
point visited.
As for algorithms in `Manopt.jl` we aim to implement this _generically_ for any manifold that
is implemented using [`ManifoldsBase.jl`](https://juliamanifolds.github.io/ManifoldsBase.jl/stable/).

**The Random Walk Minimization**

Given:
* a manifold $\mathcal M$
* a starting point $p=p^{(0)}$
* a cost function $f: \mathcal M \to\mathbb R$.
* a parameter $\sigma > 0$.
* a retraction $\operatorname{retr}_p(X)$ that maps $X\in T_p\mathcal M$ to the manifold.

1. set $k=0$
2. set our best point $q = p^{(0)}$
2. Repeat until a stopping criterion is fulfilled
  1. Choose a random tangent vector $X^{(k)} \in T_{p^{(k)}}\mathcal M$ of length $\lVert X^{(k)} \rVert \leq \sigma$
  2. “Walk” along this direction, i.e. $p^{(k+1)} = \operatorname{retr}_{p^{(k)}}(X^{(k)})$
  3. If $f(p^{(k+1)}) < f(q)$ set q = p^{(k+1)}$ as our new best visited point
4. Return $q$ as the resulting best point we visited

## Preliminaries – Elements a Solver works on

THere is two main ingredients a solver needs:
A problem to work on and the state of a solver, which “identifies” the solver.

### The “Task” – An `AbstractManoptProblem`

A problem in `Manopt.jl` usually consists of a manifold (an [`AbstractManifold`](https://juliamanifolds.github.io/ManifoldsBase.jl/stable/types.html#The-AbstractManifold)) and an [`AbstractManifoldObjective`](@ref)
describing the function we have and its features.
In our case the objective is (just) a [`ManifoldCostObjective`](@ref) that stores cost function
`f(M,p) = ...`. MOre general it might for example store a gradient function or the Hessian
or any other information we have about our task.

This is something indepentend of the solver itself, since it only identifies the problem we
want to solve indepentend of how we want to solve it – or in other words, this type contains
all information that is static and independent of the specific solver at hand.

Usually the problems variable is called `mp`.

### The “Solver” An `AbstractManoptSolverState`

Everything that is needed by a solver during the iterations, all its parameters, interims
values that are needed beyond just one iteration, is stored in a subtype of the
[`AbstractManoptSolverState`](@ref). This identifies the solver uniquely.

In our case we want to store five things

* the current iterate `p`$=p^{(k)}$
* the best visited point $q$
* the variable $\sigma > 0$
* the retraction $\operatorname{retr}$ to use (cf. [retractions and inverse retractions](https://juliamanifolds.github.io/ManifoldsBase.jl/stable/retractions.html))
* a criterion, when to stop, i.e. a [`StoppingCriterion`](@ref)

We can defined this as

```{julia}
struct RandomWalkState <: AbstractManoptSolverState{P,S<:StoppingCriterion,R<:AbstractRetractionMethod}
  p::P
  q::P
  σ::Float64
  retraction:method::R
  stop::S
end
```

The stopping criterion is usually stored in the states `stop` field, if you have a reason to
do otherwise, you have one more function to implement (see next section).
For ease of use, we can provide a constructor, that for example chooses a good default for
the retraction based on a given manifold.

```{julia}
function RandomWalkState(M::AbstractManifold, p::P=rand(M);
    retraction_method::R=default_retraction_method(M),
    stopping_criterion::S=StopAfterIteration(200)
) where {P, R<:AbstractRetractionMethod, S<:StoppingCriterion}
    return RandomWalkState{P,R,S}(p, copy(M, p), retraction_method, stopping_criterion)
```

Parametrising the state avoid that we have abstract typed fields.
The keyword arguments for the retraction and stopping criterion are the ones usually used
in `Manopt.jl` and provide an easy way to construct this state now.

States usually have a shortened name as their variable, we will use `rws` for our state here.

## Implementing the Your solver

There is basically only two methods we need to implement for our solver

* `initialize_solver!(mp, rws)` which initialises the solver before the first iteration
* `step_solver!(mp, rws, i)` implement the `i`th iteration, where `i` is given to you as the third parameter

Both functions are in-place functions, that is they modify our solver state `rws`.
You implement these by multiple dispatch on the types after importing said functions from Mantop:

```{julia}
import Manopt: initialize_solver!, step_solver!
```

The state above has two fields where we use the common names used in `Manopt.jl`,
that is the [`StoppingCriterion`](@ref) is usually in `stop` and the iterate in `p`.
If your choice is different, you need to reimplement

* `stop_solver!(mp, rws, i)` to determine whether or not to stop after the `i`th iteration.
* `get_iterate(rws)` to access the current iterate

We recommend to follow the general scheme with the `stop` field. If you have specific criteria
when to stop, consider implementing your own [stoping criterion](https://manoptjl.org/stable/plans/stopping_criteria/) instead

TODO: The stopping criterion page could have a small example in the begining as well.

### Initialization

For our solver, there is not so much to initialize, just to be safe we should copy over the
initial value in `p` we start with, to `q`. We do not have to care about remembering the iterate,
that is done by `Manopt.jl`.

```{julia}
function initialize_solver!(mp::AbstractManoptProblem, rws::RandomWalkState)
    copyto!(M, rws.q, rws.p) # Set p^{(0)} = q
    return rws
end
```

and siilarly we implement the step. Here we make use of the fact that the problem
(and also the objective in fact) have access functions for their elements,
the one we need is [`get_cost`](@ref).

```{julia}
function step_solver!(mp::AbstractManoptProblem, rws::RandomWalkState)
    # generate a direction
    X = rand(M, vector_at=p)
    X .*= rws.σ/norm(M, p, X)
    # Walk
    retract!(M, rws.p, rws.p, X, rws.retraction_method)
    # is the new point better? Then store it
    if get_cost(M, rws.p) < get_cost(M, rws.q)
        copyto!(M, rws.p, rws.q)
    end
    return rws
end
```

Performance wise we could improve the number of allocations by making `X` also a field of
our `rws` but let's keep it simple here.
We could also store the cost of `q` in the state, but we will see how to easily also enable
this solver to allow for [caching](https://manoptjl.org/stable/tutorials/CountAndCache/#How-to-Count-and-Cache-Function-Calls)

## Ease of Use I: An Interface with the Objective

## Ease of Use II: The high level interface

## Ease of USe III: The Sumary