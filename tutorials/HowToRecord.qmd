---
title: "How to Record Data During the Iterations"
author: Ronny Bergmann
---

The recording and debugging features make it possible to record nearly any data during the iterations.
This tutorial illustrates how to:

* record one value during the iterations;
* record multiple values during the iterations and access them afterwards;
* define an own `RecordAction` to perform individual recordings.

Several predefined recordings exist, for example [`RecordCost`](https://manoptjl.org/stable/plans/record/#Manopt.RecordCost) or [`RecordGradient`](https://manoptjl.org/stable/solvers/gradient_descent/#Manopt.RecordGradient), if the problem the solver uses provides a gradient.
For fields of the `State` the recording can also be done [`RecordEntry`](https://manoptjl.org/stable/plans/record/#Manopt.RecordEvery).
For other recordings, for example more advanced computations before storing a value, an own `RecordAction` can be defined.

We illustrate these using the gradient descent from the [Get Started: Optimize!](https://manoptjl.org/stable/tutorials/Optimize!.html) tutorial.

Here we focus on ways to investigate the behaviour during iterations by using Recording techniques.

```{julia}
#| echo: false
#| code-fold: true
#| output: false
using Pkg;
cd(@__DIR__)
Pkg.activate("."); # for reproducibility use the local tutorial environment.
```

Let's first load the necessary packages.

```{julia}
using Manopt, Manifolds, Random
Random.seed!(42);
```

## The Objective

We generate data and define our cost and gradient:

```{julia}
Random.seed!(42)
m = 30
M = Sphere(m)
n = 800
σ = π / 8
x = zeros(Float64, m + 1)
x[2] = 1.0
data = [exp(M, x, σ * rand(M; vector_at=x)) for i in 1:n]
f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)
grad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)))
```

## Plain Examples

For the high level interfaces of the solvers, like [`gradient_descent`](https://manoptjl.org/stable/solvers/gradient_descent.html) we have to set `return_state` to `true` to obtain the whole [solver state](https://manoptjl.org/stable/plans/state/) and not only the resulting minimizer.

Then we can easily use the `record=` option to add recorded values. This keyword accepts [`RecordAction`](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s
as well as several symbols as shortcuts, for example `:Cost` to record the cost, or if your options have a field `f`, `:f` would record that entry.
An overview of the symbols that can be used is given [here](https://manoptjl.org/stable/plans/record/#Manopt.RecordActionFactory-Tuple{AbstractManoptSolverState,%20RecordAction}).

We first just record the cost after every iteration

```{julia}
R = gradient_descent(M, f, grad_f, data[1]; record=:Cost, return_state=true)
```

From the returned state, we see that the [`GradientDescentState`](https://manoptjl.org/stable/solvers/gradient_descent/#Manopt.GradientDescentState) are encapsulated (decorated) within a [`RecordSolverState`](https://manoptjl.org/stable/plans/record/#Manopt.RecordSolverState).

For such a state, one can attach different recorders to some operations, currently to `:Start`. `:Stop`, and `:Iteration`, where `:Iteration` is the default when using the `record=` keyword with a [`RecordAction`](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction) as above.
We can access all values recorded during the iterations by calling `get_record(R, :Iteation)` or since this is the default even shorter

```{julia}
get_record(R)
```

To record more than one value, you can pass an array of a mix of symbols and [`RecordAction`](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s which formally introduces [`RecordGroup`](https://manoptjl.org/stable/plans/record/#Manopt.RecordGroup). Such a group records a tuple of values in every iteration:

```{julia}
R2 = gradient_descent(M, f, grad_f, data[1]; record=[:Iteration, :Cost], return_state=true)
```

Here, the symbol `:Cost` is mapped to using the [`RecordCost`](https://manoptjl.org/stable/plans/record/#Manopt.RecordCost) action. The same holds for `:Iteration` obiously records the current iteration number `i`.
To access these you can first extract the group of records (that is where the `:Iteration`s are recorded – note the plural) and then access the `:Cost`
"""

```{julia}
get_record_action(R2, :Iteration)
```

Since `iteration` is the default, we can also omit it here again.
To access single recorded values, one can use

```{julia}
get_record_action(R2)[:Cost]
```

This can be also done by using a the high level interface [`get_record`](https://manoptjl.org/stable/plans/record/#Manopt.get_record)

```{julia}
get_record(R2, :Iteration, :Cost)
```

Note that the first symbol again refers to the point where we record (not to the thing we record).
We can also pass a tuple as second argument to have our own order within the tuples returned. Switching the order of recorded cost and Iteration can be done using
"""

```{julia}
get_record(R2, :Iteration, (:Iteration, :Cost))
```

## A more Complex Example

To illustrate a complicated example let's record:
* the iteration number, cost and gradient field, but only every sixth iteration;
* the iteration at which we stop.

We first generate the problem and the state, to also illustrate the low-level works when not using the high-level iterface [`gradient_descent`](https://manoptjl.org/stable/solvers/gradient_descent.html).

```{julia}
p = DefaultManoptProblem(M, ManifoldGradientObjective(f, grad_f))
s = GradientDescentState(
    M,
    copy(data[1]);
    stopping_criterion=StopAfterIteration(200) | StopWhenGradientNormLess(10.0^-9),
)
```

We now first build a  [`RecordGroup`](https://manoptjl.org/stable/plans/record/#Manopt.RecordGroup) to group the three entries we want to record per iteration. We then put this into a [`RecordEvery`](https://manoptjl.org/stable/plans/record/#Manopt.RecordEvery) to only record this every 6th iteration

```{julia}
rI = RecordEvery(
    RecordGroup([
        :Iteration => RecordIteration(),
        :Cost => RecordCost(),
        :Gradient => RecordEntry(similar(data[1]), :X),
    ]),
    6,
)
```

and for recodring the final iteration number

```{julia}
sI = RecordIteration()
```

We now combine both into the [`RecordSolverState`](https://manoptjl.org/stable/plans/record/#Manopt.RecordSolverState) decorator. It acts completely the same as any [`AbstractManoptSolverState`](https://manoptjl.org/stable/plans/state/#Manopt.AbstractManoptSolverState) but records something in every iteration additionally. This is stored in a dictionary of [`RecordAction`](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s, where `:Iteration` is the action (here the only every 6th iteration group) and the `sI` which is executed at stop.

Note that the keyword `record=` in the high level interface `gradient_descent` only would fill the `:Iteration` symbol of said dictionary.

```{julia}
r = RecordSolverState(s, Dict(:Iteration => rI, :Stop => sI))
```

We now call the solver

```{julia}
res = solve!(p, r)
```

And we can check the recorded value at `:Stop` to see how many iterations were performed

```{julia}
get_record(res, :Stop)
```

and the other values during the iterations are

```{julia}
get_record(res, :Iteration, (:Iteration, :Cost))
```

## Writing an own [`RecordAction`](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s

Let's investigate where we want to count the number of function evaluations, again just to illustrate, since for the gradient this is just one evaluation per iteration.
We first define a cost, that counts its own calls.
"""

```{julia}
mutable struct MyCost{T}
    data::T
    count::Int
end
MyCost(data::T) where {T} = MyCost{T}(data, 0)
function (c::MyCost)(M, x)
    c.count += 1
    return sum(1 / (2 * length(c.data)) * distance.(Ref(M), Ref(x), c.data) .^ 2)
end
```

and we define an own, new [`RecordAction`](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction), which is a functor, i.e. a struct that is also a function. The function we have to implement is similar to a single solver step in signature, since it might get called every iteration:

```{julia}
mutable struct RecordCount <: RecordAction
    recorded_values::Vector{Int}
    RecordCount() = new(Vector{Int}())
end
function (r::RecordCount)(p::AbstractManoptProblem, ::AbstractManoptSolverState, i)
    if i > 0
        push!(r.recorded_values, get_cost_function(get_objective(p)).count)
    elseif i < 0 # reset if negative
        r.recorded_values = Vector{Int}()
    end
end
```

Now we can initialize the new cost and call the gradient descent.
Note that this illustrates also the last use case – you can pass symbol-action pairs into the `record=`array.

```{julia}
f2 = MyCost(data)
```

Now for the plain gradient descent, we have to modify the step (to a constant stepsize) and remove the default check whether the cost increases (setting `debug` to `[]`).
We also only look at the first 20 iterations to keep this example small in recorded values. We call

```{julia}
R3 = gradient_descent(
    M,
    f2,
    grad_f,
    data[1];
    record=[:Iteration, :Count => RecordCount(), :Cost],
    stepsize = ConstantStepsize(1.0),
    stopping_criterion=StopAfterIteration(20),
    debug=[],
    return_state=true,
)
```

For `:Cost` we already learned how to access them, the `:Count =>` introduces the following action to obtain the `:Count`. We can again access the whole sets of records

```{julia}
get_record(R3)
```

this is equivalent to calling `R[:Iteration]`.
Note that since we introduced `:Count` we can also access a single recorded value using

```{julia}
R3[:Iteration, :Count]
```

and we see that the cost function is called once per iteration.

If we use this counting cost and run the default gradient descent with Armijo linesearch, we can infer how many Armijo linesearch backtracks are preformed:

```{julia}
f3 = MyCost(data)
```

To not get too many entries let's just look at the first 20 iterations again

```{julia}
R4 = gradient_descent(
    M,
    f3,
    grad_f,
    data[1];
    record=[:Count => RecordCount()],
    return_state=true,
)
```

```{julia}
get_record(R4)
```

We can see that the number of cost function calls varies, depending on how many linesearch backtrack steps were required to obtain a good stepsize.
