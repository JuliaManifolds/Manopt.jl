---
title: "How to do constrained optimization"
author: "Ronny Bergmann"
---

This tutorial is a short introduction to using solvers for constraint optimisation in [`Manopt.jl`](https://manoptjl.org).

## Introduction

A constraint optimisation problem is given by

```math
\tag{P}
\begin{align*}
\operatorname*{arg\,min}_{p∈\mathcal M} & f(p)\\
\text{such that} &\quad g(p) \leq 0\\
&\quad h(p) = 0,\\
\end{align*}
```
where $f:  \mathcal M → ℝ$ is a cost function, and $g:  \mathcal M → ℝ^m$ and $h:  \mathcal M → ℝ^n$ are the inequality and equality constraints, respectively. The $\leq$ and $=$ in (P) are meant element-wise.

This can be seen as a balance between moving constraints into the geometry of a manifold $\mathcal M$ and keeping some, since they can be handled well in algorithms, see [BergmannHerzog:2019](@cite), [LiuBoumal:2019](@cite)  for details.

```{julia}
#| echo: false
#| code-fold: true
#| output: false
using Pkg;
cd(@__DIR__)
Pkg.activate("."); # for reproducibility use the local tutorial environment.
```

```{julia}
using Distributions, LinearAlgebra, Manifolds, Manopt, Random
Random.seed!(42);
```

In this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrate the different available forms.

We consider the problem of a Nonnegative PCA, cf. Section 5.1.2 in [LiuBoumal:2019](@cite)

let $v_0 ∈ ℝ^d$, $\lVert v_0 \rVert=1$ be given spike signal, that is a signal that is sparse with only $s=\lfloor δd \rfloor$ nonzero entries.

```math
Z = \sqrt{σ} v_0v_0^{\mathrm{T}}+N,
```

where $\sigma$ is a signal-to-noise ratio and $N$ is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation $1/d$ on the off-diagonals and $2/d$ on the diagonal

```{julia}
d = 150; # dimension of v0
σ = 0.1^2; # SNR
δ = 0.1; sp = Int(floor(δ * d)); # Sparsity
S = sample(1:d, sp; replace=false);
v0 =  [i ∈ S ? 1 / sqrt(sp) : 0.0 for i in 1:d];
N = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);
Z = Z = sqrt(σ) * v0 * transpose(v0) + N;
```

In order to recover $v_0$ we consider the constrained optimisation problem on the sphere $\mathcal S^{d-1}$ given by

```math
\begin{align*}
\operatorname*{arg\,min}_{p∈\mathcal S^{d-1}} & -p^{\mathrm{T}}Zp^{\mathrm{T}}\\
\text{such that} &\quad p \geq 0\\
\end{align*}
```

or in the previous notation $f(p) = -p^{\mathrm{T}}Zp^{\mathrm{T}}$ and $g(p) = -p$. We first initialize the manifold under consideration

```{julia}
M = Sphere(d - 1)
```

## A first augmented Lagrangian run

We first defined $f$  and $g$ as usual functions

```{julia}
f(M, p) = -transpose(p) * Z * p;
g(M, p) = -p;
```

since $f$ is a functions defined in the embedding $ℝ^d$ as well, we obtain its gradient by projection.

```{julia}
grad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p);
```

For the constraints this is a little more involved, since each function $g_i=g(p)_i=p_i$
has to return its own gradient. These are again in the embedding just $\operatorname{grad} g_i(p) = -e_i$ the $i$ th unit vector. We can project these again onto the tangent space at $p$:

```{julia}
grad_g(M, p) = project.(
	Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]
);
```

We further start in a random point:

```{julia}
p0 = rand(M);
```

Let's verify a few things for the initial point

```{julia}
f(M, p0)
```

How much the function g is positive

```{julia}
maximum(g(M, p0))
```


Now as a first method we can just call the [Augmented Lagrangian Method](https://manoptjl.org/stable/solvers/augmented_Lagrangian_method/) with a simple call:

```{julia}
@time v1 = augmented_Lagrangian_method(
   	M, f, grad_f, p0; g=g, grad_g=grad_g,
    debug=[:Iteration, :Cost, :Stop, " | ", (:Change, "Δp : %1.5e"), 20, "\n"],
    stopping_criterion = StopAfterIteration(300) | (
        StopWhenSmallerOrEqual(:ϵ, 1e-5) & StopWhenChangeLess(M, 1e-8)
    )
);
```

Now we have both a lower function value and the point is nearly within the constraints,
namely up to numerical inaccuracies

```{julia}
f(M, v1)
```
```{julia}
maximum( g(M, v1) )
```

## A faster augmented Lagrangian run

Now this is a little slow, so we can modify two things:

1. Gradients should be evaluated in place, so for example

```{julia}
grad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p);
```

2. The constraints are currently always evaluated all together, since the function `grad_g` always returns a vector of gradients.
We first change the constraints function into a vector of functions.
We further change the gradient _both_ into a vector of gradient functions $\operatorname{grad} g_i,i=1,\ldots,d$, _as well as_ gradients that are computed in place.


```{julia}
g2 = [(M, p) -> -p[i] for i in 1:d];
grad_g2! = [
    (M, X, p) -> project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d
];
```

We obtain

```{julia}
@time v2 = augmented_Lagrangian_method(
    	M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),
    	debug=[:Iteration, :Cost, :Stop, " | ", (:Change, "Δp : %1.5e"), 20, "\n"],
		stopping_criterion = StopAfterIteration(300) | (
          StopWhenSmallerOrEqual(:ϵ, 1e-5) & StopWhenChangeLess(M, 1e-8)
		)
	);
```

As a technical remark: note that (by default) the change to [`InplaceEvaluation`](https://manoptjl.org/stable/plans/problem/#Manopt.InplaceEvaluation)s affects both the constrained solver as well as the inner solver of the subproblem in each iteration.


```{julia}
f(M, v2)
```


```{julia}
maximum(g(M, v2))
```

These are the very similar to the previous values but the solver took much less time and less memory allocations.

## Exact penalty method

As a second solver, we have the [Exact Penalty Method](https://manoptjl.org/stable/solvers/exact_penalty_method/), which currently is available with two smoothing variants, which make an inner solver for smooth optimization, that is by default again [quasi Newton] possible:
[`LogarithmicSumOfExponentials`](https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials)
and [`LinearQuadraticHuber`](https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber). We compare both here as well. The first smoothing technique is the default, so we can just call

```{julia}
@time v3 = exact_penalty_method(
   	M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),
   	debug=[:Iteration, :Cost, :Stop, " | ", :Change, 50, "\n"],
);
```

We obtain a similar cost value as for the Augmented Lagrangian Solver from before,
but here the constraint is actually fulfilled and not just numerically “on the boundary”.

```{julia}
f(M, v3)
```

```{julia}
maximum(g(M, v3))
```

The second smoothing technique is often beneficial, when we have a lot of constraints (in the previously mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time.

```{julia}
@time v4 = exact_penalty_method(
    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!,
    evaluation=InplaceEvaluation(),
    smoothing=LinearQuadraticHuber(),
   	debug=[:Iteration, :Cost, :Stop, " | ", :Change, 50, "\n"],
);
```

For the result we see the same behaviour as for the other smoothing.

```{julia}
f(M, v4)
```

```{julia}
maximum(g(M, v4))
```

## Comparing to the unconstrained solver

We can compare this to the _global_ optimum on the sphere, which is the unconstrained optimisation problem, where we can just use Quasi Newton.

Note that this is much faster, since every iteration of the algorithm does a quasi-Newton call as well.

```{julia}
@time w1 = quasi_Newton(
    M, f, grad_f!, p0; evaluation=InplaceEvaluation()
);
```

```{julia}
f(M, w1)
```

But for sure here the constraints here are not fulfilled and we have quite positive entries in $g(w_1)$

```{julia}
maximum(g(M, w1))
```

## Technical details

This tutorial is cached. It was last run on the following package versions.

```{julia}
#| code-fold: true
using Pkg
Pkg.status()
```
```{julia}
#| code-fold: true
using Dates
now()
```

## Literature

````{=commonmark}
```@bibliography
Pages = ["ConstrainedOptimization.md"]
Canonical=false
```
````
