<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Conjugate gradient descent Â· Manopt.jl</title><meta name="title" content="Conjugate gradient descent Â· Manopt.jl"/><meta property="og:title" content="Conjugate gradient descent Â· Manopt.jl"/><meta property="twitter:title" content="Conjugate gradient descent Â· Manopt.jl"/><meta name="description" content="Documentation for Manopt.jl."/><meta property="og:description" content="Documentation for Manopt.jl."/><meta property="twitter:description" content="Documentation for Manopt.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Manopt.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../about/">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../../tutorials/Optimize/">ğŸ”ï¸ Get started: optimize.</a></li><li><a class="tocitem" href="../../tutorials/InplaceGradient/">Speedup using in-place computations</a></li><li><a class="tocitem" href="../../tutorials/AutomaticDifferentiation/">Use automatic differentiation</a></li><li><a class="tocitem" href="../../tutorials/EmbeddingObjectives/">Define objectives in the embedding</a></li><li><a class="tocitem" href="../../tutorials/CountAndCache/">Count and use a cache</a></li><li><a class="tocitem" href="../../tutorials/HowToDebug/">Print debug output</a></li><li><a class="tocitem" href="../../tutorials/HowToRecord/">Record values</a></li><li><a class="tocitem" href="../../tutorials/ImplementASolver/">Implement a solver</a></li><li><a class="tocitem" href="../../tutorials/ImplementOwnManifold/">Optimize on your own manifold</a></li><li><a class="tocitem" href="../../tutorials/ConstrainedOptimization/">Do constrained optimization</a></li><li><a class="tocitem" href="../../tutorials/GeodesicRegression/">Do geodesic regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../adaptive-regularization-with-cubics/">Adaptive Regularization with Cubics</a></li><li><a class="tocitem" href="../alternating_gradient_descent/">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../augmented_Lagrangian_method/">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../ChambollePock/">Chambolle-Pock</a></li><li class="is-active"><a class="tocitem" href>Conjugate gradient descent</a><ul class="internal"><li><a class="tocitem" href="#State"><span>State</span></a></li><li><a class="tocitem" href="#cg-coeffs"><span>Available coefficients</span></a></li><li><a class="tocitem" href="#sec-cgd-technical-details"><span>Technical details</span></a></li><li class="toplevel"><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../cyclic_proximal_point/">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../difference_of_convex/">Difference of Convex</a></li><li><a class="tocitem" href="../DouglasRachford/">Douglasâ€”Rachford</a></li><li><a class="tocitem" href="../exact_penalty_method/">Exact Penalty Method</a></li><li><a class="tocitem" href="../FrankWolfe/">Frank-Wolfe</a></li><li><a class="tocitem" href="../gradient_descent/">Gradient Descent</a></li><li><a class="tocitem" href="../LevenbergMarquardt/">Levenbergâ€“Marquardt</a></li><li><a class="tocitem" href="../NelderMead/">Nelderâ€“Mead</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../primal_dual_semismooth_Newton/">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../quasi_Newton/">Quasi-Newton</a></li><li><a class="tocitem" href="../stochastic_gradient_descent/">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../subgradient/">Subgradient method</a></li><li><a class="tocitem" href="../truncated_conjugate_gradient_descent/">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../trust_regions/">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../../plans/">Specify a Solver</a></li><li><a class="tocitem" href="../../plans/problem/">Problem</a></li><li><a class="tocitem" href="../../plans/objective/">Objective</a></li><li><a class="tocitem" href="../../plans/state/">Solver State</a></li><li><a class="tocitem" href="../../plans/stepsize/">Stepsize</a></li><li><a class="tocitem" href="../../plans/stopping_criteria/">Stopping Criteria</a></li><li><a class="tocitem" href="../../plans/debug/">Debug Output</a></li><li><a class="tocitem" href="../../plans/record/">Recording values</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../../helpers/checks/">Checks</a></li><li><a class="tocitem" href="../../helpers/exports/">Exports</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../../extensions/">Extensions</a></li><li><a class="tocitem" href="../../notation/">Notation</a></li><li><a class="tocitem" href="../../changelog/">Changelog</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href>Conjugate gradient descent</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Conjugate gradient descent</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/solvers/conjugate_gradient_descent.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ï„</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="CGSolver"><a class="docs-heading-anchor" href="#CGSolver">Conjugate gradient descent</a><a id="CGSolver-1"></a><a class="docs-heading-anchor-permalink" href="#CGSolver" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.conjugate_gradient_descent" href="#Manopt.conjugate_gradient_descent"><code>Manopt.conjugate_gradient_descent</code></a> â€” <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">conjugate_gradient_descent(M, F, gradF, p=rand(M))
conjugate_gradient_descent(M, gradient_objective, p)</code></pre><p>perform a conjugate gradient based descent</p><p class="math-container">\[p_{k+1} = \operatorname{retr}_{p_k} \bigl( s_kÎ´_k \bigr),\]</p><p>where <span>$\operatorname{retr}$</span> denotes a retraction on the <code>Manifold</code> <code>M</code> and one can employ different rules to update the descent direction <span>$Î´_k$</span> based on the last direction <span>$Î´_{k-1}$</span> and both gradients <span>$\operatorname{grad}f(x_k)$</span>,<span>$\operatorname{grad}f(x_{k-1})$</span>. The <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> <span>$s_k$</span> may be determined by a <a href="../../plans/stepsize/#Manopt.Linesearch"><code>Linesearch</code></a>.</p><p>Alternatively to <code>f</code> and <code>grad_f</code> you can provide the <a href="../../plans/objective/#Manopt.AbstractManifoldGradientObjective"><code>AbstractManifoldGradientObjective</code></a> <code>gradient_objective</code> directly.</p><p>Available update rules are <a href="#Manopt.SteepestDirectionUpdateRule"><code>SteepestDirectionUpdateRule</code></a>, which yields a <a href="../gradient_descent/#Manopt.gradient_descent"><code>gradient_descent</code></a>, <a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a> (the default), <a href="#Manopt.DaiYuanCoefficient"><code>DaiYuanCoefficient</code></a>, <a href="#Manopt.FletcherReevesCoefficient"><code>FletcherReevesCoefficient</code></a>, <a href="#Manopt.HagerZhangCoefficient"><code>HagerZhangCoefficient</code></a>, <a href="#Manopt.HestenesStiefelCoefficient"><code>HestenesStiefelCoefficient</code></a>, <a href="#Manopt.LiuStoreyCoefficient"><code>LiuStoreyCoefficient</code></a>, and <a href="#Manopt.PolakRibiereCoefficient"><code>PolakRibiereCoefficient</code></a>. These can all be combined with a <a href="#Manopt.ConjugateGradientBealeRestart"><code>ConjugateGradientBealeRestart</code></a> rule.</p><p>They all compute <span>$Î²_k$</span> such that this algorithm updates the search direction as</p><p class="math-container">\[\delta_k=\operatorname{grad}f(p_k) + Î²_k \delta_{k-1}\]</p><p><strong>Input</strong></p><ul><li><code>M</code> : a manifold <span>$\mathcal M$</span></li><li><code>f</code> : a cost function <span>$F:\mathcal Mâ†’â„$</span> to minimize implemented as a function <code>(M,p) -&gt; v</code></li><li><code>grad_f</code>: the gradient <span>$\operatorname{grad}F:\mathcal M â†’ T\mathcal M$</span> of <span>$F$</span> implemented also as <code>(M,x) -&gt; X</code></li><li><code>p</code> : an initial value <span>$xâˆˆ\mathcal M$</span></li></ul><p><strong>Optional</strong></p><ul><li><code>coefficient</code> : (<a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a> <code>&lt;:</code> <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>) rule to compute the descent direction update coefficient <span>$Î²_k$</span>, as a functor, i.e. the resulting function maps <code>(amp, cgs, i) -&gt; Î²</code>, where <code>amp</code> is an <a href="../../plans/problem/#Manopt.AbstractManoptProblem"><code>AbstractManoptProblem</code></a>, <code>cgs</code> are the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a> <code>o</code> and <code>i</code> is the current iterate.</li><li><code>evaluation</code> â€“ (<a href="../../plans/objective/#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>) specify whether the gradient works by allocation (default) form <code>gradF(M, x)</code> or <a href="../../plans/objective/#Manopt.InplaceEvaluation"><code>InplaceEvaluation</code></a> in place, i.e. is of the form <code>gradF!(M, X, x)</code>.</li><li><code>retraction_method</code> - (<code>default_retraction_method(M, typeof(p))</code>) a retraction method to use.</li><li><code>stepsize</code> - (<a href="../../plans/stepsize/#Manopt.ArmijoLinesearch"><code>ArmijoLinesearch</code></a> via <a href="../../plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{&lt;:AbstractManoptSolverState}}"><code>default_stepsize</code></a>) A <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> function applied to the search direction. The default is a constant step size 1.</li><li><code>stopping_criterion</code> : (<code>stopWhenAny( stopAtIteration(200), stopGradientNormLess(10.0^-8))</code>) a function indicating when to stop.</li><li><code>vector_transport_method</code> â€“ (<code>default_vector_transport_method(M, typeof(p))</code>) vector transport method to transport the old descent direction when computing the new descent direction.</li></ul><p>If you provide the <a href="../../plans/objective/#Manopt.ManifoldGradientObjective"><code>ManifoldGradientObjective</code></a> directly, <code>evaluation</code> is ignored.</p><p><strong>Output</strong></p><p>the obtained (approximate) minimizer <span>$p^*$</span>, see <a href="../#Manopt.get_solver_return"><code>get_solver_return</code></a> for details</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/solvers/conjugate_gradient_descent.jl#L30-L86">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.conjugate_gradient_descent!" href="#Manopt.conjugate_gradient_descent!"><code>Manopt.conjugate_gradient_descent!</code></a> â€” <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">conjugate_gradient_descent!(M, F, gradF, x)
conjugate_gradient_descent!(M, gradient_objective, p; kwargs...)</code></pre><p>perform a conjugate gradient based descent in place of <code>x</code>, i.e.</p><p class="math-container">\[p_{k+1} = \operatorname{retr}_{p_k} \bigl( s_k\delta_k \bigr),\]</p><p>where <span>$\operatorname{retr}$</span> denotes a retraction on the <code>Manifold</code> <code>M</code></p><p><strong>Input</strong></p><ul><li><code>M</code> : a manifold <span>$\mathcal M$</span></li><li><code>f</code> : a cost function <span>$F:\mathcal Mâ†’â„$</span> to minimize</li><li><code>grad_f</code>: the gradient <span>$\operatorname{grad}F:\mathcal Mâ†’ T\mathcal M$</span> of F</li><li><code>p</code> : an initial value <span>$pâˆˆ\mathcal M$</span></li></ul><p>Alternatively to <code>f</code> and <code>grad_f</code> you can provide the <a href="../../plans/objective/#Manopt.AbstractManifoldGradientObjective"><code>AbstractManifoldGradientObjective</code></a> <code>gradient_objective</code> directly.</p><p>for more details and options, especially the <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>s,  see <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/solvers/conjugate_gradient_descent.jl#L120-L141">source</a></section></article><h2 id="State"><a class="docs-heading-anchor" href="#State">State</a><a id="State-1"></a><a class="docs-heading-anchor-permalink" href="#State" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.ConjugateGradientDescentState" href="#Manopt.ConjugateGradientDescentState"><code>Manopt.ConjugateGradientDescentState</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateGradientState &lt;: AbstractGradientSolverState</code></pre><p>specify options for a conjugate gradient descent algorithm, that solves a [<code>DefaultManoptProblem</code>].</p><p><strong>Fields</strong></p><ul><li><code>p</code>                       â€“ the current iterate, a point on a manifold</li><li><code>X</code>                       â€“ the current gradient, also denoted as <span>$Î¾$</span> or <span>$X_k$</span> for the gradient in the <span>$k$</span>th step.</li><li><code>Î´</code>                       â€“ the current descent direction, i.e. also tangent vector</li><li><code>Î²</code>                       â€“ the current update coefficient rule, see .</li><li><code>coefficient</code>             â€“ (<a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a><code>()</code>) a <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a> function to determine the new <code>Î²</code></li><li><code>stepsize</code>                â€“ (<a href="../../plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{&lt;:AbstractManoptSolverState}}"><code>default_stepsize</code></a><code>(M, ConjugateGradientDescentState; retraction_method=retraction_method)</code>) a <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> function</li><li><code>stop</code>                    â€“ (<a href="../../plans/stopping_criteria/#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(500) |</code><a href="../../plans/stopping_criteria/#Manopt.StopWhenGradientNormLess"><code>StopWhenGradientNormLess</code></a><code>(1e-8)</code>) a <a href="../../plans/stopping_criteria/#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a></li><li><code>retraction_method</code>       â€“ (<code>default_retraction_method(M, typeof(p))</code>) a type of retraction</li><li><code>vector_transport_method</code> â€“ (<code>default_retraction_method(M, typeof(p))</code>) a type of retraction</li></ul><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">ConjugateGradientState(M, p)</code></pre><p>where the last five fields above can be set by their names as keyword and the <code>X</code> can be set to a tangent vector type using the keyword <code>initial_gradient</code> which defaults to <code>zero_vector(M,p)</code>, and <code>Î´</code> is initialized to a copy of this vector.</p><p><strong>See also</strong></p><p><a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a>, <a href="../../plans/problem/#Manopt.DefaultManoptProblem"><code>DefaultManoptProblem</code></a>, <a href="../../plans/stepsize/#Manopt.ArmijoLinesearch"><code>ArmijoLinesearch</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L22-L51">source</a></section></article><h2 id="cg-coeffs"><a class="docs-heading-anchor" href="#cg-coeffs">Available coefficients</a><a id="cg-coeffs-1"></a><a class="docs-heading-anchor-permalink" href="#cg-coeffs" title="Permalink"></a></h2><p>The update rules act as <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>, which internally always first evaluate the gradient itself.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.ConjugateGradientBealeRestart" href="#Manopt.ConjugateGradientBealeRestart"><code>Manopt.ConjugateGradientBealeRestart</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateGradientBealeRestart &lt;: DirectionUpdateRule</code></pre><p>An update rule might require a restart, that is using pure gradient as descent direction, if the last two gradients are nearly orthogonal, cf. <a href="../../references/#HagerZhang:2006">Hager, Zhang, Pacific J Optim, 2006</a>, page 12 (in the pdf, 46 in Journal page numbers). This method is named after E. Beale from his proceedings paper in 1972 [<a href="../../references/#Beale:1972">Bea72</a>]. This method acts as a <em>decorator</em> to any existing <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a> <code>direction_update</code>.</p><p>When obtain from the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgs</code> the last <span>$p_k,X_k$</span> and the current <span>$p_{k+1},X_{k+1}$</span> iterate and the gradient, respectively.</p><p>Then a restart is performed, i.e. <span>$Î²_k = 0$</span> returned if</p><p class="math-container">\[    \frac{ âŸ¨X_{k+1}, P_{p_{k+1}\gets p_k}X_kâŸ©}{\lVert X_k \rVert_{p_k}} &gt; Î¾,\]</p><p>where <span>$P_{a\gets b}(â‹…)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>, and <span>$Î¾$</span> is the <code>threshold</code>. The default threshold is chosen as <code>0.2</code> as recommended in <a href="../../references/#Powell:1977">Powell, Math. Prog., 1977</a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">ConjugateGradientBealeRestart(
    direction_update::D,
    threshold=0.2;
    manifold::AbstractManifold = DefaultManifold(),
    vector_transport_method::V=default_vector_transport_method(manifold),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L594-L622">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.ConjugateDescentCoefficient" href="#Manopt.ConjugateDescentCoefficient"><code>Manopt.ConjugateDescentCoefficient</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateDescentCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#Fletcher:1987">Fletcher, 1987</a> adapted to manifolds:</p><p class="math-container">\[Î²_k =
\frac{ \lVert X_{k+1} \rVert_{p_{k+1}}^2 }
{\langle -\delta_k,X_k \rangle_{p_k}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">ConjugateDescentCoefficient(a::StoreStateAction=())</code></pre><p>Construct the conjugate descent coefficient update rule, a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L147-L167">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.DaiYuanCoefficient" href="#Manopt.DaiYuanCoefficient"><code>Manopt.DaiYuanCoefficient</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DaiYuanCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>, based on <a href="../../references/#DaiYuan:1999">Dai, Yuan, Siam J Optim, 1999</a> adapted to manifolds:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(â‹…)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the coefficient reads</p><p class="math-container">\[Î²_k =
\frac{ \lVert X_{k+1} \rVert_{p_{k+1}}^2 }
{\langle P_{p_{k+1}\gets p_k}\delta_k, \nu_k \rangle_{p_{k+1}}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function DaiYuanCoefficient(
    M::AbstractManifold=DefaultManifold(2);
    t::AbstractVectorTransportMethod=default_vector_transport_method(M)
)</code></pre><p>Construct the Dai Yuan coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L190-L219">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.FletcherReevesCoefficient" href="#Manopt.FletcherReevesCoefficient"><code>Manopt.FletcherReevesCoefficient</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FletcherReevesCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#FletcherReeves:1964">Flecther, Reeves, Comput. J, 1964</a> adapted to manifolds:</p><p class="math-container">\[Î²_k =
\frac{\lVert X_{k+1}\rVert_{p_{k+1}}^2}{\lVert X_k\rVert_{x_{k}}^2}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">FletcherReevesCoefficient(a::StoreStateAction=())</code></pre><p>Construct the Fletcher Reeves coefficient update rule, a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L258-L277">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.HagerZhangCoefficient" href="#Manopt.HagerZhangCoefficient"><code>Manopt.HagerZhangCoefficient</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HagerZhangCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>, based on <a href="../../references/#HagerZhang:2005">Hager, Zhang, SIAM J Optim, 2005</a>. adapted to manifolds: let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(â‹…)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p class="math-container">\[Î²_k = \Bigl\langle\nu_k -
\frac{ 2\lVert \nu_k\rVert_{p_{k+1}}^2 }{ \langle P_{p_{k+1}\gets p_k}\delta_k, \nu_k \rangle_{p_{k+1}} }
P_{p_{k+1}\gets p_k}\delta_k,
\frac{X_{k+1}}{ \langle P_{p_{k+1}\gets p_k}\delta_k, \nu_k \rangle_{p_{k+1}} }
\Bigr\rangle_{p_{k+1}}.\]</p><p>This method includes a numerical stability proposed by those authors.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function HagerZhangCoefficient(t::AbstractVectorTransportMethod)
function HagerZhangCoefficient(M::AbstractManifold = DefaultManifold(2))</code></pre><p>Construct the Hager Zhang coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L301-L329">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.HestenesStiefelCoefficient" href="#Manopt.HestenesStiefelCoefficient"><code>Manopt.HestenesStiefelCoefficient</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HestenesStiefelCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#HestenesStiefel:1952">Heestenes, Stiefel, J. Research Nat. Bur. Standards, 1952</a> adapted to manifolds as follows:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>. Then the update reads</p><p class="math-container">\[Î²_k = \frac{\langle X_{k+1}, \nu_k \rangle_{p_{k+1}} }
    { \langle P_{p_{k+1}\gets p_k} \delta_k, \nu_k\rangle_{p_{k+1}} },\]</p><p>where <span>$P_{a\gets b}(â‹…)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function HestenesStiefelCoefficient(transport_method::AbstractVectorTransportMethod)
function HestenesStiefelCoefficient(M::AbstractManifold = DefaultManifold(2))</code></pre><p>Construct the Heestens Stiefel coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L378-L405">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.LiuStoreyCoefficient" href="#Manopt.LiuStoreyCoefficient"><code>Manopt.LiuStoreyCoefficient</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LiuStoreyCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#LiuStorey:1991">Lui, Storey, J. Optim. Theoru Appl., 1991</a> adapted to manifolds:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(â‹…)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the coefficient reads</p><p class="math-container">\[Î²_k = -
\frac{ \langle X_{k+1},\nu_k \rangle_{p_{k+1}} }
{\langle \delta_k,X_k \rangle_{p_k}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function LiuStoreyCoefficient(t::AbstractVectorTransportMethod)
function LiuStoreyCoefficient(M::AbstractManifold = DefaultManifold(2))</code></pre><p>Construct the Lui Storey coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L445-L473">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.PolakRibiereCoefficient" href="#Manopt.PolakRibiereCoefficient"><code>Manopt.PolakRibiereCoefficient</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PolakRibiereCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code> include the last iterates <span>$p_k,X_k$</span>, the current iterates <span>$p_{k+1},X_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <a href="../../references/#PolakRibiere:1969">Poliak, Ribiere, ESIAM Math. Modelling Num. Anal., 1969</a> and <a href="../../references/#Polyak:1969">Polyak, USSR Comp. Math. Math. Phys., 1969</a> adapted to manifolds:</p><p>Let <span>$\nu_k = X_{k+1} - P_{p_{k+1}\gets p_k}X_k$</span>, where <span>$P_{a\gets b}(â‹…)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the update reads</p><p class="math-container">\[Î²_k =
\frac{ \langle X_{k+1}, \nu_k \rangle_{p_{k+1}} }
{\lVert X_k \rVert_{p_k}^2 }.\]</p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">function PolakRibiereCoefficient(
    M::AbstractManifold=DefaultManifold(2);
    t::AbstractVectorTransportMethod=default_vector_transport_method(M)
)</code></pre><p>Construct the PolakRibiere coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L509-L540">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.SteepestDirectionUpdateRule" href="#Manopt.SteepestDirectionUpdateRule"><code>Manopt.SteepestDirectionUpdateRule</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SteepestDirectionUpdateRule &lt;: DirectionUpdateRule</code></pre><p>The simplest rule to update is to have no influence of the last direction and hence return an update <span>$Î² = 0$</span> for all <a href="#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a><code>cgds</code></p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/86a2866c57383a28f4ba159586145efa7567e565/src/plans/conjugate_gradient_plan.jl#L575-L582">source</a></section></article><h2 id="sec-cgd-technical-details"><a class="docs-heading-anchor" href="#sec-cgd-technical-details">Technical details</a><a id="sec-cgd-technical-details-1"></a><a class="docs-heading-anchor-permalink" href="#sec-cgd-technical-details" title="Permalink"></a></h2><p>The <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a> solver requires the following functions of a manifold to be available</p><ul><li>A <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/retractions/"><code>retract!</code></a><code>(M, q, p, X)</code>; it is recommended to set the <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/retractions/#ManifoldsBase.default_retraction_method-Tuple{AbstractManifold}"><code>default_retraction_method</code></a> to a favourite retraction. If this default is set, a <code>retraction_method=</code> does not have to be specified.</li><li>A <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/vector_transports/"><code>vector_transport_to!</code></a><code>M, Y, p, X, q)</code>; it is recommended to set the <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/vector_transports/#ManifoldsBase.default_vector_transport_method-Tuple{AbstractManifold}"><code>default_vector_transport_method</code></a> to a favourite retraction. If this default is set, a <code>vector_transport_method=</code> or <code>vector_transport_method_dual=</code> (for <span>$\mathcal N$</span>) does not have to be specified.</li><li>By default gradient descent uses <a href="../../plans/stepsize/#Manopt.ArmijoLinesearch"><code>ArmijoLinesearch</code></a> which requires <a href="../../extensions/#Manopt.max_stepsize-Tuple{FiberBundle{ğ”½, ManifoldsBase.TangentSpaceType, M} where {ğ”½, M&lt;:AbstractManifold{ğ”½}}, Any}"><code>max_stepsize</code></a><code>(M)</code> to be set and an implementation of <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/functions/#ManifoldsBase.inner-Tuple%7BAbstractManifold,%20Any,%20Any,%20Any%7D"><code>inner</code></a><code>(M, p, X)</code>.</li><li>By default the stopping criterion uses the <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/functions/#LinearAlgebra.norm-Tuple{AbstractManifold,%20Any,%20Any}"><code>norm</code></a> as well, to stop when the norm of the gradient is small, but if you implemented <code>inner</code>, the norm is provided already.</li><li>By default the tangent vector storing the gradient is initialized calling <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/functions/#ManifoldsBase.zero_vector-Tuple{AbstractManifold,%20Any}"><code>zero_vector</code></a><code>(M,p)</code>.</li></ul><h1 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h1><div class="citation noncanonical"><dl><dt>[Bea72]</dt><dd><div>E.Â M.Â Beale. <em>A derivation of conjugate gradients</em>. In: <em>Numerical methods for nonlinear optimization</em>, edited by F.Â A.Â Lootsma (Academic Press, London, London, 1972); pp.Â 39â€“43.</div></dd><dt>[DY99]</dt><dd><div>Y.Â H.Â Dai and Y.Â Yuan. <em>A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property</em>. <a href="https://doi.org/10.1137/s1052623497318992">SIAMÂ JournalÂ onÂ Optimization <strong>10</strong>, 177â€“182</a> (1999).</div></dd><dt>[Fle87]</dt><dd><div>R.Â Fletcher. <em>Practical Methods of Optimization</em>. 2Â Edition, <em>A Wiley-Interscience Publication</em> (John Wiley &amp; Sons Ltd., 1987).</div></dd><dt>[FR64]</dt><dd><div>R.Â Fletcher and C.Â M.Â Reeves. <em>Function minimization by conjugate gradients</em>. <a href="https://doi.org/10.1093/comjnl/7.2.149">TheÂ ComputerÂ Journal <strong>7</strong>, 149â€“154</a> (1964).</div></dd><dt>[HZ06]</dt><dd><div>W.Â W.Â Hager and H.Â Zhang. <a href="http://www.yokohamapublishers.jp/online2/pjov2-1.html"><em>A survey of nonlinear conjugate gradient methods</em></a>. PacificÂ JournalÂ ofÂ Optimization <strong>2</strong>, 35â€“58 (2006).</div></dd><dt>[HZ05]</dt><dd><div>W.Â W.Â Hager and H.Â Zhang. <em>A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search</em>. <a href="https://doi.org/10.1137/030601880">SIAMÂ JournalÂ onÂ Optimization <strong>16</strong>, 170â€“192</a> (2005).</div></dd><dt>[HS52]</dt><dd><div>M.Â Hestenes and E.Â Stiefel. <em>Methods of conjugate gradients for solving linear systems</em>. <a href="https://doi.org/10.6028/jres.049.044">JournalÂ ofÂ ResearchÂ ofÂ theÂ NationalÂ BureauÂ ofÂ Standards <strong>49</strong>, 409</a> (1952).</div></dd><dt>[LS91]</dt><dd><div>Y.Â Liu and C.Â Storey. <em>Efficient generalized conjugate gradient algorithms,  part 1: Theory</em>. <a href="https://doi.org/10.1007/bf00940464">JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications <strong>69</strong>, 129â€“137</a> (1991).</div></dd><dt>[PR69]</dt><dd><div>E.Â Polak and G.Â RibiÃ¨re. <em>Note sur la convergence de mÃ©thodes de directions conjuguÃ©es</em>. <a href="https://doi.org/10.1051/m2an/196903r100351">RevueÂ franÃ§aiseÂ dâ€™informatiqueÂ etÂ deÂ rechercheÂ opÃ©rationnelle <strong>3</strong>, 35â€“43</a> (1969).</div></dd><dt>[Pol69]</dt><dd><div>B.Â T.Â Polyak. <em>The conjugate gradient method in extremal problems</em>. <a href="https://doi.org/10.1016/0041-5553(69)90035-4">USSRÂ ComputationalÂ MathematicsÂ andÂ MathematicalÂ Physics <strong>9</strong>, 94â€“112</a> (1969).</div></dd><dt>[Pow77]</dt><dd><div>M.Â J.Â Powell. <em>Restart procedures for the conjugate gradient method</em>. <a href="https://doi.org/10.1007/bf01593790">MathematicalÂ Programming <strong>12</strong>, 241â€“254</a> (1977).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ChambollePock/">Â« Chambolle-Pock</a><a class="docs-footer-nextpage" href="../cyclic_proximal_point/">Cyclic Proximal Point Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Tuesday 16 January 2024 09:50">Tuesday 16 January 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
