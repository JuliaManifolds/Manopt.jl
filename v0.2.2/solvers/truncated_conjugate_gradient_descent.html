<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Steihaug-Toint TCG Method · Manopt.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img src="../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Manopt.jl</span></div><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><a class="tocitem" href="../about.html">About</a></li><li><a class="tocitem" href="../plans/index.html">Plans</a></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="index.html">Introduction</a></li><li><a class="tocitem" href="conjugate_gradient_descent.html">Conjugate gradient descent</a></li><li><a class="tocitem" href="cyclic_proximal_point.html">Cyclic Proximal Point</a></li><li><a class="tocitem" href="DouglasRachford.html">Douglas–Rachford</a></li><li><a class="tocitem" href="gradientDescent.html">Gradient Descent</a></li><li><a class="tocitem" href="NelderMead.html">Nelder–Mead</a></li><li><a class="tocitem" href="subgradient.html">Subgradient method</a></li><li class="is-active"><a class="tocitem" href="truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a><ul class="internal"><li><a class="tocitem" href="#Initialization-1"><span>Initialization</span></a></li><li><a class="tocitem" href="#Iteration-1"><span>Iteration</span></a></li><li><a class="tocitem" href="#Result-1"><span>Result</span></a></li><li><a class="tocitem" href="#Remarks-1"><span>Remarks</span></a></li><li><a class="tocitem" href="#Interface-1"><span>Interface</span></a></li><li><a class="tocitem" href="#Options-1"><span>Options</span></a></li><li><a class="tocitem" href="#Additional-Stopping-Criteria-1"><span>Additional Stopping Criteria</span></a></li></ul></li><li><a class="tocitem" href="trust_regions.html">Riemannian Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../functions/index.html">Introduction</a></li><li><a class="tocitem" href="../functions/costFunctions.html">cost functions</a></li><li><a class="tocitem" href="../functions/differentials.html">Differentials</a></li><li><a class="tocitem" href="../functions/adjointDifferentials.html">Adjoint Differentials</a></li><li><a class="tocitem" href="../functions/gradients.html">Gradients</a></li><li><a class="tocitem" href="../functions/jacobiFields.html">JacobiFields</a></li><li><a class="tocitem" href="../functions/proximalMaps.html">Proximal Maps</a></li><li><a class="tocitem" href="../functions/manifold.html">Specific manifold functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../helpers/data.html">Data</a></li><li><a class="tocitem" href="../helpers/errorMeasures.html">Error Measures</a></li><li><a class="tocitem" href="../helpers/exports.html">Exports</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/MeanAndMedian.html">Getting Started: Optimize!</a></li><li><a class="tocitem" href="../tutorials/GradientOfSecondOrderDifference.html">Gradient of <span>$d_2$</span></a></li><li><a class="tocitem" href="../tutorials/JacobiFields.html">Jacobi Fields</a></li></ul></li><li><a class="tocitem" href="../list.html">Function Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href="truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/solvers/truncated_conjugate_gradient_descent.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="tCG-1"><a class="docs-heading-anchor" href="#tCG-1">Steihaug-Toint Truncated Conjugate-Gradient Method</a><a class="docs-heading-anchor-permalink" href="#tCG-1" title="Permalink"></a></h1><p>The aim is to solve the trust-region subproblem</p><div>\[\operatorname*{arg\,min}_{\eta  ∈  T_{x}\mathcal{M}} m_{x}(\eta) = F(x) +
\langle \nabla F(x), \eta \rangle_{x} + \frac{1}{2} \langle
\operatorname{Hess}[F](\eta)_ {x}, \eta \rangle_{x}\]</div><div>\[\text{s.t.} \; \langle \eta, \eta \rangle_{x} \leq {\Delta}^2\]</div><p>on a manifold by using the Steihaug-Toint truncated conjugate-gradient method. All terms involving the trust-region radius use an inner product w.r.t. the preconditioner; this is because the iterates grow in length w.r.t. the preconditioner, guaranteeing that we do not re-enter the trust-region.</p><h2 id="Initialization-1"><a class="docs-heading-anchor" href="#Initialization-1">Initialization</a><a class="docs-heading-anchor-permalink" href="#Initialization-1" title="Permalink"></a></h2><p>Initialize <span>$\eta_0 = \eta$</span> if using randomized approach and <span>$\eta$</span> the zero tangent vector otherwise, <span>$r_0 = \nabla F(x)$</span>, <span>$z_0 = \operatorname{P}(r_0)$</span>, <span>$\delta_0 = z_0$</span> and <span>$k=0$</span></p><h2 id="Iteration-1"><a class="docs-heading-anchor" href="#Iteration-1">Iteration</a><a class="docs-heading-anchor-permalink" href="#Iteration-1" title="Permalink"></a></h2><p>Repeat until a convergence criterion is reached</p><ol><li>Set <span>$\kappa = \langle \delta_k, \operatorname{Hess}[F] (\delta_k)_ {x} \rangle_{x}$</span>,  <span>$\alpha =\frac{\langle r_k, z_k \rangle_{x}}{\kappa}$</span> and  <span>$\langle \eta_k, \eta_k \rangle_{x}^{* } = \langle \eta_k, \operatorname{P}(\eta_k) \rangle_{x} +  2\alpha \langle \eta_k, \operatorname{P}(\delta_k) \rangle_{x} +  {\alpha}^2  \langle \delta_k, \operatorname{P}(\delta_k) \rangle_{x}$</span>.</li><li>If <span>$\kappa \leqq 0$</span> or <span>$\langle \eta_k, \eta_k \rangle_{x}^{* } \geqq {\Delta}^2$</span>  return <span>$\eta_{k+1} = \eta_k + \tau \delta_k$</span> and stop.</li><li>Set <span>$\eta_{k}^{* }= \eta_k + \alpha \delta_k$</span>, if  <span>$\langle \eta_k, \eta_k \rangle_{x} + \frac{1}{2} \langle \eta_k,  \operatorname{Hess}[F] (\eta_k)_ {x} \rangle_{x} \leqq \langle \eta_k^{* },  \eta_k^{* } \rangle_{x} + \frac{1}{2} \langle \eta_k^{* },  \operatorname{Hess}[F] (\eta_k)_ {x} \rangle_{x}$</span>  set <span>$\eta_{k+1} = \eta_k$</span> else set <span>$\eta_{k+1} = \eta_{k}^{* }$</span>.</li><li>Set <span>$r_{k+1} = r_k + \alpha \operatorname{Hess}[F] (\delta_k)_ {x}$</span>,   <span>$z_{k+1} = \operatorname{P}(r_{k+1})$</span>,  <span>$\beta = \frac{\langle r_{k+1},  z_{k+1} \rangle_{x}}{\langle r_k, z_k  \rangle_{x}}$</span> and <span>$\delta_{k+1} = -z_{k+1} + \beta \delta_k$</span>.</li><li>Set <span>$k=k+1$</span>.</li></ol><h2 id="Result-1"><a class="docs-heading-anchor" href="#Result-1">Result</a><a class="docs-heading-anchor-permalink" href="#Result-1" title="Permalink"></a></h2><p>The result is given by the last computed <span>$η_k$</span>.</p><h2 id="Remarks-1"><a class="docs-heading-anchor" href="#Remarks-1">Remarks</a><a class="docs-heading-anchor-permalink" href="#Remarks-1" title="Permalink"></a></h2><p>The <span>$\operatorname{P}(\cdot)$</span> denotes the symmetric, positive deﬁnite preconditioner. It is required if a randomized approach is used i.e. using a random tangent vector <span>$\eta$</span> as initial vector. The idea behind it is to avoid saddle points. Preconditioning is simply a rescaling of the variables and thus a redeﬁnition of the shape of the trust region. Ideally <span>$\operatorname{P}(\cdot)$</span> is a cheap, positive approximation of the inverse of the Hessian of <span>$F$</span> at <span>$x$</span>. On default, the preconditioner is just the identity.</p><p>To step number 2: Obtain <span>$\tau$</span> from the positive root of <span>$\left\lVert \eta_k + \tau \delta_k \right\rVert_{\operatorname{P}, x} = \Delta$</span> what becomes after the conversion of the equation to</p><div>\[ \tau = \frac{-\langle \eta_k, \operatorname{P}(\delta_k) \rangle_{x} +
 \sqrt{\langle \eta_k, \operatorname{P}(\delta_k) \rangle_{x}^{2} +
 \langle \delta_k, \operatorname{P}(\delta_k) \rangle_{x} ( \Delta^2 -
 \langle \eta_k, \operatorname{P}(\eta_k) \rangle_{x})}}
 {\langle \delta_k, \operatorname{P}(\delta_k) \rangle_{x}}.\]</div><p>It can occur that <span>$\langle \delta_k, \operatorname{Hess}[F] (\delta_k)_ {x} \rangle_{x} = \kappa \leqq 0$</span> at iteration <span>$k$</span>. In this case, the model is not strictly convex, and the stepsize <span>$\alpha =\frac{\langle r_k, z_k \rangle_{x}} {\kappa}$</span> computed in step 1. does not give a reduction in the modelfunction <span>$m_{x}(\cdot)$</span>. Indeed, <span>$m_{x}(\cdot)$</span> is unbounded from below along the line <span>$\eta_k + \alpha \delta_k$</span>. If our aim is to minimize the model within the trust-region, it makes far more sense to reduce <span>$m_{x}(\cdot)$</span> along <span>$\eta_k + \alpha \delta_k$</span> as much as we can while staying within the trust-region, and this means moving to the trust-region boundary along this line. Thus when <span>$\kappa \leqq 0$</span> at iteration k, we replace <span>$\alpha = \frac{\langle r_k, z_k \rangle_{x}}{\kappa}$</span> with <span>$\tau$</span> described as above. The other possibility is that <span>$\eta_{k+1}$</span> would lie outside the trust-region at iteration k (i.e. <span>$\langle \eta_k, \eta_k \rangle_{x}^{* } \geqq {\Delta}^2$</span> what can be identified with the norm of <span>$\eta_{k+1}$</span>). In particular, when <span>$\operatorname{Hess}[F] (\cdot)_ {x}$</span> is positive deﬁnite and <span>$\eta_{k+1}$</span> lies outside the trust region, the solution to the trust-region problem must lie on the trust-region boundary. Thus, there is no reason to continue with the conjugate gradient iteration, as it stands, as subsequent iterates will move further outside the trust-region boundary. A sensible strategy, just as in the case considered above, is to move to the trust-region boundary by ﬁnding <span>$\tau$</span>.</p><h2 id="Interface-1"><a class="docs-heading-anchor" href="#Interface-1">Interface</a><a class="docs-heading-anchor-permalink" href="#Interface-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Manopt.truncated_conjugate_gradient_descent" href="#Manopt.truncated_conjugate_gradient_descent"><code>Manopt.truncated_conjugate_gradient_descent</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">truncated_conjugate_gradient_descent(M, F, ∇F, x, η, H, Δ)</code></pre><p>solve the trust-region subproblem</p><div>\[\operatorname*{arg\,min}_{\eta  ∈  T_{x}M} m_{x}(\eta) = F(x) + \langle \nabla F(x), \eta \rangle_{x} + \frac{1}{2} \langle \operatorname{Hess}[F](\eta)_ {x}, \eta \rangle_{x}\]</div><div>\[\text{s.t.} \; \langle \eta, \eta \rangle_{x} \leqq {\Delta}^2\]</div><p>with the Steihaug-Toint truncated conjugate-gradient method. For a description of the algorithm and theorems offering convergence guarantees, see the reference:</p><ul><li>P.-A. Absil, C.G. Baker, K.A. Gallivan,   Trust-region methods on Riemannian manifolds, FoCM, 2007.   doi: <a href="https://doi.org/10.1007/s10208-005-0179-9">10.1007/s10208-005-0179-9</a></li><li>A. R. Conn, N. I. M. Gould, P. L. Toint, Trust-region methods, SIAM,   MPS, 2000. doi: <a href="https://doi.org/10.1137/1.9780898719857">10.1137/1.9780898719857</a></li></ul><p><strong>Input</strong></p><ul><li><code>M</code> – a manifold <span>$\mathcal M$</span></li><li><code>F</code> – a cost function <span>$F\colon\mathcal M\to\mathbb R$</span> to minimize</li><li><code>∇F</code> – the gradient <span>$\nabla F\colon\mathcal M\to T\mathcal M$</span> of F</li><li><code>x</code> – a point on the manifold <span>$x ∈ \mathcal M$</span></li><li><code>η</code> – an update tangential vector <span>$\eta ∈ \mathcal{T_{x}M}$</span></li><li><code>H</code> – the hessian <span>$H( \mathcal M, x, \xi)$</span> of F</li><li><code>Δ</code> – a trust-region radius</li></ul><p><strong>Optional</strong></p><ul><li><code>preconditioner</code> – a preconditioner for the hessian H</li><li><code>θ</code> – 1+θ is the superlinear convergence target rate. The algorithm will   terminate early if the residual was reduced by a power of 1+theta.</li><li><code>κ</code> – the linear convergence target rate: algorithm will terminate   early if the residual was reduced by a factor of kappa.</li><li><code>useRandom</code> – set to true if the trust-region solve is to be initiated with a   random tangent vector. If set to true, no preconditioner will be   used. This option is set to true in some scenarios to escape saddle   points, but is otherwise seldom activated.</li><li><code>stopping_criterion</code> – (<a href="index.html#Manopt.StopWhenAny"><code>StopWhenAny</code></a>, <a href="index.html#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a>,   <a href="truncated_conjugate_gradient_descent.html#Manopt.stopIfResidualIsReducedByFactor"><code>stopIfResidualIsReducedByFactor</code></a>, <a href="truncated_conjugate_gradient_descent.html#Manopt.stopIfResidualIsReducedByPower"><code>stopIfResidualIsReducedByPower</code></a>,   <a href="truncated_conjugate_gradient_descent.html#Manopt.StopWhenCurvatureIsNegative"><code>StopWhenCurvatureIsNegative</code></a>, <a href="truncated_conjugate_gradient_descent.html#Manopt.StopWhenTrustRegionIsExceeded"><code>StopWhenTrustRegionIsExceeded</code></a> )   a functor inheriting from <a href="index.html#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a> indicating when to stop,   where for the default, the maximal number of iterations is set to the dimension of the   manifold, the power factor is <code>θ</code>, the reduction factor is <code>κ</code>.   .</li><li><code>return_options</code> – (<code>false</code>) – if actiavated, the extended result, i.e. the   complete <a href="../plans/index.html#Manopt.Options"><code>Options</code></a> re returned. This can be used to access recorded values.   If set to false (default) just the optimal value <code>xOpt</code> is returned</li></ul><p>and the ones that are passed to <a href="../plans/index.html#Manopt.decorate_options"><code>decorate_options</code></a> for decorators.</p><p><strong>Output</strong></p><ul><li><code>η</code> – an approximate solution of the trust-region subproblem in   <span>$\mathcal{T_{x}M}$</span>.</li></ul><p>OR</p><ul><li><code>options</code> - the options returned by the solver (see <code>return_options</code>)</li></ul><p><strong>see also</strong></p><p><a href="trust_regions.html#Manopt.trust_regions"><code>trust_regions</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/972df59576e429a554d4866666d5d752bdba2571/src/solvers/truncated_conjugate_gradient_descent.jl#L1-L63">source</a></section></article><h2 id="Options-1"><a class="docs-heading-anchor" href="#Options-1">Options</a><a class="docs-heading-anchor-permalink" href="#Options-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Manopt.TruncatedConjugateGradientOptions" href="#Manopt.TruncatedConjugateGradientOptions"><code>Manopt.TruncatedConjugateGradientOptions</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TruncatedConjugateGradientOptions &lt;: HessianOptions</code></pre><p>describe the Steihaug-Toint truncated conjugate-gradient method, with</p><p><strong>Fields</strong></p><p>a default value is given in brackets if a parameter can be left out in initialization.</p><ul><li><code>x</code> : a point, where the trust-region subproblem needs   to be solved</li><li><code>stop</code> : a function s,r = @(o,iter,ξ,x,xnew) returning a stop   indicator and a reason based on an iteration number, the gradient and the   last and current iterates</li><li><code>η</code> : a tangent vector (called update vector), which solves the   trust-region subproblem after successful calculation by the algorithm</li><li><code>δ</code> : search direction</li><li><code>Δ</code> : the trust-region radius</li><li><code>residual</code> : the gradient</li><li><code>useRand</code> : indicates if the trust-region solve and so the algorithm is to be       initiated with a random tangent vector. If set to true, no       preconditioner will be used. This option is set to true in some       scenarios to escape saddle points, but is otherwise seldom activated.</li></ul><p><strong>Constructor</strong></p><pre><code class="language-none">TruncatedConjugateGradientOptions(x, stop, eta, delta, Delta, res, uR)</code></pre><p>construct a truncated conjugate-gradient Option with the fields as above.</p><p><strong>See also</strong></p><p><a href="truncated_conjugate_gradient_descent.html#Manopt.truncated_conjugate_gradient_descent"><code>truncated_conjugate_gradient_descent</code></a>, <a href="trust_regions.html#Manopt.trust_regions"><code>trust_regions</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/972df59576e429a554d4866666d5d752bdba2571/src/plans/hessianPlan.jl#L33-L64">source</a></section></article><h2 id="Additional-Stopping-Criteria-1"><a class="docs-heading-anchor" href="#Additional-Stopping-Criteria-1">Additional Stopping Criteria</a><a class="docs-heading-anchor-permalink" href="#Additional-Stopping-Criteria-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Manopt.stopIfResidualIsReducedByPower" href="#Manopt.stopIfResidualIsReducedByPower"><code>Manopt.stopIfResidualIsReducedByPower</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">stopIfResidualIsReducedByPower &lt;: StoppingCriterion</code></pre><p>A functor for testing if the norm of residual at the current iterate is reduced by a power of 1+θ compared to the norm of the initial residual, i.e. <span>$\Vert r_k \Vert_x \leqq  \Vert r_0 \Vert_{x}^{1+\theta}$</span>. In this case the algorithm reached superlinear convergence.</p><p><strong>Fields</strong></p><ul><li><code>θ</code> – part of the reduction power</li><li><code>initialResidualNorm</code> - stores the norm of the residual at the initial vector   <span>$\eta$</span> of the Steihaug-Toint tcg mehtod <a href="truncated_conjugate_gradient_descent.html#Manopt.truncated_conjugate_gradient_descent"><code>truncated_conjugate_gradient_descent</code></a></li><li><code>reason</code> – stores a reason of stopping if the stopping criterion has one be   reached, see <a href="index.html#Manopt.get_reason"><code>get_reason</code></a>.</li></ul><p><strong>Constructor</strong></p><pre><code class="language-none">stopIfResidualIsReducedByPower(iRN, θ)</code></pre><p>initialize the stopIfResidualIsReducedByFactor functor to indicate to stop after the norm of the current residual is lesser than the norm of the initial residual iRN to the power of 1+θ.</p><p><strong>See also</strong></p><p><a href="truncated_conjugate_gradient_descent.html#Manopt.truncated_conjugate_gradient_descent"><code>truncated_conjugate_gradient_descent</code></a>, <a href="trust_regions.html#Manopt.trust_regions"><code>trust_regions</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/972df59576e429a554d4866666d5d752bdba2571/src/plans/hessianPlan.jl#L256-L281">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.stopIfResidualIsReducedByFactor" href="#Manopt.stopIfResidualIsReducedByFactor"><code>Manopt.stopIfResidualIsReducedByFactor</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">stopIfResidualIsReducedByFactor &lt;: StoppingCriterion</code></pre><p>A functor for testing if the norm of residual at the current iterate is reduced by a factor compared to the norm of the initial residual, i.e. <span>$\Vert r_k \Vert_x \leqq \kappa \Vert r_0 \Vert_x$</span>. In this case the algorithm reached linear convergence.</p><p><strong>Fields</strong></p><ul><li><code>κ</code> – the reduction factor</li><li><code>initialResidualNorm</code> - stores the norm of the residual at the initial vector   <span>$\eta$</span> of the Steihaug-Toint tcg mehtod <a href="truncated_conjugate_gradient_descent.html#Manopt.truncated_conjugate_gradient_descent"><code>truncated_conjugate_gradient_descent</code></a></li><li><code>reason</code> – stores a reason of stopping if the stopping criterion has one be reached, see <a href="index.html#Manopt.get_reason"><code>get_reason</code></a>.</li></ul><p><strong>Constructor</strong></p><pre><code class="language-none">stopIfResidualIsReducedByFactor(iRN, κ)</code></pre><p>initialize the stopIfResidualIsReducedByFactor functor to indicate to stop after the norm of the current residual is lesser than the norm of the initial residual iRN times κ.</p><p><strong>See also</strong></p><p><a href="truncated_conjugate_gradient_descent.html#Manopt.truncated_conjugate_gradient_descent"><code>truncated_conjugate_gradient_descent</code></a>, <a href="trust_regions.html#Manopt.trust_regions"><code>trust_regions</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/972df59576e429a554d4866666d5d752bdba2571/src/plans/hessianPlan.jl#L216-L241">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.StopWhenTrustRegionIsExceeded" href="#Manopt.StopWhenTrustRegionIsExceeded"><code>Manopt.StopWhenTrustRegionIsExceeded</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">StopWhenTrustRegionIsExceeded &lt;: StoppingCriterion</code></pre><p>A functor for testing if the norm of the next iterate in the  Steihaug-Toint tcg mehtod is larger than the trust-region radius, i.e. <span>$\Vert η_{k}^{*} \Vert_x ≧ Δ$</span>. terminate the algorithm when the trust region has been left.</p><p><strong>Fields</strong></p><ul><li><code>reason</code> – stores a reason of stopping if the stopping criterion has one be   reached, see <a href="index.html#Manopt.get_reason"><code>get_reason</code></a>.</li><li><code>storage</code> – stores the necessary parameters <code>η, δ, residual</code> to check the   criterion.</li></ul><p><strong>Constructor</strong></p><pre><code class="language-none">StopWhenTrustRegionIsExceeded([a])</code></pre><p>initialize the StopWhenTrustRegionIsExceeded functor to indicate to stop after the norm of the next iterate is greater than the trust-region radius using the <a href="../plans/index.html#Manopt.StoreOptionsAction"><code>StoreOptionsAction</code></a> <code>a</code>, which is initialized to store <code>:η, :δ, :residual</code> by default.</p><p><strong>See also</strong></p><p><a href="truncated_conjugate_gradient_descent.html#Manopt.truncated_conjugate_gradient_descent"><code>truncated_conjugate_gradient_descent</code></a>, <a href="trust_regions.html#Manopt.trust_regions"><code>trust_regions</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/972df59576e429a554d4866666d5d752bdba2571/src/plans/hessianPlan.jl#L296-L320">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.StopWhenCurvatureIsNegative" href="#Manopt.StopWhenCurvatureIsNegative"><code>Manopt.StopWhenCurvatureIsNegative</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">StopWhenCurvatureIsNegative &lt;: StoppingCriterion</code></pre><p>A functor for testing if the curvature of the model is negative, i.e. <span>$\langle \delta_k, \operatorname{Hess}[F](\delta_k)\rangle_x \leqq 0$</span>. In this case, the model is not strictly convex, and the stepsize as computed does not give a reduction of the model.</p><p><strong>Fields</strong></p><ul><li><code>reason</code> – stores a reason of stopping if the stopping criterion has one be   reached, see <a href="index.html#Manopt.get_reason"><code>get_reason</code></a>.</li><li><code>storage</code> – stores the necessary parameter <code>δ</code> to check the   criterion.</li></ul><p><strong>Constructor</strong></p><pre><code class="language-none">StopWhenCurvatureIsNegative([a])</code></pre><p>initialize the StopWhenCurvatureIsNegative functor to indicate to stop after the inner product of the search direction and the hessian applied on the search dircetion is less than zero using the <a href="../plans/index.html#Manopt.StoreOptionsAction"><code>StoreOptionsAction</code></a> <code>a</code>, which is initialized to just store <code>:δ</code> by default.</p><p><strong>See also</strong></p><p><a href="truncated_conjugate_gradient_descent.html#Manopt.truncated_conjugate_gradient_descent"><code>truncated_conjugate_gradient_descent</code></a>, <a href="trust_regions.html#Manopt.trust_regions"><code>trust_regions</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/972df59576e429a554d4866666d5d752bdba2571/src/plans/hessianPlan.jl#L346-L371">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="subgradient.html">« Subgradient method</a><a class="docs-footer-nextpage" href="trust_regions.html">Riemannian Trust-Regions Solver »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 26 April 2020 14:07">Sunday 26 April 2020</span>. Using Julia version 1.4.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
