<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Adaptive Regularization with Cubics ¬∑ Manopt.jl</title><meta name="title" content="Adaptive Regularization with Cubics ¬∑ Manopt.jl"/><meta property="og:title" content="Adaptive Regularization with Cubics ¬∑ Manopt.jl"/><meta property="twitter:title" content="Adaptive Regularization with Cubics ¬∑ Manopt.jl"/><meta name="description" content="Documentation for Manopt.jl."/><meta property="og:description" content="Documentation for Manopt.jl."/><meta property="twitter:description" content="Documentation for Manopt.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Manopt.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../about/">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../../tutorials/Optimize/">üèîÔ∏è Get started: optimize.</a></li><li><a class="tocitem" href="../../tutorials/InplaceGradient/">Speedup using in-place computations</a></li><li><a class="tocitem" href="../../tutorials/AutomaticDifferentiation/">Use automatic differentiation</a></li><li><a class="tocitem" href="../../tutorials/EmbeddingObjectives/">Define objectives in the embedding</a></li><li><a class="tocitem" href="../../tutorials/CountAndCache/">Count and use a cache</a></li><li><a class="tocitem" href="../../tutorials/HowToDebug/">Print debug output</a></li><li><a class="tocitem" href="../../tutorials/HowToRecord/">Record values</a></li><li><a class="tocitem" href="../../tutorials/ImplementASolver/">Implement a solver</a></li><li><a class="tocitem" href="../../tutorials/ImplementOwnManifold/">Optimize on your own manifold</a></li><li><a class="tocitem" href="../../tutorials/ConstrainedOptimization/">Do constrained optimization</a></li><li><a class="tocitem" href="../../tutorials/GeodesicRegression/">Do geodesic regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../">Introduction</a></li><li class="is-active"><a class="tocitem" href>Adaptive Regularization with Cubics</a><ul class="internal"><li><a class="tocitem" href="#State"><span>State</span></a></li><li><a class="tocitem" href="#Sub-solvers"><span>Sub solvers</span></a></li><li><a class="tocitem" href="#Lanczos-iteration"><span>Lanczos iteration</span></a></li><li><a class="tocitem" href="#(Conjugate)-gradient-descent"><span>(Conjugate) gradient descent</span></a></li><li><a class="tocitem" href="#Additional-stopping-criteria"><span>Additional stopping criteria</span></a></li><li><a class="tocitem" href="#sec-arc-technical-details"><span>Technical details</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../alternating_gradient_descent/">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../augmented_Lagrangian_method/">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../ChambollePock/">Chambolle-Pock</a></li><li><a class="tocitem" href="../conjugate_gradient_descent/">Conjugate gradient descent</a></li><li><a class="tocitem" href="../convex_bundle_method/">Convex bundle method</a></li><li><a class="tocitem" href="../cyclic_proximal_point/">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../difference_of_convex/">Difference of Convex</a></li><li><a class="tocitem" href="../DouglasRachford/">Douglas‚ÄîRachford</a></li><li><a class="tocitem" href="../exact_penalty_method/">Exact Penalty Method</a></li><li><a class="tocitem" href="../FrankWolfe/">Frank-Wolfe</a></li><li><a class="tocitem" href="../gradient_descent/">Gradient Descent</a></li><li><a class="tocitem" href="../LevenbergMarquardt/">Levenberg‚ÄìMarquardt</a></li><li><a class="tocitem" href="../NelderMead/">Nelder‚ÄìMead</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../primal_dual_semismooth_Newton/">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../proximal_bundle_method/">Proximal bundle method</a></li><li><a class="tocitem" href="../quasi_Newton/">Quasi-Newton</a></li><li><a class="tocitem" href="../stochastic_gradient_descent/">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../subgradient/">Subgradient method</a></li><li><a class="tocitem" href="../truncated_conjugate_gradient_descent/">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../trust_regions/">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../../plans/">Specify a Solver</a></li><li><a class="tocitem" href="../../plans/problem/">Problem</a></li><li><a class="tocitem" href="../../plans/objective/">Objective</a></li><li><a class="tocitem" href="../../plans/state/">Solver State</a></li><li><a class="tocitem" href="../../plans/stepsize/">Stepsize</a></li><li><a class="tocitem" href="../../plans/stopping_criteria/">Stopping Criteria</a></li><li><a class="tocitem" href="../../plans/debug/">Debug Output</a></li><li><a class="tocitem" href="../../plans/record/">Recording values</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../../helpers/checks/">Checks</a></li><li><a class="tocitem" href="../../helpers/exports/">Exports</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../../extensions/">Extensions</a></li><li><a class="tocitem" href="../../notation/">Notation</a></li><li><a class="tocitem" href="../../changelog/">Changelog</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href>Adaptive Regularization with Cubics</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Adaptive Regularization with Cubics</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ÔÇõ</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/solvers/adaptive-regularization-with-cubics.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ÔÅÑ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Adaptive-regularization-with-cubics"><a class="docs-heading-anchor" href="#Adaptive-regularization-with-cubics">Adaptive regularization with cubics</a><a id="Adaptive-regularization-with-cubics-1"></a><a class="docs-heading-anchor-permalink" href="#Adaptive-regularization-with-cubics" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.adaptive_regularization_with_cubics" href="#Manopt.adaptive_regularization_with_cubics"><code>Manopt.adaptive_regularization_with_cubics</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">adaptive_regularization_with_cubics(M, f, grad_f, Hess_f, p=rand(M); kwargs...)
adaptive_regularization_with_cubics(M, f, grad_f, p=rand(M); kwargs...)
adaptive_regularization_with_cubics(M, mho, p=rand(M); kwargs...)</code></pre><p>Solve an optimization problem on the manifold <code>M</code> by iteratively minimizing</p><p class="math-container">\[  m_k(X) = f(p_k) + ‚ü®X, \operatorname{grad} f(p_k)‚ü© + \frac{1}{2}‚ü®X, \operatorname{Hess} f(p_k)[X]‚ü© + \frac{œÉ_k}{3}\lVert X \rVert^3\]</p><p>on the tangent space at the current iterate <span>$p_k$</span>, where <span>$X ‚àà T_{p_k}\mathcal M$</span> and <span>$œÉ_k &gt; 0$</span> is a regularization parameter.</p><p>Let <span>$X_k$</span> denote the minimizer of the model <span>$m_k$</span> and use the model improvement</p><p class="math-container">\[  œÅ_k = \frac{f(p_k) - f(\operatorname{retr}_{p_k}(X_k))}{m_k(0) - m_k(X_k) + \frac{œÉ_k}{3}\lVert X_k\rVert^3}.\]</p><p>With two thresholds <span>$Œ∑_2 ‚â• Œ∑_1 &gt; 0$</span> set <span>$p_{k+1} = \operatorname{retr}_{p_k}(X_k)$</span> if <span>$œÅ ‚â• Œ∑_1$</span> and reject the candidate otherwise, that is, set <span>$p_{k+1} = p_k$</span>.</p><p>Further update the regularization parameter using factors <span>$0 &lt; Œ≥_1 &lt; 1 &lt; Œ≥_2$</span></p><p class="math-container">\[œÉ_{k+1} =
\begin{cases}
    \max\{œÉ_{\min}, Œ≥_1œÉ_k\} &amp; \text{ if } œÅ \geq Œ∑_2 &amp;\text{   (the model was very successful)},\\
    œÉ_k &amp; \text{ if } œÅ ‚àà [Œ∑_1, Œ∑_2)&amp;\text{   (the model was successful)},\\
    Œ≥_2œÉ_k &amp; \text{ if } œÅ &lt; Œ∑_1&amp;\text{   (the model was unsuccessful)}.
\end{cases}\]</p><p>For more details see [<a href="../../references/#AgarwalBoumalBullinsCartis:2020">ABBC20</a>].</p><p><strong>Input</strong></p><ul><li><code>M</code>:      a manifold <span>$\mathcal M$</span></li><li><code>f</code>:      a cost function <span>$F: \mathcal M ‚Üí ‚Ñù$</span> to minimize</li><li><code>grad_f</code>: the gradient <span>$\operatorname{grad}F: \mathcal M ‚Üí T \mathcal M$</span> of <span>$F$</span></li><li><code>Hess_f</code>: (optional) the Hessian <span>$H( \mathcal M, x, Œæ)$</span> of <span>$F$</span></li><li><code>p</code>:      an initial value <span>$p ‚àà \mathcal M$</span></li></ul><p>For the case that no Hessian is provided, the Hessian is computed using finite difference, see <a href="../trust_regions/#Manopt.ApproxHessianFiniteDifference"><code>ApproxHessianFiniteDifference</code></a>.</p><p>the cost <code>f</code> and its gradient and Hessian might also be provided as a <a href="../../plans/objective/#Manopt.ManifoldHessianObjective"><code>ManifoldHessianObjective</code></a></p><p><strong>Keyword arguments</strong></p><p>the default values are given in brackets</p><ul><li><code>œÉ</code>:                      (<code>100.0 / sqrt(manifold_dimension(M)</code>) initial regularization parameter</li><li><code>œÉmin</code>:                   (<code>1e-10</code>) minimal regularization value <span>$œÉ_{\min}$</span></li><li><code>Œ∑1</code>:                     (<code>0.1</code>) lower model success threshold</li><li><code>Œ∑2</code>:                     (<code>0.9</code>) upper model success threshold</li><li><code>Œ≥1</code>:                     (<code>0.1</code>) regularization reduction factor (for the success case)</li><li><code>Œ≥2</code>:                     (<code>2.0</code>) regularization increment factor (for the non-success case)</li><li><code>evaluation</code>:             (<a href="../../plans/objective/#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>) specify whether the gradient works by allocation (default) form <code>grad_f(M, p)</code> or <a href="../../plans/objective/#Manopt.InplaceEvaluation"><code>InplaceEvaluation</code></a> in place, that is of the form <code>grad_f!(M, X, p)</code> and analogously for the Hessian.</li><li><code>retraction_method</code>:      (<code>default_retraction_method(M, typeof(p))</code>) a retraction to use</li><li><code>initial_tangent_vector</code>: (<code>zero_vector(M, p)</code>) initialize any tangent vector data,</li><li><code>maxIterLanczos</code>:         (<code>200</code>) a shortcut to set the stopping criterion in the sub solver,</li><li><code>œÅ_regularization</code>:       (<code>1e3</code>) a regularization to avoid dividing by zero for small values of cost and model</li><li><code>stopping_criterion</code>:     (<a href="../../plans/stopping_criteria/#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(40) |</code><a href="../../plans/stopping_criteria/#Manopt.StopWhenGradientNormLess"><code>StopWhenGradientNormLess</code></a><code>(1e-9) |</code><a href="#Manopt.StopWhenAllLanczosVectorsUsed"><code>StopWhenAllLanczosVectorsUsed</code></a><code>(maxIterLanczos)</code>)</li><li><code>sub_state</code>:              <a href="#Manopt.LanczosState"><code>LanczosState</code></a><code>(M, copy(M, p); maxIterLanczos=maxIterLanczos, œÉ=œÉ) a state for the subproblem or an [</code>AbstractEvaluationType`](@ref) if the problem is a function.</li><li><code>sub_objective</code>:          a shortcut to modify the objective of the subproblem used within in the</li><li><code>sub_problem</code>:            <a href="../../plans/problem/#Manopt.DefaultManoptProblem"><code>DefaultManoptProblem</code></a><code>(M, sub_objective)</code> the problem (or a function) for the sub problem</li></ul><p>All other keyword arguments are passed to <a href="../../plans/state/#Manopt.decorate_state!"><code>decorate_state!</code></a> for state decorators or <a href="../../plans/objective/#Manopt.decorate_objective!"><code>decorate_objective!</code></a> for objective, respectively. If you provide the <a href="../../plans/objective/#Manopt.ManifoldGradientObjective"><code>ManifoldGradientObjective</code></a> directly, these decorations can still be specified</p><p>By default the <code>debug=</code> keyword is set to <a href="../../plans/debug/#Manopt.DebugIfEntry"><code>DebugIfEntry</code></a><code>(:œÅ_denominator, &gt;(0); message=&quot;Denominator nonpositive&quot;, type=:error)</code> to avoid that by rounding errors the denominator in the computation of <code>œÅ</code> gets nonpositive.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/9b34085169e8586fe59b12f02b7e2babfbb98667/src/solvers/adaptive_regularization_with_cubics.jl#L165-L243">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.adaptive_regularization_with_cubics!" href="#Manopt.adaptive_regularization_with_cubics!"><code>Manopt.adaptive_regularization_with_cubics!</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">adaptive_regularization_with_cubics!(M, f, grad_f, Hess_f, p; kwargs...)
adaptive_regularization_with_cubics!(M, f, grad_f, p; kwargs...)
adaptive_regularization_with_cubics!(M, mho, p; kwargs...)</code></pre><p>evaluate the Riemannian adaptive regularization with cubics solver in place of <code>p</code>.</p><p><strong>Input</strong></p><ul><li><code>M</code>:      a manifold <span>$\mathcal M$</span></li><li><code>f</code>:      a cost function <span>$F: \mathcal M ‚Üí ‚Ñù$</span> to minimize</li><li><code>grad_f</code>: the gradient <span>$\operatorname{grad}F: \mathcal M ‚Üí T \mathcal M$</span> of <span>$F$</span></li><li><code>Hess_f</code>: (optional) the Hessian <span>$H( \mathcal M, x, Œæ)$</span> of <span>$F$</span></li><li><code>p</code>:      an initial value <span>$p  ‚àà  \mathcal M$</span></li></ul><p>For the case that no Hessian is provided, the Hessian is computed using finite difference, see <a href="../trust_regions/#Manopt.ApproxHessianFiniteDifference"><code>ApproxHessianFiniteDifference</code></a>.</p><p>the cost <code>f</code> and its gradient and Hessian might also be provided as a <a href="../../plans/objective/#Manopt.ManifoldHessianObjective"><code>ManifoldHessianObjective</code></a></p><p>for more details and all options, see <a href="#Manopt.adaptive_regularization_with_cubics"><code>adaptive_regularization_with_cubics</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/9b34085169e8586fe59b12f02b7e2babfbb98667/src/solvers/adaptive_regularization_with_cubics.jl#L320-L340">source</a></section></article><h2 id="State"><a class="docs-heading-anchor" href="#State">State</a><a id="State-1"></a><a class="docs-heading-anchor-permalink" href="#State" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.AdaptiveRegularizationState" href="#Manopt.AdaptiveRegularizationState"><code>Manopt.AdaptiveRegularizationState</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AdaptiveRegularizationState{P,T} &lt;: AbstractHessianSolverState</code></pre><p>A state for the <a href="#Manopt.adaptive_regularization_with_cubics"><code>adaptive_regularization_with_cubics</code></a> solver.</p><p><strong>Fields</strong></p><p>a default value is given in brackets if a parameter can be left out in initialization.</p><ul><li><code>Œ∑1</code>, <code>Œ∑2</code>:           (<code>0.1</code>, <code>0.9</code>) bounds for evaluating the regularization parameter</li><li><code>Œ≥1</code>, <code>Œ≥2</code>:           (<code>0.1</code>, <code>2.0</code>) shrinking and expansion factors for regularization parameter <code>œÉ</code></li><li><code>p</code>:                  (<code>rand(M)</code> the current iterate</li><li><code>X</code>:                  (<code>zero_vector(M,p)</code>) the current gradient <span>$\operatorname{grad}f(p)$</span></li><li><code>s</code>:                  (<code>zero_vector(M,p)</code>) the tangent vector step resulting from minimizing the model problem in the tangent space <span>$\mathcal T_{p} \mathcal M$</span></li><li><code>œÉ</code>:                  the current cubic regularization parameter</li><li><code>œÉmin</code>:               (<code>1e-7</code>) lower bound for the cubic regularization parameter</li><li><code>œÅ_regularization</code>:   (<code>1e3</code>) regularization parameter for computing œÅ.</li></ul><p>When approaching convergence œÅ may be difficult to compute with numerator and denominator approaching zero.  Regularizing the ratio lets œÅ go to 1 near convergence.</p><ul><li><code>evaluation</code>:         (<code>AllocatingEvaluation()</code>) if you provide a</li><li><code>retraction_method</code>:  (<code>default_retraction_method(M)</code>) the retraction to use</li><li><code>stopping_criterion</code>: (<a href="../../plans/stopping_criteria/#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(100)</code>) a <a href="../../plans/stopping_criteria/#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a></li><li><code>sub_problem</code>:        sub problem solved in each iteration</li><li><code>sub_state</code>:          sub state for solving the sub problem, either a solver state if the problem is an <a href="../../plans/problem/#Manopt.AbstractManoptProblem"><code>AbstractManoptProblem</code></a> or an <a href="../../plans/objective/#Manopt.AbstractEvaluationType"><code>AbstractEvaluationType</code></a> if it is a function, where it defaults to <a href="../../plans/objective/#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>.</li></ul><p>Furthermore the following integral fields are defined</p><ul><li><code>q</code>:                  (<code>copy(M,p)</code>) a point for the candidates to evaluate model and œÅ</li><li><code>H</code>:                  (<code>copy(M, p, X)</code>) the current Hessian, <span>$\operatorname{Hess}F(p)[‚ãÖ]$</span></li><li><code>S</code>:                  (<code>copy(M, p, X)</code>) the current solution from the subsolver</li><li><code>œÅ</code>:                  the current regularized ratio of actual improvement and model improvement.</li><li><code>œÅ_denominator</code>:      (<code>one(œÅ)</code>) a value to store the denominator from the computation of œÅ to allow for a warning or error when this value is non-positive.</li></ul><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">AdaptiveRegularizationState(M, p=rand(M); X=zero_vector(M, p); kwargs...)</code></pre><p>Construct the solver state with all fields stated as keyword arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/9b34085169e8586fe59b12f02b7e2babfbb98667/src/solvers/adaptive_regularization_with_cubics.jl#L1-L42">source</a></section></article><h2 id="Sub-solvers"><a class="docs-heading-anchor" href="#Sub-solvers">Sub solvers</a><a id="Sub-solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Sub-solvers" title="Permalink"></a></h2><p>There are several ways to approach the subsolver. The default is the first one.</p><h2 id="Lanczos-iteration"><a class="docs-heading-anchor" href="#Lanczos-iteration">Lanczos iteration</a><a id="Lanczos-iteration-1"></a><a class="docs-heading-anchor-permalink" href="#Lanczos-iteration" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.LanczosState" href="#Manopt.LanczosState"><code>Manopt.LanczosState</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LanczosState{P,T,SC,B,I,R,TM,V,Y} &lt;: AbstractManoptSolverState</code></pre><p>Solve the adaptive regularized subproblem with a Lanczos iteration</p><p><strong>Fields</strong></p><ul><li><code>stop</code>:            the stopping criterion</li><li><code>œÉ</code>:               the current regularization parameter</li><li><code>X</code>:               the Iterate</li><li><code>Lanczos_vectors</code>: the obtained Lanczos vectors</li><li><code>tridig_matrix</code>:   the tridiagonal coefficient matrix T</li><li><code>coefficients</code>:    the coefficients <span>$y_1,...y_k$</span> that determine the solution</li><li><code>Hp</code>:              a temporary vector containing the evaluation of the Hessian</li><li><code>Hp_residual</code>:     a temporary vector containing the residual to the Hessian</li><li><code>S</code>:               the current obtained / approximated solution</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/9b34085169e8586fe59b12f02b7e2babfbb98667/src/solvers/Lanczos.jl#L5-L21">source</a></section></article><h2 id="(Conjugate)-gradient-descent"><a class="docs-heading-anchor" href="#(Conjugate)-gradient-descent">(Conjugate) gradient descent</a><a id="(Conjugate)-gradient-descent-1"></a><a class="docs-heading-anchor-permalink" href="#(Conjugate)-gradient-descent" title="Permalink"></a></h2><p>There is a generic objective, that implements the sub problem</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.AdaptiveRagularizationWithCubicsModelObjective" href="#Manopt.AdaptiveRagularizationWithCubicsModelObjective"><code>Manopt.AdaptiveRagularizationWithCubicsModelObjective</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AdaptiveRagularizationWithCubicsModelObjective</code></pre><p>A model for the adaptive regularization with Cubics</p><p class="math-container">\[m(X) = f(p) + ‚ü®\operatorname{grad} f(p), X ‚ü©_p + \frac{1}{2} ‚ü®\operatorname{Hess} f(p)[X], X‚ü©_p
       +  \frac{œÉ}{3} \lVert X \rVert^3,\]</p><p>cf. Eq. (33) in [<a href="../../references/#AgarwalBoumalBullinsCartis:2020">ABBC20</a>]</p><p><strong>Fields</strong></p><ul><li><code>objective</code>: an <a href="../../plans/objective/#Manopt.AbstractManifoldHessianObjective"><code>AbstractManifoldHessianObjective</code></a> proving <span>$f$</span>, its gradient and Hessian</li><li><code>œÉ</code>:         the current (cubic) regularization parameter</li></ul><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AdaptiveRagularizationWithCubicsModelObjective(mho, œÉ=1.0)</code></pre><p>with either an <a href="../../plans/objective/#Manopt.AbstractManifoldHessianObjective"><code>AbstractManifoldHessianObjective</code></a> <code>objective</code> or an decorator containing such an objective.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/9b34085169e8586fe59b12f02b7e2babfbb98667/src/plans/adabtive_regularization_with_cubics_plan.jl#L1-L23">source</a></section></article><p>Since the sub problem is given on the tangent space, you have to provide</p><pre><code class="nohighlight hljs">arc_obj = AdaptiveRagularizationWithCubicsModelObjective(mho, œÉ)
sub_problem = DefaultProblem(TangentSpaceAt(M,p), arc_obj)</code></pre><p>where <code>mho</code> is the Hessian objective of <code>f</code> to solve. Then use this for the <code>sub_problem</code> keyword and use your favourite gradient based solver for the <code>sub_state</code> keyword, for example a <a href="../conjugate_gradient_descent/#Manopt.ConjugateGradientDescentState"><code>ConjugateGradientDescentState</code></a></p><h2 id="Additional-stopping-criteria"><a class="docs-heading-anchor" href="#Additional-stopping-criteria">Additional stopping criteria</a><a id="Additional-stopping-criteria-1"></a><a class="docs-heading-anchor-permalink" href="#Additional-stopping-criteria" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.StopWhenAllLanczosVectorsUsed" href="#Manopt.StopWhenAllLanczosVectorsUsed"><code>Manopt.StopWhenAllLanczosVectorsUsed</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">StopWhenAllLanczosVectorsUsed &lt;: StoppingCriterion</code></pre><p>When an inner iteration has used up all Lanczos vectors, then this stopping criterion is a fallback / security stopping criterion to not access a non-existing field in the array allocated for vectors.</p><p>Note that this stopping criterion (for now) is only implemented for the case that an <a href="#Manopt.AdaptiveRegularizationState"><code>AdaptiveRegularizationState</code></a> when using a <a href="#Manopt.LanczosState"><code>LanczosState</code></a> subsolver</p><p><strong>Fields</strong></p><ul><li><code>maxLanczosVectors</code>: maximal number of Lanczos vectors</li><li><code>reason</code>:            a String indicating the reason if the criterion indicated to stop</li></ul><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">StopWhenAllLanczosVectorsUsed(maxLancosVectors::Int)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/9b34085169e8586fe59b12f02b7e2babfbb98667/src/solvers/Lanczos.jl#L303-L322">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Manopt.StopWhenFirstOrderProgress" href="#Manopt.StopWhenFirstOrderProgress"><code>Manopt.StopWhenFirstOrderProgress</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">StopWhenFirstOrderProgress &lt;: StoppingCriterion</code></pre><p>A stopping criterion related to the Riemannian adaptive regularization with cubics (ARC) solver indicating that the model function at the current (outer) iterate,</p><p class="math-container">\[    m(X) = f(p) + &lt;X, \operatorname{grad}f(p)&gt;
      + \frac{1}{2} &lt;X, \operatorname{Hess} f(p)[X]&gt; +  \frac{œÉ}{3} \lVert X \rVert^3,\]</p><p>defined on the tangent space <span>$T_{p}\mathcal M$</span> fulfills at the current iterate <span>$X_k$</span> that</p><p class="math-container">\[m(X_k) \leq m(0)
\quad\text{ and }\quad
\lVert \operatorname{grad} m(X_k) \rVert ‚â§ Œ∏ \lVert X_k \rVert^2\]</p><p><strong>Fields</strong></p><ul><li><code>Œ∏</code>:      the factor <span>$Œ∏$</span> in the second condition</li><li><code>reason</code>: a String indicating the reason if the criterion indicated to stop</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/9b34085169e8586fe59b12f02b7e2babfbb98667/src/solvers/Lanczos.jl#L225-L248">source</a></section></article><h2 id="sec-arc-technical-details"><a class="docs-heading-anchor" href="#sec-arc-technical-details">Technical details</a><a id="sec-arc-technical-details-1"></a><a class="docs-heading-anchor-permalink" href="#sec-arc-technical-details" title="Permalink"></a></h2><p>The <a href="#Manopt.adaptive_regularization_with_cubics"><code>adaptive_regularization_with_cubics</code></a> requires the following functions of a manifolds to be available</p><ul><li>A <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/retractions/"><code>retract!</code></a><code>(M, q, p, X)</code>; it is recommended to set the <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/retractions/#ManifoldsBase.default_retraction_method-Tuple%7BAbstractManifold%7D"><code>default_retraction_method</code></a> to a favourite retraction. If this default is set, a <code>retraction_method=</code> does not have to be specified.</li><li>if you do not provide an initial regularization parameter <code>œÉ</code>, a <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/functions/#ManifoldsBase.manifold_dimension-Tuple%7BAbstractManifold%7D"><code>manifold_dimension</code></a> is required.</li><li>By default the tangent vector storing the gradient is initialized calling <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/functions/#ManifoldsBase.zero_vector-Tuple%7BAbstractManifold%2C%20Any%7D"><code>zero_vector</code></a><code>(M,p)</code>.</li><li><a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/functions/#ManifoldsBase.inner-Tuple%7BAbstractManifold%2C%20Any%2C%20Any%2C%20Any%7D"><code>inner</code></a><code>(M, p, X, Y)</code> is used within the algorithm step</li></ul><p>Furthermore, within the Lanczos subsolver, generating a random vector (at <code>p</code>) using <a href="https://juliamanifolds.github.io/ManifoldsBase.jl/stable/functions/#Base.rand-Tuple%7BAbstractManifold%7D"><code>rand!</code></a>(M, X; vector_at=p)<code>in place of</code>X` is required</p><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[ABBC20]</dt><dd><div>N.¬†Agarwal, N.¬†Boumal, B.¬†Bullins and C.¬†Cartis. <em>Adaptive regularization with cubics on manifolds</em>. <a href="https://doi.org/10.1007/s10107-020-01505-1">Mathematical¬†Programming</a> (2020).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">¬´ Introduction</a><a class="docs-footer-nextpage" href="../alternating_gradient_descent/">Alternating Gradient Descent ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Friday 15 March 2024 21:32">Friday 15 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
