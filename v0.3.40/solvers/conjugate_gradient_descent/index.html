<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Conjugate gradient descent · Manopt.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Manopt.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../about/">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../../tutorials/Optimize!/">Get started: Optimize!</a></li><li><a class="tocitem" href="../../tutorials/AutomaticDifferentiation/">Use AD in Manopt</a></li><li><a class="tocitem" href="../../tutorials/HowToRecord/">Record values</a></li><li><a class="tocitem" href="../../tutorials/GeodesicRegression/">Do Geodesic regression</a></li><li><a class="tocitem" href="../../tutorials/Bezier/">Use Bezier Curves</a></li><li><a class="tocitem" href="../../tutorials/SecondOrderDifference/">Compute a second order difference</a></li><li><a class="tocitem" href="../../tutorials/StochasticGradientDescent/">Do stochastic gradient descent</a></li><li><a class="tocitem" href="../../tutorials/Benchmark/">speed up! using <code>gradF!</code></a></li><li><a class="tocitem" href="../../tutorials/JacobiFields/">Illustrate Jacobi Fields</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../alternating_gradient_descent/">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../ChambollePock/">Chambolle-Pock</a></li><li class="is-active"><a class="tocitem" href>Conjugate gradient descent</a><ul class="internal"><li><a class="tocitem" href="#Options"><span>Options</span></a></li><li><a class="tocitem" href="#cg-coeffs"><span>Available Coefficients</span></a></li><li class="toplevel"><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../cyclic_proximal_point/">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../DouglasRachford/">Douglas–Rachford</a></li><li><a class="tocitem" href="../FrankWolfe/">Frank-Wolfe</a></li><li><a class="tocitem" href="../gradient_descent/">Gradient Descent</a></li><li><a class="tocitem" href="../NelderMead/">Nelder–Mead</a></li><li><a class="tocitem" href="../particle_swarm/">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../primal_dual_semismooth_Newton/">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../quasi_Newton/">Quasi-Newton</a></li><li><a class="tocitem" href="../stochastic_gradient_descent/">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../subgradient/">Subgradient method</a></li><li><a class="tocitem" href="../truncated_conjugate_gradient_descent/">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../trust_regions/">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/robustPCA/">Robust PCA</a></li><li><a class="tocitem" href="../../examples/smallestEigenvalue/">Rayleigh quotient</a></li><li><a class="tocitem" href="../../examples/FrankWolfeSPDMean/">Frank Wolfe for Riemannian Center of Mass</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../../plans/">Specify a Solver</a></li><li><a class="tocitem" href="../../plans/problem/">Problem</a></li><li><a class="tocitem" href="../../plans/options/">Options</a></li><li><a class="tocitem" href="../../plans/stepsize/">Stepsize</a></li><li><a class="tocitem" href="../../plans/stopping_criteria/">Stopping Criteria</a></li><li><a class="tocitem" href="../../plans/debug/">Debug Output</a></li><li><a class="tocitem" href="../../plans/record/">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../../functions/">Introduction</a></li><li><a class="tocitem" href="../../functions/bezier/">Bézier curves</a></li><li><a class="tocitem" href="../../functions/costs/">Cost functions</a></li><li><a class="tocitem" href="../../functions/differentials/">Differentials</a></li><li><a class="tocitem" href="../../functions/adjointdifferentials/">Adjoint Differentials</a></li><li><a class="tocitem" href="../../functions/gradients/">Gradients</a></li><li><a class="tocitem" href="../../functions/Jacobi_fields/">Jacobi Fields</a></li><li><a class="tocitem" href="../../functions/proximal_maps/">Proximal Maps</a></li><li><a class="tocitem" href="../../functions/manifold/">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../../helpers/checks/">Checks</a></li><li><a class="tocitem" href="../../helpers/data/">Data</a></li><li><a class="tocitem" href="../../helpers/errorMeasures/">Error Measures</a></li><li><a class="tocitem" href="../../helpers/exports/">Exports</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../../notation/">Notation</a></li><li><a class="tocitem" href="../../list/">Function Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href>Conjugate gradient descent</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Conjugate gradient descent</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/solvers/conjugate_gradient_descent.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="CGSolver"><a class="docs-heading-anchor" href="#CGSolver">Conjugate Gradient Descent</a><a id="CGSolver-1"></a><a class="docs-heading-anchor-permalink" href="#CGSolver" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="Manopt.conjugate_gradient_descent" href="#Manopt.conjugate_gradient_descent"><code>Manopt.conjugate_gradient_descent</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">conjugate_gradient_descent(M, F, gradF, x)</code></pre><p>perform a conjugate gradient based descent</p><p class="math-container">\[x_{k+1} = \operatorname{retr}_{x_k} \bigl( s_kδ_k \bigr),\]</p><p>where <span>$\operatorname{retr}$</span> denotes a retraction on the <code>Manifold</code> <code>M</code> and one can employ different rules to update the descent direction <span>$δ_k$</span> based on the last direction <span>$δ_{k-1}$</span> and both gradients <span>$\operatorname{grad}f(x_k)$</span>,<span>$\operatorname{grad}f(x_{k-1})$</span>. The <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> <span>$s_k$</span> may be determined by a <a href="../../plans/stepsize/#Manopt.Linesearch"><code>Linesearch</code></a>.</p><p>Available update rules are <a href="#Manopt.SteepestDirectionUpdateRule"><code>SteepestDirectionUpdateRule</code></a>, which yields a <a href="../gradient_descent/#Manopt.gradient_descent"><code>gradient_descent</code></a>, <a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a> (the default), <a href="#Manopt.DaiYuanCoefficient"><code>DaiYuanCoefficient</code></a>, <a href="#Manopt.FletcherReevesCoefficient"><code>FletcherReevesCoefficient</code></a>, <a href="#Manopt.HagerZhangCoefficient"><code>HagerZhangCoefficient</code></a>, <a href="#Manopt.HeestenesStiefelCoefficient"><code>HeestenesStiefelCoefficient</code></a>, <a href="#Manopt.LiuStoreyCoefficient"><code>LiuStoreyCoefficient</code></a>, and <a href="#Manopt.PolakRibiereCoefficient"><code>PolakRibiereCoefficient</code></a>.</p><p>They all compute <span>$β_k$</span> such that this algorithm updates the search direction as</p><p class="math-container">\[\delta_k=\operatorname{grad}f(x_k) + β_k \delta_{k-1}\]</p><p><strong>Input</strong></p><ul><li><code>M</code> : a manifold <span>$\mathcal M$</span></li><li><code>F</code> : a cost function <span>$F:\mathcal M→ℝ$</span> to minimize</li><li><code>gradF</code>: the gradient <span>$\operatorname{grad}F:\mathcal M → T\mathcal M$</span> of <span>$F$</span></li><li><code>x</code> : an initial value <span>$x∈\mathcal M$</span></li></ul><p><strong>Optional</strong></p><ul><li><code>coefficient</code> : (<a href="#Manopt.ConjugateDescentCoefficient"><code>ConjugateDescentCoefficient</code></a> <code>&lt;:</code> <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>) rule to compute the descent direction update coefficient <span>$β_k$</span>, as a functor, i.e. the resulting function maps <code>(p,o,i) -&gt; β</code>, where <code>p</code> is the current <a href="../../plans/problem/#Manopt.GradientProblem"><code>GradientProblem</code></a>, <code>o</code> are the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a> <code>o</code> and <code>i</code> is the current iterate.</li><li><code>evaluation</code> – (<a href="../../plans/problem/#Manopt.AllocatingEvaluation"><code>AllocatingEvaluation</code></a>) specify whether the gradient works by allocation (default) form <code>gradF(M, x)</code> or <a href="../../plans/problem/#Manopt.MutatingEvaluation"><code>MutatingEvaluation</code></a> in place, i.e. is of the form <code>gradF!(M, X, x)</code>.</li><li><code>retraction_method</code> - (<code>default_retraction_method(M</code>) a retraction method to use.</li><li><code>return_options</code> – (<code>false</code>) – if actiavated, the extended result, i.e. the   complete <a href="../../plans/options/#Manopt.Options"><code>Options</code></a> re returned. This can be used to access recorded values.   If set to false (default) just the optimal value <code>x_opt</code> if returned</li><li><code>stepsize</code> - (<code>Constant(1.)</code>) A <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> function applied to the search direction. The default is a constant step size 1.</li><li><code>stopping_criterion</code> : (<code>stopWhenAny( stopAtIteration(200), stopGradientNormLess(10.0^-8))</code>) a function indicating when to stop.</li><li><code>vector_transport_method</code> – (<code>default_vector_transport_method(M)</code>) vector transport method to transport the old descent direction when computing the new descent direction.</li></ul><p><strong>Output</strong></p><ul><li><code>x_opt</code> – the resulting (approximately critical) point of gradientDescent</li></ul><p>OR</p><ul><li><code>options</code> - the options returned by the solver (see <code>return_options</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/solvers/conjugate_gradient_descent.jl#L1-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.conjugate_gradient_descent!" href="#Manopt.conjugate_gradient_descent!"><code>Manopt.conjugate_gradient_descent!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">conjugate_gradient_descent!(M, F, gradF, x)</code></pre><p>perform a conjugate gradient based descent in place of <code>x</code>, i.e.</p><p class="math-container">\[x_{k+1} = \operatorname{retr}_{x_k} \bigl( s_k\delta_k \bigr),\]</p><p>where <span>$\operatorname{retr}$</span> denotes a retraction on the <code>Manifold</code> <code>M</code></p><p><strong>Input</strong></p><ul><li><code>M</code> : a manifold <span>$\mathcal M$</span></li><li><code>F</code> : a cost function <span>$F:\mathcal M→ℝ$</span> to minimize</li><li><code>gradF</code>: the gradient <span>$\operatorname{grad}F:\mathcal M→ T\mathcal M$</span> of F</li><li><code>x</code> : an initial value <span>$x∈\mathcal M$</span></li></ul><p>for more details and options, especially the <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>s,  see <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/solvers/conjugate_gradient_descent.jl#L60-L77">source</a></section></article><h2 id="Options"><a class="docs-heading-anchor" href="#Options">Options</a><a id="Options-1"></a><a class="docs-heading-anchor-permalink" href="#Options" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Manopt.ConjugateGradientDescentOptions" href="#Manopt.ConjugateGradientDescentOptions"><code>Manopt.ConjugateGradientDescentOptions</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateGradientOptions &lt;: AbstractGradientOptions</code></pre><p>specify options for a conjugate gradient descent algorithm, that solves a [<code>GradientProblem</code>].</p><p><strong>Fields</strong></p><ul><li><code>x</code> – the current iterate, a point on a manifold</li><li><code>gradient</code> – the current gradient, also denoted as <span>$ξ$</span> or <span>$ξ_k$</span> for the gradient in the <span>$k$</span>th step.</li><li><code>δ</code> – the current descent direction, i.e. also tangent vector</li><li><code>β</code> – the current update coefficient rule, see .</li><li><code>coefficient</code> – a <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a> function to determine the new <code>β</code></li><li><code>stepsize</code> – a <a href="../../plans/stepsize/#Manopt.Stepsize"><code>Stepsize</code></a> function</li><li><code>stop</code> – a <a href="../../plans/stopping_criteria/#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a></li><li><code>retraction_method</code> – (<code>default_retraction_method(M)</code>) a type of retraction</li></ul><p><strong>See also</strong></p><p><a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a>, <a href="../../plans/problem/#Manopt.GradientProblem"><code>GradientProblem</code></a>, <a href="../../plans/stepsize/#Manopt.ArmijoLinesearch"><code>ArmijoLinesearch</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L1-L20">source</a></section></article><h2 id="cg-coeffs"><a class="docs-heading-anchor" href="#cg-coeffs">Available Coefficients</a><a id="cg-coeffs-1"></a><a class="docs-heading-anchor-permalink" href="#cg-coeffs" title="Permalink"></a></h2><p>The update rules act as <a href="../gradient_descent/#Manopt.DirectionUpdateRule"><code>DirectionUpdateRule</code></a>, which internally always first evaluate the gradient itself.</p><article class="docstring"><header><a class="docstring-binding" id="Manopt.ConjugateDescentCoefficient" href="#Manopt.ConjugateDescentCoefficient"><code>Manopt.ConjugateDescentCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConjugateDescentCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code> include the last iterates <span>$x_k,ξ_k$</span>, the current iterates <span>$x_{k+1},ξ_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <sup class="footnote-reference"><a id="citeref-Flethcer1987" href="#footnote-Flethcer1987">[Flethcer1987]</a></sup> adapted to manifolds:</p><p class="math-container">\[β_k =
\frac{ \lVert ξ_{k+1} \rVert_{x_{k+1}}^2 }
{\langle -\delta_k,ξ_k \rangle_{x_k}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">ConjugateDescentCoefficient(a::StoreOptionsAction=())</code></pre><p>Construct the conjugate descent coefficient update rule, a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L76-L100">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.DaiYuanCoefficient" href="#Manopt.DaiYuanCoefficient"><code>Manopt.DaiYuanCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DaiYuanCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code> include the last iterates <span>$x_k,ξ_k$</span>, the current iterates <span>$x_{k+1},ξ_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>, based on <sup class="footnote-reference"><a id="citeref-DaiYuan1999" href="#footnote-DaiYuan1999">[DaiYuan1999]</a></sup> adapted to manifolds:</p><p>Let <span>$\nu_k = ξ_{k+1} - P_{x_{k+1}\gets x_k}ξ_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the coefficient reads</p><p class="math-container">\[β_k =
\frac{ \lVert ξ_{k+1} \rVert_{x_{k+1}}^2 }
{\langle P_{x_{k+1}\gets x_k}\delta_k, \nu_k \rangle_{x_{k+1}}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">DaiYuanCoefficient(
    t::AbstractVectorTransportMethod=ParallelTransport(),
    a::StoreOptionsAction=(),
)</code></pre><p>Construct the Dai Yuan coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L121-L155">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.FletcherReevesCoefficient" href="#Manopt.FletcherReevesCoefficient"><code>Manopt.FletcherReevesCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FletcherReevesCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code> include the last iterates <span>$x_k,ξ_k$</span>, the current iterates <span>$x_{k+1},ξ_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <sup class="footnote-reference"><a id="citeref-FletcherReeves1964" href="#footnote-FletcherReeves1964">[FletcherReeves1964]</a></sup> adapted to manifolds:</p><p class="math-container">\[β_k =
\frac{\lVert ξ_{k+1}\rVert_{x_{k+1}}^2}{\lVert ξ_{k}\rVert_{x_{k}}^2}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">FletcherReevesCoefficient(a::StoreOptionsAction=())</code></pre><p>Construct the Fletcher Reeves coefficient update rule, a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L181-L205">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.HagerZhangCoefficient" href="#Manopt.HagerZhangCoefficient"><code>Manopt.HagerZhangCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HagerZhangCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code> include the last iterates <span>$x_k,ξ_k$</span>, the current iterates <span>$x_{k+1},ξ_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>, based on <sup class="footnote-reference"><a id="citeref-HagerZhang2005" href="#footnote-HagerZhang2005">[HagerZhang2005]</a></sup> adapted to manifolds: let <span>$\nu_k = ξ_{k+1} - P_{x_{k+1}\gets x_k}ξ_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p class="math-container">\[β_k = \Bigl\langle\nu_k -
\frac{ 2\lVert \nu_k\rVert_{x_{k+1}}^2 }{ \langle P_{x_{k+1}\gets x_k}\delta_k, \nu_k \rangle_{x_{k+1}} }
P_{x_{k+1}\gets x_k}\delta_k,
\frac{ξ_{k+1}}{ \langle P_{x_{k+1}\gets x_k}\delta_k, \nu_k \rangle_{x_{k+1}} }
\Bigr\rangle_{x_{k+1}}.\]</p><p>This method includes a numerical stability proposed by those authors.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">HagerZhangCoefficient(
    t::AbstractVectorTransportMethod=ParallelTransport(),
    a::StoreOptionsAction=(),
)</code></pre><p>Construct the Hager Zhang coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L226-L261">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.HeestenesStiefelCoefficient" href="#Manopt.HeestenesStiefelCoefficient"><code>Manopt.HeestenesStiefelCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HeestenesStiefelCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code> include the last iterates <span>$x_k,ξ_k$</span>, the current iterates <span>$x_{k+1},ξ_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <sup class="footnote-reference"><a id="citeref-HeestensStiefel1952" href="#footnote-HeestensStiefel1952">[HeestensStiefel1952]</a></sup> adapted to manifolds as follows:</p><p>Let <span>$\nu_k = ξ_{k+1} - P_{x_{k+1}\gets x_k}ξ_k$</span>. Then the update reads</p><p class="math-container">\[β_k = \frac{\langle ξ_{k+1}, \nu_k \rangle_{x_{k+1}} }
    { \langle P_{x_{k+1}\gets x_k} \delta_k, \nu_k\rangle_{x_{k+1}} },\]</p><p>where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">HeestenesStiefelCoefficient(
    t::AbstractVectorTransportMethod=ParallelTransport(),
    a::StoreOptionsAction=()
)</code></pre><p>Construct the Heestens Stiefel coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L297-L331">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.LiuStoreyCoefficient" href="#Manopt.LiuStoreyCoefficient"><code>Manopt.LiuStoreyCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LiuStoreyCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code> include the last iterates <span>$x_k,ξ_k$</span>, the current iterates <span>$x_{k+1},ξ_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <sup class="footnote-reference"><a id="citeref-LuiStorey1991" href="#footnote-LuiStorey1991">[LuiStorey1991]</a></sup> adapted to manifolds:</p><p>Let <span>$\nu_k = ξ_{k+1} - P_{x_{k+1}\gets x_k}ξ_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the coefficient reads</p><p class="math-container">\[β_k = -
\frac{ \langle ξ_{k+1},\nu_k \rangle_{x_{k+1}} }
{\langle \delta_k,ξ_k \rangle_{x_k}}.\]</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">LiuStoreyCoefficient(
    t::AbstractVectorTransportMethod=ParallelTransport(),
    a::StoreOptionsAction=()
)</code></pre><p>Construct the Lui Storey coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L359-L394">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.PolakRibiereCoefficient" href="#Manopt.PolakRibiereCoefficient"><code>Manopt.PolakRibiereCoefficient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PolakRibiereCoefficient &lt;: DirectionUpdateRule</code></pre><p>Computes an update coefficient for the conjugate gradient method, where the <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code> include the last iterates <span>$x_k,ξ_k$</span>, the current iterates <span>$x_{k+1},ξ_{k+1}$</span> of the iterate and the gradient, respectively, and the last update direction <span>$\delta=\delta_k$</span>,  based on <sup class="footnote-reference"><a id="citeref-PolakRibiere1969" href="#footnote-PolakRibiere1969">[PolakRibiere1969]</a></sup><sup class="footnote-reference"><a id="citeref-Polyak1969" href="#footnote-Polyak1969">[Polyak1969]</a></sup> adapted to manifolds:</p><p>Let <span>$\nu_k = ξ_{k+1} - P_{x_{k+1}\gets x_k}ξ_k$</span>, where <span>$P_{a\gets b}(⋅)$</span> denotes a vector transport from the tangent space at <span>$a$</span> to <span>$b$</span>.</p><p>Then the update reads</p><p class="math-container">\[β_k =
\frac{ \langle ξ_{k+1}, \nu_k \rangle_{x_{k+1}} }
{\lVert ξ_k \rVert_{x_k}^2 }.\]</p><p><strong>Constructor</strong></p><pre><code class="nohighlight hljs">PolakRibiereCoefficient(
    t::AbstractVectorTransportMethod=ParallelTransport(),
    a::StoreOptionsAction=()
)</code></pre><p>Construct the PolakRibiere coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.</p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L419-L459">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Manopt.SteepestDirectionUpdateRule" href="#Manopt.SteepestDirectionUpdateRule"><code>Manopt.SteepestDirectionUpdateRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SteepestDirectionUpdateRule &lt;: DirectionUpdateRule</code></pre><p>The simplest rule to update is to have no influence of the last direction and hence return an update <span>$β = 0$</span> for all <a href="#Manopt.ConjugateGradientDescentOptions"><code>ConjugateGradientDescentOptions</code></a><code>o</code></p><p>See also <a href="#Manopt.conjugate_gradient_descent"><code>conjugate_gradient_descent</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaManifolds/Manopt.jl/blob/4774caf1695724ddde94949786fbfccae2adf164/src/plans/conjugate_gradient_plan.jl#L486-L493">source</a></section></article><h1 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h1><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Flethcer1987"><a class="tag is-link" href="#citeref-Flethcer1987">Flethcer1987</a><blockquote><p>R. Fletcher, <strong>Practical Methods of Optimization vol. 1: Unconstrained Optimization</strong> John Wiley &amp; Sons, New York, 1987. doi <a href="https://doi.org/10.1137/1024028">10.1137/1024028</a></p></blockquote></li><li class="footnote" id="footnote-DaiYuan1999"><a class="tag is-link" href="#citeref-DaiYuan1999">DaiYuan1999</a><blockquote><p>[Y. H. Dai and Y. Yuan, A nonlinear conjugate gradient method with a strong global convergence property, SIAM J. Optim., 10 (1999), pp. 177–182. doi: <a href="https://doi.org/10.1137/S1052623497318992">10.1137/S1052623497318992</a></p></blockquote></li><li class="footnote" id="footnote-FletcherReeves1964"><a class="tag is-link" href="#citeref-FletcherReeves1964">FletcherReeves1964</a><blockquote><p>R. Fletcher and C. Reeves, Function minimization by conjugate gradients, Comput. J., 7 (1964), pp. 149–154. doi: <a href="http://dx.doi.org/10.1093/comjnl/7.2.149">10.1093/comjnl/7.2.149</a></p></blockquote></li><li class="footnote" id="footnote-HagerZhang2005"><a class="tag is-link" href="#citeref-HagerZhang2005">HagerZhang2005</a><blockquote><p>[W. W. Hager and H. Zhang, <strong>A new conjugate gradient method with guaranteed descent and an efficient line search</strong>, SIAM J. Optim, (16), pp. 170-192, 2005. doi: <a href="https://doi.org/10.1137/030601880">10.1137/030601880</a></p></blockquote></li><li class="footnote" id="footnote-HeestensStiefel1952"><a class="tag is-link" href="#citeref-HeestensStiefel1952">HeestensStiefel1952</a><blockquote><p>M.R. Hestenes, E.L. Stiefel, Methods of conjugate gradients for solving linear systems, J. Research Nat. Bur. Standards, 49 (1952), pp. 409–436. doi: <a href="http://dx.doi.org/10.6028/jres.049.044">10.6028/jres.049.044</a></p></blockquote></li><li class="footnote" id="footnote-LuiStorey1991"><a class="tag is-link" href="#citeref-LuiStorey1991">LuiStorey1991</a><blockquote><p>[Y. Liu and C. Storey, Efficient generalized conjugate gradient algorithms, Part 1: Theory J. Optim. Theory Appl., 69 (1991), pp. 129–137. doi: <a href="https://doi.org/10.1007/BF00940464">10.1007/BF00940464</a></p></blockquote></li><li class="footnote" id="footnote-PolakRibiere1969"><a class="tag is-link" href="#citeref-PolakRibiere1969">PolakRibiere1969</a><blockquote><p>E. Polak, G. Ribiere, Note sur la convergence de méthodes de directions conjuguées ESAIM: Mathematical Modelling and Numerical Analysis - Modélisation Mathématique et Analyse Numérique, Tome 3 (1969) no. R1, p. 35-43, url: <a href="http://www.numdam.org/item/?id=M2AN_1969__3_1_35_0">http://www.numdam.org/item/?id=M2AN<em>1969__3</em>1<em>35</em>0</a></p></blockquote></li><li class="footnote" id="footnote-Polyak1969"><a class="tag is-link" href="#citeref-Polyak1969">Polyak1969</a><blockquote><p>B. T. Polyak, The conjugate gradient method in extreme problems, USSR Comp. Math. Math. Phys., 9 (1969), pp. 94–112. doi: <a href="https://doi.org/10.1016/0041-5553(69)90035-4">10.1016/0041-5553(69)90035-4</a></p></blockquote></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ChambollePock/">« Chambolle-Pock</a><a class="docs-footer-nextpage" href="../cyclic_proximal_point/">Cyclic Proximal Point »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Tuesday 27 September 2022 10:09">Tuesday 27 September 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
