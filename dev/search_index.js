var documenterSearchIndex = {"docs":
[{"location":"notation/#Notation","page":"Notation","title":"Notation","text":"In this package,the notation introduced in Manifolds.jl Notation is used with the following additional parts.\n\nSymbol Description Also used Comment\noperatornameargmin argument of a function f where a local or global minimum is attained  \nk the current iterate Ã¬ the goal is to unify this to k\n The Levi-Cevita connection  ","category":"section"},{"location":"solvers/vectorbundle_newton/#Vector-Bundle-Newton-Method","page":"Vector Bundle Newton Method","title":"Vector Bundle Newton Method","text":"","category":"section"},{"location":"solvers/vectorbundle_newton/#Problem","page":"Vector Bundle Newton Method","title":"Problem","text":"","category":"section"},{"location":"solvers/vectorbundle_newton/#State","page":"Vector Bundle Newton Method","title":"State","text":"","category":"section"},{"location":"solvers/vectorbundle_newton/#Sec-VectorBundleNewton-Stepsize","page":"Vector Bundle Newton Method","title":"Stepsize","text":"","category":"section"},{"location":"solvers/vectorbundle_newton/#Internal-Functions","page":"Vector Bundle Newton Method","title":"Internal Functions","text":"","category":"section"},{"location":"solvers/vectorbundle_newton/#Literature","page":"Vector Bundle Newton Method","title":"Literature","text":"L.Â Weigl, R.Â Bergmann and A.Â Schiela. Newton's method for nonlinear mappings into vector bundles Part II: Application to variational problems, preprint (2025), arXiv:2507.13836.\n\n\n\nL.Â Weigl and A.Â Schiela. Newton's method for nonlinear mappings into vector bundles, preprint (2024), arXiv:2404.04073.\n\n\n\n","category":"section"},{"location":"solvers/vectorbundle_newton/#Manopt.vectorbundle_newton","page":"Vector Bundle Newton Method","title":"Manopt.vectorbundle_newton","text":"vectorbundle_newton(M, E, NE, p; kwargs...)\nvectorbundle_newton!(M, E, NE, p; kwargs...)\n\nPerform Newton's method for finding a zero of a mapping FmathcalM)  mathcalE where mathcalM) is a manifold and mathcalE is a vector bundle. In each iteration the Newton equation\n\nQ_F(p)  F(p) X + F(p) = 0\n\nis solved to compute a Newton direction X. The next iterate is then computed by applying a retraction.\n\nFor more details see [WS24, WBS25].\n\nArguments\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nE: range vector bundle\np::P: a point on the manifold mathcalM\nNE: functor representing the Newton equation. It has at least fields A and b to store a representation of the Newton matrix Q_F(p) F(p) (covariant derivative of F at p) and the right hand side F(p) at a point p  mathcalM). The point p denotes the starting point. The algorithm can be run in-place of p.\n\nKeyword arguments\n\nsub_problem::Union{AbstractManoptProblem, F} = nothing:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place., i.e. you have to provide a method for solving the Newton equation. Currently only the closed form solution is implemented, that is, this is a functor that maps either (problem::VectorBundleManoptProblem, state::VectorBundleNewtonState) -> X or (problem, X, state) -> X to compute the Newton direction.\nsub_state::Union{AbstractManoptProblem, F} =AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=default_stepsize(M,VectorBundleNewtonState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\n\n\n\n\n","category":"function"},{"location":"solvers/vectorbundle_newton/#Manopt.vectorbundle_newton!","page":"Vector Bundle Newton Method","title":"Manopt.vectorbundle_newton!","text":"vectorbundle_newton(M, E, NE, p; kwargs...)\nvectorbundle_newton!(M, E, NE, p; kwargs...)\n\nPerform Newton's method for finding a zero of a mapping FmathcalM)  mathcalE where mathcalM) is a manifold and mathcalE is a vector bundle. In each iteration the Newton equation\n\nQ_F(p)  F(p) X + F(p) = 0\n\nis solved to compute a Newton direction X. The next iterate is then computed by applying a retraction.\n\nFor more details see [WS24, WBS25].\n\nArguments\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nE: range vector bundle\np::P: a point on the manifold mathcalM\nNE: functor representing the Newton equation. It has at least fields A and b to store a representation of the Newton matrix Q_F(p) F(p) (covariant derivative of F at p) and the right hand side F(p) at a point p  mathcalM). The point p denotes the starting point. The algorithm can be run in-place of p.\n\nKeyword arguments\n\nsub_problem::Union{AbstractManoptProblem, F} = nothing:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place., i.e. you have to provide a method for solving the Newton equation. Currently only the closed form solution is implemented, that is, this is a functor that maps either (problem::VectorBundleManoptProblem, state::VectorBundleNewtonState) -> X or (problem, X, state) -> X to compute the Newton direction.\nsub_state::Union{AbstractManoptProblem, F} =AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=default_stepsize(M,VectorBundleNewtonState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\n\n\n\n\n","category":"function"},{"location":"solvers/vectorbundle_newton/#Manopt.VectorBundleManoptProblem","page":"Vector Bundle Newton Method","title":"Manopt.VectorBundleManoptProblem","text":"VectorBundleManoptProblem{M<:AbstractManifold,TV<:AbstractManifold,O} <: AbstractManoptProblem{M}\n\nModel a vector bundle problem, that consists of the domain manifold mathcalM) that is a AbstractManifold, the range vector bundle mathcalE and the Newton equation Q_F(x) F(x) Î´ x + F(x) = 0_p(F(x)). The Newton equation should be implemented as a functor that computes a representation of the Newton matrix and the right hand side. It needs to have a field A to store a representation of the Newton matrix Q_F(x) F(x) and a field b to store a representation of the right hand side F(x).\n\n\n\n\n\n","category":"type"},{"location":"solvers/vectorbundle_newton/#Manopt.VectorBundleNewtonState","page":"Vector Bundle Newton Method","title":"Manopt.VectorBundleNewtonState","text":"VectorBundleNewtonState{P,T} <: AbstractManoptSolverState\n\nIs state for the vector bundle Newton method\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\np_trial::P: a point on the manifold mathcalM next iterate needed for simplified Newton\nX::T: a tangent vector at the point p on the manifold mathcalM as current Newton direction\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place. currently only the closed form solution is implemented, that is, this is a functor that maps either (problem::VectorBundleManoptProblem, state::VectorBundleNewtonState) -> X or (problem, X, state) -> X to compute the Newton direction.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. specify how the sub_problem is evaluated, e.g. AllocatingEvaluation or InplaceEvaluation\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructor\n\nVectorBundleNewtonState(M, E, p, sub_problem, sub_state; kwargs...)\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nE: range vector bundle\np::P: a point on the manifold mathcalM\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\n\nKeyword arguments\n\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\nstepsize::Stepsize=default_stepsize(M,VectorBundleNewtonState): a functor inheriting from Stepsize to determine a step size\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\n\n\n\n\n\n","category":"type"},{"location":"solvers/vectorbundle_newton/#Manopt.AffineCovariantStepsize","page":"Vector Bundle Newton Method","title":"Manopt.AffineCovariantStepsize","text":"AffineCovariantStepsize <: Stepsize\n\nA functor to provide an affine covariant stepsize generalizing the idea of following Newton paths introduced by [WBS25, Section 4]. It can be used to derive a damped Newton method. The stepsizes (damping factors) are computed by a predictor-corrector-loop using an affine covariant quantity Î¸ to measure local convergence.\n\nFields\n\nÎ±:             stepsize (damping factor)\nÎ¸:             quantity that measures local convergence of Newton's method\nÎ¸_des:         desired Î¸\nÎ¸_acc:         acceptable Î¸\nlast_stepsize: last computed stepsize (this is an auxiliary variable used within the algorithm)\nouter_norm:    if M is a manifold with components, this is used to specify the norm, that is used to compute the overall distance based on the element-wise distance.\n\nExample\n\nOn an AbstractPowerManifold like mathcalMnifold))nifold))) = mathcalN^n any point p = (p_1p_n)  mathcalMnifold))) is a vector of length n with of points p_i  mathcalN. Then, denoting the outer_norm by r, the distance of two points pq  mathcalM) is given by\n\nmathrmd(pq) = Bigl( sum_k=1^n mathrmd(p_kq_k)^r Bigr)^frac1r\n\nwhere the sum turns into a maximum for the case r=. The outer_norm has no effect on manifolds that do not consist of components.\n\nIf the manifold does not have components, the outer norm is ignored.\n\nConstructor\n\nAffineCovariantStepsize(\n    M::AbstractManifold=DefaultManifold(2);\n    Î±=1.0, Î¸=1.3, Î¸_des=0.5, Î¸_acc=1.1*Î¸_des, outer_norm::Real=missing\n)\n\nInitializes all fields, where none of them is mandatory. The length is set to 10.\n\nSince the computation of the convergence monitor Î¸ requires simplified Newton directions a method for computing them has to be provided. This should be implemented as a method of the newton_equation(M, VB, p, p_trial) as parameters and returning a representation of the (transported) F(p_mathrmtrial).\n\n\n\n\n\n","category":"type"},{"location":"solvers/vectorbundle_newton/#Manopt.get_vectorbundle-Tuple{VectorBundleManoptProblem}","page":"Vector Bundle Newton Method","title":"Manopt.get_vectorbundle","text":"get_vectorbundle(vbp::VectorBundleManoptProblem)\n\nreturns the range vector bundle stored within a VectorBundleManoptProblem\n\n\n\n\n\n","category":"method"},{"location":"tutorials/AutomaticDifferentiation/#Using-automatic-differentiation-in-Manopt.jl","page":"Use automatic differentiation","title":"Using automatic differentiation in Manopt.jl","text":"Since Manifolds.jl 0.7, the support of automatic differentiation support has been extended.\n\nThis tutorial explains how to use Euclidean tools to derive a gradient for a real-valued function f  mathcal M  â„. Two methods are considered: an intrinsic variant and a variant employing the embedding. These gradients can then be used within any gradient based optimization algorithm in Manopt.jl.\n\nWhile by default FiniteDifferences.jlare used, one can also use FiniteDiff.jl, ForwardDiff.jl, ReverseDiff.jl, or Zygote.jl.\n\nThis tutorial looks at a few possibilities to approximate or derive the gradient of a function fmathcal M  â„ on a Riemannian manifold, without computing it yourself. There are mainly two different philosophies:\n\nWorking intrinsically, that is staying on the manifold and in the tangent spaces, considering to approximate the gradient by forward differences.\nWorking in an embedding where all tools from functions on Euclidean spaces can be used, like finite differences or automatic differentiation, and then compute the corresponding Riemannian gradient from there.\n\nFirst, load all necessary packages\n\nusing Manopt, Manifolds, Random, LinearAlgebra\nusing FiniteDifferences, ManifoldDiff, ADTypes\nRandom.seed!(42);","category":"section"},{"location":"tutorials/AutomaticDifferentiation/#1.-(Intrinsic)-forward-differences","page":"Use automatic differentiation","title":"1. (Intrinsic) forward differences","text":"A first idea is to generalize (multivariate) finite differences to Riemannian manifolds. Let X_1ldotsX_d  T_pmathcal M denote an orthonormal basis of the tangent space T_pmathcal M at the point pmathcal M on the Riemannian manifold.\n\nThe notion of a directional derivative is generalized to a â€œdirectionâ€ YT_pmathcal M. Let c  -ÎµÎµ, Îµ0, be a curve with c(0) = p, dot c(0) = Y, for example c(t)= exp_p(tY). This yields\n\n    Df(p)Y = left fracddt right_t=0 f(c(t)) = lim_t  0 frac1t(f(exp_p(tY))-f(p))\n\nThe differential Df(p)X is approximated by a finite difference scheme for an h0 as\n\nDF(p)Y  G_h(Y) = frac1h(f(exp_p(hY))-f(p))\n\nFurthermore the gradient operatornamegradf is the Riesz representer of the differential:\n\n    Df(p)Y = g_p(operatornamegradf(p) Y)qquad text for all  Y  T_pmathcal M\n\nand since it is a tangent vector, we can write it in terms of a basis as\n\n    operatornamegradf(p) = sum_i=1^d g_p(operatornamegradf(p)X_i)X_i\n    = sum_i=1^d Df(p)X_iX_i\n\nand perform the approximation from before to obtain\n\n    operatornamegradf(p)  sum_i=1^d G_h(X_i)X_i\n\nfor some suitable step size h. This comes at the cost of d+1 function evaluations and d exponential maps.\n\nThis is the first variant we can use. An advantage is that it is intrinsic in the sense that it does not require any embedding of the manifold.","category":"section"},{"location":"tutorials/AutomaticDifferentiation/#An-example:-the-Rayleigh-quotient","page":"Use automatic differentiation","title":"An example: the Rayleigh quotient","text":"The Rayleigh quotient is concerned with finding eigenvalues (and eigenvectors) of a symmetric matrix A  â„^(n+1)(n+1). The optimization problem reads\n\nF  â„^n+1  â„quad F(mathbf x) = fracmathbf x^mathrmTAmathbf xmathbf x^mathrmTmathbf x\n\nMinimizing this function yields the smallest eigenvalue lambda_1 as a value and the corresponding minimizer mathbf x^* is a corresponding eigenvector.\n\nSince the length of an eigenvector is irrelevant, there is an ambiguity in the cost function. It can be better phrased on the sphere ð•Š^n of unit vectors in â„^n+1,\n\noperatorname*argmin_p  ð•Š^n f(p) = operatorname*argmin_ p  ð•Š^n p^mathrmTAp\n\nWe can compute the Riemannian gradient exactly as\n\noperatornamegrad f(p) = 2(Ap - pp^mathrmTAp)\n\nso we can compare it to the approximation by finite differences.\n\nn = 200\nA = randn(n + 1, n + 1)\nA = Symmetric(A)\nM = Sphere(n);\n\nf1(p) = p' * A'p\ngradf1(p) = 2 * (A * p - p * p' * A * p)\n\ngradf1 (generic function with 1 method)\n\nManifolds provides a finite difference scheme in tangent spaces, that you can introduce to use an existing framework (if the wrapper is implemented) form Euclidean space. Here we use FiniteDiff.jl.\n\nr_backend = ManifoldDiff.TangentDiffBackend(\n    AutoFiniteDifferences(central_fdm(5, 1))\n)\ngradf1_FD(p) = ManifoldDiff.gradient(M, f1, p, r_backend)\n\np = zeros(n + 1)\np[1] = 1.0\nX1 = gradf1(p)\nX2 = gradf1_FD(p)\nnorm(M, p, X1 - X2)\n\n1.0156376260445835e-12\n\nWe obtain quite a good approximation of the gradient.","category":"section"},{"location":"tutorials/AutomaticDifferentiation/#EmbeddedGradient","page":"Use automatic differentiation","title":"2. Conversion of a Euclidean gradient in the embedding to a Riemannian Gradient of a (not Necessarily Isometrically) embedded manifold","text":"Let tilde f â„^m  â„ be a function on the embedding of an n-dimensional manifold mathcal M subset â„^mand let f  mathcal M  â„ denote the restriction of tilde f to the manifold mathcal M.\n\nSince we can use the pushforward of the embedding to also embed the tangent space T_pmathcal M, pmathcal M, we can similarly obtain the differential Df(p)  T_pmathcal M  â„ by restricting the differential Dtilde f(p) to the tangent space.\n\nIf both T_pmathcal M and T_pâ„^m have the same inner product, or in other words the manifold is isometrically embedded in â„^m (like for example the sphere mathbb S^nsubsetâ„^m+1), then this restriction of the differential directly translates to a projection of the gradient\n\noperatornamegradf(p) = operatornameProj_T_pmathcal M(operatornamegrad tilde f(p))\n\nMore generally take a change of the metric into account as\n\nlangle  operatornameProj_T_pmathcal M(operatornamegrad tilde f(p)) X rangle\n= Df(p)X = g_p(operatornamegradf(p) X)\n\nor in words: we have to change the Riesz representer of the (restricted/projected) differential of f (tilde f) to the one with respect to the Riemannian metric. This is done using change_representer.","category":"section"},{"location":"tutorials/AutomaticDifferentiation/#A-continued-example","page":"Use automatic differentiation","title":"A continued example","text":"We continue with the Rayleigh Quotient from before, now just starting with the definition of the Euclidean case in the embedding, the function F.\n\nF(x) = x' * A * x / (x' * x);\n\nThe cost function is the same by restriction\n\nf2(M, p) = F(p);\n\nThe gradient is now computed combining our gradient scheme with FiniteDifferences.\n\nfunction grad_f2_AD(M, p)\n    b = Manifolds.RiemannianProjectionBackend(AutoFiniteDifferences(central_fdm(5, 1)))\n    return Manifolds.gradient(M, F, p, b)\nend\nX3 = grad_f2_AD(M, p)\nnorm(M, p, X1 - X3)\n\n1.7224975655660473e-12","category":"section"},{"location":"tutorials/AutomaticDifferentiation/#An-example-for-a-non-isometrically-embedded-manifold","page":"Use automatic differentiation","title":"An example for a non-isometrically embedded manifold","text":"on the manifold mathcal P(3) of symmetric positive definite matrices.\n\nThe following function computes (half) the distance squared (with respect to the linear affine metric) on the manifold mathcal P(3) to the identity matrix I_3. Denoting the unit matrix we consider the function\n\n    G(q)\n    = frac12d^2_mathcal P(3)(qI_3)\n    = lVert operatornameLog(q) rVert_F^2\n\nwhere operatornameLog denotes the matrix logarithm and lVert cdot rVert_F is the Frobenius norm. This can be computed for symmetric positive definite matrices by summing the squares of the logarithms of the eigenvalues of q and dividing by two:\n\nG(q) = sum(log.(eigvals(Symmetric(q))) .^ 2) / 2\n\nG (generic function with 1 method)\n\nWe can also interpret this as a function on the space of matrices and apply the Euclidean finite differences machinery; in this way we can easily derive the Euclidean gradient. But when computing the Riemannian gradient, we have to change the representer (see again change_representer) after projecting onto the tangent space T_pmathcal P(n) at p.\n\nLetâ€™s first define a point and the manifold N=mathcal P(3).\n\nrotM(Î±) = [1.0 0.0 0.0; 0.0 cos(Î±) sin(Î±); 0.0 -sin(Î±) cos(Î±)]\nq = rotM(Ï€ / 6) * [1.0 0.0 0.0; 0.0 2.0 0.0; 0.0 0.0 3.0] * transpose(rotM(Ï€ / 6))\nN = SymmetricPositiveDefinite(3)\nis_point(N, q)\n\ntrue\n\nWe could first just compute the gradient using FiniteDifferences.jl, but this yields the Euclidean gradient:\n\nFiniteDifferences.grad(central_fdm(5, 1), G, q)\n\n([3.240417492806275e-14 -2.3531899864903462e-14 0.0; 0.0 0.3514812167654708 0.017000516835452926; 0.0 0.0 0.36129646973723023],)\n\nInstead, we use the RiemannianProjectedBackend of ManifoldDiff.jl, which in this case internally uses FiniteDifferences.jl to compute a Euclidean gradient but then uses the conversion explained before to derive the Riemannian gradient.\n\nWe define this here again as a function grad_G_FD that could be used in the Manopt.jl framework within a gradient based optimization.\n\nfunction grad_G_FD(N, q)\n    return Manifolds.gradient(\n        N,\n        G,\n        q,\n        ManifoldDiff.RiemannianProjectionBackend(AutoFiniteDifferences(central_fdm(5, 1))),\n    )\nend\nG1 = grad_G_FD(N, q)\n\n3Ã—3 Matrix{Float64}:\n  3.24042e-14  -2.64734e-14  -5.09481e-15\n -2.64734e-14   1.86368       0.826856\n -5.09481e-15   0.826856      2.81845\n\nNow, we can again compare this to the (known) solution of the gradient, namely the gradient of (half of) the distance squared G(q) = frac12d^2_mathcal P(3)(qI_3) is given by operatornamegrad G(q) = -operatornamelog_q I_3, where operatornamelog is th logarithmic map on the manifold.\n\nG2 = -log(N, q, Matrix{Float64}(I, 3, 3))\n\n3Ã—3 Matrix{Float64}:\n -0.0  -0.0       -0.0\n -0.0   1.86368    0.826856\n -0.0   0.826856   2.81845\n\nBoth terms agree up to 1810^-12:\n\nnorm(G1 - G2)\nisapprox(M, q, G1, G2; atol=2 * 1e-12)\n\ntrue","category":"section"},{"location":"tutorials/AutomaticDifferentiation/#Summary","page":"Use automatic differentiation","title":"Summary","text":"This tutorial illustrates how to use tools from Euclidean spaces, finite differences or automatic differentiation, to compute gradients on Riemannian manifolds. The scheme allows to use any differentiation framework within the embedding to derive a Riemannian gradient.","category":"section"},{"location":"tutorials/AutomaticDifferentiation/#Technical-details","page":"Use automatic differentiation","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:29:17.","category":"section"},{"location":"solvers/proximal_point/#Proximal-point-method","page":"Proximal point method","title":"Proximal point method","text":"","category":"section"},{"location":"solvers/proximal_point/#State","page":"Proximal point method","title":"State","text":"O.Â Ferreira and P.Â R.Â Oliveira. Proximal point algorithm on Riemannian manifolds. Optimization.Â AÂ JournalÂ ofÂ MathematicalÂ ProgrammingÂ andÂ OperationsÂ Research 51, 257â€“270 (2002).\n\n\n\n","category":"section"},{"location":"solvers/proximal_point/#Manopt.proximal_point","page":"Proximal point method","title":"Manopt.proximal_point","text":"proximal_point(M, prox_f, p=rand(M); kwargs...)\nproximal_point(M, mpmo, p=rand(M); kwargs...)\nproximal_point!(M, prox_f, p; kwargs...)\nproximal_point!(M, mpmo, p; kwargs...)\n\nPerform the proximal point algorithm from [FO02] which reads\n\np^(k+1) = operatornameprox_Î»_kf(p^(k))\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nprox_f: a proximal map (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nf=nothing: a cost function f mathcalMnifold)))â„ to minimize. For running the algorithm, f is not required, but for example when recording the cost or using a stopping criterion that requires a cost function.\nÎ»= k -> 1.0: a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-12): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_point/#Manopt.proximal_point!","page":"Proximal point method","title":"Manopt.proximal_point!","text":"proximal_point(M, prox_f, p=rand(M); kwargs...)\nproximal_point(M, mpmo, p=rand(M); kwargs...)\nproximal_point!(M, prox_f, p; kwargs...)\nproximal_point!(M, mpmo, p; kwargs...)\n\nPerform the proximal point algorithm from [FO02] which reads\n\np^(k+1) = operatornameprox_Î»_kf(p^(k))\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nprox_f: a proximal map (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nf=nothing: a cost function f mathcalMnifold)))â„ to minimize. For running the algorithm, f is not required, but for example when recording the cost or using a stopping criterion that requires a cost function.\nÎ»= k -> 1.0: a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-12): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_point/#Manopt.ProximalPointState","page":"Proximal point method","title":"Manopt.ProximalPointState","text":"ProximalPointState{P} <: AbstractGradientSolverState\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nÎ»:         a function for the values of Î»_k per iteration(cycle k\n\nConstructor\n\nProximalPointState(M::AbstractManifold; kwargs...)\n\nInitialize the proximal point method solver state, where\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\n\nKeyword arguments\n\nÎ»=k -> 1.0 a function to compute the Î»_k k  mathcalN,\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\n\nSee also\n\nproximal_point\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Conjugate-gradient-descent","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/#State","page":"Conjugate gradient descent","title":"State","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/#cg-coeffs","page":"Conjugate gradient descent","title":"Available coefficients","text":"The update rules act as DirectionUpdateRule, which internally always first evaluate the gradient itself.","category":"section"},{"location":"solvers/conjugate_gradient_descent/#cg-restart","page":"Conjugate gradient descent","title":"Restart rules","text":"The update rules might produce update steps that are not a descent direction, or at least be only approximately one. In these cases the following restart rules can be specified.","category":"section"},{"location":"solvers/conjugate_gradient_descent/#Internal-rules-for-coefficients","page":"Conjugate gradient descent","title":"Internal rules for coefficients","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/#sec-cgd-technical-details","page":"Conjugate gradient descent","title":"Technical details","text":"The conjugate_gradient_descent solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= or vector_transport_method_dual= (for mathcal N) does not have to be specified.\nBy default gradient descent uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).","category":"section"},{"location":"solvers/conjugate_gradient_descent/#Literature","page":"Conjugate gradient descent","title":"Literature","text":"E.Â M.Â Beale. A derivation of conjugate gradients. In: Numerical methods for nonlinear optimization, edited by F.Â A.Â Lootsma (Academic Press, London, London, 1972); pp.Â 39â€“43.\n\n\n\nY.Â H.Â Dai and Y.Â Yuan. A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property. SIAMÂ JournalÂ onÂ Optimization 10, 177â€“182 (1999).\n\n\n\nR.Â Fletcher. Practical Methods of Optimization. 2Â Edition, A Wiley-Interscience Publication (John Wiley & Sons Ltd., 1987).\n\n\n\nR.Â Fletcher and C.Â M.Â Reeves. Function minimization by conjugate gradients. TheÂ ComputerÂ Journal 7, 149â€“154 (1964).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A survey of nonlinear conjugate gradient methods. PacificÂ JournalÂ ofÂ Optimization 2, 35â€“58 (2006).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search. SIAMÂ JournalÂ onÂ Optimization 16, 170â€“192 (2005).\n\n\n\nM.Â Hestenes and E.Â Stiefel. Methods of conjugate gradients for solving linear systems. JournalÂ ofÂ ResearchÂ ofÂ theÂ NationalÂ BureauÂ ofÂ Standards 49, 409 (1952).\n\n\n\nY.Â Liu and C.Â Storey. Efficient generalized conjugate gradient algorithms,  part 1: Theory. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 69, 129â€“137 (1991).\n\n\n\nE.Â Polak and G.Â RibiÃ¨re. Note sur la convergence de mÃ©thodes de directions conjuguÃ©es. RevueÂ franÃ§aiseÂ dâ€™informatiqueÂ etÂ deÂ rechercheÂ opÃ©rationnelle 3, 35â€“43 (1969).\n\n\n\nM.Â J.Â Powell. Restart procedures for the conjugate gradient method. MathematicalÂ Programming 12, 241â€“254 (1977).\n\n\n\nH.Â Sakai and H.Â Iiduka. Hybrid Riemannian conjugate gradient methods with global convergence properties. ComputationalÂ OptimizationÂ andÂ Applications 77, 811â€“830 (2020).\n\n\n\nH.Â Sakai and H.Â Iiduka. Sufficient Descent Riemannian Conjugate Gradient Methods. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 190, 130â€“150 (2021).\n\n\n\n","category":"section"},{"location":"solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent","page":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent","text":"conjugate_gradient_descent(M, f, grad_f, p=rand(M))\nconjugate_gradient_descent!(M, f, grad_f, p)\nconjugate_gradient_descent(M, gradient_objective, p)\nconjugate_gradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform a conjugate gradient based descent-\n\np_k+1 = operatornameretr_p_k bigl( s_kÎ´_k bigr)\n\nwhere operatornameretr denotes a retraction on the Manifold M and one can employ different rules to update the descent direction Î´_k based on the last direction Î´_k-1 and both gradients operatornamegradf(x_k),operatornamegrad f(x_k-1). The Stepsize s_k may be determined by a Linesearch.\n\nAlternatively to f and grad_f you can provide the AbstractManifoldFirstOrderObjective gradient_objective directly.\n\nAvailable update rules are SteepestDescentCoefficientRule, which yields a gradient_descent, ConjugateDescentCoefficient (the default), DaiYuanCoefficientRule, FletcherReevesCoefficient, HagerZhangCoefficient, HestenesStiefelCoefficient, LiuStoreyCoefficient, and PolakRibiereCoefficient. These can all be combined with a ConjugateGradientBealeRestartRule rule.\n\nThey all compute Î²_k such that this algorithm updates the search direction as\n\nÎ´_k=operatornamegradf(p_k) + Î²_k delta_k-1\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\ncoefficient::DirectionUpdateRule=ConjugateDescentCoefficient(): rule to compute the descent direction update coefficient Î²_k, as a functor, where the resulting function maps are (amp, cgs, k) -> Î² with amp an AbstractManoptProblem, cgs is the ConjugateGradientDescentState, and k is the current iterate.\nrestart_condition::AbstractRestartCondition=NeverRestart(): rule when the algorithm should restart, i.e. use the negative gradient instead of the computed direction, as a functior where the resulting function maps are (amp, cgs, k) -> corr::Bool with amp an AbstractManoptProblem, cgs is the ConjugateGradientDescentState, and k is the current iterate.\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nIf you provide the ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent!","page":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent!","text":"conjugate_gradient_descent(M, f, grad_f, p=rand(M))\nconjugate_gradient_descent!(M, f, grad_f, p)\nconjugate_gradient_descent(M, gradient_objective, p)\nconjugate_gradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform a conjugate gradient based descent-\n\np_k+1 = operatornameretr_p_k bigl( s_kÎ´_k bigr)\n\nwhere operatornameretr denotes a retraction on the Manifold M and one can employ different rules to update the descent direction Î´_k based on the last direction Î´_k-1 and both gradients operatornamegradf(x_k),operatornamegrad f(x_k-1). The Stepsize s_k may be determined by a Linesearch.\n\nAlternatively to f and grad_f you can provide the AbstractManifoldFirstOrderObjective gradient_objective directly.\n\nAvailable update rules are SteepestDescentCoefficientRule, which yields a gradient_descent, ConjugateDescentCoefficient (the default), DaiYuanCoefficientRule, FletcherReevesCoefficient, HagerZhangCoefficient, HestenesStiefelCoefficient, LiuStoreyCoefficient, and PolakRibiereCoefficient. These can all be combined with a ConjugateGradientBealeRestartRule rule.\n\nThey all compute Î²_k such that this algorithm updates the search direction as\n\nÎ´_k=operatornamegradf(p_k) + Î²_k delta_k-1\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\ncoefficient::DirectionUpdateRule=ConjugateDescentCoefficient(): rule to compute the descent direction update coefficient Î²_k, as a functor, where the resulting function maps are (amp, cgs, k) -> Î² with amp an AbstractManoptProblem, cgs is the ConjugateGradientDescentState, and k is the current iterate.\nrestart_condition::AbstractRestartCondition=NeverRestart(): rule when the algorithm should restart, i.e. use the negative gradient instead of the computed direction, as a functior where the resulting function maps are (amp, cgs, k) -> corr::Bool with amp an AbstractManoptProblem, cgs is the ConjugateGradientDescentState, and k is the current iterate.\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nIf you provide the ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientDescentState","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientDescentState","text":"ConjugateGradientState <: AbstractGradientSolverState\n\nspecify options for a conjugate gradient descent algorithm, that solves a [DefaultManoptProblem].\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\nX::T: a tangent vector at the point p on the manifold mathcalM\nÎ´:                       the current descent direction, also a tangent vector\nÎ²:                       the current update coefficient rule, see .\ncoefficient:             function to determine the new Î²\nrestart_condition:       an AbstractRestartCondition to determine how to handle non-descent directions.\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nConjugateGradientState(M::AbstractManifold; kwargs...)\n\nwhere the last five fields can be set by their names as keyword and the X can be set to a tangent vector type using the keyword initial_gradient which defaults to zero_vector(M,p), and Î´ is initialized to a copy of this vector.\n\nKeyword arguments\n\nThe following fields from above <re keyword arguments\n\ninitial_gradient::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\ncoefficient=[ConjugateDescentCoefficient](@ref)(): specify a CG coefficient, see also the [ManifoldDefaultsFactory`](@ref).\nrestart_condition=NeverRestart(): specify a restart condition. It defaults to never restart.\nstepsize::Stepsize=default_stepsize(M, ConjugateGradientDescentState; retraction_method=retraction_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nconjugate_gradient_descent, DefaultManoptProblem, ArmijoLinesearch\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateDescentCoefficient","page":"Conjugate gradient descent","title":"Manopt.ConjugateDescentCoefficient","text":"ConjugateDescentCoefficient()\nConjugateDescentCoefficient(M::AbstractManifold)\n\nCompute the (classical) conjugate gradient coefficient based on [Fle87] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nThen the coefficient reads\n\nÎ²_k = fracmathrmD_tf(p_k+1)X_k+1mathrmD_tf(p_k)-Î´_k\n = fraclVert X_k+1 rVert_p_k+1^2-Î´_kX_k_p_k\n\nThe second one it the one usually stated, while the first one avoids to use the metric inner. The first one is implemented here, but falls back to calling inner if there is no dedicated differential available.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ConjugateDescentCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientBealeRestart","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientBealeRestart","text":"ConjugateGradientBealeRestart(direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory}; kwargs...)\nConjugateGradientBealeRestart(M::AbstractManifold, direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory}; kwargs...)\n\nCompute a conjugate gradient coefficient with a potential restart, when two directions are nearly orthogonal. See [HZ06a, page 12] (in the preprint, page 46 in Journal page numbers). This method is named after E. Beale from his proceedings paper in 1972 [Bea72]. This method acts as a decorator to any existing DirectionUpdateRule direction_update.\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nThen a restart is performed, hence Î²_k = 0 returned if\n\n  fracX_k+1 mathcal T_p_kp_k+1X_klVert X_k rVert_p_k  Îµ\n\nwhere Îµ is the threshold, which is set by default to 0.2, see [Pow77]\n\nInput\n\ndirection_update: a DirectionUpdateRule or a corresponding ManifoldDefaultsFactory to produce such a rule.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nthreshold=0.2\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ConjugateGradientBealeRestartRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.DaiYuanCoefficient","page":"Conjugate gradient descent","title":"Manopt.DaiYuanCoefficient","text":"DaiYuanCoefficient(; kwargs...)\nDaiYuanCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [DY99] adapted to Riemannian manifolds.\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_kp_k+1X_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k =\n=\nfracmathrmD_tf(p_k+1)X_k+1Î´_kÎ½_k_p_k+1\n=\nfraclVert X_k+1 rVert_p_k+1^2mathcal T_p_kp_k+1Î´_k Î½_k_p_k+1\n\nThe second one it the one usually stated, while the first one avoids to use the metric inner. The first one is implemented here, but falls back to calling inner if there is no dedicated differential available.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for DaiYuanCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.FletcherReevesCoefficient","page":"Conjugate gradient descent","title":"Manopt.FletcherReevesCoefficient","text":"FletcherReevesCoefficient()\nFletcherReevesCoefficient(M::AbstractManifold)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [FR64] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nThen the coefficient reads\n\nÎ²_k = fracmathrmD_tf(p_k+1)X_k+1mathrmD_tf(p_k)X_k\n = fraclVert X_k+1 rVert_p_k+1^2lVert X_k rVert_p_k^2\n\nThe second one it the one usually stated, while the first one avoids to use the metric inner. The first one is implemented here, but falls back to calling inner if there is no dedicated differential available.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for FletcherReevesCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HagerZhangCoefficient","page":"Conjugate gradient descent","title":"Manopt.HagerZhangCoefficient","text":"HagerZhangCoefficient(; kwargs...)\nHagerZhangCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [FR64] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_kp_k+1X_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k = BiglÎ½_k - frac2lVert Î½_k rVert_p_k+1^2mathcal T_p_kp_k+1Î´_k Î½_k_p_k+1\n  mathcal T_p_kp_k+1Î´_k\n  fracX_k+1mathcal T_p_kp_k+1Î´_k Î½_k_p_k+1\nBigr_p_k+1\n\nThis method includes a numerical stability proposed by those authors.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for HagerZhangCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HestenesStiefelCoefficient","page":"Conjugate gradient descent","title":"Manopt.HestenesStiefelCoefficient","text":"HestenesStiefelCoefficient(; kwargs...)\nHestenesStiefelCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [HS52] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_kp_k+1X_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nbeginaligned\nÎ²_k\n= fracmathrmD_tf(p_k+1)Î½_kmathrmD_tf(p_k+1)mathcal T_p_kp_k+1Î´_k - mathrmD_tf(p_k)Î´_k\n= fracX_k+1Î½_k_p_k+1mathcal T_p_kp_k+1Î´_kX_k+1_p_k+1 - Î´_kX_k_p_k\n= fracX_k+1Î½_k_p_k+1mathcal T_p_kp_k+1Î´_kÎ½_k_p_k+1\nendaligned\n\nThe third one is the one usually stated, while the first one avoids to use the metric inner. The first one is implemented here, but falls back to calling inner if there is no dedicated differential available.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for HestenesStiefelCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HybridCoefficient","page":"Conjugate gradient descent","title":"Manopt.HybridCoefficient","text":"HybridCoefficient(coefficients::AbstractArray{Union{DirectionUpdateRule,ManifoldDefaultsFactory}}; kwargs...)\nHybridCoefficient(M::AbstractManifold, coefficients::AbstractArray{Union{DirectionUpdateRule,ManifoldDefaultsFactory}}; kwargs...)\n\nComputes an hybrid update coefficient for the conjugate_gradient_descent.\n\nGiven coefficients Î²_i for i = 1m, a lower bound coefficient Î²_0, and a scalar factor Ïƒ for the lower bound, this coefficient computes\n\nÎ²_k = maxsetÏƒ * Î²_0 min(Î²_1  Î²_m)bigr)\n\nThis includes the HS-DY and FR-PRP hybrid parameters introduced in [SI20] and [SI21]\n\nInput\n\nargs... : CG coefficients of type DirectionUpdateRule or a corresponding ManifoldDefaultsFactory to produce such a rule, of which the minimum is taken in the\n\nhybrid rule\n\nKeyword arguments\n\nlower_bound=SteepestDescentCoefficient() : a lower bound DirectionUpdateRule or a corresponding\n\nManifoldDefaultsFactory for the resulting value of Î²\n\nlower_bound_scale=1.0 : a scalar to multiply the lower bound coefficient by.\n\nExamples\n\nThe FR-PRP parameter reads\n\nÎ²_k^mathrmFR-PRP = maxset0 min(Î²_k^FR Î²_k^PRP)bigr)\n\nand can be implemented using\n\nHybridCoefficient(FletcherReevesCoefficient(),PolakRibiereCoefficient())\n\nThe HS-DY parameter with parameter 0<Ïƒ<1 reads\n\nÎ²_k^mathrmHS-DY = maxbigl(-Ïƒ Î²_k^DY min(Î²_k^HS Î²_k^DY)bigr)\n\nand can be implemented using HybridCoefficient(HestenesStiefelCoefficient(),DaiYuanCoefficient(); lower_bound =DaiYuanCoefficient(), lower_bound_scale = -Ïƒ)\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for HybridCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.LiuStoreyCoefficient","page":"Conjugate gradient descent","title":"Manopt.LiuStoreyCoefficient","text":"LiuStoreyCoefficient(; kwargs...)\nLiuStoreyCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [LS91] adapted to manifolds\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_kp_k+1X_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k\n= - fracmathrmD_tf(p_k+1)Î½_kmathrmD_tf(p_k)Î´_k\n= - fracX_k+1Î½_k_p_k+1Î´_kX_k_p_k\n\nThe second one it the one usually stated, while the first one avoids to use the metric inner. The first one is implemented here, but falls back to calling inner if there is no dedicated differential available.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for LiuStoreyCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.PolakRibiereCoefficient","page":"Conjugate gradient descent","title":"Manopt.PolakRibiereCoefficient","text":"PolakRibiereCoefficient(; kwargs...)\nPolakRibiereCoefficient(M::AbstractManifold; kwargs...)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm based on [PR69] adapted to Riemannian manifolds.\n\nDenote the last iterate and gradient by p_kX_k, the current iterate and gradient by p_k+1 X_k+1, respectively, as well as the last update direction by Î´_k.\n\nLet Î½_k = X_k+1 - mathcal T_p_kp_k+1X_k, where mathcal T_ denotes a vector transport.\n\nThen the coefficient reads\n\nÎ²_k\n= fracmathrmD_tf(p_k+1)Î½_kmathrmD_tf(p_k)X_k\n= fracX_k+1Î½_k_p_k+1lVert X_k rVert_p_k^2\n\nThe second one is the one usually stated, while the first one avoids to use the metric inner. The first one is implemented here, but falls back to calling inner if there is no dedicated differential available.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for PolakRibiereCoefficientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.SteepestDescentCoefficient","page":"Conjugate gradient descent","title":"Manopt.SteepestDescentCoefficient","text":"SteepestDescentCoefficient()\nSteepestDescentCoefficient(M::AbstractManifold)\n\nComputes an update coefficient for the conjugate_gradient_descent algorithm so that is falls back to a gradient_descent method, that is\n\nÎ²_k = 0\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for SteepestDescentCoefficient. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.AbstractRestartCondition","page":"Conjugate gradient descent","title":"Manopt.AbstractRestartCondition","text":"AbstractRestartCondition\n\nA general struct, that indicates then to restart. It is used within the ConjugateGradientDescentState.\n\nIt is implemented to work as a functor (problem, state, iteration) -> true|false and what is done in the restart case (true) is decided by the single solver.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.NeverRestart","page":"Conjugate gradient descent","title":"Manopt.NeverRestart","text":"NeverRestart <: AbstractRestartCondition\n\nA restart strategy that indicates to never restart.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.RestartOnNonDescent","page":"Conjugate gradient descent","title":"Manopt.RestartOnNonDescent","text":"RestartOnNonDescent <: AbstractRestartCondition\n\nA restart strategy that restarts, whenever the search direction Î´ is not a descent direction, i.e. when\n\n    operatornamegradf(p) Î´  0\n\nat the current iterate p.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.RestartOnNonSufficientDescent","page":"Conjugate gradient descent","title":"Manopt.RestartOnNonSufficientDescent","text":"RestartOnNonSufficientDescent <: AbstractRestartCondition\n\nFields\n\nÎº: the sufficient decrease factor\n\nA restart strategy that indicates to restart whenever the search direction Î´ is not a sufficient descent direction, i.e.\n\n    operatornamegradf(p) Î´  - Îº lVert X rVert^2\n\nat the current iterate p.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientBealeRestartRule","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientBealeRestartRule","text":"ConjugateGradientBealeRestartRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on a restart idea of [Bea72], following [HZ06a, page 12] adapted to manifolds.\n\nFields\n\ndirection_update::DirectionUpdateRule: the actual rule, that is restarted\nthreshold::Real: a threshold for the restart check.\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nConjugateGradientBealeRestartRule(\n    direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory};\n    kwargs...\n)\nConjugateGradientBealeRestartRule(\n    M::AbstractManifold=DefaultManifold(),\n    direction_update::Union{DirectionUpdateRule,ManifoldDefaultsFactory};\n    kwargs...\n)\n\nConstruct the Beale restart coefficient update rule adapted to manifolds.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM If this is not provided, the DefaultManifold() from ManifoldsBase.jl is used.\ndirection_update: a DirectionUpdateRule or a corresponding ManifoldDefaultsFactory to produce such a rule.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nthreshold=0.2\n\nSee also\n\nConjugateGradientBealeRestart, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.DaiYuanCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.DaiYuanCoefficientRule","text":"DaiYuanCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [DY99] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nDaiYuanCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Daiâ€”Yuan coefficient update rule.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nDaiYuanCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.FletcherReevesCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.FletcherReevesCoefficientRule","text":"FletcherReevesCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [FR64] adapted to manifolds\n\nConstructor\n\nFletcherReevesCoefficientRule()\n\nConstruct the Fletcherâ€”Reeves coefficient update rule.\n\nSee also\n\nFletcherReevesCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HagerZhangCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.HagerZhangCoefficientRule","text":"HagerZhangCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [HZ05] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nHagerZhangCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Hager-Zhang coefficient update rule based on [HZ05] adapted to manifolds.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nHagerZhangCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HestenesStiefelCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.HestenesStiefelCoefficientRule","text":"HestenesStiefelCoefficientRuleRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [HS52] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nHestenesStiefelCoefficientRuleRule(M::AbstractManifold; kwargs...)\n\nConstruct the Hestenes-Stiefel coefficient update rule based on [HS52] adapted to manifolds.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nHestenesStiefelCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HybridCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.HybridCoefficientRule","text":"HybridCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute hybrid conjugate gradient update coefficients\n\nFields\n\ncoefficients::NTuple{DirectionUpdateRuleStorage, N}: NTuple containing storage wrappers of CG coefficients of which the minimum is taken\nlower_bound::DirectionUpdateRuleStorage: storage wrapper of lower bound CG coefficient\nlower_bound_scale::Real: scalar the lower bound is multiplied with\n\nConstructor\n\nHybridCoefficientRule(\n    M::AbstractManifold, coefficients::Union{DirectionUpdateRule,ManifoldDefaultsFactory}...;\n    lower_bound::Union{DirectionUpdateRule,ManifoldDefaultsFactory}=SteepestDescentCoefficient(),\n    lower_bound_scale::Real=1.0\n)\n\nConstruct the hybrid coefficient update rule.\n\nSee also\n\nHybridCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.LiuStoreyCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.LiuStoreyCoefficientRule","text":"LiuStoreyCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [LS91] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nLiuStoreyCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Lui-Storey coefficient update rule based on [LS91] adapted to manifolds.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nLiuStoreyCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.PolakRibiereCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.PolakRibiereCoefficientRule","text":"PolakRibiereCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient based on [PR69] adapted to manifolds\n\nFields\n\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nPolakRibiereCoefficientRule(M::AbstractManifold; kwargs...)\n\nConstruct the Daiâ€”Yuan coefficient update rule.\n\nKeyword arguments\n\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nPolakRibiereCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.SteepestDescentCoefficientRule","page":"Conjugate gradient descent","title":"Manopt.SteepestDescentCoefficientRule","text":"SteepestDescentCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient to obtain the steepest direction, that is Î²_k=0.\n\nConstructor\n\nSteepestDescentCoefficientRule()\n\nConstruct the steepest descent coefficient update rule.\n\nSee also\n\nSteepestDescentCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Convex-bundle-method","page":"Convex bundle method","title":"Convex bundle method","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#State","page":"Convex bundle method","title":"State","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Stopping-criteria","page":"Convex bundle method","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Debug-functions","page":"Convex bundle method","title":"Debug functions","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Helpers-and-internal-functions","page":"Convex bundle method","title":"Helpers and internal functions","text":"","category":"section"},{"location":"solvers/convex_bundle_method/#Literature","page":"Convex bundle method","title":"Literature","text":"R.Â Bergmann, R.Â Herzog and H.Â Jasa. The Riemannian Convex Bundle Method, preprint (2024), arXiv:2402.13670.\n\n\n\n","category":"section"},{"location":"solvers/convex_bundle_method/#Manopt.convex_bundle_method","page":"Convex bundle method","title":"Manopt.convex_bundle_method","text":"convex_bundle_method(M, f, âˆ‚f, p)\nconvex_bundle_method!(M, f, âˆ‚f, p)\n\nperform a convex bundle method p^(k+1) = operatornameretr_p^(k)(-g_k) where\n\ng_k = sum_j  J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nand p_k is the last serious iterate, X_q_j  f(q_j), and the Î»_j^k are solutions to the quadratic subproblem provided by the convex_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details, see [BHJ24].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nâˆ‚f: the subgradient f mathcalM  TmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\natol_Î»=eps() : tolerance parameter for the convex coefficients in Î».\natol_errors=eps(): : tolerance parameter for the linearization errors.\nbundle_cap=25`\nm=1e-3: : the parameter to test the decrease of the cost: f(q_k+1)  f(p_k) + m Î¾.\ndiameter=50.0: estimate for the diameter of the level set of the objective function at the starting point.\ndomain=(M, p) -> isfinite(f(M, p)): a function to that evaluates to true when the current candidate is in the domain of the objective f, and false otherwise.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nk_max=0: upper bound on the sectional curvature of the manifold.\nstepsize::Stepsize=default_stepsize(M,ConvexBundleMethodState): a functor inheriting from Stepsize to determine a step size\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstopping_criterion::StoppingCriterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nsub_state::Union{AbstractManoptProblem, F} =convex_bundle_method_subsolver`:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem::Union{AbstractManoptProblem, F} =AllocatingEvaluationÂ´â€Š`:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.convex_bundle_method!","page":"Convex bundle method","title":"Manopt.convex_bundle_method!","text":"convex_bundle_method(M, f, âˆ‚f, p)\nconvex_bundle_method!(M, f, âˆ‚f, p)\n\nperform a convex bundle method p^(k+1) = operatornameretr_p^(k)(-g_k) where\n\ng_k = sum_j  J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nand p_k is the last serious iterate, X_q_j  f(q_j), and the Î»_j^k are solutions to the quadratic subproblem provided by the convex_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details, see [BHJ24].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nâˆ‚f: the subgradient f mathcalM  TmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\natol_Î»=eps() : tolerance parameter for the convex coefficients in Î».\natol_errors=eps(): : tolerance parameter for the linearization errors.\nbundle_cap=25`\nm=1e-3: : the parameter to test the decrease of the cost: f(q_k+1)  f(p_k) + m Î¾.\ndiameter=50.0: estimate for the diameter of the level set of the objective function at the starting point.\ndomain=(M, p) -> isfinite(f(M, p)): a function to that evaluates to true when the current candidate is in the domain of the objective f, and false otherwise.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nk_max=0: upper bound on the sectional curvature of the manifold.\nstepsize::Stepsize=default_stepsize(M,ConvexBundleMethodState): a functor inheriting from Stepsize to determine a step size\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstopping_criterion::StoppingCriterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nsub_state::Union{AbstractManoptProblem, F} =convex_bundle_method_subsolver`:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem::Union{AbstractManoptProblem, F} =AllocatingEvaluationÂ´â€Š`:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.ConvexBundleMethodState","page":"Convex bundle method","title":"Manopt.ConvexBundleMethodState","text":"ConvexBundleMethodState <: AbstractManoptSolverState\n\nStores option values for a convex_bundle_method solver.\n\nFields\n\nTHe following fields require a (real) number type R, as well as point type P and a tangent vector type T`\n\natol_Î»::R:                 tolerance parameter for the convex coefficients in Î»\n`atol_errors::R:             tolerance parameter for the linearization errors\nbundle<:AbstractVector{Tuple{<:P,<:T}}: bundle that collects each iterate with the computed subgradient at the iterate\nbundle_cap::Int: the maximal number of elements the bundle is allowed to remember\ndiameter::R: estimate for the diameter of the level set of the objective function at the starting point\ndomain: the domain offas a function(M,p) -> bthat evaluates to true when the current candidate is in the domain off`, and false otherwise,\ng::T:                      descent direction\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nk_max::R:                  upper bound on the sectional curvature of the manifold\nlinearization_errors<:AbstractVector{<:R}: linearization errors at the last serious step\nm::R:                      the parameter to test the decrease of the cost: f(q_k+1)  f(p_k) + m Î¾.\np::P: a point on the manifold mathcalM  storing the current iterate\np_last_serious::P:         last serious iterate\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\ntransported_subgradients:  subgradients of the bundle that are transported to p_last_serious\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nX::T: a tangent vector at the point p on the manifold mathcalM storing a subgradient at the current iterate\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nÎµ::R:                      convex combination of the linearization errors\nÎ»:::AbstractVector{<:R}:   convex coefficients from the slution of the subproblem\nÎ¾:                         the stopping parameter given by Î¾ = -lVert g rVert^2  Îµ\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nConstructor\n\nConvexBundleMethodState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\nConvexBundleMethodState(M::AbstractManifold, sub_problem=convex_bundle_method_subsolver; evaluation=AllocatingEvaluation(), kwargs...)\n\nGenerate the state for the convex_bundle_method on the manifold M\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\nMost of the following keyword arguments set default values for the fields mentioned before.\n\natol_Î»=eps()\natol_errors=eps()\nbundle_cap=25`\nm=1e-2\ndiameter=50.0\ndomain=(M, p) -> isfinite(f(M, p))\nk_max=0\nk_min=0\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstepsize::Stepsize=default_stepsize(M,ConvexBundleMethodState): a functor inheriting from Stepsize to determine a step size\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the type of tangent vector to use.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Manopt.StopWhenLagrangeMultiplierLess","page":"Convex bundle method","title":"Manopt.StopWhenLagrangeMultiplierLess","text":"StopWhenLagrangeMultiplierLess <: StoppingCriterion\n\nStopping Criteria for Lagrange multipliers.\n\nCurrently these are meant for the convex_bundle_method and proximal_bundle_method, where based on the Lagrange multipliers an approximate (sub)gradient g and an error estimate Îµ is computed.\n\nThe mode=:both requires that both Îµ and lvert g rvert are smaller than their tolerances for the convex_bundle_method, and that c and lvert d rvert are smaller than their tolerances for the proximal_bundle_method.\n\nThe mode=:estimate requires that, for the convex_bundle_method -Î¾ = lvert g rvert^2 + Îµ is less than a given tolerance. For the proximal_bundle_method, the equation reads -Î½ = Î¼ lvert d rvert^2 + c.\n\nConstructors\n\nStopWhenLagrangeMultiplierLess(tolerance=1e-6; mode::Symbol=:estimate, names=nothing)\n\nCreate the stopping criterion for one of the modes mentioned. Note that tolerance can be a single number for the :estimate case, but a vector of two values is required for the :both mode. Here the first entry specifies the tolerance for Îµ (c), the second the tolerance for lvert g rvert (lvert d rvert), respectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Manopt.DebugWarnIfLagrangeMultiplierIncreases","page":"Convex bundle method","title":"Manopt.DebugWarnIfLagrangeMultiplierIncreases","text":"DebugWarnIfLagrangeMultiplierIncreases <: DebugAction\n\nprint a warning if the Lagrange parameter based value -Î¾ of the bundle method increases.\n\nConstructor\n\nDebugWarnIfLagrangeMultiplierIncreases(warn=:Once; tol=1e2)\n\nInitialize the warning to warning level (:Once) and introduce a tolerance for the test of 1e2.\n\nThe warn level can be set to :Once to only warn the first time the cost increases, to :Always to report an increase every time it happens, and it can be set to :No to deactivate the warning, then this DebugAction is inactive. All other symbols are handled as if they were :Always.\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Manopt.convex_bundle_method_subsolver","page":"Convex bundle method","title":"Manopt.convex_bundle_method_subsolver","text":"Î» = convex_bundle_method_subsolver(M, p_last_serious, linearization_errors, transported_subgradients)\nconvex_bundle_method_subsolver!(M, Î», p_last_serious, linearization_errors, transported_subgradients)\n\nsolver for the subproblem of the convex bundle method at the last serious iterate p_k given the current linearization errors c_j^k, and transported subgradients mathrmP_p_kq_j X_q_j.\n\nThe computation can also be done in-place of Î».\n\nThe subproblem for the convex bundle method is\n\nbeginalign*\n    operatorname*argmin_Î»  â„^lvert J_k rvert\n    \n    frac12BigllVert sum_j  J_k Î»_j mathrmP_p_kq_j X_q_j BiglrVert^2\n    + sum_j  J_k Î»_j  c_j^k\n    \n    texts tquad \n    sum_j  J_k Î»_j = 1\n    quad Î»_j  0\n    quad textfor all \n    j  J_k\nndalign*\n\nwhere J_k = setj  J_k-1    Î»_j  0  setk. See [BHJ24] for more details\n\ntip: Tip\nA default subsolver based on RipQP.jl and QuadraticModels is available if these two packages are loaded.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.DomainBackTrackingStepsize","page":"Convex bundle method","title":"Manopt.DomainBackTrackingStepsize","text":"DomainBackTrackingStepsize <: Stepsize\n\nImplement a backtrack as long as we are q =operatornameretr_p(X) yields a point closer to p than lVert X rVert_p or q is not on the domain. For the domain this step size requires a ConvexBundleMethodState.\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Manopt.DomainBackTracking","page":"Convex bundle method","title":"Manopt.DomainBackTracking","text":"DomainBackTracking(; kwargs...)\nDomainBackTracking(M::AbstractManifold; kwargs...)\n\nSpecify a step size that performs a backtracking to the interior of the domain of the objective function.\n\nKeyword arguments\n\ncandidate_point=allocate_result(M, rand): specify a point to be used as memory for the candidate points.\ncontraction_factor: how to update s in the decrease step\ninitial_stepsize`: specify an initial step size\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for DomainBackTrackingStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.NullStepBackTrackingStepsize","page":"Convex bundle method","title":"Manopt.NullStepBackTrackingStepsize","text":"NullStepBackTrackingStepsize <: Stepsize\n\nImplement a backtracking with a geometric condition in the case of a null step. For the domain this step size requires a ConvexBundleMethodState.\n\n\n\n\n\n","category":"type"},{"location":"solvers/convex_bundle_method/#Manopt.estimate_sectional_curvature","page":"Convex bundle method","title":"Manopt.estimate_sectional_curvature","text":"estimate_sectional_curvature(M::AbstractManifold, p)\n\nEstimate the sectional curvature of a manifold mathcalM) at a point p  mathcalM) on two random tangent vectors at p that are orthogonal to each other.\n\nSee also\n\nsectional_curvature\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.Î¶_1","page":"Convex bundle method","title":"Manopt.Î¶_1","text":"Î¶_1(Ï‰, Î´)\n\ncompute a curvature-dependent bound. The formula reads\n\nÎ¶_1 Ï‰(Î´)\n=\nbegincases   1  text if  Ï‰  0    sqrt-Ï‰Î´cot(sqrt-Ï‰Î´)  text if  Ï‰  0endcases\n\nwhere Ï‰  Îº_p for all p  mathcalU is a lower bound to the sectional curvature in a (strongly geodesically convex) bounded subset mathcalU  mathcalM) with diameter Î´.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.Î¶_2","page":"Convex bundle method","title":"Manopt.Î¶_2","text":"Î¶_2(Î©, Î´)\n\ncompute a curvature-dependent bound. The formula reads\n\nÎ¶_2 Î©(Î´) =\nbegincases   1  text if  Î©  0    sqrtÎ©Î´cot(sqrtÎ©Î´)  text if  Î©  0endcases\n\nwhere Î©  Îº_p for all p  mathcalU is an upper bound to the sectional curvature in a (strongly geodesically convex) bounded subset mathcalU  mathcalM) with diameter Î´.\n\n\n\n\n\n","category":"function"},{"location":"solvers/convex_bundle_method/#Manopt.close_point","page":"Convex bundle method","title":"Manopt.close_point","text":"close_point(M, p, tol; retraction_method=default_retraction_method(M, typeof(p)))\n\nsample a random point close to p  mathcalM) within a tolerance tol and a retraction.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_gradient_method/#Proximal-gradient-method","page":"Proximal Gradient Method","title":"Proximal gradient method","text":"","category":"section"},{"location":"solvers/proximal_gradient_method/#State","page":"Proximal Gradient Method","title":"State","text":"","category":"section"},{"location":"solvers/proximal_gradient_method/#Helping-functions","page":"Proximal Gradient Method","title":"Helping functions","text":"","category":"section"},{"location":"solvers/proximal_gradient_method/#Stopping-criteria","page":"Proximal Gradient Method","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/proximal_gradient_method/#Sec-ProxGrad-Stepsize","page":"Proximal Gradient Method","title":"Stepsize","text":"","category":"section"},{"location":"solvers/proximal_gradient_method/#Internal-functions","page":"Proximal Gradient Method","title":"Internal functions","text":"","category":"section"},{"location":"solvers/proximal_gradient_method/#Literature","page":"Proximal Gradient Method","title":"Literature","text":"R.Â Bergmann, H.Â Jasa, P.Â John and M.Â Pfeffer. The Intrinsic Riemannian Proximal Gradient Method for Convex Optimization, preprint (2025), arXiv:2507.16055.\n\n\n\nR.Â Bergmann, H.Â Jasa, P.Â John and M.Â Pfeffer. The Intrinsic Riemannian Proximal Gradient Method for Nonconvex Optimization, preprint (2025), arXiv:2506.09775.\n\n\n\nS.Â Feng, W.Â Huang, L.Â Song, S.Â Ying and T.Â Zeng. Proximal gradient method for nonconvex and nonsmooth optimization on Hadamard manifolds. OptimizationÂ Letters 16, 2277â€“2297 (2021).\n\n\n\n","category":"section"},{"location":"solvers/proximal_gradient_method/#Manopt.proximal_gradient_method","page":"Proximal Gradient Method","title":"Manopt.proximal_gradient_method","text":"proximal_gradient_method(M, f, g, grad_g, p=rand(M); prox_nonsmooth=nothing, kwargs...)\nproximal_gradient_method(M, mpgo::ManifoldProximalGradientObjective, p=rand(M); kwargs...)\nproximal_gradient_method!(M, f, g, grad_g, p; prox_nonsmooth=nothing, kwargs...)\nproximal_gradient_method!(M, mpgo::ManifoldProximalGradientObjective, p; kwargs...)\n\nPerform the proximal gradient method as introduced in [BJJP25b] and [BJJP25a]. See also [FHS+21] for a similar approach.\n\nGiven the minimization problem\n\noperatorname*argmin_pmathcalM f(p)\nquad text where  quad f(p) = g(p) + h(p)\n\nThis method performs the (intrinsic) proximal gradient method algorithm.\n\nLet Î»_k  0 be a sequence of (proximal) parameters, initialize p^(0) = p, and k=0.\n\nThen perform as long as the stopping criterion is not fulfilled\n\np^(k+1) = prox_Î»_khBigl(\noperatornameretr_a^(k)bigl(-Î»_k operatornamegrad g(a^(k)bigr)\nBigr)\n\nwhere a^(k)=p^(k) by default, but it allows to introduce some acceleration before computing the gradient step.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v total cost function f = g + h\ng:              the smooth part of the cost function\ngrad_g:           a gradient (M,p) -> X or (M, X, p) -> X of the smooth part g of the problem\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nacceleration=(p, s, k) -> (copyto!(get_manifold(M), s.a, s.p); s): a function (problem, state, k) -> state to compute an acceleration, that is performed before the gradient step - the default is to copy the current point to the acceleration point, i.e. no acceleration is performed\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nprox_nonsmooth:          a proximal map (M,Î»,p) -> q or (M, q, Î», p) -> q for the (possibly) nonsmoooth part h of f\nstepsize::Stepsize=default_stepsize(M,ProximalGradientMethodState): a functor inheriting from Stepsize to determine a step size that by default uses a ProximalGradientMethodBacktracking.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F, Nothing} = nothing:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place. or nothing to take the proximal map from the [ManifoldProximalGradientObjective`](@ref)\nsub_state::Union{AbstractManoptProblem, F} = evaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.. This field is ignored, if the sub_problem is Nothing.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_gradient_method/#Manopt.proximal_gradient_method!","page":"Proximal Gradient Method","title":"Manopt.proximal_gradient_method!","text":"proximal_gradient_method(M, f, g, grad_g, p=rand(M); prox_nonsmooth=nothing, kwargs...)\nproximal_gradient_method(M, mpgo::ManifoldProximalGradientObjective, p=rand(M); kwargs...)\nproximal_gradient_method!(M, f, g, grad_g, p; prox_nonsmooth=nothing, kwargs...)\nproximal_gradient_method!(M, mpgo::ManifoldProximalGradientObjective, p; kwargs...)\n\nPerform the proximal gradient method as introduced in [BJJP25b] and [BJJP25a]. See also [FHS+21] for a similar approach.\n\nGiven the minimization problem\n\noperatorname*argmin_pmathcalM f(p)\nquad text where  quad f(p) = g(p) + h(p)\n\nThis method performs the (intrinsic) proximal gradient method algorithm.\n\nLet Î»_k  0 be a sequence of (proximal) parameters, initialize p^(0) = p, and k=0.\n\nThen perform as long as the stopping criterion is not fulfilled\n\np^(k+1) = prox_Î»_khBigl(\noperatornameretr_a^(k)bigl(-Î»_k operatornamegrad g(a^(k)bigr)\nBigr)\n\nwhere a^(k)=p^(k) by default, but it allows to introduce some acceleration before computing the gradient step.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v total cost function f = g + h\ng:              the smooth part of the cost function\ngrad_g:           a gradient (M,p) -> X or (M, X, p) -> X of the smooth part g of the problem\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nacceleration=(p, s, k) -> (copyto!(get_manifold(M), s.a, s.p); s): a function (problem, state, k) -> state to compute an acceleration, that is performed before the gradient step - the default is to copy the current point to the acceleration point, i.e. no acceleration is performed\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nprox_nonsmooth:          a proximal map (M,Î»,p) -> q or (M, q, Î», p) -> q for the (possibly) nonsmoooth part h of f\nstepsize::Stepsize=default_stepsize(M,ProximalGradientMethodState): a functor inheriting from Stepsize to determine a step size that by default uses a ProximalGradientMethodBacktracking.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F, Nothing} = nothing:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place. or nothing to take the proximal map from the [ManifoldProximalGradientObjective`](@ref)\nsub_state::Union{AbstractManoptProblem, F} = evaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.. This field is ignored, if the sub_problem is Nothing.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_gradient_method/#Manopt.ProximalGradientMethodAcceleration","page":"Proximal Gradient Method","title":"Manopt.ProximalGradientMethodAcceleration","text":"ProximalGradientMethodAcceleration{P, T, F}\n\nCompute an acceleration step\n\na^(k) = operatornameretr_p^(k)bigl(\n  -Î²_koperatornameretr^-1_p^(k)(p)\nbigr)\n\nwhere p^(k) is the current iterate from the ProximalGradientMethodStates field p and the result is stored in state.a. The field p in this struct stores the last iterate.\n\nThe retraction and its inverse are taken from the state.\n\nFields\n\np - the last iterate\nÎ² - acceleration parameter function or value\ninverse_retraction_method - method for inverse retraction\nX - tangent vector for computations\n\nConstructor\n\nProximalGradientMethodAcceleration(M::AbstractManifold; kwargs...)\n\nGenerate the state for a given manifold M with initial iterate p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\n\nKeyword arguments\n\nÎ² = k -> (k-1)/(k+2) - acceleration parameter function or value\ninverse_retraction_method - method for inverse retraction\np - initial point\nX - initial tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_gradient_method/#Manopt.ProximalGradientMethodState","page":"Proximal Gradient Method","title":"Manopt.ProximalGradientMethodState","text":"ProximalGradientMethodState <: AbstractManoptSolverState\n\nState for the proximal_gradient_method solver.\n\nFields\n\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\na - point after acceleration step\np::P: a point on the manifold mathcalM  storing the current iterate\nq - point for storing gradient step\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nX - tangent vector for storing gradient\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nacceleration - a function (problem, state, k) -> state to compute an acceleration before the gradient step\nstepsize - a function or Stepsize object to compute the stepsize\nlast_stepsize - stores the last computed stepsize\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.   or nothing to take the proximal map from the ManifoldProximalGradientObjective\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.. This field is ignored, if the sub_problem is Nothing.\n\nConstructor\n\nProximalGradientMethodState(M::AbstractManifold; kwargs...)\n\nGenerate the state for a given manifold M with initial iterate p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\n\nKeyword arguments\n\nstepsize=default_stepsize(M, ProximalGradientMethodState)\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nacceleration=(p, s, k) -> (copyto!(get_manifold(M), s.a, s.p); s) by default no acceleration is performed\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} = nothing:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =AllocatingEvaluation():  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_gradient_method/#Manopt.ProximalGradientNonsmoothSubgradient","page":"Proximal Gradient Method","title":"Manopt.ProximalGradientNonsmoothSubgradient","text":"ProximalGradientNonsmoothSubgradient{F, R, P}\n\nStores a subgradient of the nonsmooth part h of the proximal gradient objective f = g + h, as well as the stepsize parameter Î»  â„.\n\nThis struct is also a functor in both formats     * (M, p) -> X to compute the gradient in allocating fashion. This is primarily used for computing a subgradient of the cost function h(q) + frac12Î»mathrmd^2(q p) that defines proximal map in the proximal gradient method. This reads\n\n    h(q) - frac1Î»log_q p\n\nis the proximity point where the proximal map is evaluated, i.e. the argument p of the proximal map operatornameprox_Î» h (p).\n\nFields\n\nX::F - the subgradient of the nonsmooth part of the total objective, i.e. the part of the objective whose proximal map is sought\nÎ»::R - the stepsize parameter for the proximal map\nproximity_point::P - point where the proximal map is evaluated, i.e. the argument of the proximal map that we want to solve for\n\nConstructor\n\nProximalGradientNonsmoothSubgradient(cost, Î», proximity_point)\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_gradient_method/#Manopt.ProximalGradientNonsmoothCost","page":"Proximal Gradient Method","title":"Manopt.ProximalGradientNonsmoothCost","text":"ProximalGradientNonsmoothCost{F, R, P}\n\nStores the nonsmooth part h of the proximal gradient objective f = g + h, as well as the stepsize parameter Î»  â„.\n\nThis struct is also a functor (M, q) -> v that can be used as a cost function within a solver, primarily for solving the proximal map subproblem formulation in the proximal gradient method, which reads\n\n    operatornameprox_Î» h(p) = operatorname*argmin_q  mathcalM) h(q) + frac12Î»mathrmd^2(q p)\n\nHence, the functor reads\n\n    (M q)  h(q) + \frac12Î» mathrmd^2(q p)\n\nand p is the proximity point where the proximal map is evaluated, i.e. the argument p of the proximal map operatornameprox_Î» h.\n\nFields\n\ncost::F - the nonsmooth part h of the proximal gradient objective, i.e. the part of the objective whose proximal map is sought\nÎ»::R - the stepsize parameter for the proximal map\nproximity_point::P - point where the proximal map is evaluated, i.e. the argument p of the proximal map operatornameprox_Î» h (p) that we want to solve for\n\nConstructor\n\nProximalGradientNonsmoothCost(cost, Î», proximity_point)\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_gradient_method/#Manopt.StopWhenGradientMappingNormLess","page":"Proximal Gradient Method","title":"Manopt.StopWhenGradientMappingNormLess","text":"StopWhenGradientMappingNormLess <: StoppingCriterion\n\nA stopping criterion based on the gradient mapping norm for proximal gradient methods.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nlast_change::Real: the last change recorded in this stopping criterion\nthreshold: the threshold for the change to check (run under to stop)\n\nConstructor\n\nStopWhenGradientMappingNormLess(Îµ)\n\nCreate a stopping criterion with threshold Îµ for the gradient mapping for the proximal_gradient_method. That is, this criterion indicates to stop when the gradient mapping has a norm less than Îµ. The gradient mapping GÎ»(p) is defined as -(1/Î») * logp(TÎ»(p)), where TÎ»(p) is the proximal mapping proxÎ» f(expp(-Î» * grad f(p))).\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_gradient_method/#Manopt.ProximalGradientMethodBacktracking","page":"Proximal Gradient Method","title":"Manopt.ProximalGradientMethodBacktracking","text":"ProximalGradientMethodBacktracking(; kwargs...)\nProximalGradientMethodBacktracking(M::AbstractManifold; kwargs...)\n\nCompute a stepsize for the proximal gradient method using a backtracking line search.\n\nFor the nonconvex case, the condition is:\n\nf(p) - f(T_Î»(p))  Î³Î»lVert G_Î»(p) rVert^2\n\nwhere G_Î»(p) = (1Î») * log_p(T_Î»(p)) is the gradient mapping.\n\nFor the convex case, the condition is:\n\ng(T_Î»(p))  g(p) + operatornamegrad g(p) log_p T_Î»(p) + frac12Î» mathrmd^2(p T_Î»(p))\n\nReturns a stepsize Î» that satisfies the specified condition.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ProximalGradientMethodBacktrackingStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_gradient_method/#Manopt.ProximalGradientMethodBacktrackingStepsize","page":"Proximal Gradient Method","title":"Manopt.ProximalGradientMethodBacktrackingStepsize","text":"ProximalGradientMethodBacktrackingStepsize <: Stepsize\n\nA functor for backtracking line search in proximal gradient methods.\n\nFields\n\ninitial_stepsize::T - initial step size guess\nsufficient_decrease::T - sufficient decrease parameter (default: 0.5)\ncontraction_factor::T - step size reduction factor (default: 0.5)\nstrategy::Symbol - :nonconvex or :convex (default: :nonconvex)\ncandidate_point::P - a working point used during backtracking\nlast_stepsize::T - the last computed stepsize\n\nConstructor\n\nProximalGradientMethodBacktrackingStepsize(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\ninitial_stepsize=1.0: initial stepsize to try\nstop_when_stepsize_less=1e-8: smallest stepsize when to stop (the last one before is taken)\nsufficient_decrease=0.5: sufficient decrease parameter\ncontraction_factor=0.5: step size reduction factor\nstrategy=:nonconvex: backtracking strategy, either :convex or :nonconvex\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_gradient_method/#Manopt.get_cost_smooth","page":"Proximal Gradient Method","title":"Manopt.get_cost_smooth","text":"get_cost_smooth(M::AbstractManifold, objective, p)\n\nHelper function to extract the smooth part g of a proximal gradient objective at the point p.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_gradient_method/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{<:ProximalGradientMethodState}}","page":"Proximal Gradient Method","title":"Manopt.default_stepsize","text":"default_stepsize(M::AbstractManifold, ::Type{<:ProximalGradientMethodState})\n\nReturns the default proximal stepsize, which is a nonconvex backtracking strategy.\n\n\n\n\n\n","category":"method"},{"location":"changelog/#Changelog","page":"Changelog","title":"Changelog","text":"All notable Changes to the Julia package Manopt.jl are documented in this file. The file was started with Version 0.4.\n\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning.","category":"section"},{"location":"changelog/#[0.5.33](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.33)-(February-18,-2026)","page":"Changelog","title":"0.5.33 (February 18, 2026)","text":"","category":"section"},{"location":"changelog/#Added","page":"Changelog","title":"Added","text":"A clarification on the use of AI in the CONTRIBUTING.md (#573)\n_produce_type now accepts the point p as an optional third argument, which can be used to produce objects with specific point type for internal buffers. The addition has been utilized in DirectionUpdateRules and Stepsizes to improve GPU and custom floating point type compatibility. (#577)\nAdded another package and paper using Manopt.jl to the about page (#576).","category":"section"},{"location":"changelog/#Fixed","page":"Changelog","title":"Fixed","text":"DistanceOverGradientsStepsize now requires explicitly passing a point as the second argument because it logically depends on receiving the initial point. (#577)","category":"section"},{"location":"changelog/#[0.5.32](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.32)-(January-15,-2026)","page":"Changelog","title":"0.5.32 (January 15, 2026)","text":"","category":"section"},{"location":"changelog/#Fixed-2","page":"Changelog","title":"Fixed","text":"Fixed failing precompilation related to the release of Glossaries.jl v0.1.1 (#567).","category":"section"},{"location":"changelog/#[0.5.31](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.31)-(January-11,-2026)","page":"Changelog","title":"0.5.31 (January 11, 2026)","text":"","category":"section"},{"location":"changelog/#Changed","page":"Changelog","title":"Changed","text":"Moved the documentation glossaries to using the new Glossaries.jl package.","category":"section"},{"location":"changelog/#[0.5.30](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.30)-(December-10,-2025)","page":"Changelog","title":"0.5.30 (December 10, 2025)","text":"","category":"section"},{"location":"changelog/#Added-2","page":"Changelog","title":"Added","text":"add keyword argument is_feasible_error to interior_point_Newton to control how to handle infeasible starting points (#556)\nadd keyword argument at_init to some debug options to control whether they print already at the initialisation and hence before the first iteration (#552)","category":"section"},{"location":"changelog/#Fixed-3","page":"Changelog","title":"Fixed","text":"fixed a few typos in the documentation (#557)\nfixed a bug in StopWhenRepeated where it stopped already at initialisation if the interior stopping criterion was satisfied (#558)","category":"section"},{"location":"changelog/#[0.5.29](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.29)-(November-26,-2025)","page":"Changelog","title":"0.5.29 (November 26, 2025)","text":"","category":"section"},{"location":"changelog/#Added-3","page":"Changelog","title":"Added","text":"a keyword argument atol to the ConstrainedManifoldObjective to set a tolerance for constraint satisfaction. (#545)\na spell checker following crate-ci/typos","category":"section"},{"location":"changelog/#Fixed-4","page":"Changelog","title":"Fixed","text":"Fixed a typo in DebugFeasibility, where an undefined variable was used. (#544)","category":"section"},{"location":"changelog/#Changed-2","page":"Changelog","title":"Changed","text":"Removed atol from DebugFeasibility and instead use the one newly added atol from the ConstrainedManifoldObjective. (#546)\nMove from CompatHelper to dependabot to keep track of dependency updates in Julia packages. (#547)\nmoved the ManoptTestSuite module to a sub module Manopt.Test within Manopt.jl,\n\nso it can be easier reused by others as well (#550)\n\nmoved to using a Project.toml for tests and an overall [Workspace]. This also allows finally to run single test files without installing all packages manually, but instead just switching to and instantiating the test environment. (#550)\nfor compatibility, state also [source] entries consistently in the sub Project.toml files. (#550)","category":"section"},{"location":"changelog/#[0.5.28](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.28)-(November-17,-2025)","page":"Changelog","title":"0.5.28 (November 17, 2025)","text":"","category":"section"},{"location":"changelog/#Changed-3","page":"Changelog","title":"Changed","text":"Unified the interfaces for line search related functions, especially,\nlinesearch_backtrack(M, F, p, X, s, decrease, contract, Î·, f0; kwargs...) now has lf0= and gradient= keyword arguments instead of positional ones for X and the last f0, respectively. It additionally has a Dlf0= keyword argument to pass the evaluated differential instead of the gradient, which otherwise defaults to calling the inner product.\nRefactor the nonmonotone linesearch stepsize to have an initial guess that can be set. For now it still afterwards performs the Barzilai-Borwein initial guess,\n\nso a constant initial guess is recommended here. The initial guess may be refactored in the future in a non-breaking release and the meaning of the initial guess in nonmonotone line search may change.","category":"section"},{"location":"changelog/#Fixed-5","page":"Changelog","title":"Fixed","text":"Change the construction of the product manifold in interior_point_newton from Ã— to ProductManifold, so that the algorithm also work on Product manifolds M, where it now correctly wraps M instead of extending it.\nUnified the doc strings for constrained problems.\nFixed a few typos in the doc strings of matrix update formulae within the quasi-Newton and CG solver.\nCovered one last line in proximal_gradient_plan","category":"section"},{"location":"changelog/#[0.5.27](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.27)-(November-11,-2025)","page":"Changelog","title":"0.5.27 (November 11, 2025)","text":"","category":"section"},{"location":"changelog/#Added-4","page":"Changelog","title":"Added","text":"In WolfePowellLinesearchStepsize, two new keyword arguments stop_increasing_at_step= and stop_decreasing_at_step= were added to limit the number of increase/decrease steps in the initial bracketing phase for splus and sminus, respectively. (resolves (#495))\nrefactor get_message to only allocate a string when it is asked to deliver one, not every time a message is actually stored. This makes the message system align more with get_reason.","category":"section"},{"location":"changelog/#[0.5.26](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.26)-(November-5,-2025)","page":"Changelog","title":"0.5.26 (November 5, 2025)","text":"","category":"section"},{"location":"changelog/#Added-5","page":"Changelog","title":"Added","text":"a vectorbundle_newton solver to find zeros of equations defined on vector bundles.","category":"section"},{"location":"changelog/#Fixed-6","page":"Changelog","title":"Fixed","text":"fixes a few inconsistencies regarding get_embedding, which now consistently uses a point type as positional second argument.","category":"section"},{"location":"changelog/#Changed-4","page":"Changelog","title":"Changed","text":"fixed a few typos in the documentation strings of a few solvers.\nfixed a typo in the documentation of LevenbergMarquardt.\nfixed a bug in an internal tex command to print sums in the documentation.\nfixed the use of mesh_adaptive_direct_search on manifolds with irrational injectivity radius.\nimproved the CONTRIBUTING.md to reflect the new code formatter we use, as mentioned in (#527).","category":"section"},{"location":"changelog/#[0.5.25](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.25)-(October-9,-2025)","page":"Changelog","title":"0.5.25 (October 9, 2025)","text":"","category":"section"},{"location":"changelog/#Changed-5","page":"Changelog","title":"Changed","text":"Bumped dependencies of all JuliaManifolds ecosystem packages to be consistent with ManifoldsBase.jl 2.0 and Manifolds.jl 0.11","category":"section"},{"location":"changelog/#[0.5.24](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.24)-(October-6,-2025)","page":"Changelog","title":"0.5.24 (October 6, 2025)","text":"","category":"section"},{"location":"changelog/#Added-6","page":"Changelog","title":"Added","text":"CubicBracketingLinesearch step size\nfallback in proximal_gradient_planto use the norm of the inverse retraction if the distance is not available.","category":"section"},{"location":"changelog/#[0.5.23](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.23)-(September-14,-2025)","page":"Changelog","title":"0.5.23 (September 14, 2025)","text":"","category":"section"},{"location":"changelog/#Added-7","page":"Changelog","title":"Added","text":"HybridCoefficient(args...) conjugate gradient parameters.\na function has_converged(sc) function for any StoppingCriterion to indicate that it both has stopped and the reason is a convergence certificate. Note that compared to the static evaluation of indicates_convergence(sc), which is independent of the state of the criterion, this is the dynamic variant to be used after a solver has stopped.\na has_converged(::AbstractManoptSolverState) function to check whether the solver has converged.","category":"section"},{"location":"changelog/#Changed-6","page":"Changelog","title":"Changed","text":"formerly a stopping criterion could be activated at certain iterations with sc > 5, sc >= 5, sc == 5, sc <= 5, and sc < 5. This caused too many issues with invalidations, so it has been reduced and moved to sc â©¼ 5, sc â‰Ÿ 5, sc â©» 5 for the cases 1, 3, and 5, respectively, cf. (#509).\nRefine the JuMP extension and add an allocation-free cost and gradient callback for JuMP interface (#498)","category":"section"},{"location":"changelog/#[0.5.22](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.22)-(September-09,-2025)","page":"Changelog","title":"0.5.22 (September 09, 2025)","text":"","category":"section"},{"location":"changelog/#Added-8","page":"Changelog","title":"Added","text":"a keywords_accepted(f, mode=:warn; kwargs...) function that verifies that all keywords are accepted by a certain function.\nan internal function calls_with_kwargs(f) to indicate which functions f passes kwargs... to.\na KeywordsErrorMode preference parameter to control how keywords that are not used/allowed should be treated. Values are \"none\", \"warn\" (default), and \"error\".\nAdd Distance over Gradients (RDoG) stepsize: DistanceOverGradientsStepsize and factory DistanceOverGradients, a learningâ€‘rateâ€‘free, curvatureâ€‘aware stepsize with show/repr and tests on Euclidean, Sphere, and Hyperbolic manifolds.","category":"section"},{"location":"changelog/#Fixed-7","page":"Changelog","title":"Fixed","text":"the typo in the name AdaptiveRgularizationWithCubicsModelObjective is fixed to AdaptiveRegularizationWithCubicsModelObjective.","category":"section"},{"location":"changelog/#[0.5.21](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.21)-(September-5,-2025)","page":"Changelog","title":"0.5.21 (September 5, 2025)","text":"","category":"section"},{"location":"changelog/#Added-9","page":"Changelog","title":"Added","text":"a system to track keywords, warning when unused ones are passed and a static way to explore possible keywords.\na warm_start_factor field to ProximalGradientMethodBacktrackingStepsize to allow to scale the stepsize in the backtracking procedure.\na gradient= keyword in several Stepsizes, such that one can avoid to internally avoid computing the gradient again.\nused the `gradient= keyword in\nalternating_gradient_descent\nconjugate_gradient\nFrank_Wolfe_method\ngradient_descent\ninterior_point_newton\nquasi_Newton\nprojected_gradient_method\na restart_condition functor to conjugate_gradient_descent, which allows the algorithm to restart if the search direction is sub-par (#492)\ntwo literature references","category":"section"},{"location":"changelog/#Changed-7","page":"Changelog","title":"Changed","text":"remodelled the docs for the extensions a bit, added JuMP to the DocumenterInterlinks.\nthe internal VectorizedManifold within that extension is now called ManifoldSet\nthe internal ArrayShape within that extensionis not called ManifoldPointArrayShape\nSwitch to using Runic.jl as code formatter","category":"section"},{"location":"changelog/#Fixed-8","page":"Changelog","title":"Fixed","text":"Fixed some math rendering in the docs, especially avoid raw strings and interpolate math symbols more often.","category":"section"},{"location":"changelog/#Fixed-9","page":"Changelog","title":"Fixed","text":"Fixed allocations in the callbacks of the JuMP interface so that the solver can query the cost and gradient without allocating.","category":"section"},{"location":"changelog/#[0.5.20](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.20)-(July-8,-2025)","page":"Changelog","title":"0.5.20 (July 8, 2025)","text":"","category":"section"},{"location":"changelog/#Added-10","page":"Changelog","title":"Added","text":"a DebugWarnIfStepsizeCollapsed DebugAction and a related :WarnStepsize symbol for the debug dictionary. This is to be used in conjunction with the ProximalGradientMethodBacktracking stepsize to warn if the backtracking procedure of the proximal_gradient_method hit the stepsize length threshold without converging.","category":"section"},{"location":"changelog/#Changed-8","page":"Changelog","title":"Changed","text":"bumped dependencies.","category":"section"},{"location":"changelog/#Fixed-10","page":"Changelog","title":"Fixed","text":"Fixed a few typos in the docs.","category":"section"},{"location":"changelog/#[0.5.19](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.19)-(July-4,-2025)","page":"Changelog","title":"0.5.19 (July 4, 2025)","text":"","category":"section"},{"location":"changelog/#Added-11","page":"Changelog","title":"Added","text":"a function get_differential and get_differential_function for first order objectives.\na ParentEvaluationType to indicate that a certain objective inherits it evaluation from the parent (wrapping) objective\na new AllocatingInplaceEvaluation that is used for the functions that offer both variants simultaneously.\na differential= keyword for providing a faster way of computing inner(M, p, grad_f(p), X), introduced to the algorithms conjugate_gradient_descent, gradient_descent, Frank_Wolfe_method, quasi_Newton","category":"section"},{"location":"changelog/#Changed-9","page":"Changelog","title":"Changed","text":"the ManifoldGradientObjective and the ManifoldCostGradientObjective are now merely a const special cases of the ManifoldFirstOrderObjective, since this type might now also represent a differential or other combinations of cost, grad, and differential, where they are computed together.\nthe AbstractManifoldGradientObjective is renamed to AbstractManifoldFirstOrderObjective, since the\n\nsecond function might now also represent a differential.","category":"section"},{"location":"changelog/#Fixed-11","page":"Changelog","title":"Fixed","text":"fixes a small bug where calling mesh_adaptive_direct_search with a start point in some cases did not initialise the state correctly with that start point.\nThe HestenesStiefelCoefficient now also always returns a real value, similar the other coefficient rules. To the best of our knowledge, this might have been a bug previously.","category":"section"},{"location":"changelog/#[0.5.18](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.18)-(June-18,-2025)","page":"Changelog","title":"0.5.18 (June 18, 2025)","text":"","category":"section"},{"location":"changelog/#Added-12","page":"Changelog","title":"Added","text":"Introduce the algorithm proximal_gradient_method along with ManifoldProximalGradientObjective, ProximalGradientMethodState, as well as an experimental ProximalGradientMethodAcceleration.\nAdd ProximalGradientMethodBacktracking stepsize.\nAdd StopWhenGradientMappingNormLess stopping criterion.\nIntroduce a StopWhenRepeated stopping criterion that stops when the given stopping criterion has indicated to stop n times (consecutively, if consecutive=true).\nIntroduce a StopWhenCriterionWithIterationCondition stopping criterion that stops when a given stopping criterion has been satisfied together with a certain iteration condition. This can the generated even with shortcuts like sc > 5\nIntroduce a DebugCallback that allows to add a callback function to the debug system\nIntroduce a callback= keyword to all solvers.\nAdded back functions estimate_sectional_curvature, Î¶_1, Î¶_2, close_point from convex_bundle_method; the function call can stay the same as before since there is a curvature estimation fallback\nAdd back some fields and arguments such as p_estimate, Ï±, Î±, from ConvexBundleMethodState","category":"section"},{"location":"changelog/#Changed-10","page":"Changelog","title":"Changed","text":"make the GradientDescentState a bit more tolerant to ignore keywords it does not use.","category":"section"},{"location":"changelog/#[0.5.17](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.17)-(June-3,-2025)","page":"Changelog","title":"0.5.17 (June 3, 2025)","text":"","category":"section"},{"location":"changelog/#Added-13","page":"Changelog","title":"Added","text":"Introduce a StopWhenCostChangeLess stopping criterion that stops when the cost function changes less than a given value.","category":"section"},{"location":"changelog/#[0.5.16](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.16)-(May-7,-2025)","page":"Changelog","title":"0.5.16 (May 7, 2025)","text":"","category":"section"},{"location":"changelog/#Fixed-12","page":"Changelog","title":"Fixed","text":"fixes a bug in the LineSearches.jl extension, where two (old) retract!s were still\n\npresent; they were changed to retact_fused!.","category":"section"},{"location":"changelog/#[0.5.15](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.15)-(May-6,-2025)","page":"Changelog","title":"0.5.15 (May 6, 2025)","text":"","category":"section"},{"location":"changelog/#Fixed-13","page":"Changelog","title":"Fixed","text":"CMA-ES no longer errors when the covariance matrix has nonpositive eigenvalues due to numerical issues.","category":"section"},{"location":"changelog/#[0.5.14](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.14)-(May-5,-2025)","page":"Changelog","title":"0.5.14 (May 5, 2025)","text":"","category":"section"},{"location":"changelog/#Added-14","page":"Changelog","title":"Added","text":"linear_subsolver! is added as a keyword argument to the Levenberg-Marquardt interface.","category":"section"},{"location":"changelog/#Changed-11","page":"Changelog","title":"Changed","text":"adapt to using default_basis where appropriate.\nthe tutorials are now rendered with quarto using the QuartoNotebookRunner.jl and are hence purely julia based.","category":"section"},{"location":"changelog/#[0.5.13](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.13)-(April-25,-2025)","page":"Changelog","title":"0.5.13 (April 25, 2025)","text":"","category":"section"},{"location":"changelog/#Added-15","page":"Changelog","title":"Added","text":"Allow setting AbstractManifoldObjective through JuMP","category":"section"},{"location":"changelog/#Changed-12","page":"Changelog","title":"Changed","text":"Remove dependency on ManoptExamples.jl which yielded a circular dependency, though only through extras\nUnify dummy types and several test functions into the ManoptTestSuite subpackage.","category":"section"},{"location":"changelog/#Fixed-14","page":"Changelog","title":"Fixed","text":"A scaling error that appeared only when calling get_cost_function on the new ScaledManifoldObjective.\nDocumentation issues for quasi-Newton solvers.\nfixes a scaling error in quasi newton\nFixes printing of JuMP models containing Manopt solver.","category":"section"},{"location":"changelog/#[0.5.12](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.12)-(April-13,-2025)","page":"Changelog","title":"0.5.12 (April 13, 2025)","text":"","category":"section"},{"location":"changelog/#Added-16","page":"Changelog","title":"Added","text":"a ScaledManifoldObjective to easier build scaled versions of objectives, especially turn maximisation problems into minimisation ones using a scaling of -1.\nIntroduce a ManifoldConstrainedSetObjective\nIntroduce a projected_gradient_method","category":"section"},{"location":"changelog/#[0.5.11](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.11)-(April-8,-2025)","page":"Changelog","title":"0.5.11 (April 8, 2025)","text":"","category":"section"},{"location":"changelog/#Added-17","page":"Changelog","title":"Added","text":"Configurable subsolver for the linear subproblem in Levenberg-Marquardt. The default subsolver is now also robust to numerical issues that may cause Cholesky decomposition to fail.","category":"section"},{"location":"changelog/#[0.5.10](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.10)-(April-4,-2025)","page":"Changelog","title":"0.5.10 (April 4, 2025)","text":"","category":"section"},{"location":"changelog/#Fixed-15","page":"Changelog","title":"Fixed","text":"a proper implementation of the preconditioning for quasi_Newton, that can be used instead of or in combination with the initial scaling.","category":"section"},{"location":"changelog/#[0.5.9](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.9)-(March-24,-2025)","page":"Changelog","title":"0.5.9 (March 24, 2025)","text":"","category":"section"},{"location":"changelog/#Added-18","page":"Changelog","title":"Added","text":"add a PreconditionedDirection variant to the direction gradient processor keyword argument and its corresponding PreconditionedDirectionRule\nmake the preconditioner available in quasi Newton.\nin gradient_descent and conjugate_gradient_descent the rule can be added anyway.","category":"section"},{"location":"changelog/#Fixed-16","page":"Changelog","title":"Fixed","text":"the links in the AD tutorial are fixed and moved to using extref","category":"section"},{"location":"changelog/#[0.5.8](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.8)-(February-28,-2025)","page":"Changelog","title":"0.5.8 (February 28, 2025)","text":"","category":"section"},{"location":"changelog/#Fixed-17","page":"Changelog","title":"Fixed","text":"fixed a small bug in the NonmonotoneLinesearchStepsize hwn the injectivity radius is an irrational number.\nfixed a small bug in check_gradient where eps might have been called on complex types.\nfixed a bug in several gradient based solvers like quasi_newton, such that they properly work with the combined cost grad objective.\nfixes a few typos in the docs.","category":"section"},{"location":"changelog/#[0.5.7](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.7)-(February-20,-20265)","page":"Changelog","title":"0.5.7 (February 20, 20265)","text":"","category":"section"},{"location":"changelog/#Added-19","page":"Changelog","title":"Added","text":"Adds a mesh adaptive direct search algorithm (MADS), using the LTMADS variant with a lower triangular (LT) random matrix in the mesh generation.","category":"section"},{"location":"changelog/#[0.5.6](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.6)-(February-10,-2025)","page":"Changelog","title":"0.5.6 (February 10, 2025)","text":"","category":"section"},{"location":"changelog/#Changed-13","page":"Changelog","title":"Changed","text":"bump dependencies of all JuliaManifolds ecosystem packages to be consistent with ManifoldsBase 1.0","category":"section"},{"location":"changelog/#[0.5.5](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.5)-(January-4,-2025)","page":"Changelog","title":"0.5.5 (January 4, 2025)","text":"","category":"section"},{"location":"changelog/#Added-20","page":"Changelog","title":"Added","text":"the Levenberg-Marquardt algorithm internally uses a VectorGradientFunction, which allows\n\nto use a vector of gradients of a function returning all gradients as well for the algorithm\n\nThe VectorGradientFunction now also have a get_jacobian function","category":"section"},{"location":"changelog/#Changed-14","page":"Changelog","title":"Changed","text":"Minimum Julia version is now 1.10 (the LTS which replaced 1.6)\nThe vectorial functions had a bug where the original vector function for the mutating case was not always treated as mutating.","category":"section"},{"location":"changelog/#Removed","page":"Changelog","title":"Removed","text":"The geodesic regression example, first because it is not correct, second because it should become part of ManoptExamples.jl once it is correct.","category":"section"},{"location":"changelog/#[0.5.4](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.4)-(December-11,-2024)","page":"Changelog","title":"0.5.4 (December 11, 2024)","text":"","category":"section"},{"location":"changelog/#Added-21","page":"Changelog","title":"Added","text":"An automated detection whether the tutorials are present  if not an also no quarto run is done, an automated --exclude-tutorials option is added.\nSupport for ManifoldDiff 0.4\nicons upfront external links when they link to another package or Wikipedia.","category":"section"},{"location":"changelog/#[0.5.3](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.3)-(October-18,-2024)","page":"Changelog","title":"0.5.3 (October 18, 2024)","text":"","category":"section"},{"location":"changelog/#Added-22","page":"Changelog","title":"Added","text":"StopWhenChangeLess, StopWhenGradientChangeLess and StopWhenGradientLess can now use the new idea (ManifoldsBase.jl 0.15.18) of different outer norms on manifolds with components like power and product manifolds and all others that support this from the Manifolds.jl Library, like Euclidean","category":"section"},{"location":"changelog/#Changed-15","page":"Changelog","title":"Changed","text":"stabilize max_stepsize to also work when injectivity_radius dos not exist. It however would warn new users, that activate tutorial mode.\nStart a ManoptTestSuite sub package to store dummy types and common test helpers in.","category":"section"},{"location":"changelog/#[0.5.2](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.2)-(October-5,-2024)","page":"Changelog","title":"0.5.2 (October 5, 2024)","text":"","category":"section"},{"location":"changelog/#Added-23","page":"Changelog","title":"Added","text":"three new symbols to easier state to record the :Gradient, the :GradientNorm, and the :Stepsize.","category":"section"},{"location":"changelog/#Changed-16","page":"Changelog","title":"Changed","text":"fix a few typos in the documentation\nimproved the documentation for the initial guess of ArmijoLinesearchStepsize.","category":"section"},{"location":"changelog/#[0.5.1](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.1)-(September-4,-2024)","page":"Changelog","title":"0.5.1 (September 4, 2024)","text":"","category":"section"},{"location":"changelog/#Changed-17","page":"Changelog","title":"Changed","text":"slightly improves the test for the ExponentialFamilyProjection text on the about page.","category":"section"},{"location":"changelog/#Added-24","page":"Changelog","title":"Added","text":"the proximal_point method.","category":"section"},{"location":"changelog/#[0.5.0](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.5.0)-(August-29,-2024)","page":"Changelog","title":"0.5.0 (August 29, 2024)","text":"This breaking update is mainly concerned with improving a unified experience through all solvers and some usability improvements, such that for example the different gradient update rules are easier to specify.\n\nIn general this introduces a few factories, that avoid having to pass the manifold to keyword arguments","category":"section"},{"location":"changelog/#Added-25","page":"Changelog","title":"Added","text":"A ManifoldDefaultsFactory that postpones the creation/allocation of manifold-specific fields in for example direction updates, step sizes and stopping criteria. As a rule of thumb, internal structures, like a solver state should store the final type. Any high-level interface, like the functions to start solvers, should accept such a factory in the appropriate places and call the internal _produce_type(factory, M), for example before passing something to the state.\na documentation_glossary.jl file containing a glossary of often used variables in fields, arguments, and keywords, to print them in a unified manner. The same for usual sections, text, and math notation that is often used within the doc-strings.","category":"section"},{"location":"changelog/#Changed-18","page":"Changelog","title":"Changed","text":"Any Stepsize now has a Stepsize struct used internally as the original structs before. The newly exported terms aim to fit stepsize=... in naming and create a ManifoldDefaultsFactory instead, so that any stepsize can be created without explicitly specifying the manifold.\nConstantStepsize is no longer exported, use ConstantLength instead. The length parameter is now a positional argument following the (optional) manifold. Besides that ConstantLength works as before,just that omitting the manifold fills the one specified in the solver now.\nDecreasingStepsize is no longer exported, use DecreasingLength instead. ConstantLength works as before,just that omitting the manifold fills the one specified in the solver now.\nArmijoLinesearch is now called ArmijoLinesearchStepsize. ArmijoLinesearch works as before,just that omitting the manifold fills the one specified in the solver now.\nWolfePowellLinesearch is now called WolfePowellLinesearchStepsize, its constant c_1 is now unified with Armijo and called sufficient_decrease, c_2 was renamed to sufficient_curvature. Besides that, WolfePowellLinesearch works as before, just that omitting the manifold fills the one specified in the solver now.\nWolfePowellBinaryLinesearch is now called WolfePowellBinaryLinesearchStepsize, its constant c_1 is now unified with Armijo and called sufficient_decrease, c_2 was renamed to sufficient_curvature. Besides that, WolfePowellBinaryLinesearch works as before, just that omitting the manifold fills the one specified in the solver now.\nNonmonotoneLinesearch is now called NonmonotoneLinesearchStepsize. NonmonotoneLinesearch works as before, just that omitting the manifold fills the one specified in the solver now.\nAdaptiveWNGradient is now called AdaptiveWNGradientStepsize. Its second positional argument, the gradient function was only evaluated once for the gradient_bound default, so it has been replaced by the keyword X= accepting a tangent vector. The last positional argument p has also been moved to a keyword argument. Besides that, AdaptiveWNGradient works as before, just that omitting the manifold fills the one specified in the solver now.\nAny DirectionUpdateRule now has the Rule in its name, since the original name is used to create the ManifoldDefaultsFactory instead. The original constructor now no longer requires the manifold as a parameter, that is later done in the factory. The Rule is, however, also no longer exported.\nAverageGradient is now called AverageGradientRule. AverageGradient works as before, but the manifold as its first parameter is no longer necessary and p is now a keyword argument.\nThe IdentityUpdateRule now accepts a manifold optionally for consistency, and you can use Gradient() for short as well as its factory. Hence direction=Gradient() is now available.\nMomentumGradient is now called MomentumGradientRule. MomentumGradient works as before, but the manifold as its first parameter is no longer necessary and p is now a keyword argument.\nNesterov is now called NesterovRule. Nesterov works as before, but the manifold as its first parameter is no longer necessary and p is now a keyword argument.\nConjugateDescentCoefficient is now called ConjugateDescentCoefficientRule. ConjugateDescentCoefficient works as before, but can now use the factory in between\nthe ConjugateGradientBealeRestart is now called ConjugateGradientBealeRestartRule. For the ConjugateGradientBealeRestart the manifold is now a first parameter, that is not necessary and no longer the manifold= keyword.\nDaiYuanCoefficient is now called DaiYuanCoefficientRule. For the DaiYuanCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nFletcherReevesCoefficient is now called FletcherReevesCoefficientRule. FletcherReevesCoefficient works as before, but can now use the factory in between\nHagerZhangCoefficient is now called HagerZhangCoefficientRule. For the HagerZhangCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nHestenesStiefelCoefficient is now called HestenesStiefelCoefficientRule. For the HestenesStiefelCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nLiuStoreyCoefficient is now called LiuStoreyCoefficientRule. For the LiuStoreyCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nPolakRibiereCoefficient is now called PolakRibiereCoefficientRule. For the PolakRibiereCoefficient the manifold as its first parameter is no longer necessary and the vector transport has been unified/moved to the vector_transport_method= keyword.\nthe SteepestDirectionUpdateRule is now called SteepestDescentCoefficientRule. The SteepestDescentCoefficient is equivalent, but creates the new factory temporarily.\nAbstractGradientGroupProcessor is now called AbstractGradientGroupDirectionRule\nthe StochasticGradient is now called StochasticGradientRule. The StochasticGradient is equivalent, but creates the new factory temporarily, so that the manifold is not longer necessary.\nthe AlternatingGradient is now called AlternatingGradientRule.\nThe AlternatingGradient is equivalent, but creates the new factory temporarily, so that the manifold is not longer necessary.\nquasi_Newton had a keyword scale_initial_operator= that was inconsistently declared (sometimes boolean, sometimes real) and was unused. It is now called initial_scale=1.0 and scales the initial (diagonal, unit) matrix within the approximation of the Hessian additionally to the frac1lVert g_krVert scaling with the norm of the oldest gradient for the limited memory variant. For the full matrix variant the initial identity matrix is now scaled with this parameter.\nUnify doc strings and presentation of keyword arguments\ngeneral indexing, for example in a vector, uses i\nindex for inequality constraints is unified to i running from 1,...,m\nindex for equality constraints is unified to j running from 1,...,n\niterations are using now k\nget_manopt_parameter has been renamed to get_parameter since it is internal, so internally that is clear; accessing it from outside hence reads anyway Manopt.get_parameter\nset_manopt_parameter! has been renamed to set_parameter! since it is internal, so internally that is clear; accessing it from outside hence reads Manopt.set_parameter!\nchanged the stabilize::Bool= keyword in quasi_Newton to the more flexible project!= keyword, this is also more in line with the other solvers. Internally the same is done within the QuasiNewtonLimitedMemoryDirectionUpdate. To adapt,\nthe previous stabilize=true is now set with (project!)=embed_project! in general, and if the manifold is represented by points in the embedding, like the sphere, (project!)=project! suffices\nthe new default is (project!)=copyto!, so by default no projection/stabilization is performed.\nthe positional argument p (usually the last or the third to last if sub solvers existed) has been moved to a keyword argument p= in all State constructors\nin NelderMeadState the population moved from positional to keyword argument as well,\nthe way to initialise sub solvers in the solver states has been unified In the new variant\nthe sub_problem is always a positional argument; namely the last one\nif the sub_state is given as a optional positional argument after the problem, it has to be a manopt solver state\nyou can provide the new ClosedFormSolverState(e::AbstractEvaluationType) for the state to indicate that the sub_problem is a closed form solution (function call) and how it has to be called\nif you do not provide the sub_state as positional, the keyword evaluation= is used to generate the state ClosedFormSolverState.\nwhen previously p and eventually X where positional arguments, they are now moved to keyword arguments of the same name for start point and tangent vector.\nin detail\nAdaptiveRegularizationState(M, sub_problem [, sub_state]; kwargs...) replaces the (unused) variant to only provide the objective; both X and p moved to keyword arguments.\nAugmentedLagrangianMethodState(M, objective, sub_problem; evaluation=...) was added\nAugmentedLagrangianMethodState(M, objective, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nExactPenaltyMethodState(M, sub_problem; evaluation=...) was added and ExactPenaltyMethodState(M, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nDifferenceOfConvexState(M, sub_problem; evaluation=...) was added and DifferenceOfConvexState(M, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nDifferenceOfConvexProximalState(M, sub_problem; evaluation=...) was added and DifferenceOfConvexProximalState(M, sub_problem, sub_state; evaluation=...) now has p=rand(M) as keyword argument instead of being the second positional one\nbumped Manifolds.jlto version 0.10; this mainly means that any algorithm working on a product manifold and requiring ArrayPartition now has to explicitly do using RecursiveArrayTools.","category":"section"},{"location":"changelog/#Fixed-18","page":"Changelog","title":"Fixed","text":"the AverageGradientRule filled its internal vector of gradients wrongly or mixed it up in parallel transport. This is now fixed.","category":"section"},{"location":"changelog/#Removed-2","page":"Changelog","title":"Removed","text":"the convex_bundle_method and its ConvexBundleMethodState no longer accept the keywords k_size, p_estimate nor Ï±, they are superseded by just providing k_max.\nthe truncated_conjugate_gradient_descent(M, f, grad_f, hess_f) has the Hessian now  a mandatory argument. To use the old variant,  provide ApproxHessianFiniteDifference(M, copy(M, p), grad_f) to hess_f directly.\nall deprecated keyword arguments and a few function signatures were removed:\nget_equality_constraints, get_equality_constraints!, get_inequality_constraints, get_inequality_constraints! are removed. Use their singular forms and set the index to : instead.\nStopWhenChangeLess(Îµ) is removed, use `StopWhenChangeLess(M, Îµ) instead to fill for example the retraction properly used to determine the change\nIn the WolfePowellLinesearch and  WolfeBinaryLinesearchthe linesearch_stopsize= keyword is replaced by stop_when_stepsize_less=\nDebugChange and RecordChange had a manifold= and a invretr keyword that were replaced by the first positional argument M and inverse_retraction_method=, respectively\nin the NonlinearLeastSquaresObjective and LevenbergMarquardt the jacB= keyword is now called jacobian_tangent_basis=\nin particle_swarm the n= keyword is replaced by swarm_size=.\nupdate_stopping_criterion! has been removed and unified with set_parameter!. The code adaptions are\nto set a parameter of a stopping criterion, just replace update_stopping_criterion!(sc, :Val, v) with set_parameter!(sc, :Val, v)\nto update a stopping criterion in a solver state, replace the old update_stopping_criterion!(state, :Val, v) tat passed down to the stopping criterion by the explicit pass down with set_parameter!(state, :StoppingCriterion, :Val, v)","category":"section"},{"location":"changelog/#[0.4.69](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.69)-(August-3,-2024)","page":"Changelog","title":"0.4.69 (August 3, 2024)","text":"","category":"section"},{"location":"changelog/#Changed-19","page":"Changelog","title":"Changed","text":"Improved performance of Interior Point Newton Method.","category":"section"},{"location":"changelog/#[0.4.68](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.68)-(August-2,-2024)","page":"Changelog","title":"0.4.68 (August 2, 2024)","text":"","category":"section"},{"location":"changelog/#Added-26","page":"Changelog","title":"Added","text":"an Interior Point Newton Method, the interior_point_newton\na conjugate_residual Algorithm to solve a linear system on a tangent space.\nArmijoLinesearch now allows for additional additional_decrease_condition and additional_increase_condition keywords to add further conditions to accept additional conditions when to accept an decreasing or increase of the stepsize.\nadd a DebugFeasibility to have a debug print about feasibility of points in constrained optimisation employing the new is_feasible function\nadd a InteriorPointCentralityCondition that can be added for step candidates within the line search of interior_point_newton\nAdd Several new functors\nthe LagrangianCost, LagrangianGradient, LagrangianHessian, that based on a constrained objective allow to construct the Hessian objective of its Lagrangian\nthe CondensedKKTVectorField and its CondensedKKTVectorFieldJacobian, that are being used to solve a linear system within interior_point_newton\nthe KKTVectorField as well as its KKTVectorFieldJacobian and `KKTVectorFieldAdjointJacobian\nthe KKTVectorFieldNormSq and its KKTVectorFieldNormSqGradient used within the Armijo line search of interior_point_newton\nNew stopping criteria\nA StopWhenRelativeResidualLess for the conjugate_residual\nA StopWhenKKTResidualLess for the interior_point_newton","category":"section"},{"location":"changelog/#[0.4.67](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.67)-(July-25,-2024)","page":"Changelog","title":"0.4.67 (July 25, 2024)","text":"","category":"section"},{"location":"changelog/#Added-27","page":"Changelog","title":"Added","text":"max_stepsize methods for Hyperrectangle.","category":"section"},{"location":"changelog/#Fixed-19","page":"Changelog","title":"Fixed","text":"a few typos in the documentation\nWolfePowellLinesearch no longer uses max_stepsize with invalid point by default.","category":"section"},{"location":"changelog/#[0.4.66](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.66)-(June-27,-2024)","page":"Changelog","title":"0.4.66 (June 27, 2024)","text":"","category":"section"},{"location":"changelog/#Changed-20","page":"Changelog","title":"Changed","text":"Remove functions estimate_sectional_curvature, Î¶_1, Î¶_2, close_point from convex_bundle_method\nRemove some unused fields and arguments such as p_estimate, Ï±, Î±, from ConvexBundleMethodState in favor of jut k_max\nChange parameter R placement in ProximalBundleMethodState to fifth position","category":"section"},{"location":"changelog/#[0.4.65](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.65)-(June-13,-2024)","page":"Changelog","title":"0.4.65 (June 13, 2024)","text":"","category":"section"},{"location":"changelog/#Changed-21","page":"Changelog","title":"Changed","text":"refactor stopping criteria to not store a sc.reason internally, but instead only generate the reason (and hence allocate a string) when actually asked for a reason.","category":"section"},{"location":"changelog/#[0.4.64](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.64)-(June-4,-2024)","page":"Changelog","title":"0.4.64 (June 4, 2024)","text":"","category":"section"},{"location":"changelog/#Added-28","page":"Changelog","title":"Added","text":"Remodel the constraints and their gradients into separate VectorGradientFunctions to reduce code duplication and encapsulate the inner model of these functions and their gradients\nIntroduce a ConstrainedManoptProblem to model different ranges for the gradients in the new VectorGradientFunctions beyond the default NestedPowerRepresentation\nintroduce a VectorHessianFunction to also model that one can provide the vector of Hessians to constraints\nintroduce a more flexible indexing beyond single indexing, to also include arbitrary ranges when accessing vector functions and their gradients and hence also for constraints and their gradients.","category":"section"},{"location":"changelog/#Changed-22","page":"Changelog","title":"Changed","text":"Remodel ConstrainedManifoldObjective to store an AbstractManifoldObjective internally instead of directly f and grad_f, allowing also Hessian objectives therein and implementing access to this Hessian\nFixed a bug that Lanczos produced NaNs when started exactly in a minimizer, since the algorithm initially divides by the gradient norm.","category":"section"},{"location":"changelog/#Deprecated","page":"Changelog","title":"Deprecated","text":"deprecate get_grad_equality_constraints(M, o, p), use get_grad_equality_constraint(M, o, p, :) from the more flexible indexing instead.","category":"section"},{"location":"changelog/#[0.4.63](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.63)-(May-11,-2024)","page":"Changelog","title":"0.4.63 (May 11, 2024)","text":"","category":"section"},{"location":"changelog/#Added-29","page":"Changelog","title":"Added","text":":reinitialize_direction_update option for quasi-Newton behavior when the direction is not a descent one. It is now the new default for QuasiNewtonState.\nQuasi-Newton direction update rules are now initialized upon start of the solver with the new internal function initialize_update!.","category":"section"},{"location":"changelog/#Fixed-20","page":"Changelog","title":"Fixed","text":"ALM and EPM no longer keep a part of the quasi-Newton subsolver state between runs.","category":"section"},{"location":"changelog/#Changed-23","page":"Changelog","title":"Changed","text":"Quasi-Newton solvers: :reinitialize_direction_update is the new default behavior in case of detection of non-descent direction instead of :step_towards_negative_gradient. :step_towards_negative_gradient is still available when explicitly set using the nondescent_direction_behavior keyword argument.","category":"section"},{"location":"changelog/#[0.4.62](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.62)-(May-3,-2024)","page":"Changelog","title":"0.4.62 (May 3, 2024)","text":"","category":"section"},{"location":"changelog/#Changed-24","page":"Changelog","title":"Changed","text":"bumped dependency of ManifoldsBase.jl to 0.15.9 and imported their numerical verify functions. This changes the throw_error keyword used internally to a error= with a symbol.","category":"section"},{"location":"changelog/#[0.4.61](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.61)-(April-27,-2024)","page":"Changelog","title":"0.4.61 (April 27, 2024)","text":"","category":"section"},{"location":"changelog/#Added-30","page":"Changelog","title":"Added","text":"Tests use Aqua.jl to spot problems in the code\nintroduce a feature-based list of solvers and reduce the details in the alphabetical list\nadds a PolyakStepsize\nadded a get_subgradient for AbstractManifoldGradientObjectives since their gradient is a special case of a subgradient.","category":"section"},{"location":"changelog/#Fixed-21","page":"Changelog","title":"Fixed","text":"get_last_stepsize was defined in quite different ways that caused ambiguities. That is now internally a bit restructured and should work nicer. Internally this means that the interim dispatch on get_last_stepsize(problem, state, step, vars...) was removed. Now the only two left are get_last_stepsize(p, s, vars...) and the one directly checking get_last_stepsize(::Stepsize) for stored values.\nthe accidentally exported set_manopt_parameter! is no longer exported","category":"section"},{"location":"changelog/#Changed-25","page":"Changelog","title":"Changed","text":"get_manopt_parameter and set_manopt_parameter! have been revised and better documented, they now use more semantic symbols (with capital letters) instead of direct field access (lower letter symbols). Since these are not exported, this is considered an internal, hence non-breaking change.\nsemantic symbols are now all nouns in upper case letters\n:active is changed to :Activity","category":"section"},{"location":"changelog/#[0.4.60](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.60)-(April-10,-2024)","page":"Changelog","title":"0.4.60 (April 10, 2024)","text":"","category":"section"},{"location":"changelog/#Added-31","page":"Changelog","title":"Added","text":"RecordWhenActive to allow records to be deactivated during runtime, symbol :WhenActive\nRecordSubsolver to record the result of a subsolver recording in the main solver, symbol :Subsolver\nRecordStoppingReason to record the reason a solver stopped\nmade the RecordFactory more flexible and quite similar to DebugFactory, such that it is now also easy to specify recordings at the end of solver runs. This can especially be used to record final states of sub solvers.","category":"section"},{"location":"changelog/#Changed-26","page":"Changelog","title":"Changed","text":"being a bit more strict with internal tools and made the factories for record non-exported, so this is the same as for debug.","category":"section"},{"location":"changelog/#Fixed-22","page":"Changelog","title":"Fixed","text":"The name :Subsolver to generate DebugWhenActive was misleading, it is now called :WhenActive referring to â€œprint debug only when set active, that is by the parent (main) solverâ€.\nthe old version of specifying Symbol => RecordAction for later access was ambiguous, since\n\nit could also mean to store the action in the dictionary under that symbol. Hence the order for access was switched to RecordAction => Symbol to resolve that ambiguity.","category":"section"},{"location":"changelog/#[0.4.59](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.59)-(April-7,-2024)","page":"Changelog","title":"0.4.59 (April 7, 2024)","text":"","category":"section"},{"location":"changelog/#Added-32","page":"Changelog","title":"Added","text":"A Riemannian variant of the CMA-ES (Covariance Matrix Adaptation Evolutionary Strategy) algorithm, cma_es.","category":"section"},{"location":"changelog/#Fixed-23","page":"Changelog","title":"Fixed","text":"The constructor dispatch for StopWhenAny with Vector had incorrect element type assertion which was fixed.","category":"section"},{"location":"changelog/#[0.4.58](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.58)-(March-18,-2024)","page":"Changelog","title":"0.4.58 (March 18, 2024)","text":"","category":"section"},{"location":"changelog/#Added-33","page":"Changelog","title":"Added","text":"more advanced methods to add debug to the beginning of an algorithm, a step, or the end of the algorithm with DebugAction entries at :Start, :BeforeIteration, :Iteration, and :Stop, respectively.\nIntroduce a Pair-based format to add elements to these hooks, while all others ar now added to :Iteration (no longer to :All)\n(planned) add an easy possibility to also record the initial stage and not only after the first iteration.","category":"section"},{"location":"changelog/#Changed-27","page":"Changelog","title":"Changed","text":"Changed the symbol for the :Step dictionary to be :Iteration, to unify this with the symbols used in recording, and removed the :All symbol. On the fine granular scale, all but :Start debugs are now reset on init. Since these are merely internal entries in the debug dictionary, this is considered non-breaking.\nintroduce a StopWhenSwarmVelocityLess stopping criterion for particle_swarm replacing the current default of the swarm change, since this is a bit more effective to compute","category":"section"},{"location":"changelog/#Fixed-24","page":"Changelog","title":"Fixed","text":"fixed the outdated documentation of TruncatedConjugateGradientState, that now correctly state that p is no longer stored, but the algorithm runs on TpM.\nimplemented the missing get_iterate for TruncatedConjugateGradientState.","category":"section"},{"location":"changelog/#[0.4.57](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.57)-(March-15,-2024)","page":"Changelog","title":"0.4.57 (March 15, 2024)","text":"","category":"section"},{"location":"changelog/#Changed-28","page":"Changelog","title":"Changed","text":"convex_bundle_method uses the sectional_curvature from ManifoldsBase.jl.\nconvex_bundle_method no longer has the unused k_min keyword argument.\nManifoldsBase.jl now is running on Documenter 1.3, Manopt.jl documentation now uses DocumenterInterLinks to refer to sections and functions from ManifoldsBase.jl","category":"section"},{"location":"changelog/#Fixed-25","page":"Changelog","title":"Fixed","text":"fixes a type that when passing sub_kwargs to trust_regions caused an error in the decoration of the sub objective.","category":"section"},{"location":"changelog/#[0.4.56](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.56)-(March-4,-2024)","page":"Changelog","title":"0.4.56 (March 4, 2024)","text":"","category":"section"},{"location":"changelog/#Added-34","page":"Changelog","title":"Added","text":"The option :step_towards_negative_gradient for nondescent_direction_behavior in quasi-Newton solvers does no longer emit a warning by default. This has been moved to a message, that can be accessed/displayed with DebugMessages\nDebugMessages now has a second positional argument, specifying whether all messages, or just the first (:Once) should be displayed.","category":"section"},{"location":"changelog/#[0.4.55](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.55)-(March-3,-2024)","page":"Changelog","title":"0.4.55 (March 3, 2024)","text":"","category":"section"},{"location":"changelog/#Added-35","page":"Changelog","title":"Added","text":"Option nondescent_direction_behavior for quasi-Newton solvers. By default it checks for non-descent direction which may not be handled well by some stepsize selection algorithms.","category":"section"},{"location":"changelog/#Fixed-26","page":"Changelog","title":"Fixed","text":"unified documentation, especially function signatures further.\nfixed a few typos related to math formulae in the doc strings.","category":"section"},{"location":"changelog/#[0.4.54](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.54)-(February-28,-2024)","page":"Changelog","title":"0.4.54 (February 28, 2024)","text":"","category":"section"},{"location":"changelog/#Added-36","page":"Changelog","title":"Added","text":"convex_bundle_method optimization algorithm for non-smooth geodesically convex functions\nproximal_bundle_method optimization algorithm for non-smooth functions.\nStopWhenSubgradientNormLess, StopWhenLagrangeMultiplierLess, and stopping criteria.","category":"section"},{"location":"changelog/#Fixed-27","page":"Changelog","title":"Fixed","text":"Doc strings now follow a vale.sh policy. Though this is not fully working, this PR improves a lot of the doc strings concerning wording and spelling.","category":"section"},{"location":"changelog/#[0.4.53](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.53)-(February-13,-2024)","page":"Changelog","title":"0.4.53 (February 13, 2024)","text":"","category":"section"},{"location":"changelog/#Fixed-28","page":"Changelog","title":"Fixed","text":"fixes two storage action defaults, that accidentally still tried to initialize a :Population (as modified back to :Iterate 0.4.49).\nfix a few typos in the documentation and add a reference for the subgradient method.","category":"section"},{"location":"changelog/#[0.4.52](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.52)-(February-5,-2024)","page":"Changelog","title":"0.4.52 (February 5, 2024)","text":"","category":"section"},{"location":"changelog/#Added-37","page":"Changelog","title":"Added","text":"introduce an environment persistent way of setting global values with the set_manopt_parameter! function using Preferences.jl.\nintroduce such a value named :Mode to enable a \"Tutorial\" mode that shall often provide more warnings and information for people getting started with optimisation on manifolds","category":"section"},{"location":"changelog/#[0.4.51](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.51)-(January-30,-2024)","page":"Changelog","title":"0.4.51 (January 30, 2024)","text":"","category":"section"},{"location":"changelog/#Added-38","page":"Changelog","title":"Added","text":"A StopWhenSubgradientNormLess stopping criterion for subgradient-based optimization.\nAllow the message= of the DebugIfEntry debug action to contain a format element to print the field in the message as well.","category":"section"},{"location":"changelog/#[0.4.50](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.50)-(January-26,-2024)","page":"Changelog","title":"0.4.50 (January 26, 2024)","text":"","category":"section"},{"location":"changelog/#Fixed-29","page":"Changelog","title":"Fixed","text":"Fix Quasi Newton on complex manifolds.","category":"section"},{"location":"changelog/#[0.4.49](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.49)-(January-18,-2024)","page":"Changelog","title":"0.4.49 (January 18, 2024)","text":"","category":"section"},{"location":"changelog/#Added-39","page":"Changelog","title":"Added","text":"A StopWhenEntryChangeLess to be able to stop on arbitrary small changes of specific fields\ngeneralises StopWhenGradientNormLess to accept arbitrary norm= functions\nrefactor the default in particle_swarm to no longer â€œmisuseâ€ the iteration change, but actually the new one the :swarm entry","category":"section"},{"location":"changelog/#[0.4.48](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.48)-(January-16,-2024)","page":"Changelog","title":"0.4.48 (January 16, 2024)","text":"","category":"section"},{"location":"changelog/#Fixed-30","page":"Changelog","title":"Fixed","text":"fixes an imprecision in the interface of get_iterate that sometimes led to the swarm of particle_swarm being returned as the iterate.\nrefactor particle_swarm in naming and access functions to avoid this also in the future. To access the whole swarm, one now should use get_manopt_parameter(pss, :Population)","category":"section"},{"location":"changelog/#[0.4.47](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.47)-(January-6,-2024)","page":"Changelog","title":"0.4.47 (January 6, 2024)","text":"","category":"section"},{"location":"changelog/#Fixed-31","page":"Changelog","title":"Fixed","text":"fixed a bug, where the retraction set in check_Hessian was not passed on to the optional inner check_gradient call, which could lead to unwanted side effects, see #342.","category":"section"},{"location":"changelog/#[0.4.46](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.46)-(January-1,-2024)","page":"Changelog","title":"0.4.46 (January 1, 2024)","text":"","category":"section"},{"location":"changelog/#Changed-29","page":"Changelog","title":"Changed","text":"An error is thrown when a line search from LineSearches.jl reports search failure.\nChanged default stopping criterion in ALM algorithm to mitigate an issue occurring when step size is very small.\nDefault memory length in default ALM subsolver is now capped at manifold dimension.\nReplaced CI testing on Julia 1.8 with testing on Julia 1.10.","category":"section"},{"location":"changelog/#Fixed-32","page":"Changelog","title":"Fixed","text":"A bug in LineSearches.jl extension leading to slower convergence.\nFixed a bug in L-BFGS related to memory storage, which caused significantly slower convergence.","category":"section"},{"location":"changelog/#[0.4.45](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.45)-(December-28,-2023)","page":"Changelog","title":"0.4.45 (December 28, 2023)","text":"","category":"section"},{"location":"changelog/#Added-40","page":"Changelog","title":"Added","text":"Introduce sub_kwargs and sub_stopping_criterion for trust_regions as noticed in #336","category":"section"},{"location":"changelog/#Changed-30","page":"Changelog","title":"Changed","text":"WolfePowellLineSearch, ArmijoLineSearch step sizes now allocate less\nlinesearch_backtrack! is now available\nQuasi Newton Updates can work in-place of a direction vector as well.\nFaster safe_indices in L-BFGS.","category":"section"},{"location":"changelog/#[0.4.44](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.44)-(December-12,-2023)","page":"Changelog","title":"0.4.44 (December 12, 2023)","text":"Formally one could consider this version breaking, since a few functions have been moved, that in earlier versions (0.3.x) have been used in example scripts. These examples are now available again within ManoptExamples.jl, and with their â€œreappearanceâ€ the corresponding costs, gradients, differentials, adjoint differentials, and proximal maps have been moved there as well. This is not considered breaking, since the functions were only used in the old, removed examples. Each and every moved function is still documented. They have been partly renamed, and their documentation and testing has been extended.","category":"section"},{"location":"changelog/#Changed-31","page":"Changelog","title":"Changed","text":"Bumped and added dependencies on all 3 Project.toml files, the main one, the docs/, an the tutorials/ one.\nartificial_S2_lemniscate is available as ManoptExample.Lemniscate and works on arbitrary manifolds now.\nartificial_S1_signal is available as ManoptExample.artificial_S1_signal\nartificial_S1_slope_signal is available as ManoptExamples.artificial_S1_slope_signal\nartificial_S2_composite_bezier_curve is available as ManoptExamples.artificial_S2_composite_Bezier_curve\nartificial_S2_rotation_image is available as ManoptExamples.artificial_S2_rotation_image\nartificial_S2_whirl_image is available as ManoptExamples.artificial_S2_whirl_image\nartificial_S2_whirl_patch is available as ManoptExamples.artificial_S2_whirl_path\nartificial_SAR_image is available as ManoptExamples.artificial_SAR_image\nartificial_SPD_image is available as ManoptExamples.artificial_SPD_image\nartificial_SPD_image2 is available as ManoptExamples.artificial_SPD_image\nadjoint_differential_forward_logs is available as ManoptExamples.adjoint_differential_forward_logs\nadjoint:differential_bezier_control is available as ManoptExamples.adjoint_differential_Bezier_control_points\nBezierSegment is available as ManoptExamples.BeziÃ©rSegment\ncost_acceleration_bezier is available as ManoptExamples.acceleration_Bezier\ncost_L2_acceleration_bezier is available as ManoptExamples.L2_acceleration_Bezier\ncostIntrICTV12 is available as ManoptExamples.Intrinsic_infimal_convolution_TV12\ncostL2TV is available as ManoptExamples.L2_Total_Variation\ncostL2TV12 is available as ManoptExamples.L2_Total_Variation_1_2\ncostL2TV2 is available as ManoptExamples.L2_second_order_Total_Variation\ncostTV is available as ManoptExamples.Total_Variation\ncostTV2 is available as ManoptExamples.second_order_Total_Variation\nde_casteljau is available as ManoptExamples.de_Casteljau\ndifferential_forward_logs is available as ManoptExamples.differential_forward_logs\ndifferential_bezier_control is available as ManoptExamples.differential_Bezier_control_points\nforward_logs is available as ManoptExamples.forward_logs\nget_bezier_degree is available as ManoptExamples.get_Bezier_degree\nget_bezier_degrees is available as ManoptExamples.get_Bezier_degrees\nget_Bezier_inner_points is available as ManoptExamples.get_Bezier_inner_points\nget_bezier_junction_tangent_vectors is available as ManoptExamples.get_Bezier_junction_tangent_vectors\nget_bezier_junctions is available as ManoptExamples.get_Bezier_junctions\nget_bezier_points is available as ManoptExamples.get_Bezier_points\nget_bezier_segments is available as ManoptExamples.get_Bezier_segments\ngrad_acceleration_bezier is available as ManoptExamples.grad_acceleration_Bezier\ngrad_L2_acceleration_bezier is available as ManoptExamples.grad_L2_acceleration_Bezier\ngrad_Intrinsic_infimal_convolution_TV12 is available as ManoptExamples.Intrinsic_infimal_convolution_TV12\ngrad_TV is available as ManoptExamples.grad_Total_Variation\ncostIntrICTV12 is available as ManoptExamples.Intrinsic_infimal_convolution_TV12\nproject_collaborative_TV is available as ManoptExamples.project_collaborative_TV\nprox_parallel_TV is available as ManoptExamples.prox_parallel_TV\ngrad_TV2 is available as ManoptExamples.prox_second_order_Total_Variation\nprox_TV is available as ManoptExamples.prox_Total_Variation\nprox_TV2 is available as ManopExamples.prox_second_order_Total_Variation","category":"section"},{"location":"changelog/#[0.4.43](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.43)-(November-19,-2023)","page":"Changelog","title":"0.4.43 (November 19, 2023)","text":"","category":"section"},{"location":"changelog/#Added-41","page":"Changelog","title":"Added","text":"vale.sh as a CI to keep track of a consistent documentation","category":"section"},{"location":"changelog/#[0.4.42](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.42)-(November-6,-2023)","page":"Changelog","title":"0.4.42 (November 6, 2023)","text":"","category":"section"},{"location":"changelog/#Added-42","page":"Changelog","title":"Added","text":"add Manopt.JuMP_Optimizer implementing JuMP's solver interface","category":"section"},{"location":"changelog/#[0.4.41](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.41)-(November-2,-2023)","page":"Changelog","title":"0.4.41 (November 2, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-32","page":"Changelog","title":"Changed","text":"trust_regions is now more flexible and the sub solver (Steihaug-Toint tCG by default) can now be exchanged.\nadaptive_regularization_with_cubics is now more flexible as well, where it previously was a bit too much tightened to the Lanczos solver as well.\nUnified documentation notation and bumped dependencies to use DocumenterCitations 1.3","category":"section"},{"location":"changelog/#[0.4.40](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.40)-(October-24,-2023)","page":"Changelog","title":"0.4.40 (October 24, 2023)","text":"","category":"section"},{"location":"changelog/#Added-43","page":"Changelog","title":"Added","text":"add a --help argument to docs/make.jl to document all available command line arguments\nadd a --exclude-tutorials argument to docs/make.jl. This way, when quarto is not available on a computer, the docs can still be build with the tutorials not being added to the menu such that documenter does not expect them to exist.","category":"section"},{"location":"changelog/#Changes","page":"Changelog","title":"Changes","text":"Bump dependencies to ManifoldsBase.jl 0.15 and Manifolds.jl 0.9\nmove the ARC CG subsolver to the main package, since TangentSpace is now already available from ManifoldsBase.","category":"section"},{"location":"changelog/#[0.4.39](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.39)-(October-9,-2023)","page":"Changelog","title":"0.4.39 (October 9, 2023)","text":"","category":"section"},{"location":"changelog/#Changes-2","page":"Changelog","title":"Changes","text":"also use the pair of a retraction and the inverse retraction (see last update) to perform the relaxation within the Douglas-Rachford algorithm.","category":"section"},{"location":"changelog/#[0.4.38](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.38)-(October-8,-2023)","page":"Changelog","title":"0.4.38 (October 8, 2023)","text":"","category":"section"},{"location":"changelog/#Changes-3","page":"Changelog","title":"Changes","text":"avoid allocations when calling get_jacobian! within the Levenberg-Marquard Algorithm.","category":"section"},{"location":"changelog/#Fixed-33","page":"Changelog","title":"Fixed","text":"Fix a lot of typos in the documentation","category":"section"},{"location":"changelog/#[0.4.37](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.37)-(September-28,-2023)","page":"Changelog","title":"0.4.37 (September 28, 2023)","text":"","category":"section"},{"location":"changelog/#Changes-4","page":"Changelog","title":"Changes","text":"add more of the Riemannian Levenberg-Marquard algorithms parameters as keywords, so they can be changed on call\ngeneralize the internal reflection of Douglas-Rachford, such that is also works with an arbitrary pair of a reflection and an inverse reflection.","category":"section"},{"location":"changelog/#[0.4.36](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.36)-(-September-20,-2023)","page":"Changelog","title":"0.4.36 ( September 20, 2023)","text":"","category":"section"},{"location":"changelog/#Fixed-34","page":"Changelog","title":"Fixed","text":"Fixed a bug that caused non-matrix points and vectors to fail when working with approximate","category":"section"},{"location":"changelog/#[0.4.35](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.35)-(-September-14,-2023)","page":"Changelog","title":"0.4.35 ( September 14, 2023)","text":"","category":"section"},{"location":"changelog/#Added-44","page":"Changelog","title":"Added","text":"The access to functions of the objective is now unified and encapsulated in proper get_ functions.","category":"section"},{"location":"changelog/#[0.4.34](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.34)-(-September-02,-2023)","page":"Changelog","title":"0.4.34 ( September 02, 2023)","text":"","category":"section"},{"location":"changelog/#Added-45","page":"Changelog","title":"Added","text":"an ManifoldEuclideanGradientObjective to allow the cost, gradient, and Hessian and other first or second derivative based elements to be Euclidean and converted when needed.\na keyword objective_type=:Euclidean for all solvers, that specifies that an Objective shall be created of the new type","category":"section"},{"location":"changelog/#[0.4.33](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.33)-(August-24,-2023)","page":"Changelog","title":"0.4.33 (August 24, 2023)","text":"","category":"section"},{"location":"changelog/#Added-46","page":"Changelog","title":"Added","text":"ConstantStepsize and DecreasingStepsize now have an additional field type::Symbol to assess whether the step-size should be relatively (to the gradient norm) or absolutely constant.","category":"section"},{"location":"changelog/#[0.4.32](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.32)-(August-23,-2023)","page":"Changelog","title":"0.4.32 (August 23, 2023)","text":"","category":"section"},{"location":"changelog/#Added-47","page":"Changelog","title":"Added","text":"The adaptive regularization with cubics (ARC) solver.","category":"section"},{"location":"changelog/#[0.4.31](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.31)-(August-14,-2023)","page":"Changelog","title":"0.4.31 (August 14, 2023)","text":"","category":"section"},{"location":"changelog/#Added-48","page":"Changelog","title":"Added","text":"A :Subsolver keyword in the debug= keyword argument, that activates the new DebugWhenActiveto de/activate subsolver debug from the main solversDebugEvery`.","category":"section"},{"location":"changelog/#[0.4.30](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.30)-(August-3,-2023)","page":"Changelog","title":"0.4.30 (August 3, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-33","page":"Changelog","title":"Changed","text":"References in the documentation are now rendered using DocumenterCitations.jl\nAsymptote export now also accepts a size in pixel instead of its default 4cm size and render can be deactivated setting it to nothing.","category":"section"},{"location":"changelog/#[0.4.29](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.29)-(July-12,-2023)","page":"Changelog","title":"0.4.29 (July 12, 2023)","text":"","category":"section"},{"location":"changelog/#Fixed-35","page":"Changelog","title":"Fixed","text":"fixed a bug, where cyclic_proximal_point did not work with decorated objectives.","category":"section"},{"location":"changelog/#[0.4.28](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.28)-(June-24,-2023)","page":"Changelog","title":"0.4.28 (June 24, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-34","page":"Changelog","title":"Changed","text":"max_stepsize was specialized for FixedRankManifold to follow Matlab Manopt.","category":"section"},{"location":"changelog/#[0.4.27](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.27)-(June-15,-2023)","page":"Changelog","title":"0.4.27 (June 15, 2023)","text":"","category":"section"},{"location":"changelog/#Added-49","page":"Changelog","title":"Added","text":"The AdaptiveWNGrad stepsize is available as a new stepsize functor.","category":"section"},{"location":"changelog/#Fixed-36","page":"Changelog","title":"Fixed","text":"Levenberg-Marquardt now possesses its parameters initial_residual_values and initial_jacobian_f also as keyword arguments, such that their default initialisations can be adapted, if necessary","category":"section"},{"location":"changelog/#[0.4.26](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.26)-(June-11,-2023)","page":"Changelog","title":"0.4.26 (June 11, 2023)","text":"","category":"section"},{"location":"changelog/#Added-50","page":"Changelog","title":"Added","text":"simplify usage of gradient descent as sub solver in the DoC solvers.\nadd a get_state function\ndocument indicates_convergence.","category":"section"},{"location":"changelog/#[0.4.25](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.25)-(June-5,-2023)","page":"Changelog","title":"0.4.25 (June 5, 2023)","text":"","category":"section"},{"location":"changelog/#Fixed-37","page":"Changelog","title":"Fixed","text":"Fixes an allocation bug in the difference of convex algorithm","category":"section"},{"location":"changelog/#[0.4.24](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.24)-(June-4,-2023)","page":"Changelog","title":"0.4.24 (June 4, 2023)","text":"","category":"section"},{"location":"changelog/#Added-51","page":"Changelog","title":"Added","text":"another workflow that deletes old PR renderings from the docs to keep them smaller in overall size.","category":"section"},{"location":"changelog/#Changes-5","page":"Changelog","title":"Changes","text":"bump dependencies since the extension between Manifolds.jl and ManifoldsDiff.jl has been moved to Manifolds.jl","category":"section"},{"location":"changelog/#[0.4.23](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.23)-(June-4,-2023)","page":"Changelog","title":"0.4.23 (June 4, 2023)","text":"","category":"section"},{"location":"changelog/#Added-52","page":"Changelog","title":"Added","text":"More details on the Count and Cache tutorial","category":"section"},{"location":"changelog/#Changed-35","page":"Changelog","title":"Changed","text":"loosen constraints slightly","category":"section"},{"location":"changelog/#[0.4.22](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.22)-(May-31,-2023)","page":"Changelog","title":"0.4.22 (May 31, 2023)","text":"","category":"section"},{"location":"changelog/#Added-53","page":"Changelog","title":"Added","text":"A tutorial on how to implement a solver","category":"section"},{"location":"changelog/#[0.4.21](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.21)-(May-22,-2023)","page":"Changelog","title":"0.4.21 (May 22, 2023)","text":"","category":"section"},{"location":"changelog/#Added-54","page":"Changelog","title":"Added","text":"A ManifoldCacheObjective as a decorator for objectives to cache results of calls, using LRU Caches as a weak dependency. For now this works with cost and gradient evaluations\nA ManifoldCountObjective as a decorator for objectives to enable counting of calls to for example the cost and the gradient\nadds a return_objective keyword, that switches the return of a solver to a tuple (o, s), where o is the (possibly decorated) objective, and s is the â€œclassicalâ€ solver return (state or point). This way the counted values can be accessed and the cache can be reused.\nchange solvers on the mid level (form solver(M, objective, p)) to also accept decorated objectives","category":"section"},{"location":"changelog/#Changed-36","page":"Changelog","title":"Changed","text":"Switch all Requires weak dependencies to actual weak dependencies starting in Julia 1.9","category":"section"},{"location":"changelog/#[0.4.20](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.20)-(May-11,-2023)","page":"Changelog","title":"0.4.20 (May 11, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-37","page":"Changelog","title":"Changed","text":"the default tolerances for the numerical check_ functions were loosened a bit, such that check_vector can also be changed in its tolerances.","category":"section"},{"location":"changelog/#[0.4.19](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.19)-(May-7,-2023)","page":"Changelog","title":"0.4.19 (May 7, 2023)","text":"","category":"section"},{"location":"changelog/#Added-55","page":"Changelog","title":"Added","text":"the sub solver for trust_regions is now customizable and can now be exchanged.","category":"section"},{"location":"changelog/#Changed-38","page":"Changelog","title":"Changed","text":"slightly changed the definitions of the solver states for ALM and EPM to be type stable","category":"section"},{"location":"changelog/#[0.4.18](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.18)-(May-4,-2023)","page":"Changelog","title":"0.4.18 (May 4, 2023)","text":"","category":"section"},{"location":"changelog/#Added-56","page":"Changelog","title":"Added","text":"A function check_Hessian(M, f, grad_f, Hess_f) to numerically verify the (Riemannian) Hessian of a function f","category":"section"},{"location":"changelog/#[0.4.17](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.17)-(April-28,-2023)","page":"Changelog","title":"0.4.17 (April 28, 2023)","text":"","category":"section"},{"location":"changelog/#Added-57","page":"Changelog","title":"Added","text":"A new interface of the form alg(M, objective, p0) to allow to reuse objectives without creating AbstractManoptSolverStates and calling solve!. This especially still allows for any decoration of the objective and/or the state using debug=, or record=.","category":"section"},{"location":"changelog/#Changed-39","page":"Changelog","title":"Changed","text":"All solvers now have the initial point p as an optional parameter making it more accessible to first time users, gradient_descent(M, f, grad_f) is equivalent to gradient_descent(M, f, grad_f, rand(M))","category":"section"},{"location":"changelog/#Fixed-38","page":"Changelog","title":"Fixed","text":"Unified the framework to work on manifold where points are represented by numbers for several solvers","category":"section"},{"location":"changelog/#[0.4.16](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.16)-(April-18,-2023)","page":"Changelog","title":"0.4.16 (April 18, 2023)","text":"","category":"section"},{"location":"changelog/#Fixed-39","page":"Changelog","title":"Fixed","text":"the inner products used in truncated_gradient_descent now also work thoroughly on complex matrix manifolds","category":"section"},{"location":"changelog/#[0.4.15](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.15)-(April-13,-2023)","page":"Changelog","title":"0.4.15 (April 13, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-40","page":"Changelog","title":"Changed","text":"trust_regions(M, f, grad_f, hess_f, p) now has the Hessian hess_f as well as the start point p0 as an optional parameter and approximate it otherwise.\ntrust_regions!(M, f, grad_f, hess_f, p) has the Hessian as an optional parameter and approximate it otherwise.","category":"section"},{"location":"changelog/#Removed-3","page":"Changelog","title":"Removed","text":"support for ManifoldsBase.jl 0.13.x, since with the definition of copy(M,p::Number), in 0.14.4, that one is used instead of defining it ourselves.","category":"section"},{"location":"changelog/#[0.4.14](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.14)-(April-06,-2023)","page":"Changelog","title":"0.4.14 (April 06, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-41","page":"Changelog","title":"Changed","text":"particle_swarm now uses much more in-place operations","category":"section"},{"location":"changelog/#Fixed-40","page":"Changelog","title":"Fixed","text":"particle_swarm used quite a few deepcopy(p) commands still, which were replaced by copy(M, p)","category":"section"},{"location":"changelog/#[0.4.13](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.13)-(April-09,-2023)","page":"Changelog","title":"0.4.13 (April 09, 2023)","text":"","category":"section"},{"location":"changelog/#Added-58","page":"Changelog","title":"Added","text":"get_message to obtain messages from sub steps of a solver\nDebugMessages to display the new messages in debug\nsafeguards in Armijo line search and L-BFGS against numerical over- and underflow that report in messages","category":"section"},{"location":"changelog/#[0.4.12](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.12)-(April-4,-2023)","page":"Changelog","title":"0.4.12 (April 4, 2023)","text":"","category":"section"},{"location":"changelog/#Added-59","page":"Changelog","title":"Added","text":"Introduce the Difference of Convex Algorithm (DCA) difference_of_convex_algorithm(M, f, g, âˆ‚h, p0)\nIntroduce the Difference of Convex Proximal Point Algorithm (DCPPA) difference_of_convex_proximal_point(M, prox_g, grad_h, p0)\nIntroduce a StopWhenGradientChangeLess stopping criterion","category":"section"},{"location":"changelog/#[0.4.11](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.11)-(March-27,-2023)","page":"Changelog","title":"0.4.11 (March 27, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-42","page":"Changelog","title":"Changed","text":"adapt tolerances in tests to the speed/accuracy optimized distance on the sphere in Manifolds.jl (part II)","category":"section"},{"location":"changelog/#[0.4.10](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.10)-(March-26,-2023)","page":"Changelog","title":"0.4.10 (March 26, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-43","page":"Changelog","title":"Changed","text":"adapt tolerances in tests to the speed/accuracy optimized distance on the sphere in Manifolds.jl","category":"section"},{"location":"changelog/#[0.4.9](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.9)-(March-3,-2023)","page":"Changelog","title":"0.4.9 (March 3, 2023)","text":"","category":"section"},{"location":"changelog/#Added-60","page":"Changelog","title":"Added","text":"introduce a wrapper that allows line searches from LineSearches.jl to be used within Manopt.jl, introduce the manoptjl.org/stable/extensions/ page to explain the details.","category":"section"},{"location":"changelog/#[0.4.8](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.8)-(February-21,-2023)","page":"Changelog","title":"0.4.8 (February 21, 2023)","text":"","category":"section"},{"location":"changelog/#Added-61","page":"Changelog","title":"Added","text":"a status_summary that displays the main parameters within several structures of Manopt, most prominently a solver state","category":"section"},{"location":"changelog/#Changed-44","page":"Changelog","title":"Changed","text":"Improved storage performance by introducing separate named tuples for points and vectors\nchanged the show methods of AbstractManoptSolverStates to display their `state_summary\nMove tutorials to be rendered with Quarto into the documentation.","category":"section"},{"location":"changelog/#[0.4.7](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.7)-(February-14,-2023)","page":"Changelog","title":"0.4.7 (February 14, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-45","page":"Changelog","title":"Changed","text":"Bump [compat] entry of ManifoldDiff to also include 0.3","category":"section"},{"location":"changelog/#[0.4.6](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.6)-(February-3,-2023)","page":"Changelog","title":"0.4.6 (February 3, 2023)","text":"","category":"section"},{"location":"changelog/#Fixed-41","page":"Changelog","title":"Fixed","text":"Fixed a few stopping criteria even indicated to stop before the algorithm started.","category":"section"},{"location":"changelog/#[0.4.5](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.5)-(January-24,-2023)","page":"Changelog","title":"0.4.5 (January 24, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-46","page":"Changelog","title":"Changed","text":"the new default functions that include p are used where possible\na first step towards faster storage handling","category":"section"},{"location":"changelog/#[0.4.4](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.4)-(January-20,-2023)","page":"Changelog","title":"0.4.4 (January 20, 2023)","text":"","category":"section"},{"location":"changelog/#Added-62","page":"Changelog","title":"Added","text":"Introduce ConjugateGradientBealeRestart to allow CG restarts using Bealeâ€˜s rule","category":"section"},{"location":"changelog/#Fixed-42","page":"Changelog","title":"Fixed","text":"fix a type in HestenesStiefelCoefficient","category":"section"},{"location":"changelog/#[0.4.3](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.3)-(January-17,-2023)","page":"Changelog","title":"0.4.3 (January 17, 2023)","text":"","category":"section"},{"location":"changelog/#Fixed-43","page":"Changelog","title":"Fixed","text":"the CG coefficient Î² can now be complex\nfix a bug in grad_distance","category":"section"},{"location":"changelog/#[0.4.2](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.2)-(January-16,-2023)","page":"Changelog","title":"0.4.2 (January 16, 2023)","text":"","category":"section"},{"location":"changelog/#Changed-47","page":"Changelog","title":"Changed","text":"the usage of inner in line search methods, such that they work well with complex manifolds as well","category":"section"},{"location":"changelog/#[0.4.1](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.1)-(January-15,-2023)","page":"Changelog","title":"0.4.1 (January 15, 2023)","text":"","category":"section"},{"location":"changelog/#Fixed-44","page":"Changelog","title":"Fixed","text":"a max_stepsize per manifold to avoid leaving the injectivity radius, which it also defaults to","category":"section"},{"location":"changelog/#[0.4.0](https://github.com/JuliaManifolds/Manopt.jl/releases/tag/v0.4.0)-(January-10,-2023)","page":"Changelog","title":"0.4.0 (January 10, 2023)","text":"","category":"section"},{"location":"changelog/#Added-63","page":"Changelog","title":"Added","text":"Dependency on ManifoldDiff.jl and a start of moving actual derivatives, differentials, and gradients there.\nAbstractManifoldObjective to store the objective within the AbstractManoptProblem\nIntroduce a CostGrad structure to store a function that computes the cost and gradient within one function.\nstarted a changelog.md to thoroughly keep track of changes","category":"section"},{"location":"changelog/#Changed-48","page":"Changelog","title":"Changed","text":"AbstractManoptProblem replaces Problem\nthe problem now contains a\nAbstractManoptSolverState replaces Options\nrandom_point(M) is replaced by rand(M) from `ManifoldsBase.jl\nrandom_tangent(M, p) is replaced by rand(M; vector_at=p)","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Mesh-adaptive-direct-search-(MADS)","page":"Mesh Adaptive Direct Search","title":"Mesh adaptive direct search (MADS)","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#State","page":"Mesh Adaptive Direct Search","title":"State","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Poll","page":"Mesh Adaptive Direct Search","title":"Poll","text":"as well as the internal functions","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Search","page":"Mesh Adaptive Direct Search","title":"Search","text":"as well as the internal functions","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Additional-stopping-criteria","page":"Mesh Adaptive Direct Search","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Technical-details","page":"Mesh Adaptive Direct Search","title":"Technical details","text":"The mesh_adaptive_direct_search solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nWithin the default initialization rand(M) is used to generate the initial population\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Literature","page":"Mesh Adaptive Direct Search","title":"Literature","text":"D.Â W.Â Dreisigmeyer. Direct Search Algorithms over Riemannian Manifolds (Optimization Online, 2007).\n\n\n\n","category":"section"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.mesh_adaptive_direct_search","page":"Mesh Adaptive Direct Search","title":"Manopt.mesh_adaptive_direct_search","text":"mesh_adaptive_direct_search(M, f, p=rand(M); kwargs...)\nmesh_adaptive_direct_search(M, mco::AbstractManifoldCostObjective, p=rand(M); kwargs..)\nmesh_adaptive_direct_search!(M, f, p; kwargs...)\nmesh_adaptive_direct_search!(M, mco::AbstractManifoldCostObjective, p; kwargs..)\n\nThe Mesh Adaptive Direct Search (MADS) algorithm minimizes an objective function f mathcalMnifold)))  â„ on the manifold M. The algorithm constructs an implicit mesh in the tangent space T_pmathcalM at the current candidate p. Each iteration consists of a search step and a poll step.\n\nThe search step selects points from the implicit mesh and attempts to find an improved candidate solution that reduces the value of f. If the search step fails to generate an improved candidate solution, the poll step is performed. It consists of a local exploration on the current implicit mesh in the neighbourhood of the current iterate.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nmesh_basis=DefaultOrthonormalBasis: a basis to generate the mesh in. The mesh is generated in coordinates of this basis in every tangent space\nmax_stepsize=injectivity_radius(M): a maximum step size to take. any vector generated on the mesh is shortened to this length to avoid leaving the injectivity radius,\npoll::AbstractMeshPollFunction=LowerTriangularAdaptivePoll(M, copy(M,p)): the poll function to use. The mesh_basis (as basis), retraction_method, and vector_transport_method are passed to this default as well.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nscale_mesh=injectivity_radius(M) / 4: initial scaling of the mesh\nsearch::AbstractMeshSearchFunction=DefaultMeshAdaptiveDirectSearch(M, copy(M,p)): the search function to use. The retraction_method is passed to this default as well.\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenPollSizeLess(1e-10): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.mesh_adaptive_direct_search!","page":"Mesh Adaptive Direct Search","title":"Manopt.mesh_adaptive_direct_search!","text":"mesh_adaptive_direct_search(M, f, p=rand(M); kwargs...)\nmesh_adaptive_direct_search(M, mco::AbstractManifoldCostObjective, p=rand(M); kwargs..)\nmesh_adaptive_direct_search!(M, f, p; kwargs...)\nmesh_adaptive_direct_search!(M, mco::AbstractManifoldCostObjective, p; kwargs..)\n\nThe Mesh Adaptive Direct Search (MADS) algorithm minimizes an objective function f mathcalMnifold)))  â„ on the manifold M. The algorithm constructs an implicit mesh in the tangent space T_pmathcalM at the current candidate p. Each iteration consists of a search step and a poll step.\n\nThe search step selects points from the implicit mesh and attempts to find an improved candidate solution that reduces the value of f. If the search step fails to generate an improved candidate solution, the poll step is performed. It consists of a local exploration on the current implicit mesh in the neighbourhood of the current iterate.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nmesh_basis=DefaultOrthonormalBasis: a basis to generate the mesh in. The mesh is generated in coordinates of this basis in every tangent space\nmax_stepsize=injectivity_radius(M): a maximum step size to take. any vector generated on the mesh is shortened to this length to avoid leaving the injectivity radius,\npoll::AbstractMeshPollFunction=LowerTriangularAdaptivePoll(M, copy(M,p)): the poll function to use. The mesh_basis (as basis), retraction_method, and vector_transport_method are passed to this default as well.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nscale_mesh=injectivity_radius(M) / 4: initial scaling of the mesh\nsearch::AbstractMeshSearchFunction=DefaultMeshAdaptiveDirectSearch(M, copy(M,p)): the search function to use. The retraction_method is passed to this default as well.\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenPollSizeLess(1e-10): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.MeshAdaptiveDirectSearchState","page":"Mesh Adaptive Direct Search","title":"Manopt.MeshAdaptiveDirectSearchState","text":"MeshAdaptiveDirectSearchState <: AbstractManoptSolverState\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\nmesh_size: the current (internal) mesh size\nscale_mesh: the current scaling of the internal mesh size, yields the actual mesh size used\nmax_stepsize: an upper bound for the longest step taken in looking for a candidate in either poll or search\npoll_size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\npoll::[AbstractMeshPollFunction]: a poll step (functor) to perform\nsearch::[AbstractMeshSearchFunction}(@ref) a search step (functor) to perform\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.AbstractMeshPollFunction","page":"Mesh Adaptive Direct Search","title":"Manopt.AbstractMeshPollFunction","text":"AbstractMeshPollFunction\n\nAn abstract type for common â€œpollâ€ strategies in the mesh_adaptive_direct_search solver. A subtype of this The functor has to fulfil\n\nbe callable as poll!(problem, mesh_size; kwargs...) and modify the state\n\nas well as to provide functions\n\nis_successful(poll!) that indicates whether the last poll was successful in finding a new candidate\nget_basepoint(poll!) that returns the base point at which the mesh is build\nget_candidate(poll!) that returns the last found candidate if the poll was successful. Otherwise the base point is returned\nget_descent_direction(poll!) the the vector that points from the base point to the candidate. If the last poll was not successful, the zero vector is returned\nupdate_basepoint!(M, poll!, p) that updates the base point to p and all necessary internal data to a new point to build a mesh at\n\nThe kwargs... could include\n\nscale_mesh=1.0: to rescale the mesh globally\nmax_stepsize=Inf: avoid exceeding a step size beyond this value, e.g. injectivity radius. any vector longer than this should be shortened to the provided maximum step size.\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.LowerTriangularAdaptivePoll","page":"Mesh Adaptive Direct Search","title":"Manopt.LowerTriangularAdaptivePoll","text":"LowerTriangularAdaptivePoll <: AbstractMeshPollFunction\n\nGenerate a mesh (poll step) based on Section 6 and 7 of [Dre07], with two small modifications:\n\nThe mesh can be scaled globally so instead of Î”_0^m=1 a certain different scale is used\nAny poll direction can be rescaled if it is too long. This is to not exceed the injectivity radius for example.\n\nFunctor\n\n(p::LowerTriangularAdaptivePoll)(problem, mesh_size; scale_mesh=1.0, max_stepsize=inf)\n\nFields\n\nbase_point::P: a point on the manifold, where the mesh is build in the tangent space\nbasis: a basis of the current tangent space with respect to which the mesh is stored\ncandidate::P: a memory for a new point/candidate\nmesh: a vector of tangent vectors storing the mesh.\nrandom_vector: a d-dimensional random vector b_l`\nrandom_index: a random index Î¹\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nX::T the last successful poll direction stored as a tangent vector. initialised to the zero vector and reset to the zero vector after moving to a new tangent space.\n\nConstructor\n\nLowerTriangularAdaptivePoll(M, p=rand(M); kwargs...)\n\nKeyword arguments\n\nbasis=DefaultOrthonormalBasis\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_descent_direction-Tuple{LowerTriangularAdaptivePoll}","page":"Mesh Adaptive Direct Search","title":"Manopt.get_descent_direction","text":"get_descent_direction(ltap::LowerTriangularAdaptivePoll)\n\nReturn the direction of the last LowerTriangularAdaptivePoll that yields a descent of the cost. If the poll was not successful, the zero vector is returned\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.is_successful-Tuple{LowerTriangularAdaptivePoll}","page":"Mesh Adaptive Direct Search","title":"Manopt.is_successful","text":"is_successful(ltap::LowerTriangularAdaptivePoll)\n\nReturn whether the last LowerTriangularAdaptivePoll step was successful\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_candidate-Tuple{LowerTriangularAdaptivePoll}","page":"Mesh Adaptive Direct Search","title":"Manopt.get_candidate","text":"get_candidate(ltap::LowerTriangularAdaptivePoll)\n\nReturn the candidate of the last successful LowerTriangularAdaptivePoll. If the poll was unsuccessful, the base point is returned.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_basepoint-Tuple{LowerTriangularAdaptivePoll}","page":"Mesh Adaptive Direct Search","title":"Manopt.get_basepoint","text":"get_basepoint(ltap::LowerTriangularAdaptivePoll)\n\nReturn the base point of the tangent space, where the mash for the LowerTriangularAdaptivePoll is build in.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.update_basepoint!-Union{Tuple{P}, Tuple{Any, LowerTriangularAdaptivePoll{P, T, F} where {T, F<:Real}, P}} where P","page":"Mesh Adaptive Direct Search","title":"Manopt.update_basepoint!","text":"update_basepoint!(M, ltap::LowerTriangularAdaptivePoll, p)\n\nUpdate the base point of the LowerTriangularAdaptivePoll. This especially also updates the basis, that is used to build a (new) mesh.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.AbstractMeshSearchFunction","page":"Mesh Adaptive Direct Search","title":"Manopt.AbstractMeshSearchFunction","text":"AbstractMeshSearchFunction\n\nShould be callable as search!(problem, mesh_size, p, X; kwargs...)\n\nwhere X is the last successful poll direction from the tangent space at p if that exists and the zero vector otherwise.\n\nBesides that the following functions should be implemented\n\nis_successful(search!) that indicates whether the last search was successful in finding a new candidate\nget_candidate(search!) that returns the last found candidate\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.DefaultMeshAdaptiveDirectSearch","page":"Mesh Adaptive Direct Search","title":"Manopt.DefaultMeshAdaptiveDirectSearch","text":"DefaultMeshAdaptiveDirectSearch <: AbstractMeshSearchFunction\n\nFunctor\n\n(s::DefaultMeshAdaptiveDirectSearch)(problem, mesh_size::Real, X; scale_mesh::Real=1.0, max_stepsize::Real=inf)\n\nFields\n\nq: a temporary memory for a point on the manifold\nX: information to perform the search, e.g. the last direction found by poll.\nlast_search_improved::Bool indicate whether the last search was successful, i.e. improved the cost.\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructor\n\nDefaultMeshAdaptiveDirectSearch(M::AbstractManifold, p=rand(M); kwargs...)\n\nKeyword arguments\n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\n\n\n\n\n","category":"type"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.is_successful-Tuple{DefaultMeshAdaptiveDirectSearch}","page":"Mesh Adaptive Direct Search","title":"Manopt.is_successful","text":"is_successful(dmads::DefaultMeshAdaptiveDirectSearch)\n\nReturn whether the last DefaultMeshAdaptiveDirectSearch was successful.\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.get_candidate-Tuple{DefaultMeshAdaptiveDirectSearch}","page":"Mesh Adaptive Direct Search","title":"Manopt.get_candidate","text":"get_candidate(dmads::DefaultMeshAdaptiveDirectSearch)\n\nReturn the last candidate a DefaultMeshAdaptiveDirectSearch found\n\n\n\n\n\n","category":"method"},{"location":"solvers/mesh_adaptive_direct_search/#Manopt.StopWhenPollSizeLess","page":"Mesh Adaptive Direct Search","title":"Manopt.StopWhenPollSizeLess","text":"StopWhenPollSizeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the poll mesh size of an MeshAdaptiveDirectSearchState.\n\nConstructor\n\nStopWhenPollSizeLess(Îµ)\n\ninitialize the stopping criterion to a threshold Îµ.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Gradient-descent","page":"Gradient Descent","title":"Gradient descent","text":"","category":"section"},{"location":"solvers/gradient_descent/#State","page":"Gradient Descent","title":"State","text":"","category":"section"},{"location":"solvers/gradient_descent/#Direction-update-rules","page":"Gradient Descent","title":"Direction update rules","text":"A field of the options is the direction, a DirectionUpdateRule, which by default IdentityUpdateRule just evaluates the gradient but can be enhanced for example to\n\nwhich internally use the ManifoldDefaultsFactory and produce the internal elements","category":"section"},{"location":"solvers/gradient_descent/#Debug-actions","page":"Gradient Descent","title":"Debug actions","text":"","category":"section"},{"location":"solvers/gradient_descent/#Record-actions","page":"Gradient Descent","title":"Record actions","text":"","category":"section"},{"location":"solvers/gradient_descent/#sec-gradient-descent-technical-details","page":"Gradient Descent","title":"Technical details","text":"The gradient_descent solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nBy default gradient descent uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).","category":"section"},{"location":"solvers/gradient_descent/#Literature","page":"Gradient Descent","title":"Literature","text":"D.Â G.Â Luenberger. The gradient projection method along geodesics. ManagementÂ Science 18, 620â€“631 (1972).\n\n\n\nH.Â Zhang and S.Â Sra. Towards Riemannian accelerated gradient methods, arXivÂ Preprint,Â 1806.02812 (2018).\n\n\n\n","category":"section"},{"location":"solvers/gradient_descent/#Manopt.gradient_descent","page":"Gradient Descent","title":"Manopt.gradient_descent","text":"gradient_descent(M, f, grad_f, p=rand(M); kwargs...)\ngradient_descent(M, gradient_objective, p=rand(M); kwargs...)\ngradient_descent!(M, f, grad_f, p; kwargs...)\ngradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform the gradient descent algorithm\n\np_k+1 = operatornameretr_p_kbigl( s_koperatornamegradf(p_k) bigr)\nqquad k=01\n\nwhere s_k  0 denotes a step size.\n\nThe algorithm can be performed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldFirstOrderObjective gradient_objective directly.\n\nKeyword arguments\n\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\ndirection=IdentityUpdateRule(): specify to perform a certain processing of the direction, for example Nesterov, MomentumGradient or AverageGradient.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second. For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=default_stepsize(M,GradientDescentState; retraction_method=retraction_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.gradient_descent!","page":"Gradient Descent","title":"Manopt.gradient_descent!","text":"gradient_descent(M, f, grad_f, p=rand(M); kwargs...)\ngradient_descent(M, gradient_objective, p=rand(M); kwargs...)\ngradient_descent!(M, f, grad_f, p; kwargs...)\ngradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform the gradient descent algorithm\n\np_k+1 = operatornameretr_p_kbigl( s_koperatornamegradf(p_k) bigr)\nqquad k=01\n\nwhere s_k  0 denotes a step size.\n\nThe algorithm can be performed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldFirstOrderObjective gradient_objective directly.\n\nKeyword arguments\n\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\ndirection=IdentityUpdateRule(): specify to perform a certain processing of the direction, for example Nesterov, MomentumGradient or AverageGradient.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second. For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=default_stepsize(M,GradientDescentState; retraction_method=retraction_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.GradientDescentState","page":"Gradient Descent","title":"Manopt.GradientDescentState","text":"GradientDescentState{P,T} <: AbstractGradientSolverState\n\nDescribes the state of a gradient based descent algorithm.\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\nX::T: a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\ndirection::DirectionUpdateRule : a processor to handle the obtained gradient and compute a direction to â€œwalk intoâ€.\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructor\n\nGradientDescentState(M::AbstractManifold; kwargs...)\n\nInitialize the gradient descent solver state, where\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\n\nKeyword arguments\n\ndirection=IdentityUpdateRule()\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=default_stepsize(M,GradientDescentState; retraction_method=retraction_method): a functor inheriting from Stepsize to determine a step size\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nSee also\n\ngradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.AverageGradient","page":"Gradient Descent","title":"Manopt.AverageGradient","text":"AverageGradient(; kwargs...)\nAverageGradient(M::AbstractManifold; kwargs...)\n\nAdd an average of gradients to a gradient processor. A set of previous directions (from the inner processor) and the last iterate are stored, average is taken after vector transporting them to the current iterates tangent space.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM (optional)\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\ndirection=IdentityUpdateRule preprocess the actual gradient before adding momentum\ngradients=[zero_vector(M, p) for _ in 1:n] how to initialise the internal storage\nn=10 number of gradient evaluations to take the mean over\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for AverageGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.DirectionUpdateRule","page":"Gradient Descent","title":"Manopt.DirectionUpdateRule","text":"DirectionUpdateRule\n\nA general functor, that handles direction update rules. It's fields are usually only a StoreStateAction by default initialized to the fields required for the specific coefficient, but can also be replaced by a (common, global) individual one that provides these values.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.IdentityUpdateRule","page":"Gradient Descent","title":"Manopt.IdentityUpdateRule","text":"IdentityUpdateRule <: DirectionUpdateRule\n\nThe default gradient direction update is the identity, usually it just evaluates the gradient.\n\nYou can also use Gradient() to create the corresponding factory, though this only delays this parameter-free instantiation to later.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.MomentumGradient","page":"Gradient Descent","title":"Manopt.MomentumGradient","text":"MomentumGradient()\n\nAppend a momentum to a gradient processor, where the last direction and last iterate are stored and the new is composed as Î·_i = m*Î·_i-1 - s d_i, where sd_i is the current (inner) direction and Î·_i-1 is the vector transported last direction multiplied by momentum m.\n\nInput\n\nM (optional)\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM\ndirection=IdentityUpdateRule preprocess the actual gradient before adding momentum\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\nmomentum=0.2 amount of momentum to use\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for MomentumGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.Nesterov","page":"Gradient Descent","title":"Manopt.Nesterov","text":"Nesterov(; kwargs...)\nNesterov(M::AbstractManifold; kwargs...)\n\nAssume f is L-Lipschitz and Î¼-strongly convex. Given\n\na step size h_kfrac1L (from the GradientDescentState\na shrinkage parameter Î²_k\nand a current iterate p_k\nas well as the interim values Î³_k and v_k from the previous iterate.\n\nThis compute a Nesterov type update using the following steps, see [ZS18]\n\nCompute the positive root Î±_k(01) of Î±^2 = h_kbigl((1-Î±_k)Î³_k+Î±_k Î¼bigr).\nSet barÎ³_k+1 = (1-Î±_k)Î³_k + Î±_kÎ¼\ny_k = operatornameretr_p_kBigl(fracÎ±_kÎ³_kÎ³_k + Î±_kÎ¼operatornameretr^-1_p_kv_k Bigr)\nx_k+1 = operatornameretr_y_k(-h_k operatornamegradf(y_k))\nv_k+1 = operatornameretr_y_kBigl(frac(1-Î±_k)Î³_kbarÎ³_koperatornameretr_y_k^-1(v_k) - fracÎ±_kbarÎ³_k+1operatornamegradf(y_k) Bigr)\nÎ³_k+1 = frac11+Î²_kbarÎ³_k+1\n\nThen the direction from p_k to p_k+1 by d = operatornameretr^-1_p_kp_k+1 is returned.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM (optional)\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nÎ³=0.001\nÎ¼=0.9\nshrinkage = k -> 0.8\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for NesterovRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.PreconditionedDirection","page":"Gradient Descent","title":"Manopt.PreconditionedDirection","text":"PreconditionedDirection(preconditioner; kwargs...)\nPreconditionedDirection(M::AbstractManifold, preconditioner; kwargs...)\n\nAdd a preconditioner to a gradient processor following the motivation for optimization, as a linear invertible map P T_pmathcalM  T_pmathcalM that usually should be\n\nsymmetric: X P(Y) = P(X) Y\npositive definite X P(X)  0 for X not the zero-vector\n\nThe gradient is then preconditioned as P(X), where X is either the gradient of the objective or the result of a previous (internally stored) gradient processor.\n\nFor example if you provide as the preconditioner the inverse of the Hessian operatornameHess^-1 f, you turn a gradient descent into a Newton method.\n\nArguments\n\nM::AbstractManifold: a Riemannian manifold mathcalM (optional)\npreconditioner:   preconditioner function, either as a (M, p, X) -> Y allocating or (M, Y, p, X) -> Y mutating function\n\nKeyword arguments\n\ndirection=IdentityUpdateRule internal DirectionUpdateRule to determine the gradients to store or a ManifoldDefaultsFactory generating one\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for PreconditionedDirectionRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.AverageGradientRule","page":"Gradient Descent","title":"Manopt.AverageGradientRule","text":"AverageGradientRule <: DirectionUpdateRule\n\nAdd an average of gradients to a gradient processor. A set of previous directions (from the inner processor) and the last iterate are stored. The average is taken after vector transporting them to the current iterates tangent space.\n\nFields\n\ngradients:               the last n gradient/direction updates\nlast_iterate:            last iterate (needed to transport the gradients)\ndirection:               internal DirectionUpdateRule to determine directions to apply the averaging to\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructors\n\nAverageGradientRule(\n    M::AbstractManifold;\n    p::P=rand(M);\n    n::Int=10\n    direction::Union{<:DirectionUpdateRule,ManifoldDefaultsFactory}=IdentityUpdateRule(),\n    gradients = fill(zero_vector(p.M, o.x),n),\n    last_iterate = deepcopy(x0),\n    vector_transport_method = default_vector_transport_method(M, typeof(p))\n)\nAverageGradientRule(M::AbstractManifold, p; kwargs...)\n\nAdd average to a gradient problem, where\n\nn:                       determines the size of averaging\ndirection:               is the internal DirectionUpdateRule to determine the gradients to store\ngradients:               can be pre-filled with some history\nlast_iterate:            stores the last iterate\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.ConjugateDescentCoefficientRule","page":"Gradient Descent","title":"Manopt.ConjugateDescentCoefficientRule","text":"ConjugateDescentCoefficientRule <: DirectionUpdateRule\n\nA functor (problem, state, k) -> Î²_k to compute the conjugate gradient update coefficient adapted to manifolds\n\nSee also conjugate_gradient_descent\n\nConstructor\n\nConjugateDescentCoefficientRule()\n\nConstruct the conjugate descent coefficient update rule, a new storage is created by default.\n\nSee also\n\nConjugateDescentCoefficient, conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.MomentumGradientRule","page":"Gradient Descent","title":"Manopt.MomentumGradientRule","text":"MomentumGradientRule <: DirectionUpdateRule\n\nStore the necessary information to compute the MomentumGradient direction update.\n\nFields\n\np_old::P: a point on the manifold mathcalM\nmomentum::Real: factor for the momentum\ndirection: internal DirectionUpdateRule to determine directions to add the momentum to.\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nX_old::T: a tangent vector at the point p on the manifold mathcalM\n\nConstructors\n\nMomentumGradientRule(M::AbstractManifold; kwargs...)\nMomentumGradientRule(M::AbstractManifold, p; kwargs...)\n\nInitialize a momentum gradient rule to s, where p and X are memory for interim values.\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM\ns=IdentityUpdateRule()\nmomentum=0.2\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nSee also\n\nMomentumGradient\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.NesterovRule","page":"Gradient Descent","title":"Manopt.NesterovRule","text":"NesterovRule <: DirectionUpdateRule\n\nCompute a Nesterov inspired direction update rule. See Nesterov for details\n\nFields\n\nÎ³::Real, Î¼::Real: coefficients from the last iterate\nv::P:      an interim point to compute the next gradient evaluation point y_k\nshrinkage: a function k -> ... to compute the shrinkage Î²_k per iterate k`.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nConstructor\n\nNesterovRule(M::AbstractManifold; kwargs...)\nNesterovRule(M::AbstractManifold, p; kwargs...)\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nÎ³=0.001`\nÎ¼=0.9`\nshrinkage = k -> 0.8\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nSee also\n\nNesterov\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.PreconditionedDirectionRule","page":"Gradient Descent","title":"Manopt.PreconditionedDirectionRule","text":"PreconditionedDirectionRule{E<:AbstractEvaluationType} <: DirectionUpdateRule\n\nAdd a preconditioning as gradient processor, see PreconditionedDirection for more mathematical background.\n\nFields\n\ndirection:      internal DirectionUpdateRule to determine directions to apply the preconditioning to\npreconditioner: the preconditioner function\n\nConstructors\n\nPreconditionedDirectionRule(\n    M::AbstractManifold,\n    preconditioner;\n    direction::Union{<:DirectionUpdateRule,ManifoldDefaultsFactory}=IdentityUpdateRule(),\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n)\n\nAdd preconditioning to a gradient problem.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\npreconditioner:   preconditioner function, either as a (M, p, X) -> Yallocating or(M, Y, p, X) -> Y` mutating function\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ndirection=IdentityUpdateRule internal DirectionUpdateRule to determine the gradients to store or a ManifoldDefaultsFactory generating one\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.DebugGradient","page":"Gradient Descent","title":"Manopt.DebugGradient","text":"DebugGradient <: DebugAction\n\ndebug for the gradient evaluated at the current iterate\n\nConstructors\n\nDebugGradient(; long=false, prefix= , format= \"$prefix%s\", io=stdout, at_init=false)\n\ndisplay the short (false) or long (true) default text for the gradient, or set the prefix manually. Alternatively the complete format can be set.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.DebugGradientNorm","page":"Gradient Descent","title":"Manopt.DebugGradientNorm","text":"DebugGradientNorm <: DebugAction\n\ndebug for gradient evaluated at the current iterate.\n\nConstructors\n\nDebugGradientNorm([long=false, format= \"$prefix%s\", io=stdout, at_init=true])\n\ndisplay the short (false) or long (true) default text for the gradient norm.\n\nDebugGradientNorm(prefix[, p=print])\n\ndisplay the a prefix in front of the gradient norm.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.DebugStepsize","page":"Gradient Descent","title":"Manopt.DebugStepsize","text":"DebugStepsize <: DebugAction\n\ndebug for the current step size.\n\nConstructors\n\nDebugStepsize(;long=false,prefix=\"step size:\", format=\"$prefix%s\", io=stdout, at_init=true)\n\ndisplay the a prefix in front of the step size.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.RecordGradient","page":"Gradient Descent","title":"Manopt.RecordGradient","text":"RecordGradient <: RecordAction\n\nrecord the gradient evaluated at the current iterate\n\nConstructors\n\nRecordGradient(Î¾)\n\ninitialize the RecordAction to the corresponding type of the tangent vector.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.RecordGradientNorm","page":"Gradient Descent","title":"Manopt.RecordGradientNorm","text":"RecordGradientNorm <: RecordAction\n\nrecord the norm of the current gradient\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.RecordStepsize","page":"Gradient Descent","title":"Manopt.RecordStepsize","text":"RecordStepsize <: RecordAction\n\nrecord the step size\n\n\n\n\n\n","category":"type"},{"location":"solvers/#Available-solvers-in-Manopt.jl","page":"List of Solvers","title":"Available solvers in Manopt.jl","text":"Optimisation problems can be classified with respect to several criteria. The following list of the algorithms is a grouped with respect to the â€œinformationâ€ available about a optimisation problem\n\noperatorname*argmin_pmathbb M f(p)\n\nWithin each group short notes on advantages of the individual solvers, and required properties the cost f should have, are provided. In that list a ðŸ… is used to indicate state-of-the-art solvers, that usually perform best in their corresponding group and ðŸ« for a maybe not so fast, maybe not so state-of-the-art method, that nevertheless gets the job done most reliably.","category":"section"},{"location":"solvers/#Derivative-free","page":"List of Solvers","title":"Derivative free","text":"For derivative free only function evaluations of f are used.\n\nNelder-Mead a simplex based variant, that is using d+1 points, where d is the dimension of the manifold.\nParticle Swarm ðŸ« use the evolution of a set of points, called swarm, to explore the domain of the cost and find a minimizer.\nMesh adaptive direct search performs a mesh based exploration (poll) and search.\nCMA-ES uses a stochastic evolutionary strategy to perform minimization robust to local minima of the objective.","category":"section"},{"location":"solvers/#First-order","page":"List of Solvers","title":"First order","text":"","category":"section"},{"location":"solvers/#Gradient","page":"List of Solvers","title":"Gradient","text":"Gradient Descent uses the gradient from f to determine a descent direction. Here, the direction can also be changed to be Averaged, Momentum-based, based on Nesterovs rule.\nConjugate Gradient Descent uses information from the previous descent direction to improve the current (gradient-based) one including several such update rules.\nThe Quasi-Newton Method ðŸ… uses gradient evaluations to approximate the Hessian, which is then used in a Newton-like scheme, where both a limited memory and a full Hessian approximation are available with several different update rules.\nSteihaug-Toint Truncated Conjugate-Gradient Method a solver for a constrained problem defined on a tangent space.","category":"section"},{"location":"solvers/#Subgradient","page":"List of Solvers","title":"Subgradient","text":"The following methods require the Riemannian subgradient f to be available. While the subgradient might be set-valued, the function should provide one of the subgradients.\n\nThe Subgradient Method takes the negative subgradient as a step direction and can be combined with a step size.\nThe Convex Bundle Method (CBM) uses a former collection of sub gradients at the previous iterates and iterate candidates to solve a local approximation to f in every iteration by solving a quadratic problem in the tangent space.\nThe Proximal Bundle Method works similar to CBM, but solves a proximal map-based problem in every iteration.","category":"section"},{"location":"solvers/#Second-order","page":"List of Solvers","title":"Second order","text":"Adaptive Regularisation with Cubics ðŸ… locally builds a cubic model to determine the next descent direction.\nThe Riemannian Trust-Regions Solver builds a quadratic model within a trust region to determine the next descent direction.","category":"section"},{"location":"solvers/#Splitting-based","page":"List of Solvers","title":"Splitting based","text":"For splitting methods, the algorithms are based on splitting the cost into different parts, usually in a sum of two or more summands. This is usually very well tailored for non-smooth objectives.","category":"section"},{"location":"solvers/#Smooth","page":"List of Solvers","title":"Smooth","text":"The following methods require that the splitting, for example into several summands, is smooth in the sense that for every summand of the cost, the gradient should still exist everywhere\n\nLevenberg-Marquardt minimizes the square norm of f mathcal Mâ„^d provided the gradients of the component functions, or in other words the Jacobian of f.\nStochastic Gradient Descent is based on a splitting of f into a sum of several components f_i whose gradients are provided. Steps are performed according to gradients of randomly selected components.\nThe Alternating Gradient Descent alternates gradient descent steps on the components of the product manifold. All these components should be smooth as it is required, that the gradient exists, and is (locally) convex.","category":"section"},{"location":"solvers/#Nonsmooth","page":"List of Solvers","title":"Nonsmooth","text":"If the gradient does not exist everywhere, that is if the splitting yields summands that are nonsmooth, usually methods based on proximal maps are used.\n\nThe Chambolle-Pock algorithm uses a splitting f(p) = F(p) + G(Î›(p)), where G is defined on a manifold mathcal N and the proximal map of its Fenchel dual is required. Both these functions can be non-smooth.\nThe Cyclic Proximal Point ðŸ« uses proximal maps of the functions from splitting f into summands f_i\nDifference of Convex Algorithm (DCA) uses a splitting of the (non-convex) function f = g - h into a difference of two functions; for each of these it is required to have access to the gradient of g and the subgradient of h to state a sub problem in every iteration to be solved.\nDifference of Convex Proximal Point uses a splitting of the (non-convex) function f = g - h into a difference of two functions; provided the proximal map of g and the subgradient of h, the next iterate is computed. Compared to DCA, the corresponding sub problem is here written in a form that yields the proximal map.\nDouglasâ€”Rachford uses a splitting f(p) = F(x) + G(x) and their proximal maps to compute a minimizer of f, which can be non-smooth.\nPrimal-dual Riemannian semismooth Newton Algorithm extends Chambolle-Pock and requires the differentials of the proximal maps additionally.\nThe Proximal Point uses the proximal map of f iteratively.","category":"section"},{"location":"solvers/#Constrained","page":"List of Solvers","title":"Constrained","text":"Constrained problems of the form\n\nbeginalign*\noperatorname*argmin_pmathbb M f(p)\ntextsuch that   g(p) leq 0h(p) = 0\nendalign*\n\nFor these you can use\n\nThe Augmented Lagrangian Method (ALM), where both g and grad_g as well as h and grad_h are keyword arguments, and one of these pairs is mandatory.\nThe Exact Penalty Method (EPM) uses a penalty term instead of augmentation, but has the same interface as ALM.\nThe Interior Point Newton Method (IPM) rephrases the KKT system of a constrained problem into an Newton iteration being performed in every iteration.\nFrank-Wolfe algorithm, where besides the gradient of f either a closed form solution or a (maybe even automatically generated) sub problem solver for operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq is required, where p_k is a fixed point on the manifold (changed in every iteration).\nGradient Projection Method","category":"section"},{"location":"solvers/#On-the-tangent-space","page":"List of Solvers","title":"On the tangent space","text":"Conjugate Residual a solver for a linear system mathcal AX + b = 0 on a tangent space.\nSteihaug-Toint Truncated Conjugate-Gradient Method a solver for a constrained problem defined on a tangent space.","category":"section"},{"location":"solvers/#Alphabetical-list-of-algorithms","page":"List of Solvers","title":"Alphabetical list of algorithms","text":"Solver Function State\nAdaptive Regularisation with Cubics adaptive_regularization_with_cubics AdaptiveRegularizationState\nAugmented Lagrangian Method augmented_Lagrangian_method AugmentedLagrangianMethodState\nChambolle-Pock ChambollePock ChambollePockState\nConjugate Gradient Descent conjugate_gradient_descent ConjugateGradientDescentState\nConjugate Residual conjugate_residual ConjugateResidualState\nConvex Bundle Method convex_bundle_method ConvexBundleMethodState\nCyclic Proximal Point cyclic_proximal_point CyclicProximalPointState\nDifference of Convex Algorithm difference_of_convex_algorithm DifferenceOfConvexState\nDifference of Convex Proximal Point difference_of_convex_proximal_point DifferenceOfConvexProximalState\nDouglasâ€”Rachford DouglasRachford DouglasRachfordState\nExact Penalty Method exact_penalty_method ExactPenaltyMethodState\nFrank-Wolfe algorithm Frank_Wolfe_method FrankWolfeState\nGradient Descent gradient_descent GradientDescentState\nInterior Point Newton interior_point_Newton \nLevenberg-Marquardt LevenbergMarquardt LevenbergMarquardtState\nNelder-Mead NelderMead NelderMeadState\nParticle Swarm particle_swarm ParticleSwarmState\nPrimal-dual Riemannian semismooth Newton Algorithm primal_dual_semismooth_Newton PrimalDualSemismoothNewtonState\nProximal Bundle Method proximal_bundle_method ProximalBundleMethodState\nProximal Point proximal_point ProximalPointState\nQuasi-Newton Method quasi_Newton QuasiNewtonState\nSteihaug-Toint Truncated Conjugate-Gradient Method truncated_conjugate_gradient_descent TruncatedConjugateGradientState\nSubgradient Method subgradient_method SubGradientMethodState\nStochastic Gradient Descent stochastic_gradient_descent StochasticGradientDescentState\nRiemannian Trust-Regions trust_regions TrustRegionsState\n\nNote that the solvers (their AbstractManoptSolverState, to be precise) can also be decorated to enhance your algorithm by general additional properties, see debug output and recording values. This is done using the debug= and record= keywords in the function calls. Similarly, a cache= keyword is available in any of the function calls, that wraps the AbstractManoptProblem in a cache for certain parts of the objective.","category":"section"},{"location":"solvers/#Technical-details","page":"List of Solvers","title":"Technical details","text":"The main function a solver calls is\n\nwhich is a framework that you in general should not change or redefine. It uses the following methods, which also need to be implemented on your own algorithm, if you want to provide one.","category":"section"},{"location":"solvers/#API-for-solvers","page":"List of Solvers","title":"API for solvers","text":"this is a short overview of the different types of high-level functions are usually available for a solver. Assume the solver is called new_solver and requires a cost f and some first order information df as well as a starting point p on M. f and df form the objective together called obj.\n\nThen there are basically two different variants to call","category":"section"},{"location":"solvers/#The-easy-to-access-call","page":"List of Solvers","title":"The easy to access call","text":"new_solver(M, f, df, p=rand(M); kwargs...)\nnew_solver!(M, f, df, p; kwargs...)\n\nWhere the start point should be optional. Keyword arguments include the type of evaluation, decorators like debug= or record= as well as algorithm specific ones. If you provide an immutable point p or the rand(M) point is immutable, like on the Circle() this method should turn the point into a mutable one as well.\n\nThe third variant works in place of p, so it is mandatory.\n\nThis first interface would set up the objective and pass all keywords on the objective based call.","category":"section"},{"location":"solvers/#Objective-based-calls-to-solvers","page":"List of Solvers","title":"Objective based calls to solvers","text":"new_solver(M, obj, p=rand(M); kwargs...)\nnew_solver!(M, obj, p; kwargs...)\n\nHere the objective would be created beforehand for example to compare different solvers on the same objective, and for the first variant the start point is optional. Keyword arguments include decorators like debug= or record= as well as algorithm specific ones.\n\nThis variant would generate the problem and the state and verify validity of all provided keyword arguments that affect the state. Then it would call the iterate process.","category":"section"},{"location":"solvers/#Manual-calls","page":"List of Solvers","title":"Manual calls","text":"If you generate the corresponding problem and state as the previous step does, you can also use the third (lowest level) and just call\n\nsolve!(problem, state)","category":"section"},{"location":"solvers/#Closed-form-sub-solvers","page":"List of Solvers","title":"Closed-form sub solvers","text":"If a subsolver solution is available in closed form, ClosedFormSubSolverState is used to indicate that.","category":"section"},{"location":"solvers/#Manopt.solve!-Tuple{AbstractManoptProblem, AbstractManoptSolverState}","page":"List of Solvers","title":"Manopt.solve!","text":"solve!(p::AbstractManoptProblem, s::AbstractManoptSolverState)\n\nrun the solver implemented for the AbstractManoptProblemp and the AbstractManoptSolverStates employing initialize_solver!, step_solver!, as well as the stop_solver! of the solver.\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Manopt.initialize_solver!","page":"List of Solvers","title":"Manopt.initialize_solver!","text":"initialize_solver!(ams::AbstractManoptProblem, amp::AbstractManoptSolverState)\n\nInitialize the solver to the optimization AbstractManoptProblem amp by initializing the necessary values in the AbstractManoptSolverState amp.\n\n\n\n\n\ninitialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState)\n\nExtend the initialization of the solver by a hook to run the DebugAction that was added to the :Start entry of the debug lists. All others are triggered (with iteration number 0) to trigger possible resets\n\n\n\n\n\ninitialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState)\n\nExtend the initialization of the solver by a hook to run records that were added to the :Start entry.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.step_solver!","page":"List of Solvers","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, k)\n\nDo one iteration step (the ith) for an AbstractManoptProblemp by modifying the values in the AbstractManoptSolverState ams.\n\n\n\n\n\nstep_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, k)\n\nExtend the ith step of the solver by a hook to run debug prints, that were added to the :BeforeIteration and :Iteration entries of the debug lists.\n\n\n\n\n\nstep_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, k)\n\nExtend the ith step of the solver by a hook to run records, that were added to the :Iteration entry.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.get_solver_result","page":"List of Solvers","title":"Manopt.get_solver_result","text":"get_solver_result(ams::AbstractManoptSolverState)\nget_solver_result(tos::Tuple{AbstractManifoldObjective,AbstractManoptSolverState})\nget_solver_result(o::AbstractManifoldObjective, s::AbstractManoptSolverState)\n\nReturn the final result after all iterations that is stored within the AbstractManoptSolverState ams, which was modified during the iterations.\n\nFor the case the objective is passed as well, but default, the objective is ignored, and the solver result for the state is called.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.get_solver_return","page":"List of Solvers","title":"Manopt.get_solver_return","text":"get_solver_return(s::AbstractManoptSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::AbstractManoptSolverState)\n\ndetermine the result value of a call to a solver. By default this returns the same as get_solver_result.\n\nget_solver_return(s::ReturnSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::ReturnSolverState)\n\nreturn the internally stored state of the ReturnSolverState instead of the minimizer. This means that when the state are decorated like this, the user still has to call get_solver_result on the internal state separately.\n\nget_solver_return(o::ReturnManifoldObjective, s::AbstractManoptSolverState)\n\nreturn both the objective and the state as a tuple.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Any}","page":"List of Solvers","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, k)\n\ndepending on the current AbstractManoptProblem amp, the current state of the solver stored in AbstractManoptSolverState ams and the current iterate i this function determines whether to stop the solver, which by default means to call the internal StoppingCriterion. ams.stop\n\n\n\n\n\n","category":"method"},{"location":"solvers/#Manopt.ClosedFormSubSolverState","page":"List of Solvers","title":"Manopt.ClosedFormSubSolverState","text":"ClosedFormSubSolverState{E<:AbstractEvaluationType} <: AbstractManoptSolverState\n\nSubsolver state indicating that a closed-form solution is available with AbstractEvaluationType E.\n\nConstructor\n\nClosedFormSubSolverState(; evaluation=AllocatingEvaluation())\n\n\n\n\n\n","category":"type"},{"location":"extensions/#Extensions","page":"Extensions","title":"Extensions","text":"","category":"section"},{"location":"extensions/#LineSearches.jl","page":"Extensions","title":"LineSearches.jl","text":"Manopt can be used with line search algorithms implemented in LineSearches.jl. This can be illustrated by the following example of optimizing Rosenbrock function constrained to the unit sphere.\n\nusing Manopt, Manifolds, LineSearches\n\n# define objective function and its gradient\np = [1.0, 100.0]\nfunction rosenbrock(::AbstractManifold, x)\n    val = zero(eltype(x))\n    for i in 1:(length(x) - 1)\n        val += (p[1] - x[i])^2 + p[2] * (x[i + 1] - x[i]^2)^2\n    end\n    return val\nend\nfunction rosenbrock_grad!(M::AbstractManifold, storage, x)\n    storage .= 0.0\n    for i in 1:(length(x) - 1)\n        storage[i] += -2.0 * (p[1] - x[i]) - 4.0 * p[2] * (x[i + 1] - x[i]^2) * x[i]\n        storage[i + 1] += 2.0 * p[2] * (x[i + 1] - x[i]^2)\n    end\n    project!(M, storage, x, storage)\n    return storage\nend\n# define constraint\nn_dims = 5\nM = Manifolds.Sphere(n_dims)\n# set initial point\nx0 = vcat(zeros(n_dims - 1), 1.0)\n# use LineSearches.jl HagerZhang method with Manopt.jl quasiNewton solver\nls_hz = Manopt.LineSearchesStepsize(M, LineSearches.HagerZhang())\nx_opt = quasi_Newton(\n    M,\n    rosenbrock,\n    rosenbrock_grad!,\n    x0;\n    stepsize=ls_hz,\n    evaluation=InplaceEvaluation(),\n    stopping_criterion=StopAfterIteration(1000) | StopWhenGradientNormLess(1e-6),\n    return_state=true,\n)\n\nIn general this defines the following new stepsize","category":"section"},{"location":"extensions/#Manifolds.jl","page":"Extensions","title":"Manifolds.jl","text":"Loading Manifolds.jl introduces the following additional functions\n\nInternally, Manopt.jl provides the two additional functions to choose some Euclidean space when needed as","category":"section"},{"location":"extensions/#[JuMP.jl](@extref-JuMP-:std:doc:index)","page":"Extensions","title":"JuMP.jl","text":"Manopt can be used from within JuMP.jl. The manifold is provided in the @variable macro. Note that until now, only variables (points on manifolds) are supported, that are arrays, especially structs do not yet work. The algebraic expression of the objective function is specified in the @objective macro. The descent_state_type attribute specifies the solver.\n\nusing JuMP, Manopt, Manifolds\nmodel = Model(Manopt.JuMP_Optimizer)\n# Change the solver with this option, `GradientDescentState` is the default\nset_attribute(model, \"descent_state_type\", GradientDescentState)\n@variable(model, U[1:2, 1:2] in Stiefel(2, 2), start = 1.0)\n@objective(model, Min, sum((A - U) .^ 2))\noptimize!(model)\nsolution_summary(model)\n\nSeveral functions from the Mathematical Optimization Interface (MOI) are extended when both Manopt.jl and JuMP.jl are loaded:","category":"section"},{"location":"extensions/#Internal-functions","page":"Extensions","title":"Internal functions","text":"","category":"section"},{"location":"extensions/#Internal-wrappers-and-their-functions","page":"Extensions","title":"Internal wrappers and their functions","text":"","category":"section"},{"location":"extensions/#Manopt.LineSearchesStepsize","page":"Extensions","title":"Manopt.LineSearchesStepsize","text":"LineSearchesStepsize <: Stepsize\n\nWrapper for line searches available in the LineSearches.jl library.\n\nConstructors\n\nLineSearchesStepsize(M::AbstractManifold, linesearch; kwargs...\nLineSearchesStepsize(\n    linesearch;\n    retraction_method=ExponentialRetraction(),\n    vector_transport_method=ParallelTransport(),\n)\n\nWrap linesearch (for example HagerZhang or MoreThuente). The initial step selection from Linesearches.jl is not yet supported and the value 1.0 is used.\n\nKeyword Arguments\n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"extensions/#Manopt.max_stepsize-Tuple{FixedRankMatrices, Any}","page":"Extensions","title":"Manopt.max_stepsize","text":"max_stepsize(M::FixedRankMatrices, p)\n\nReturn a reasonable guess of maximum step size on FixedRankMatrices following the choice of typical distance in Matlab Manopt, the dimension of M. See this note\n\n\n\n\n\n","category":"method"},{"location":"extensions/#Manopt.max_stepsize-Tuple{Hyperrectangle, Any}","page":"Extensions","title":"Manopt.max_stepsize","text":"max_stepsize(M::Hyperrectangle, p)\n\nThe default maximum stepsize for Hyperrectangle manifold with corners is maximum of distances from p to each boundary.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#Manopt.max_stepsize-Tuple{FiberBundle{ð”½, ManifoldsBase.TangentSpaceType, M} where {ð”½, M<:AbstractManifold{ð”½}}, Any}","page":"Extensions","title":"Manopt.max_stepsize","text":"max_stepsize(M::TangentBundle, p)\n\nTangent bundle has injectivity radius of either infinity (for flat manifolds) or 0 (for non-flat manifolds). This makes a guess of what a reasonable maximum stepsize on a tangent bundle might be.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManifoldsBase.mid_point","page":"Extensions","title":"ManifoldsBase.mid_point","text":"mid_point(M, p, q, x)\nmid_point!(M, y, p, q, x)\n\nCompute the mid point between p and q. If there is more than one mid point of (not necessarily minimizing) geodesics (for example on the sphere), the one nearest to x is returned (in place of y).\n\n\n\n\n\n","category":"function"},{"location":"extensions/#Manopt.Rn","page":"Extensions","title":"Manopt.Rn","text":"Rn(args; kwargs...)\nRn(s::Symbol=:Manifolds, args; kwargs...)\n\nA small internal helper function to choose a Euclidean space. By default, this uses the DefaultManifold unless you load a more advanced Euclidean space like Euclidean from Manifolds.jl\n\n\n\n\n\n","category":"function"},{"location":"extensions/#Manopt.Rn_default","page":"Extensions","title":"Manopt.Rn_default","text":"Rn_default()\n\nSpecify a default value to dispatch Rn on. This default is set to Manifolds, indicating, that when this package is loaded, it is the preferred package to ask for a vector space space.\n\nThe default within Manopt.jl is to use the DefaultManifold from ManifoldsBase.jl. If you load Manifolds.jl this switches to using Euclidean.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#Manopt.JuMP_Optimizer","page":"Extensions","title":"Manopt.JuMP_Optimizer","text":"Manopt.JuMP_Optimizer()\n\nRepresent a solver from Manopt.jl within the MathOptInterface (MOI) framework. See ManoptOptimizer for the fields and their meaning.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#JuMP.build_variable","page":"Extensions","title":"JuMP.build_variable","text":"JuMP.build_variable(::Function, func, m::ManifoldsBase.AbstractManifold)\n\nBuild a JuMP.VariablesConstrainedOnCreation object containing variables and the ManifoldSet in which they should belong as well as the shape that can be used to go from the vectorized MOI representation to the shape of the manifold, that is, ManifoldPointArrayShape.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.add_constrained_variables","page":"Extensions","title":"MathOptInterface.add_constrained_variables","text":"MOI.add_constrained_variables(model::ManoptOptimizer, set::ManifoldSet)\n\nAdd dimension(set) variables constrained in set and return the list of variable indices that can be used to reference them as well a constraint index for the constraint enforcing the membership of the variables manifold as a set.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.copy_to","page":"Extensions","title":"MathOptInterface.copy_to","text":"MOI.copy_to(dest::ManoptOptimizer, src::MOI.ModelLike)\n\nBecause supports_incremental_interface(dest) is true, this simply uses default_copy_to and copies the variables with add_constrained_variables and the objective sense with set.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.empty!","page":"Extensions","title":"MathOptInterface.empty!","text":"MOI.empty!(model::ManoptOptimizer)\n\nClear all model data from model but keep the options set.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.dimension","page":"Extensions","title":"MathOptInterface.dimension","text":"MOI.dimension(set::ManifoldSet)\n\nReturn the representation size of points on the (vectorized in representation) manifold. As the MOI variables are real, this means if the representation_size yields (in product) n, this refers to the vectorized point / tangent vector  from (a subset of â„^n).\n\nNote that this is not the dimension of the manifold itself, but the vector length of the vectorized representation of the manifold.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.supports_add_constrained_variables","page":"Extensions","title":"MathOptInterface.supports_add_constrained_variables","text":"MOI.supports_add_constrained_variables(::ManoptOptimizer, ::Type{<:ManifoldSet})\n\nReturn true indicating that ManoptOptimizer support optimization on variables constrained to belong in a vectorized manifold.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.get","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(::ManoptOptimizer, ::MOI.SolverVersion)\n\nReturn the version of the Manopt solver, it corresponds to the version of Manopt.jl.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn last value set by set(model, attr, value).\n\n\n\n\n\nMOI.get(::ManoptOptimizer, ::MOI.SolverName)\n\nReturn the name of the ManoptOptimizer with the value of the descent_state_type option.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, ::MOI.NumberOfVariables)\n\nReturn the number of variables added in the model, this corresponds to the dimension of the ManifoldSet.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, ::MOI.ObjectiveSense)\n\nReturn the objective sense, defaults to FEASIBILITY_SENSE if no sense has already been set.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, ::MOI.ResultCount)\n\nReturn OPTIMIZE_NOT_CALLED if optimize! hasn't been called yet and LOCALLY_SOLVED otherwise indicating that the solver has solved the problem to local optimality the value of RawStatusString for more details on why the solver stopped.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, ::MOI.ResultCount)\n\nReturn 0 if optimize! hasn't been called yet and 1 otherwise indicating that one solution is available.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, ::MOI.PrimalStatus)\n\nReturn MOI.NO_SOLUTION if optimize! hasn't been called yet and MOI.FEASIBLE_POINT if it is otherwise indicating that a solution is available to query with VariablePrimalStart.\n\n\n\n\n\nMOI.get(::ManoptOptimizer, ::MOI.DualStatus)\n\nReturns MOI.NO_SOLUTION indicating that there is no dual solution available.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, ::MOI.RawStatusString)\n\nReturn a String containing get_reason without the ending newline character.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, attr::MOI.ObjectiveValue)\n\nReturn the value of the objective function evaluated at the solution.\n\n\n\n\n\nMOI.get(model::ManoptOptimizer, attr::MOI.VariablePrimal, vi::MOI.VariableIndex)\n\nReturn the value of the solution for the variable of index vi.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.is_valid","page":"Extensions","title":"MathOptInterface.is_valid","text":"MOI.is_valid(model::ManoptOptimizer, vi::MOI.VariableIndex)\n\nReturn whether vi is a valid variable index.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.supports","page":"Extensions","title":"MathOptInterface.supports","text":"MOI.supports(::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn a Bool indicating whether attr.name is a valid option name for Manopt.\n\n\n\n\n\nMOI.supports(::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn true indicating that ManoptOptimizer supports starting values for the variables.\n\n\n\n\n\nMOI.supports(::ManoptOptimizer, ::Union{MOI.ObjectiveSense,MOI.ObjectiveFunction})\n\nReturn true indicating that Optimizer supports being set the objective sense (that is, min, max or feasibility) and the objective function.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.supports_incremental_interface","page":"Extensions","title":"MathOptInterface.supports_incremental_interface","text":"MOI.supports_incremental_interface(::ManoptOptimizer)\n\nReturn true indicating that ManoptOptimizer implements add_constrained_variables and set for ObjectiveFunction so it can be used with direct_model and does not require a CachingOptimizer. See See supports_incremental_interface.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#MathOptInterface.set","page":"Extensions","title":"MathOptInterface.set","text":"MOI.get(model::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nSet the value for the keyword argument attr.name to give for the constructor model.options[DESCENT_STATE_TYPE].\n\n\n\n\n\nfunction MOI.set(\n    model::ManoptOptimizer,\n    ::MOI.VariablePrimalStart,\n    vi::MOI.VariableIndex,\n    value::Union{Real,Nothing},\n)\n\nSet the starting value of the variable of index vi to value. Note that if value is nothing then it essentially unset any previous starting values set and hence MOI.optimize! unless another starting value is set.\n\n\n\n\n\nMOI.set(model::ManoptOptimizer, ::MOI.ObjectiveSense, sense::MOI.OptimizationSense)\n\nModify the objective sense to either MAX_SENSE, MIN_SENSE or FEASIBILITY_SENSE.\n\n\n\n\n\nMOI.set(model::ManoptOptimizer, ::MOI.ObjectiveFunction{F}, func::F) where {F}\n\nSet the objective function as func for model.\n\n\n\n\n\n","category":"function"},{"location":"extensions/#ManoptJuMPExt.ManifoldPointArrayShape","page":"Extensions","title":"ManoptJuMPExt.ManifoldPointArrayShape","text":"ManifoldPointArrayShape{N} <: JuMP.AbstractShape\n\nRepresent some generic AbstractArray of a certain size representing an point on a manifold\n\nFields\n\nsize::NTuple{N,Int}: The size of the array\n\n\n\n\n\n","category":"type"},{"location":"extensions/#ManoptJuMPExt.ManifoldSet","page":"Extensions","title":"ManoptJuMPExt.ManifoldSet","text":"ManifoldSet{M<:ManifoldsBase.AbstractManifold} <: MOI.AbstractVectorSet\n\nModel a manifold from ManifoldsBase.jl as a vectorial set in the MathOptInterface (MOI). This is a slight misuse of notation, since the manifold itself might not be embedded, but just be parametrized in a certain way.\n\nFields\n\nmanifold::M: The manifold in which the variables are constrained to lie. This is a ManifoldsBase.AbstractManifold object.\n\n\n\n\n\n","category":"type"},{"location":"extensions/#ManoptJuMPExt.ManoptOptimizer","page":"Extensions","title":"ManoptJuMPExt.ManoptOptimizer","text":"ManoptOptimizer <: MOI.AbstractOptimizer\n\nRepresent a solver from Manopt.jl within the MathOptInterface (MOI) framework of JuMP.jl\n\nFields\n\nproblem::AbstractManoptProblem a problem in manopt, especially   containing the manifold and the objective function. It can be constructed as soon as   the manifold and the objective are present.\nmanifold::AbstractManifold the manifold on which the optimization is performed.\nobjective::AbstractManifoldObjective the objective function to be optimized.\nstate::AbstractManoptSolverState the state specifying the solver to use.\nvariable_primal_start::Vector{Union{Nothing,Float64}} starting value for the solver,   in a vectorized form that JuMP.jl requires.\nsense::MOI.OptimizationSense the sense of optimization, currently only minimization and maximization are supported.\noptions::Dict{String,Any}: parameters specifying a solver before the state is initialized, so especially which AbstractManoptSolverState to use, when setting up the `state.\n\nAll types in brackets can also be Nothing, indicating they were not yet initialized.\n\n\n\n\n\n","category":"type"},{"location":"extensions/#ManoptJuMPExt.RiemannianFunction","page":"Extensions","title":"ManoptJuMPExt.RiemannianFunction","text":"RiemannianFunction{MO<:Manopt.AbstractManifoldObjective} <: MOI.AbstractScalarFunction\n\nA wrapper for a AbstractManifoldObjective that can be used as a MOI.AbstractScalarFunction.\n\nFields\n\nfunc::MO: The AbstractManifoldObjective function to be wrapped.\n\n\n\n\n\n","category":"type"},{"location":"extensions/#ManoptJuMPExt._EmbeddingObjective","page":"Extensions","title":"ManoptJuMPExt._EmbeddingObjective","text":"_EmbeddingObjective{E<:MOI.AbstractNLPEvaluator,T}\n\nObjective where evaluator is a MathOptInterface evaluator for the objective in the embedding. The fields vectorized_point, vectorized_tangent and embedding_tangent are used as preallocated buffer so that the conversion to Euclidean objective is allocation-free.\n\n\n\n\n\n","category":"type"},{"location":"extensions/#Base.length-Tuple{ManoptJuMPExt.ManifoldPointArrayShape}","page":"Extensions","title":"Base.length","text":"length(shape::ManifoldPointArrayShape)\n\nReturn the length of the vectors in the vectorized representation.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#JuMP.build_variable-Tuple{Function, Any, AbstractManifold}","page":"Extensions","title":"JuMP.build_variable","text":"JuMP.build_variable(::Function, func, m::ManifoldsBase.AbstractManifold)\n\nBuild a JuMP.VariablesConstrainedOnCreation object containing variables and the ManifoldSet in which they should belong as well as the shape that can be used to go from the vectorized MOI representation to the shape of the manifold, that is, ManifoldPointArrayShape.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#JuMP.jump_function-Tuple{AbstractModel, ManoptJuMPExt.RiemannianFunction}","page":"Extensions","title":"JuMP.jump_function","text":"JuMP.jump_function(::JuMP.AbstractModel, F::Type{<:RiemannianFunction})\n\nThe JuMP.jl function of a RiemannianFunction for any AbstractModel is that function itself.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#JuMP.jump_function_type-Tuple{AbstractModel, Type{<:ManoptJuMPExt.RiemannianFunction}}","page":"Extensions","title":"JuMP.jump_function_type","text":"JuMP.jump_function_type(::JuMP.AbstractModel, F::Type{<:RiemannianFunction})\n\nThe JuMP.jl function type of a function of type RiemannianFunction for any AbstractModel is that function type itself\n\n\n\n\n\n","category":"method"},{"location":"extensions/#JuMP.reshape_vector-Tuple{Vector, ManoptJuMPExt.ManifoldPointArrayShape}","page":"Extensions","title":"JuMP.reshape_vector","text":"JuMP.reshape_vector(vector::Vector, shape::ManifoldPointArrayShape)\n\nGiven some vector representation vector used within JuMP of a point on a manifold represents points by arrays, use the information from the shape to reshape it back into such an array. For the inverse see JuMP.vectorize.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#JuMP.set_objective_function-Tuple{Model, AbstractManifoldObjective}","page":"Extensions","title":"JuMP.set_objective_function","text":"JuMP.set_objective_function(model::JuMP.Model, obj::Manopt.AbstractManifoldObjective)\n\nSet the objective function of a JuMP.Model model to an AbstractManifoldObjective obj. This allows to use @objective with an objective from Manopt.jl.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#JuMP.vectorize-Union{Tuple{N}, Tuple{T}, Tuple{Array{T, N}, ManoptJuMPExt.ManifoldPointArrayShape{N}}} where {T, N}","page":"Extensions","title":"JuMP.vectorize","text":"JuMP.vectorize(p::Array{T,N}, shape::ManifoldPointArrayShape{N}) where {T,N}\n\nGiven a point p as an N-dimensional array representing a point on a certain manifold, reshape it to a vector, which is necessary within JuMP. For the inverse see JuMP.reshape_vector.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#Manopt.JuMP_Optimizer-Tuple","page":"Extensions","title":"Manopt.JuMP_Optimizer","text":"Manopt.JuMP_Optimizer()\n\nRepresent a solver from Manopt.jl within the MathOptInterface (MOI) framework. See ManoptOptimizer for the fields and their meaning.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManoptJuMPExt._get_cost-Tuple{Any, ManoptJuMPExt._EmbeddingObjective, Any}","page":"Extensions","title":"ManoptJuMPExt._get_cost","text":"_get_cost(M, objective::_EmbeddingObjective, p)\n\nConvert the point p to its vectorization and then evaluate the objective using objective.evaluator.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManoptJuMPExt._get_gradient!-Tuple{Any, Any, ManoptJuMPExt._EmbeddingObjective, Any}","page":"Extensions","title":"ManoptJuMPExt._get_gradient!","text":"_get_cost(M, objective::_EmbeddingObjective, p)\n\nConvert the point p to its vectorization and then evaluate the gradient using objective.evaluator to get the vectorized gradient. Then reshape the gradient and convert it to the Riemannian gradient.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManoptJuMPExt._reshape_vector!-Union{Tuple{N}, Tuple{T}, Tuple{Array{T, N}, Vector{T}, ManoptJuMPExt.ManifoldPointArrayShape{N}}} where {T, N}","page":"Extensions","title":"ManoptJuMPExt._reshape_vector!","text":"_reshape_vector!(res::Array{T,N}, vec::Vector{T}, ::ManifoldPointArrayShape{N}) where {T,N}\n\nInplace version of res = JuMP.reshape_vector(vec, shape).\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManoptJuMPExt._shape-Tuple{AbstractManifold}","page":"Extensions","title":"ManoptJuMPExt._shape","text":"_shape(m::ManifoldsBase.AbstractManifold)\n\nReturn the shape of points of the manifold m. At the moment, we only support manifolds for which the shape is a Array.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManoptJuMPExt._vectorize!-Union{Tuple{N}, Tuple{T}, Tuple{Vector{T}, Array{T, N}, ManoptJuMPExt.ManifoldPointArrayShape{N}}} where {T, N}","page":"Extensions","title":"ManoptJuMPExt._vectorize!","text":"_vectorize!(res::Vector{T}, array::Array{T,N}, shape::ManifoldPointArrayShape{N}) where {T,N}\n\nInplace version of res = JuMP.vectorize(array, shape).\n\n\n\n\n\n","category":"method"},{"location":"extensions/#ManoptJuMPExt._zero-Union{Tuple{ManoptJuMPExt.ManifoldPointArrayShape{N}}, Tuple{N}} where N","page":"Extensions","title":"ManoptJuMPExt._zero","text":"_zero(shape::ManifoldPointArrayShape)\n\nReturn a zero element of the shape shape.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.Utilities.map_indices-Tuple{Function, ManoptJuMPExt.RiemannianFunction}","page":"Extensions","title":"MathOptInterface.Utilities.map_indices","text":"MOI.Utilities.map_indices(index_map::Function, func::RiemannianFunction)\n\nThe original docstring states something about substituting some variable indices by their index map variants. On a RiemannianFunction there is nothing to substitute,\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.add_constrained_variables-Tuple{ManoptJuMPExt.ManoptOptimizer, ManoptJuMPExt.ManifoldSet}","page":"Extensions","title":"MathOptInterface.add_constrained_variables","text":"MOI.add_constrained_variables(model::ManoptOptimizer, set::ManifoldSet)\n\nAdd dimension(set) variables constrained in set and return the list of variable indices that can be used to reference them as well a constraint index for the constraint enforcing the membership of the variables manifold as a set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.copy_to-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.ModelLike}","page":"Extensions","title":"MathOptInterface.copy_to","text":"MOI.copy_to(dest::ManoptOptimizer, src::MOI.ModelLike)\n\nBecause supports_incremental_interface(dest) is true, this simply uses default_copy_to and copies the variables with add_constrained_variables and the objective sense with set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.dimension-Tuple{ManoptJuMPExt.ManifoldSet}","page":"Extensions","title":"MathOptInterface.dimension","text":"MOI.dimension(set::ManifoldSet)\n\nReturn the representation size of points on the (vectorized in representation) manifold. As the MOI variables are real, this means if the representation_size yields (in product) n, this refers to the vectorized point / tangent vector  from (a subset of â„^n).\n\nNote that this is not the dimension of the manifold itself, but the vector length of the vectorized representation of the manifold.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.empty!-Tuple{ManoptJuMPExt.ManoptOptimizer}","page":"Extensions","title":"MathOptInterface.empty!","text":"MOI.empty!(model::ManoptOptimizer)\n\nClear all model data from model but keep the options set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.DualStatus}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(::ManoptOptimizer, ::MOI.DualStatus)\n\nReturns MOI.NO_SOLUTION indicating that there is no dual solution available.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.NumberOfVariables}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, ::MOI.NumberOfVariables)\n\nReturn the number of variables added in the model, this corresponds to the dimension of the ManifoldSet.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.ObjectiveSense}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, ::MOI.ObjectiveSense)\n\nReturn the objective sense, defaults to FEASIBILITY_SENSE if no sense has already been set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.ObjectiveValue}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, attr::MOI.ObjectiveValue)\n\nReturn the value of the objective function evaluated at the solution.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.PrimalStatus}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, ::MOI.PrimalStatus)\n\nReturn MOI.NO_SOLUTION if optimize! hasn't been called yet and MOI.FEASIBLE_POINT if it is otherwise indicating that a solution is available to query with VariablePrimalStart.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.RawOptimizerAttribute}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn last value set by set(model, attr, value).\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.RawStatusString}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, ::MOI.RawStatusString)\n\nReturn a String containing get_reason without the ending newline character.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.ResultCount}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, ::MOI.ResultCount)\n\nReturn 0 if optimize! hasn't been called yet and 1 otherwise indicating that one solution is available.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.SolverName}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(::ManoptOptimizer, ::MOI.SolverName)\n\nReturn the name of the ManoptOptimizer with the value of the descent_state_type option.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.SolverVersion}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(::ManoptOptimizer, ::MOI.SolverVersion)\n\nReturn the version of the Manopt solver, it corresponds to the version of Manopt.jl.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.TerminationStatus}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, ::MOI.ResultCount)\n\nReturn OPTIMIZE_NOT_CALLED if optimize! hasn't been called yet and LOCALLY_SOLVED otherwise indicating that the solver has solved the problem to local optimality the value of RawStatusString for more details on why the solver stopped.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.get-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.VariablePrimal, MathOptInterface.VariableIndex}","page":"Extensions","title":"MathOptInterface.get","text":"MOI.get(model::ManoptOptimizer, attr::MOI.VariablePrimal, vi::MOI.VariableIndex)\n\nReturn the value of the solution for the variable of index vi.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.is_valid-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.VariableIndex}","page":"Extensions","title":"MathOptInterface.is_valid","text":"MOI.is_valid(model::ManoptOptimizer, vi::MOI.VariableIndex)\n\nReturn whether vi is a valid variable index.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.ObjectiveFunction, MathOptInterface.AbstractScalarFunction}","page":"Extensions","title":"MathOptInterface.set","text":"MOI.set(model::ManoptOptimizer, ::MOI.ObjectiveFunction{F}, func::F) where {F}\n\nSet the objective function as func for model.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.ObjectiveSense, OptimizationSense}","page":"Extensions","title":"MathOptInterface.set","text":"MOI.set(model::ManoptOptimizer, ::MOI.ObjectiveSense, sense::MOI.OptimizationSense)\n\nModify the objective sense to either MAX_SENSE, MIN_SENSE or FEASIBILITY_SENSE.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.RawOptimizerAttribute, Any}","page":"Extensions","title":"MathOptInterface.set","text":"MOI.get(model::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nSet the value for the keyword argument attr.name to give for the constructor model.options[DESCENT_STATE_TYPE].\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.set-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.VariablePrimalStart, MathOptInterface.VariableIndex, Union{Nothing, Real}}","page":"Extensions","title":"MathOptInterface.set","text":"function MOI.set(\n    model::ManoptOptimizer,\n    ::MOI.VariablePrimalStart,\n    vi::MOI.VariableIndex,\n    value::Union{Real,Nothing},\n)\n\nSet the starting value of the variable of index vi to value. Note that if value is nothing then it essentially unset any previous starting values set and hence MOI.optimize! unless another starting value is set.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.RawOptimizerAttribute}","page":"Extensions","title":"MathOptInterface.supports","text":"MOI.supports(::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn a Bool indicating whether attr.name is a valid option name for Manopt.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.ManoptOptimizer, MathOptInterface.VariablePrimalStart, Type{MathOptInterface.VariableIndex}}","page":"Extensions","title":"MathOptInterface.supports","text":"MOI.supports(::ManoptOptimizer, attr::MOI.RawOptimizerAttribute)\n\nReturn true indicating that ManoptOptimizer supports starting values for the variables.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports-Tuple{ManoptJuMPExt.ManoptOptimizer, Union{MathOptInterface.ObjectiveSense, MathOptInterface.ObjectiveFunction}}","page":"Extensions","title":"MathOptInterface.supports","text":"MOI.supports(::ManoptOptimizer, ::Union{MOI.ObjectiveSense,MOI.ObjectiveFunction})\n\nReturn true indicating that Optimizer supports being set the objective sense (that is, min, max or feasibility) and the objective function.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports_add_constrained_variables-Tuple{ManoptJuMPExt.ManoptOptimizer, Type{<:ManoptJuMPExt.ManifoldSet}}","page":"Extensions","title":"MathOptInterface.supports_add_constrained_variables","text":"MOI.supports_add_constrained_variables(::ManoptOptimizer, ::Type{<:ManifoldSet})\n\nReturn true indicating that ManoptOptimizer support optimization on variables constrained to belong in a vectorized manifold.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#MathOptInterface.supports_incremental_interface-Tuple{ManoptJuMPExt.ManoptOptimizer}","page":"Extensions","title":"MathOptInterface.supports_incremental_interface","text":"MOI.supports_incremental_interface(::ManoptOptimizer)\n\nReturn true indicating that ManoptOptimizer implements add_constrained_variables and set for ObjectiveFunction so it can be used with direct_model and does not require a CachingOptimizer. See See supports_incremental_interface.\n\n\n\n\n\n","category":"method"},{"location":"tutorials/ImplementOwnManifold/#Optimize-on-your-own-manifold","page":"Optimize on your own manifold","title":"Optimize on your own manifold","text":"Ronny Bergmann\n\nWhen you have used a few solvers from Manopt.jl for example like in the opening tutorial ðŸ”ï¸ Get started with Manopt.jl and also familiarized yourself with how to work with manifolds in general at ðŸš€ Get Started with Manifolds.jl, you might come across the point that you want to implementing a manifold yourself and use it within Manopt.jl. A challenge might be, which functions are necessary, since the overall interface of ManifoldsBase.jl is maybe not completely necessary.\n\nThis tutorial aims to help you through these steps to implement necessary parts of a manifold to get started with the solver you have in mind.","category":"section"},{"location":"tutorials/ImplementOwnManifold/#An-example-problem","page":"Optimize on your own manifold","title":"An example problem","text":"We get started by loading the packages we need.\n\nusing LinearAlgebra, Manifolds, ManifoldsBase, Random\nusing Manopt\nRandom.seed!(42)\n\nWe also define the same manifold as in the implementing a manifold tutorial.\n\n\"\"\"\n    ScaledSphere <: AbstractManifold{â„}\n\nDefine a sphere of fixed radius\n\n# Fields\n\n* `dimension` dimension of the sphere\n* `radius` the radius of the sphere\n\n# Constructor\n\n    ScaledSphere(dimension,radius)\n\nInitialize the manifold to a certain `dimension` and `radius`,\nwhich by default is set to `1.0`\n\"\"\"\nstruct ScaledSphere <: AbstractManifold{â„}\n    dimension::Int\n    radius::Float64\nend\n\nWe would like to compute a mean and/or median similar to ðŸ”ï¸ Get started with Manopt.jl!. For given a set of points q_1ldotsq_n we want to compute [Kar77]\n\n  operatorname*argmin_pmathcal M\n  frac12n sum_i=1^n d_mathcal M^2(p q_i)\n\nOn the ScaledSphere we just defined. We define a few parameters first\n\nd = 5  # dimension of the sphere - embedded in R^{d+1}\nr = 2.0 # radius of the sphere\nN = 100 # data set size\n\nM = ScaledSphere(d,r)\n\nScaledSphere(5, 2.0)\n\nIf we generate a few points\n\n# generate 100 points around the north pole\npts = [ [zeros(d)..., M.radius] .+ 0.5.*([rand(d)...,0.5] .- 0.5) for _=1:N]\n# project them onto the r-sphere\npts = [ r/norm(p) .* p for p in pts]\n\nThen, before starting with optimization, we need the distance on the manifold, to define the cost function, as well as the logarithmic map to defined the gradient. For both, we here use the â€œlazyâ€ approach of using the Sphere as a fallback. Finally, we have to provide information about how points and tangent vectors are stored on the manifold by implementing their representation_size function, which is often required when allocating memory. While we could\n\nimport ManifoldsBase: distance, log, representation_size\nfunction distance(M::ScaledSphere, p, q)\n    return M.radius * distance(Sphere(M.dimension), p ./ M.radius, q ./ M.radius)\nend\nfunction log(M::ScaledSphere, p, q)\n    return M.radius * log(Sphere(M.dimension), p ./ M.radius, q ./ M.radius)\nend\nrepresentation_size(M::ScaledSphere) = (M.dimension+1,)","category":"section"},{"location":"tutorials/ImplementOwnManifold/#Define-the-cost-and-gradient","page":"Optimize on your own manifold","title":"Define the cost and gradient","text":"f(M, q) = sum(distance(M, q, p)^2 for p in pts)\ngrad_f(M,q) = sum( - log(M, q, p) for p in pts)","category":"section"},{"location":"tutorials/ImplementOwnManifold/#Defining-the-necessary-functions-to-run-a-solver","page":"Optimize on your own manifold","title":"Defining the necessary functions to run a solver","text":"The documentation usually lists the necessary functions in a section â€œTechnical Detailsâ€ close to the end of the documentation of a solver, for our case that is The gradient descentâ€™s Technical Details,\n\nThey list all details, but we can start even step by step here if we are a bit careful.","category":"section"},{"location":"tutorials/ImplementOwnManifold/#A-retraction","page":"Optimize on your own manifold","title":"A retraction","text":"We first implement a retraction. Informally,Â given a current point and a direction to â€œwalk intoâ€ we need a function that performs that walk. Since we take an easy one that just projects onto the sphere, we use the ProjectionRetraction type. To be precise, we have to implement the in-place variant retract_project!\n\nimport ManifoldsBase: retract_project!\nfunction retract_project!(M::ScaledSphere, q, p, X)\n    q .= p .+ X\n    q .*= M.radius / norm(q)\n    return q\nend\n\nretract_project! (generic function with 18 methods)\n\nThe other two technical remarks refer to the step size and the stopping criterion, so if we set these to something simpler, we should already be able to do a first run.\n\nWe have to specify\n\nthat we want to use the new retraction,\na simple step size and stopping criterion\n\nWe start with a certain point of cost\n\np0 = [zeros(d)...,1.0]\nf(M,p0)\n\n444.60374551157634\n\nThen we can run our first solver,Â where we have to overwrite a few defaults, which would use functions we do not (yet) have. Letâ€™s discuss these in the next steps.\n\nq1 = gradient_descent(M, f, grad_f, p0;\n    retraction_method = ProjectionRetraction(),   # state, that we use the retraction from above\n    stepsize = DecreasingLength(M; length=1.0), # A simple step size\n    stopping_criterion = StopAfterIteration(10),  # A simple stopping criterion\n    X = zeros(d+1),                               # how we define/represent tangent vectors\n)\nf(M,q1)\n\n162.4000287847332\n\nWe at least see, that the function value decreased.","category":"section"},{"location":"tutorials/ImplementOwnManifold/#Norm-and-maximal-step-size","page":"Optimize on your own manifold","title":"Norm and maximal step size","text":"To use more advanced stopping criteria and step sizes we first need an inner(M, p, X). We also need a max_stepsize(M), to avoid having too large steps on positively curved manifolds like our scaled sphere in this example\n\nimport ManifoldsBase: inner\nimport Manopt: max_stepsize\ninner(M::ScaledSphere, p, X,Y) = dot(X,Y) # inherited from the embedding\n # set the maximal allowed stepsize to injectivity radius.\nManopt.max_stepsize(M::ScaledSphere) = M.radius*Ï€\n\nThen we can use the default step size (ArmijoLinesearch) and the default stopping criterion, which checks for a small gradient Norm\n\nq2 = gradient_descent(M, f, grad_f, p0;\n    retraction_method = ProjectionRetraction(), # as before\n    X = zeros(d+1), # as before\n)\nf(M, q2)\n\n9.772830131357034","category":"section"},{"location":"tutorials/ImplementOwnManifold/#Making-life-easier:-default-retraction-and-zero-vector","page":"Optimize on your own manifold","title":"Making life easier: default retraction and zero vector","text":"To initialize tangent vector memory, the function zero_vector(M,p) is called. Similarly, the most-used retraction is returned by default_retraction_method\n\nWe can use both here, to make subsequent calls to the solver less verbose. We define\n\nimport ManifoldsBase: zero_vector, default_retraction_method\nzero_vector(M::ScaledSphere, p) = zeros(M.dimension+1)\ndefault_retraction_method(M::ScaledSphere) = ProjectionRetraction()\n\ndefault_retraction_method (generic function with 20 methods)\n\nand now we can even just call\n\nq3 = gradient_descent(M, f, grad_f, p0)\nf(M, q3)\n\n9.772830131357034\n\nBut we for example automatically also get the possibility to obtain debug information like\n\ngradient_descent(M, f, grad_f, p0; debug = [:Iteration, :Cost, :Stepsize, 25, :GradientNorm, :Stop, \"\\n\"]);\n\nInitial f(x): 444.603746s:1.0|grad f(p)|:134.76867266301872\n# 25    f(x): 9.772833s:0.018299583806109226|grad f(p)|:0.020516914880881486\n# 50    f(x): 9.772830s:0.018299583806109226|grad f(p)|:0.00013449321419330018\nThe algorithm reached approximately critical point after 72 iterations; the gradient norm (9.20733514568335e-9) is less than 1.0e-8.\n\nsee How to Print Debug Output for more details.","category":"section"},{"location":"tutorials/ImplementOwnManifold/#Technical-details","page":"Optimize on your own manifold","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:32:51.","category":"section"},{"location":"tutorials/ImplementOwnManifold/#Literature","page":"Optimize on your own manifold","title":"Literature","text":"H.Â Karcher. Riemannian center of mass and mollifier smoothing. CommunicationsÂ onÂ PureÂ andÂ AppliedÂ Mathematics 30, 509â€“541 (1977).\n\n\n\n","category":"section"},{"location":"tutorials/getstarted/#Get-started-with-Manopt.jl","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"ðŸ”ï¸ Get started with Manopt.jl","text":"Ronny Bergmann\n\nThis tutorial both introduces the basics of optimisation on manifolds as well as how to use Manopt.jl to perform optimisation on manifolds in Julia.\n\nFor more theoretical background, see for example [Car92] for an introduction to Riemannian manifolds and [AMS08] or [Bou23] to read more about optimisation thereon.\n\nLet mathcal M denote a (Riemannian manifold and let f  mathcal M  â„ be a cost function. The aim is to determine or obtain a point p^* where f is minimal or in other words p^* is a minimizer of f.\n\nThis can also be written as\n\n    operatorname*argmin_p  mathcal M f(p)\n\nwhere the aim is to compute the minimizer p^* numerically. As an example, consider the generalisation of the (arithmetic) mean. In the Euclidean case with dmathbb N, that is for nmathbb N data points y_1ldotsy_n  â„^d the mean\n\n  frac1nsum_i=1^n y_i\n\ncan not be directly generalised to data q_1ldotsq_n  mathcal M, since on a manifold there is no addition available. But the mean can also be characterised as the following minimizer\n\n  operatorname*argmin_xâ„^d frac12nsum_i=1^n lVert x - y_irVert^2\n\nand using the Riemannian distance d_mathcal M, this can be written on Riemannian manifolds, which is the so called Riemannian Center of Mass [Kar77]\n\n  operatorname*argmin_pmathcal M\n  frac12n sum_i=1^n d_mathcal M^2(p q_i)\n\nFortunately the gradient can be computed and is\n\n frac1n sum_i=1^n -log_p q_i","category":"section"},{"location":"tutorials/getstarted/#Loading-the-necessary-packages","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Loading the necessary packages","text":"Letâ€™s assume you have already installed both Manopt.jl and Manifolds.jl in Julia (using for example using Pkg; Pkg.add([\"Manopt\", \"Manifolds\"])). Then we can get started by loading both packages as well as Random.jl for persistency in this tutorial.\n\nusing Manopt, Manifolds, Random, LinearAlgebra, ManifoldDiff\nusing ManifoldDiff: grad_distance, prox_distance\nRandom.seed!(42);\n\nNow assume we are on the Sphere mathcal M = mathbb S^2 and we generate some random points â€œaroundâ€ some initial point p\n\nn = 100\nÏƒ = Ï€ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];\n\nNow we can define the cost function f and its (Riemannian) gradient operatornamegrad f for the Riemannian center of mass:\n\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)));\n\nand just call gradient_descent. For a first start, we do not have to provide more than the manifold, the cost, the gradient, and a starting point, which we just set to the first data point\n\nm1 = gradient_descent(M, f, grad_f, data[1])\n\n3-element Vector{Float64}:\n 0.6868392759384782\n 0.006531603309348398\n 0.7267799854058424\n\nIn order to get more details, we further add the debug= keyword argument, which act as a decorator pattern.\n\nThis way we can easily specify a certain debug to be printed. The goal is to get an output of the form\n\n# i | Last Change: [...] | F(x): [...] |\n\nbut where we also want to fix the display format for the change and the cost numbers (the [...]) to have a certain format. Furthermore, the reason why the solver stopped should be printed at the end\n\nThese can easily be specified using either a Symbol when using the default format for numbers, or a tuple of a symbol and a format-string in the debug= keyword that is available for every solver. We can also,Â for illustration reasons,Â just look at the first 6 steps by setting a stopping_criterion=\n\nm2 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Î”p|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop],\n    stopping_criterion = StopAfterIteration(6)\n  )\n\nInitial  F(x): 0.32487988924 | \n# 1     |Î”p|: 1.063609017 | F(x): 0.25232524046 | \n# 2     |Î”p|: 0.809858671 | F(x): 0.20966960102 | \n# 3     |Î”p|: 0.616665145 | F(x): 0.18546505598 | \n# 4     |Î”p|: 0.470841764 | F(x): 0.17121604104 | \n# 5     |Î”p|: 0.359345690 | F(x): 0.16300825911 | \n# 6     |Î”p|: 0.274597420 | F(x): 0.15818548927 | \nAt iteration 6 the algorithm reached its maximal number of iterations (6).\n\n3-element Vector{Float64}:\n  0.7533872481682506\n -0.060531070555836286\n  0.6547851890466333\n\nSee here for the list of available symbols.\n\ninfo: Technical Detail\nThe debug= keyword is actually a list of DebugActions added to every iteration, allowing you to write your own ones even. Additionally, :Stop is an action added to the end of the solver to display the reason why the solver stopped.\n\nThe default stopping criterion for gradient_descent is, to either stop when the gradient is small (<1e-9) or a max number of iterations is reached (as a fallback). Combining stopping-criteria can be done by | or &. We further pass a number 25 to debug= to only an output every 25th iteration:\n\nm3 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Î”p|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 25],\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |Â StopAfterIteration(400),\n)\n\nInitial  F(x): 0.32487988924 | \n# 25    |Î”p|: 0.459715605 | F(x): 0.15145076374 | \n# 50    |Î”p|: 0.000551270 | F(x): 0.15145051509 | \n# 75    |Î”p|: 0.000000673 | F(x): 0.15145051509 | \n# 100   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 125   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 150   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 175   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 200   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 225   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 250   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 275   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 300   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 325   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 350   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 375   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \n# 400   |Î”p|: 0.000000000 | F(x): 0.15145051509 | \nAt iteration 400 the algorithm reached its maximal number of iterations (400).\n\n3-element Vector{Float64}:\n 0.6868392794588207\n 0.0065316006956840245\n 0.726779982102452\n\nWe can finally use another way to determine the stepsize, for example a little more expensive ArmijoLineSearch than the default stepsize rule used on the Sphere.\n\nm4 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Î”p|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 2],\n      stepsize = ArmijoLinesearch(; contraction_factor=0.999, sufficient_decrease=0.5),\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |Â StopAfterIteration(400),\n)\n\nInitial  F(x): 0.32487988924 | \n# 2     |Î”p|: 0.001318138 | F(x): 0.15145051509 | \n# 4     |Î”p|: 0.000000004 | F(x): 0.15145051509 | \n# 6     |Î”p|: 0.000000000 | F(x): 0.15145051509 | \nThe algorithm reached approximately critical point after 7 iterations; the gradient norm (5.073696618059386e-15) is less than 1.0e-14.\n\n3-element Vector{Float64}:\n 0.6868392794788669\n 0.006531600680779358\n 0.7267799820836413\n\nThen we reach approximately the same point as in the previous run, but in far less steps\n\n[f(M, m3)-f(M,m4), distance(M, m3, m4)]\n\n2-element Vector{Float64}:\n -1.1102230246251565e-16\n  3.127047005767766e-11","category":"section"},{"location":"tutorials/getstarted/#Using-the-tutorial-mode","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Using the tutorial mode","text":"Since a few things on manifolds are a bit different from (classical) Euclidean optimization, Manopt.jl has a mode to warn about a few pitfalls.\n\nIt can be set using\n\nManopt.set_parameter!(:Mode, \"Tutorial\")\n\n[ Info: Setting the `Manopt.jl` parameter :Mode to Tutorial.\n\nto activate these. Continuing from the example before, one might argue, that the minimizer of f does not depend on the scaling of the function. In theory this is of course also the case on manifolds, but for the optimizations there is a caveat. When we define the Riemannian mean without the scaling\n\nf2(M, p) = sum(1 / 2 * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f2(M, p) = sum(grad_distance.(Ref(M), data, Ref(p)));\n\nAnd we consider the gradient at the starting point in norm\n\nnorm(M, data[1], grad_f2(M, data[1]))\n\n57.47318616893399\n\nOn the sphere, when we follow a geodesic, we â€œreturnâ€ to the start point after length 2Ï€. If we â€œlandâ€ short before the starting point due to a gradient of length just shy of 2Ï€, the line search would take the gradient direction (and not the negative gradient direction) as a start. The line search is still performed, but in this case returns a much too small, maybe even nearly zero step size.\n\nIn other words, we have to be careful that the optimisation stays a â€œlocalâ€ argument we use.\n\nThis is also warned for in \"Tutorial\" mode. Calling\n\nmX = gradient_descent(M, f2, grad_f2, data[1])\n\nâ”Œ Warning: At iteration #0\nâ”‚ the gradient norm (57.47318616893399) is larger that 1.0 times the injectivity radius 3.141592653589793 at the current iterate.\nâ”” @ Manopt ~/work/Manopt.jl/Manopt.jl/src/plans/debug.jl:1177\nâ”Œ Warning: Further warnings will be suppressed, use DebugWarnIfGradientNormTooLarge(1.0, :Always) to get all warnings.\nâ”” @ Manopt ~/work/Manopt.jl/Manopt.jl/src/plans/debug.jl:1181\n\n3-element Vector{Float64}:\n 0.6868392795133489\n 0.006531600655343761\n 0.726779982051283\n\nSo just by chance it seems we still got nearly the same point as before, but when we for example look when this one stops, that is takes more steps.\n\ngradient_descent(M, f2, grad_f2, data[1], debug=[:Stop]);\n\nThe algorithm reached approximately critical point after 75 iterations; the gradient norm (6.288404737033495e-9) is less than 1.0e-8.\n\nThis also illustrates one way to deactivate the hints, namely by overwriting the debug= keyword, that in Tutorial mode contains additional warnings. The other option is to globally reset the :Mode back to\n\nManopt.set_parameter!(:Mode, \"\")\n\n[ Info: Resetting the `Manopt.jl` parameter :Mode to default.","category":"section"},{"location":"tutorials/getstarted/#Example-2:-computing-the-median-of-symmetric-positive-definite-matrices","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Example 2: computing the median of symmetric positive definite matrices","text":"For the second example letâ€™s consider the manifold of 3  3 symmetric positive definite matrices and again 100 random points\n\nN = SymmetricPositiveDefinite(3)\nm = 100\nÏƒ = 0.005\nq = Matrix{Float64}(I, 3, 3)\ndata2 = [exp(N, q, Ïƒ * rand(N; vector_at=q)) for i in 1:m];\n\nInstead of the mean, letâ€™s consider a non-smooth optimisation task: the median can be generalized to Manifolds as the minimiser of the sum of distances, see [Bac14]. We define\n\ng(N, q) = sum(1 / (2 * m) * distance.(Ref(N), Ref(q), data2))\n\ng (generic function with 1 method)\n\nSince the function is non-smooth, we can not use a gradient-based approach. But since for every summand the proximal map is available, we can use the cyclic proximal point algorithm (CPPA). We hence define the vector of proximal maps as\n\nproxes_g = Function[(N, Î», q) -> prox_distance(N, Î» / m, di, q, 1) for di in data2];\n\nBesides also looking at a some debug prints, we can also easily record these values. Similarly to debug=, record= also accepts Symbols, see list here, to indicate things to record. We further set return_state to true to obtain not just the (approximate) minimizer.\n\nres = cyclic_proximal_point(N, g, proxes_g, data2[1];\n  debug=[:Iteration,\" | \",:Change,\" | \",(:Cost, \"F(x): %1.12f\"),\"\\n\", 1000, :Stop,\n        ],\n        record=[:Iteration, :Change, :Cost, :Iterate],\n        return_state=true,\n    );\n\nInitial  |  | F(x): 0.005875512856\n# 1000   | Last Change: 0.003704 | F(x): 0.003239019699\n# 2000   | Last Change: 0.000015 | F(x): 0.003238996105\n# 3000   | Last Change: 0.000005 | F(x): 0.003238991748\n# 4000   | Last Change: 0.000002 | F(x): 0.003238990225\n# 5000   | Last Change: 0.000001 | F(x): 0.003238989520\nAt iteration 5000 the algorithm reached its maximal number of iterations (5000).\n\nnote: Technical Detail\nThe recording is realised by RecordActions that are (also) executed at every iteration. These can also be individually implemented and added to the record= array instead of symbols.\n\nFirst, the computed median can be accessed as\n\nmedian = get_solver_result(res)\n\n3Ã—3 Matrix{Float64}:\n 1.0          2.12236e-5   0.000398721\n 2.12236e-5   1.00044      0.000141798\n 0.000398721  0.000141798  1.00041\n\nbut we can also look at the recorded values. For simplicity (of output), lets just look at the recorded values at iteration 42\n\nget_record(res)[42]\n\n(42, 1.0569455859265397e-5, 0.003252547739370141, [0.9998583866917481 0.000209888031262373 0.0002895445818452691; 0.00020988803126231748 1.0000931572564782 0.00020843715016860553; 0.0002895445818453246 0.00020843715016857778 1.000070920743252])\n\nBut we can also access whole series and see that the cost does not decrease that fast; actually, the CPPA might converge relatively slow. For that we can for example access the :Cost that was recorded every :Iterate as well as the (maybe a little boring) :Iteration-number in a semi-log-plot.\n\nx = get_record(res, :Iteration, :Iteration)\ny = get_record(res, :Iteration, :Cost)\nusing Plots\nplot(x,y,xaxis=:log, label=\"CPPA Cost\")\n\n(Image: )","category":"section"},{"location":"tutorials/getstarted/#Technical-details","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:35:21.","category":"section"},{"location":"tutorials/getstarted/#Literature","page":"ðŸ”ï¸ Get started with Manopt.jl","title":"Literature","text":"P.-A.Â Absil, R.Â Mahony and R.Â Sepulchre. Optimization Algorithms on Matrix Manifolds (Princeton University Press, 2008), available online at press.princeton.edu/chapters/absil/.\n\n\n\nM.Â BaÄÃ¡k. Computing medians and means in Hadamard spaces. SIAMÂ JournalÂ onÂ Optimization 24, 1542â€“1566 (2014), arXiv:1210.2145.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nM.Â P.Â doÂ Carmo. Riemannian Geometry. Mathematics: Theory & Applications (BirkhÃ¤user Boston, Inc., Boston, MA, 1992); p.Â xiv+300.\n\n\n\nH.Â Karcher. Riemannian center of mass and mollifier smoothing. CommunicationsÂ onÂ PureÂ andÂ AppliedÂ Mathematics 30, 509â€“541 (1977).\n\n\n\n","category":"section"},{"location":"solvers/subgradient/#sec-subgradient-method","page":"Subgradient method","title":"Subgradient method","text":"","category":"section"},{"location":"solvers/subgradient/#State","page":"Subgradient method","title":"State","text":"For DebugActions and RecordActions to record (sub)gradient, its norm and the step sizes, see the gradient descent actions.","category":"section"},{"location":"solvers/subgradient/#sec-sgm-technical-details","page":"Subgradient method","title":"Technical details","text":"The subgradient_method solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.","category":"section"},{"location":"solvers/subgradient/#Literature","page":"Subgradient method","title":"Literature","text":"O.Â Ferreira and P.Â R.Â Oliveira. Subgradient algorithm on Riemannian manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 97, 93â€“104 (1998).\n\n\n\n","category":"section"},{"location":"solvers/subgradient/#Manopt.subgradient_method","page":"Subgradient method","title":"Manopt.subgradient_method","text":"subgradient_method(M, f, âˆ‚f, p=rand(M); kwargs...)\nsubgradient_method(M, sgo, p=rand(M); kwargs...)\nsubgradient_method!(M, f, âˆ‚f, p; kwargs...)\nsubgradient_method!(M, sgo, p; kwargs...)\n\nperform a subgradient method p^(k+1) = operatornameretrbigl(p^(k) s^(k)f(p^(k))bigr), where operatornameretr is a retraction, s^(k) is a step size.\n\nThough the subgradient might be set valued, the argument âˆ‚f should always return one element from the subgradient, but not necessarily deterministic. For more details see [FO98].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nâˆ‚f: the subgradient f mathcalM  TmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nalternatively to f and âˆ‚f a ManifoldSubgradientObjective sgo can be provided.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=default_stepsize(M,SubGradientMethodState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nand the ones that are passed to decorate_state! for decorators.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/subgradient/#Manopt.subgradient_method!","page":"Subgradient method","title":"Manopt.subgradient_method!","text":"subgradient_method(M, f, âˆ‚f, p=rand(M); kwargs...)\nsubgradient_method(M, sgo, p=rand(M); kwargs...)\nsubgradient_method!(M, f, âˆ‚f, p; kwargs...)\nsubgradient_method!(M, sgo, p; kwargs...)\n\nperform a subgradient method p^(k+1) = operatornameretrbigl(p^(k) s^(k)f(p^(k))bigr), where operatornameretr is a retraction, s^(k) is a step size.\n\nThough the subgradient might be set valued, the argument âˆ‚f should always return one element from the subgradient, but not necessarily deterministic. For more details see [FO98].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nâˆ‚f: the subgradient f mathcalM  TmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nalternatively to f and âˆ‚f a ManifoldSubgradientObjective sgo can be provided.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=default_stepsize(M,SubGradientMethodState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nand the ones that are passed to decorate_state! for decorators.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/subgradient/#Manopt.SubGradientMethodState","page":"Subgradient method","title":"Manopt.SubGradientMethodState","text":"SubGradientMethodState <: AbstractManoptSolverState\n\nstores option values for a subgradient_method solver\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\np_star: optimal value\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nX: the current element from the possible subgradients at p that was last evaluated.\n\nConstructor\n\nSubGradientMethodState(M::AbstractManifold; kwargs...)\n\nInitialise the Subgradient method state\n\nKeyword arguments\n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstepsize::Stepsize=default_stepsize(M,SubGradientMethodState): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/projected_gradient_method/#Projected-gradient-method","page":"Projected Gradient Method","title":"Projected gradient method","text":"","category":"section"},{"location":"solvers/projected_gradient_method/#State","page":"Projected Gradient Method","title":"State","text":"","category":"section"},{"location":"solvers/projected_gradient_method/#Stopping-criteria","page":"Projected Gradient Method","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/projected_gradient_method/#Literature","page":"Projected Gradient Method","title":"Literature","text":"R.Â Bergmann, O.Â P.Â Ferreira, S.Â Z.Â NÃ©meth and J.Â Zhu. On projection mappings and the gradient projection method on hyperbolic space forms. Preprint,Â inÂ preparation (2025).\n\n\n\n","category":"section"},{"location":"solvers/projected_gradient_method/#Manopt.projected_gradient_method","page":"Projected Gradient Method","title":"Manopt.projected_gradient_method","text":"projected_gradient_method(M, f, grad_f, proj, p=rand(M); kwargs...)\nprojected_gradient_method(M, obj::ManifoldConstrainedSetObjective, p=rand(M); kwargs...)\nprojected_gradient_method!(M, f, grad_f, proj, p; kwargs...)\nprojected_gradient_method!(M, obj::ManifoldConstrainedSetObjective, p; kwargs...)\n\nCompute the projected gradient method for the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquad p  mathcalC  mathcalM\nendaligned\n\nby performing the following steps\n\nUsing the stepsize Î±_k compute a candidate q_k = operatornameproj_mathcalCBigl(operatornameretr_p_kbigl(-Î±_k operatornamegrad f(p_k)bigr)Bigr)\nCompute a backtracking stepsize Î²_k  1 along Y_k = operatornameretr_p_k^-1q_k\nCompute the new iterate p_k+1 = operatornameretr_p_k( Î²_k operatornameretr_p_k^-1q_k )\n\nuntil the stopping_criterion= is fulfilled.\n\nFor more information see [BFNZ25].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nproj the function that projects onto the set mathcalC as a function (M, p) -> q or a function (M, q, p) -> q computing the projection in-place of q.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nbacktrack::Stepsize=ArmijoLinesearchStepsize(M; stop_increasing_at_step=0): a functor inheriting from Stepsize to determine a step size to perform the backtracking to determine the Î²_k. Note that the method requires Î²_k  1, otherwise the projection step no longer provides points within the constraints\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=ConstantStepsize(injectivity_radius(M)/2): a functor inheriting from Stepsize to determine a step size to perform the candidate projected step.\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/projected_gradient_method/#Manopt.projected_gradient_method!","page":"Projected Gradient Method","title":"Manopt.projected_gradient_method!","text":"projected_gradient_method(M, f, grad_f, proj, p=rand(M); kwargs...)\nprojected_gradient_method(M, obj::ManifoldConstrainedSetObjective, p=rand(M); kwargs...)\nprojected_gradient_method!(M, f, grad_f, proj, p; kwargs...)\nprojected_gradient_method!(M, obj::ManifoldConstrainedSetObjective, p; kwargs...)\n\nCompute the projected gradient method for the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquad p  mathcalC  mathcalM\nendaligned\n\nby performing the following steps\n\nUsing the stepsize Î±_k compute a candidate q_k = operatornameproj_mathcalCBigl(operatornameretr_p_kbigl(-Î±_k operatornamegrad f(p_k)bigr)Bigr)\nCompute a backtracking stepsize Î²_k  1 along Y_k = operatornameretr_p_k^-1q_k\nCompute the new iterate p_k+1 = operatornameretr_p_k( Î²_k operatornameretr_p_k^-1q_k )\n\nuntil the stopping_criterion= is fulfilled.\n\nFor more information see [BFNZ25].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nproj the function that projects onto the set mathcalC as a function (M, p) -> q or a function (M, q, p) -> q computing the projection in-place of q.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nbacktrack::Stepsize=ArmijoLinesearchStepsize(M; stop_increasing_at_step=0): a functor inheriting from Stepsize to determine a step size to perform the backtracking to determine the Î²_k. Note that the method requires Î²_k  1, otherwise the projection step no longer provides points within the constraints\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=ConstantStepsize(injectivity_radius(M)/2): a functor inheriting from Stepsize to determine a step size to perform the candidate projected step.\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/projected_gradient_method/#Manopt.ProjectedGradientMethodState","page":"Projected Gradient Method","title":"Manopt.ProjectedGradientMethodState","text":"ProjectedGradientMethodState <: AbstractManoptSolverState\n\nFields\n\nbacktracking::Stepsize: a functor inheriting from Stepsize to determine a step size to determine the step size Î²_k step size from p_k to the candidate q_k\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np::P: a point on the manifold mathcalM  storing the current iterate\nq::P: a point on the manifold mathcalM an interims point for the projected gradient step\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size Î±_k to determine the q_k candidate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nX::T: a tangent vector at the point p on the manifold mathcalM\nY::T: a tangent vector at the point p on the manifold mathcalM a temporary memory for a tangent vector to store the no. Used within the backtracking\n\nConstructor\n\nProjectedGradientMethodState(M, p=rand(M); kwargs...)\n\nKeyword arguments\n\nbacktracking::Stepsize=ArmijoLinesearchStepsize(M): a functor inheriting from Stepsize to determine a step size p_k to the candidate q_k\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstepsize::Stepsize=ConstantStepsize(M): a functor inheriting from Stepsize to determine a step size Î±_k to determine the q_k candidate\nstop::StoppingCriterion=StopAfterIteration(300): a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\n\n\n\n\n","category":"type"},{"location":"solvers/projected_gradient_method/#Manopt.StopWhenProjectedGradientStationary","page":"Projected Gradient Method","title":"Manopt.StopWhenProjectedGradientStationary","text":"StopWhenProjectedGradientStationary <: StoppingCriterion\n\nStop when the step taken by the projection is  (before linesearch) exactly the opposite of the\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Augmented-Lagrangian-method","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian method","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#State","page":"Augmented Lagrangian Method","title":"State","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#Helping-functions","page":"Augmented Lagrangian Method","title":"Helping functions","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#sec-agd-technical-details","page":"Augmented Lagrangian Method","title":"Technical details","text":"The augmented_Lagrangian_method solver requires the following functions of a manifold to be available\n\nA copyto!(M, q, p) and copy(M,p) for points.\nEverything the subsolver requires, which by default is the quasi_Newton method\nA zero_vector(M,p).","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#Literature","page":"Augmented Lagrangian Method","title":"Literature","text":"C.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\n","category":"section"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method","page":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method","text":"augmented_Lagrangian_method(M, f, grad_f, p=rand(M); kwargs...)\naugmented_Lagrangian_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\naugmented_Lagrangian_method!(M, f, grad_f, p; kwargs...)\naugmented_Lagrangian_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the augmented Lagrangian method (ALM) [LB19]. This method can work in-place of p.\n\nThe aim of the ALM is to find the solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. In every step k of the algorithm, the AugmentedLagrangianCost  mathcalL_Ï^(k)(p Î¼^(k) Î»^(k)) is minimized on \\mathcal{M},   where Î¼^(k)  â„^n and Î»^(k)  â„^m are the current iterates of the Lagrange multipliers and Ï^(k) is the current penalty parameter.\n\nThe Lagrange multipliers are then updated by\n\nÎ»_j^(k+1) =operatornameclip_Î»_minÎ»_max (Î»_j^(k) + Ï^(k) h_j(p^(k+1))) textfor all j=1p\n\nand\n\nÎ¼_i^(k+1) =operatornameclip_0Î¼_max (Î¼_i^(k) + Ï^(k) g_i(p^(k+1))) text for all  i=1m\n\nwhere Î»_textmin  Î»_textmax and Î¼_textmax are the multiplier boundaries.\n\nNext, the accuracy tolerance Ïµ is updated as\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_textmin is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor.\n\nLast, the penalty parameter Ï is updated as follows: with\n\nÏƒ^(k)=max_j=1p i=1m h_j(p^(k)) max_i=1mg_i(p^(k)) -fracÎ¼_i^(k-1)Ï^(k-1)  \n\nÏ is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  Ïƒ^(k)leq Î¸_Ï Ïƒ^(k-1) \nÏ^(k-1)  textelse\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\n\nOptional (if not called with the ConstrainedManifoldObjective cmo)\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nKeyword Arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÏµ=1e-3:           the accuracy tolerance\nÏµ_min=1e-6:       the lower bound for the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor; also 1/number of iterations until maximal accuracy is needed to end algorithm naturally\nequality_constraints=nothing: the number n of equality constraints.\nIf not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nÎ»=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the equality constraints\nÎ»_max=20.0:       an upper bound for the Lagrange multiplier belonging to the equality constraints\nÎ»_min=- Î»_max:    a lower bound for the Lagrange multiplier belonging to the equality constraints\nÎ¼=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the inequality constraints\nÎ¼_max=20.0: an upper bound for the Lagrange multiplier belonging to the inequality constraints\nÏ=1.0:            the penalty parameter\nÏ„=0.8:            factor for the improvement of the evaluation of the penalty parameter\nÎ¸_Ï=0.3:          the scaling factor of the penalty parameter\nÎ¸_Ïµ=(Ïµ_min / Ïµ)^(Ïµ_exponent): the scaling factor of the exactness\nsub_cost=[AugmentedLagrangianCostÂ± (@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian cost, based on the ConstrainedManifoldObjective build from the functions provided.  This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=[AugmentedLagrangianGrad](@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian gradient, based on the [ConstrainedManifoldObjective](@ref) build from the functions provided. This is used to define thesubproblem=keyword and has hence no effect, if you setsubproblem` directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nstopping_criterion::StoppingCriterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(:Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) )|StopWhenChangeLess`: a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function., where more precisely as quasi newton method, the QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used.\nsub_stopping_criterion::StoppingCriterion=StopAfterIteration(300)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-8),\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method!","page":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method!","text":"augmented_Lagrangian_method(M, f, grad_f, p=rand(M); kwargs...)\naugmented_Lagrangian_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\naugmented_Lagrangian_method!(M, f, grad_f, p; kwargs...)\naugmented_Lagrangian_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the augmented Lagrangian method (ALM) [LB19]. This method can work in-place of p.\n\nThe aim of the ALM is to find the solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. In every step k of the algorithm, the AugmentedLagrangianCost  mathcalL_Ï^(k)(p Î¼^(k) Î»^(k)) is minimized on \\mathcal{M},   where Î¼^(k)  â„^n and Î»^(k)  â„^m are the current iterates of the Lagrange multipliers and Ï^(k) is the current penalty parameter.\n\nThe Lagrange multipliers are then updated by\n\nÎ»_j^(k+1) =operatornameclip_Î»_minÎ»_max (Î»_j^(k) + Ï^(k) h_j(p^(k+1))) textfor all j=1p\n\nand\n\nÎ¼_i^(k+1) =operatornameclip_0Î¼_max (Î¼_i^(k) + Ï^(k) g_i(p^(k+1))) text for all  i=1m\n\nwhere Î»_textmin  Î»_textmax and Î¼_textmax are the multiplier boundaries.\n\nNext, the accuracy tolerance Ïµ is updated as\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_textmin is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor.\n\nLast, the penalty parameter Ï is updated as follows: with\n\nÏƒ^(k)=max_j=1p i=1m h_j(p^(k)) max_i=1mg_i(p^(k)) -fracÎ¼_i^(k-1)Ï^(k-1)  \n\nÏ is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  Ïƒ^(k)leq Î¸_Ï Ïƒ^(k-1) \nÏ^(k-1)  textelse\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\n\nOptional (if not called with the ConstrainedManifoldObjective cmo)\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nKeyword Arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÏµ=1e-3:           the accuracy tolerance\nÏµ_min=1e-6:       the lower bound for the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor; also 1/number of iterations until maximal accuracy is needed to end algorithm naturally\nequality_constraints=nothing: the number n of equality constraints.\nIf not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nÎ»=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the equality constraints\nÎ»_max=20.0:       an upper bound for the Lagrange multiplier belonging to the equality constraints\nÎ»_min=- Î»_max:    a lower bound for the Lagrange multiplier belonging to the equality constraints\nÎ¼=ones(size(h(M,x),1)): the Lagrange multiplier with respect to the inequality constraints\nÎ¼_max=20.0: an upper bound for the Lagrange multiplier belonging to the inequality constraints\nÏ=1.0:            the penalty parameter\nÏ„=0.8:            factor for the improvement of the evaluation of the penalty parameter\nÎ¸_Ï=0.3:          the scaling factor of the penalty parameter\nÎ¸_Ïµ=(Ïµ_min / Ïµ)^(Ïµ_exponent): the scaling factor of the exactness\nsub_cost=[AugmentedLagrangianCostÂ± (@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian cost, based on the ConstrainedManifoldObjective build from the functions provided.  This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=[AugmentedLagrangianGrad](@ref)(cmo, Ï, Î¼, Î»): use augmented Lagrangian gradient, based on the [ConstrainedManifoldObjective](@ref) build from the functions provided. This is used to define thesubproblem=keyword and has hence no effect, if you setsubproblem` directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nstopping_criterion::StoppingCriterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(:Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) )|StopWhenChangeLess`: a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function., where more precisely as quasi newton method, the QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used.\nsub_stopping_criterion::StoppingCriterion=StopAfterIteration(300)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-8),\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianMethodState","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianMethodState","text":"AugmentedLagrangianMethodState{P,T} <: AbstractManoptSolverState\n\nDescribes the augmented Lagrangian method, with\n\nFields\n\na default value is given in brackets if a parameter can be left out in initialization.\n\nÏµ:     the accuracy tolerance\nÏµ_min: the lower bound for the accuracy tolerance\nÎ»:     the Lagrange multiplier with respect to the equality constraints\nÎ»_max: an upper bound for the Lagrange multiplier belonging to the equality constraints\nÎ»_min: a lower bound for the Lagrange multiplier belonging to the equality constraints\np::P: a point on the manifold mathcalM  storing the current iterate\npenalty: evaluation of the current penalty term, initialized to Inf.\nÎ¼:     the Lagrange multiplier with respect to the inequality constraints\nÎ¼_max: an upper bound for the Lagrange multiplier belonging to the inequality constraints\nÏ:     the penalty parameter\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nÏ„:     factor for the improvement of the evaluation of the penalty parameter\nÎ¸_Ï:   the scaling factor of the penalty parameter\nÎ¸_Ïµ:   the scaling factor of the accuracy tolerance\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nConstructor\n\nAugmentedLagrangianMethodState(M::AbstractManifold, co::ConstrainedManifoldObjective,\n    sub_problem, sub_state; kwargs...\n)\n\nconstruct an augmented Lagrangian method options, where the manifold M and the ConstrainedManifoldObjective co are used for manifold- or objective specific defaults.\n\nAugmentedLagrangianMethodState(M::AbstractManifold, co::ConstrainedManifoldObjective,\n    sub_problem; evaluation=AllocatingEvaluation(), kwargs...\n)\n\nconstruct an augmented Lagrangian method options, where the manifold M and the ConstrainedManifoldObjective co are used for manifold- or objective specific defaults, and sub_problem is a closed form solution with evaluation as type of evaluation.\n\nKeyword arguments\n\nthe following keyword arguments are available to initialise the corresponding fields\n\nÏµ=1eâ€“3\nÏµ_min=1e-6\nÎ»=ones(n): n is the number of equality constraints in the ConstrainedManifoldObjective co.\nÎ»_max=20.0\nÎ»_min=- Î»_max\nÎ¼=ones(m): m is the number of inequality constraints in the ConstrainedManifoldObjective co.\nÎ¼_max=20.0\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nÏ=1.0\nÏ„=0.8\nÎ¸_Ï=0.3\nÎ¸_Ïµ=(Ïµ_min/Ïµ)^(Ïµ_exponent)\nstoppingcriterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual`(:Ïµ, Ïµmin)[ & ](@ref StopWhenAll)[StopWhenChangeLess](@ref)(1e-10) )[ | ](@ref StopWhenAny)[StopWhenChangeLess](@ref).\n\nSee also\n\naugmented_Lagrangian_method\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianCost","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianCost","text":"AugmentedLagrangianCost{CO,R,T}\n\nStores the parameters Ï  â„, Î¼  â„^m, Î»  â„^n of the augmented Lagrangian associated to the ConstrainedManifoldObjective co.\n\nThis struct is also a functor (M,p) -> v that can be used as a cost function within a solver, based on the internal ConstrainedManifoldObjective it computes\n\nmathcalL_Ï(p Î¼ Î»)\n= f(x) + fracÏ2biggl(\n  sum_j=1^nBigl(\n    h_j(p) + fracÎ»_jÏ\n  Bigr)^2\n  +\n  sum_i=1^mmaxset0 fracÎ¼_iÏ + g_i(p)^2\nbiggr)\n\nFields\n\nco::CO, Ï::R, Î¼::T, Î»::T as mentioned in the formula, where R should be the\n\nnumber type used and T the vector type.\n\nConstructor\n\nAugmentedLagrangianCost(co, Ï, Î¼, Î»)\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianGrad","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianGrad","text":"AugmentedLagrangianGrad{CO,R,T} <: AbstractConstrainedFunctor{T}\n\nStores the parameters Ï  â„, Î¼  â„^m, Î»  â„^n of the augmented Lagrangian associated to the ConstrainedManifoldObjective co.\n\nThis struct is also a functor in both formats\n\n(M, p) -> X to compute the gradient in allocating fashion.\n(M, X, p) to compute the gradient in in-place fashion.\n\nadditionally this gradient does accept a positional last argument to specify the range for the internal gradient call of the constrained objective.\n\nbased on the internal ConstrainedManifoldObjective and computes the gradient \\operatorname{grad}\\mathcal{L}_{Ï}(p, Î¼, Î»), see also [AugmentedLagrangianCost`](@ref).\n\nFields\n\nco::CO, Ï::R, Î¼::T, Î»::T as mentioned in the formula, where R should be the\n\nnumber type used and T the vector type.\n\nConstructor\n\nAugmentedLagrangianGrad(co, Ï, Î¼, Î»)\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Covariance-matrix-adaptation-evolutionary-strategy","page":"CMA-ES","title":"Covariance matrix adaptation evolutionary strategy","text":"The CMA-ES algorithm has been implemented based on [Han23] with basic Riemannian adaptations, related to transport of covariance matrix and its update vectors. Other attempts at adapting CMA-ES to Riemannian optimization include [CFFS10]. The algorithm is suitable for global optimization.\n\nCovariance matrix transport between consecutive mean points is handled by eigenvector_transport! function which is based on the idea of transport of matrix eigenvectors.","category":"section"},{"location":"solvers/cma_es/#State","page":"CMA-ES","title":"State","text":"","category":"section"},{"location":"solvers/cma_es/#Stopping-criteria","page":"CMA-ES","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/cma_es/#sec-cma-es-technical-details","page":"CMA-ES","title":"Technical details","text":"The cma_es solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points and similarly copy(M, p, X) for tangent vectors.\nget_coordinates!(M, Y, p, X, b) and get_vector!(M, X, p, c, b) with respect to the AbstractBasis b provided, which is DefaultOrthonormalBasis by default from the basis= keyword.\nAn is_flat(M).","category":"section"},{"location":"solvers/cma_es/#Internal-helpers","page":"CMA-ES","title":"Internal helpers","text":"You may add new methods to eigenvector_transport! if you know a more optimized implementation for your manifold.","category":"section"},{"location":"solvers/cma_es/#Literature","page":"CMA-ES","title":"Literature","text":"S.Â Colutto, F.Â Fruhauf, M.Â Fuchs and O.Â Scherzer. The CMA-ES on Riemannian Manifolds to Reconstruct Shapes in 3-D Voxel Images. IEEEÂ TransactionsÂ onÂ EvolutionaryÂ Computation 14, 227â€“245 (2010).\n\n\n\nN.Â Hansen. The CMA Evolution Strategy: A Tutorial. ArXivÂ Preprint (2023).\n\n\n\n","category":"section"},{"location":"solvers/cma_es/#Manopt.cma_es","page":"CMA-ES","title":"Manopt.cma_es","text":"cma_es(M, f, p_m=rand(M); Ïƒ::Real=1.0, kwargs...)\n\nPerform covariance matrix adaptation evolutionary strategy search for global gradient-free randomized optimization. It is suitable for complicated non-convex functions. It can be reasonably expected to find global minimum within 3Ïƒ distance from p_m.\n\nImplementation is based on [Han23] with basic adaptations to the Riemannian setting.\n\nInput\n\nM:      a manifold mathcalM)\nf:      a cost function f mathcalMnifold)))â„ to find a minimizer p^* for\n\nKeyword arguments\n\np_m=rand(M): an initial point p\nÏƒ=1.0: initial standard deviation\nÎ»:                  (4 + Int(floor(3 * log(manifold_dimension(M))))population size (can be increased for a more thorough global search but decreasing is not recommended)\ntol_fun=1e-12: tolerance for the StopWhenPopulationCostConcentrated, similar to absolute difference between function values at subsequent points\ntol_x=1e-12: tolerance for the StopWhenPopulationStronglyConcentrated, similar to absolute difference between subsequent point but actually computed from distribution parameters.\nstopping_criterion::StoppingCriterion=defaultcmaesstoppingcriterion(M, Î»; tolfun=tolfun, tolx=tolx)``: a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nbasis               (DefaultOrthonormalBasis()) basis used to represent covariance in\nrng=default_rng(): random number generator for generating new points on M\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cma_es/#Manopt.CMAESState","page":"CMA-ES","title":"Manopt.CMAESState","text":"CMAESState{P,T} <: AbstractManoptSolverState\n\nState of covariance matrix adaptation evolution strategy.\n\nFields\n\np::P: a point on the manifold mathcalM storing the best point found so far\np_obj                       objective value at p\nÎ¼                           parent number\nÎ»                           population size\nÎ¼_eff                       variance effective selection mass for the mean\nc_1                         learning rate for the rank-one update\nc_c                         decay rate for cumulation path for the rank-one update\nc_Î¼                         learning rate for the rank-Î¼ update\nc_Ïƒ                         decay rate for the cumulation path for the step-size control\nc_m                         learning rate for the mean\nd_Ïƒ                         damping parameter for step-size update\npopulation                  population of the current generation\nys_c                        coordinates of random vectors for the current generation\ncovariance_matrix           coordinates of the covariance matrix\ncovariance_matrix_eigen     eigen decomposition of covariance_matrix\ncovariance_matrix_cond      condition number of covariance_matrix, updated after eigen decomposition\nbest_fitness_current_gen    best fitness value of individuals in the current generation\nmedian_fitness_current_gen  median fitness value of individuals in the current generation\nworst_fitness_current_gen   worst fitness value of individuals in the current generation\np_m                         point around which the search for new candidates is done\nÏƒ                           step size\np_Ïƒ                         coordinates of a vector in T_p_mmathcalM\np_c                         coordinates of a vector in T_p_mmathcalM\ndeviations                  standard deviations of coordinate RNG\nbuffer                      buffer for random number generation and wmean_y_c of length n_coords\ne_mv_norm                   expected value of norm of the n_coords-variable standard normal distribution\nrecombination_weights       recombination weights used for updating covariance matrix\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nbasis                       a real coefficient basis for covariance matrix\nrng                         RNG for generating new points\n\nConstructor\n\nCMAESState(\n    M::AbstractManifold,\n    p_m::P,\n    Î¼::Int,\n    Î»::Int,\n    Î¼_eff::TParams,\n    c_1::TParams,\n    c_c::TParams,\n    c_Î¼::TParams,\n    c_Ïƒ::TParams,\n    c_m::TParams,\n    d_Ïƒ::TParams,\n    stop::TStopping,\n    covariance_matrix::Matrix{TParams},\n    Ïƒ::TParams,\n    recombination_weights::Vector{TParams};\n    retraction_method::TRetraction=default_retraction_method(M, typeof(p_m)),\n    vector_transport_method::TVTM=default_vector_transport_method(M, typeof(p_m)),\n    basis::TB=default_basis(M, typeof(p_m)),\n    rng::TRng=default_rng(),\n) where {\n    P,\n    TParams<:Real,\n    TStopping<:StoppingCriterion,\n    TRetraction<:AbstractRetractionMethod,\n    TVTM<:AbstractVectorTransportMethod,\n    TB<:AbstractBasis,\n    TRng<:AbstractRNG,\n}\n\nSee also\n\ncma_es\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenBestCostInGenerationConstant","page":"CMA-ES","title":"Manopt.StopWhenBestCostInGenerationConstant","text":"StopWhenBestCostInGenerationConstant <: StoppingCriterion\n\nStop if the range of the best objective function values of the last iteration_range generations is zero. This corresponds to EqualFUnValues condition from [Han23].\n\nSee also StopWhenPopulationCostConcentrated.\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenCovarianceIllConditioned","page":"CMA-ES","title":"Manopt.StopWhenCovarianceIllConditioned","text":"StopWhenCovarianceIllConditioned <: StoppingCriterion\n\nStop CMA-ES if condition number of covariance matrix exceeds threshold. This corresponds to ConditionCov condition from [Han23].\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenEvolutionStagnates","page":"CMA-ES","title":"Manopt.StopWhenEvolutionStagnates","text":"StopWhenEvolutionStagnates{TParam<:Real} <: StoppingCriterion\n\nThe best and median fitness in each iteration is tracked over the last 20% but at least min_size and no more than max_size iterations. Solver is stopped if in both histories the median of the most recent fraction of values is not better than the median of the oldest fraction.\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenPopulationCostConcentrated","page":"CMA-ES","title":"Manopt.StopWhenPopulationCostConcentrated","text":"StopWhenPopulationCostConcentrated{TParam<:Real} <: StoppingCriterion\n\nStop if the range of the best objective function value in the last max_size generations and all function values in the current generation is below tol. This corresponds to TolFun condition from [Han23].\n\nConstructor\n\nStopWhenPopulationCostConcentrated(tol::Real, max_size::Int)\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenPopulationDiverges","page":"CMA-ES","title":"Manopt.StopWhenPopulationDiverges","text":"StopWhenPopulationDiverges{TParam<:Real} <: StoppingCriterion\n\nStop if Ïƒ times maximum deviation increased by more than tol. This usually indicates a far too small Ïƒ, or divergent behavior. This corresponds to TolXUp condition from [Han23].\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.StopWhenPopulationStronglyConcentrated","page":"CMA-ES","title":"Manopt.StopWhenPopulationStronglyConcentrated","text":"StopWhenPopulationStronglyConcentrated{TParam<:Real} <: StoppingCriterion\n\nStop if the standard deviation in all coordinates is smaller than tol and norm of Ïƒ * p_c is smaller than tol. This corresponds to TolX condition from [Han23].\n\nFields\n\ntol the tolerance to verify against\nat_iteration an internal field to indicate at with iteration i  0 the tolerance was met.\n\nConstructor\n\nStopWhenPopulationStronglyConcentrated(tol::Real)\n\n\n\n\n\n","category":"type"},{"location":"solvers/cma_es/#Manopt.eigenvector_transport!","page":"CMA-ES","title":"Manopt.eigenvector_transport!","text":"eigenvector_transport!(\n    M::AbstractManifold,\n    matrix_eigen::Eigen,\n    p,\n    q,\n    basis::AbstractBasis,\n    vtm::AbstractVectorTransportMethod,\n)\n\nTransport the matrix with matrix_eig eigen decomposition when expanded in basis from point p to point q on M. Update matrix_eigen in-place.\n\n(p, matrix_eig) belongs to the fiber bundle of B = mathcalM)))  SPD(n), where n is the (real) dimension of M. The function corresponds to the Ehresmann connection defined by vector transport vtm of eigenvectors of matrix_eigen.\n\n\n\n\n\n","category":"function"},{"location":"plans/record/#sec-record","page":"Recording values","title":"Record values","text":"To record values during the iterations of a solver run, there are in general two possibilities. On the one hand, the high-level interfaces provide a record= keyword, that accepts several different inputs. For more details see How to record.","category":"section"},{"location":"plans/record/#subsec-record-states","page":"Recording values","title":"Record Actions & the solver state decorator","text":"","category":"section"},{"location":"plans/record/#Access-functions","page":"Recording values","title":"Access functions","text":"","category":"section"},{"location":"plans/record/#Internal-factory-functions","page":"Recording values","title":"Internal factory functions","text":"Further specific RecordActions can be found when specific types of AbstractManoptSolverState define them on their corresponding site.","category":"section"},{"location":"plans/record/#Technical-details","page":"Recording values","title":"Technical details","text":"","category":"section"},{"location":"plans/record/#Manopt.RecordAction","page":"Recording values","title":"Manopt.RecordAction","text":"RecordAction\n\nA RecordAction is a small functor to record values. The usual call is given by\n\n(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, k) -> s\n\nthat performs the record for the current problem and solver combination, and where k is the current iteration.\n\nBy convention i=0 is interpreted as \"For Initialization only,\" so only initialize internal values, but not trigger any record, that the record is called from within stop_solver! which returns true afterwards.\n\nAny negative value is interpreted as a â€œresetâ€, and should hence delete all stored recordings, for example when reusing a RecordAction. The start of a solver calls the :Iteration and :Stop dictionary entries with -1, to reset those recordings.\n\nBy default any RecordAction is assumed to record its values in a field recorded_values, an Vector of recorded values. See get_record(ra).\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordChange","page":"Recording values","title":"Manopt.RecordChange","text":"RecordChange <: RecordAction\n\ndebug for the amount of change of the iterate (see get_iterate(s) of the AbstractManoptSolverState) during the last iteration.\n\nFields\n\nstorage                   : a StoreStateAction to store (at least) the last iterate to use this as the last value (to compute the change) serving as a potential cache shared with other components of the solver.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nrecorded_values           : to store the recorded values\n\nConstructor\n\nRecordChange(M=DefaultManifold();\n    inverse_retraction_method = default_inverse_retraction_method(M),\n    storage                   = StoreStateAction(M; store_points=Tuple{:Iterate})\n)\n\nwith the previous fields as keywords. For the DefaultManifold only the field storage is used. Providing the actual manifold moves the default storage to the efficient point storage.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordCost","page":"Recording values","title":"Manopt.RecordCost","text":"RecordCost <: RecordAction\n\nRecord the current cost function value, see get_cost.\n\nFields\n\nrecorded_values : to store the recorded values\n\nConstructor\n\nRecordCost()\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEntry","page":"Recording values","title":"Manopt.RecordEntry","text":"RecordEntry{T} <: RecordAction\n\nrecord a certain fields entry of type {T} during the iterates\n\nFields\n\nrecorded_values : the recorded Iterates\nfield           : Symbol the entry can be accessed with within AbstractManoptSolverState\n\nConstructor\n\nRecordEntry(::T, f::Symbol)\nRecordEntry(T::DataType, f::Symbol)\n\nInitialize the record action to record the state field f, and initialize the recorded_values to be a vector of element type T.\n\nExamples\n\nRecordEntry(rand(M), :q) to record the points from M stored in some states s.q\nRecordEntry(SVDMPoint, :p) to record the field s.p which takes values of type SVDMPoint.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEntryChange","page":"Recording values","title":"Manopt.RecordEntryChange","text":"RecordEntryChange{T} <: RecordAction\n\nrecord a certain entries change during iterates\n\nAdditional fields\n\nrecorded_values : the recorded Iterates\nfield           : Symbol the field can be accessed with within AbstractManoptSolverState\ndistance        : function (p,o,x1,x2) to compute the change/distance between two values of the entry\nstorage         : a StoreStateAction to store (at least) getproperty(o, d.field)\n\nConstructor\n\nRecordEntryChange(f::Symbol, d, a::StoreStateAction=StoreStateAction([f]))\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEvery","page":"Recording values","title":"Manopt.RecordEvery","text":"RecordEvery <: RecordAction\n\nrecord only every kth iteration. Otherwise (optionally, but activated by default) just update internal tracking values.\n\nThis method does not perform any record itself but relies on it's children's methods\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordGroup","page":"Recording values","title":"Manopt.RecordGroup","text":"RecordGroup <: RecordAction\n\ngroup a set of RecordActions into one action, where the internal RecordActions act independently, but the results can be collected in a grouped fashion, a tuple per calls of this group. The entries can be later addressed either by index or semantic Symbols\n\nConstructors\n\nRecordGroup(g::Array{<:RecordAction, 1})\n\nconstruct a group consisting of an Array of RecordActions g,\n\nRecordGroup(g, symbols)\n\nExamples\n\ng1 = RecordGroup([RecordIteration(), RecordCost()])\n\nA RecordGroup to record the current iteration and the cost. The cost can then be accessed using get_record(r,2) or r[2].\n\ng2 = RecordGroup([RecordIteration(), RecordCost()], Dict(:Cost => 2))\n\nA RecordGroup to record the current iteration and the cost, which can then be accessed using get_record(:Cost) or r[:Cost].\n\ng3 = RecordGroup([RecordIteration(), RecordCost() => :Cost])\n\nA RecordGroup identical to the previous constructor, just a little easier to use. To access all recordings of the second entry of this last g3 you can do either g4[2] or g[:Cost], the first one can only be accessed by g4[1], since no symbol was given here.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordIterate","page":"Recording values","title":"Manopt.RecordIterate","text":"RecordIterate <: RecordAction\n\nrecord the iterate\n\nConstructors\n\nRecordIterate(x0)\n\ninitialize the iterate record array to the type of x0, which indicates the kind of iterate\n\nRecordIterate(P)\n\ninitialize the iterate record array to the data type T.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordIteration","page":"Recording values","title":"Manopt.RecordIteration","text":"RecordIteration <: RecordAction\n\nrecord the current iteration\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordSolverState","page":"Recording values","title":"Manopt.RecordSolverState","text":"RecordSolverState <: AbstractManoptSolverState\n\nappend to any AbstractManoptSolverState the decorator with record capability, Internally a dictionary is kept that stores a RecordAction for several concurrent modes using a Symbol as reference. The default mode is :Iteration, which is used to store information that is recorded during the iterations. RecordActions might be added to :Start or :Stop to record values at the beginning or for the stopping time point, respectively\n\nThe original options can still be accessed using the get_state function.\n\nFields\n\noptions          the options that are extended by debug information\nrecordDictionary a Dict{Symbol,RecordAction} to keep track of all different recorded values\n\nConstructors\n\nRecordSolverState(o,dR)\n\nconstruct record decorated AbstractManoptSolverState, where dR can be\n\na RecordAction, then it is stored within the dictionary at :Iteration\nan Array of RecordActions, then it is stored as a recordDictionary(@ref).\na Dict{Symbol,RecordAction}.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordStoppingReason","page":"Recording values","title":"Manopt.RecordStoppingReason","text":"RecordStoppingReason <: RecordAction\n\nRecord reason the solver stopped, see get_reason.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordSubsolver","page":"Recording values","title":"Manopt.RecordSubsolver","text":"RecordSubsolver <: RecordAction\n\nRecord the current sub solvers recording, by calling get_record on the sub state with\n\nFields\n\nrecords: an array to store the recorded values\nsymbols: arguments for get_record. Defaults to just one symbol :Iteration, but could be set to also record the :Stop action.\n\nConstructor\n\nRecordSubsolver(; record=[:Iteration,], record_type=eltype([]))\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordTime","page":"Recording values","title":"Manopt.RecordTime","text":"RecordTime <: RecordAction\n\nrecord the time elapsed during the current iteration.\n\nThe three possible modes are\n\n:cumulative record times without resetting the timer\n:iterative record times with resetting the timer\n:total record a time only at the end of an algorithm (see stop_solver!)\n\nThe default is :cumulative, and any non-listed symbol default to using this mode.\n\nConstructor\n\nRecordTime(; mode::Symbol=:cumulative)\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordWhenActive","page":"Recording values","title":"Manopt.RecordWhenActive","text":"RecordWhenActive <: RecordAction\n\nrecord action that only records if the active boolean is set to true. This can be set from outside and is for example triggered by |RecordEvery](@ref) on recordings of the subsolver. While this is for sub solvers maybe not completely necessary, recording values that are never accessible, is not that useful.\n\nFields\n\nactive:        a boolean that can (de-)activated from outside to turn on/off debug\nalways_update: whether or not to call the inner debugs with nonpositive iterates (init/reset)\n\nConstructor\n\nRecordWhenActive(r::RecordAction, active=true, always_update=true)\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Base.getindex-Tuple{RecordGroup, Vararg{Any}}","page":"Recording values","title":"Base.getindex","text":"getindex(r::RecordGroup, s::Symbol)\nr[s]\ngetindex(r::RecordGroup, sT::NTuple{N,Symbol})\nr[sT]\ngetindex(r::RecordGroup, i)\nr[i]\n\nreturn an array of recorded values with respect to the s, the symbols from the tuple sT or the index i. See get_record for details.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Base.getindex-Tuple{RecordSolverState, Symbol}","page":"Recording values","title":"Base.getindex","text":"get_index(rs::RecordSolverState, s::Symbol)\nro[s]\n\nGet the recorded values for recorded type s, see get_record for details.\n\nget_index(rs::RecordSolverState, s::Symbol, i...)\nro[s, i...]\n\nAccess the recording type of type s and call its RecordAction with [i...].\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record","page":"Recording values","title":"Manopt.get_record","text":"get_record(s::AbstractManoptSolverState, [,symbol=:Iteration])\nget_record(s::RecordSolverState, [,symbol=:Iteration])\n\nreturn the recorded values from within the RecordSolverState s that where recorded with respect to the Symbol symbol as an Array. The default refers to any recordings during an :Iteration.\n\nWhen called with arbitrary AbstractManoptSolverState, this method looks for the RecordSolverState decorator and calls get_record on the decorator.\n\n\n\n\n\n","category":"function"},{"location":"plans/record/#Manopt.get_record-Tuple{RecordAction}","page":"Recording values","title":"Manopt.get_record","text":"get_record(r::RecordAction)\n\nreturn the recorded values stored within a RecordAction r.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record-Tuple{RecordGroup}","page":"Recording values","title":"Manopt.get_record","text":"get_record(r::RecordGroup)\n\nreturn an array of tuples, where each tuple is a recorded set per iteration or record call.\n\nget_record(r::RecordGroup, k::Int)\n\nreturn an array of values corresponding to the ith entry in this record group\n\nget_record(r::RecordGroup, s::Symbol)\n\nreturn an array of recorded values with respect to the s, see RecordGroup.\n\nget_record(r::RecordGroup, s1::Symbol, s2::Symbol,...)\n\nreturn an array of tuples, where each tuple is a recorded set corresponding to the symbols s1, s2,... per iteration / record call.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record_action","page":"Recording values","title":"Manopt.get_record_action","text":"get_record_action(s::AbstractManoptSolverState, s::Symbol)\n\nreturn the action contained in the (first) RecordSolverState decorator within the AbstractManoptSolverState o.\n\n\n\n\n\n","category":"function"},{"location":"plans/record/#Manopt.get_record_state-Tuple{AbstractManoptSolverState}","page":"Recording values","title":"Manopt.get_record_state","text":"get_record_state(s::AbstractManoptSolverState)\n\nreturn the RecordSolverState among the decorators from the AbstractManoptSolverState o\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.has_record-Tuple{RecordSolverState}","page":"Recording values","title":"Manopt.has_record","text":"has_record(s::AbstractManoptSolverState)\n\nIndicate whether the AbstractManoptSolverStates are decorated with RecordSolverState\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordActionFactory-Tuple{AbstractManoptSolverState, RecordAction}","page":"Recording values","title":"Manopt.RecordActionFactory","text":"RecordActionFactory(s::AbstractManoptSolverState, a)\n\ncreate a RecordAction where\n\na RecordAction is passed through\na [Symbol] creates\n:Change        to record the change of the iterates, see RecordChange\n:Gradient      to record the gradient, see RecordGradient\n:GradientNorm   to record the norm of the gradient, see [RecordGradientNorm`](@ref)\n:Iterate       to record the iterate\n:Iteration     to record the current iteration number\nIterativeTime  to record the time iteratively\n:Cost          to record the current cost function value\n:Stepsize      to record the current step size\n:Time          to record the total time taken after every iteration\n:IterativeTime to record the times taken for each iteration.\n\nand every other symbol is passed to RecordEntry, which results in recording the field of the state with the symbol indicating the field of the solver to record.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordActionFactory-Union{Tuple{T}, Tuple{AbstractManoptSolverState, Tuple{Symbol, T}}} where T","page":"Recording values","title":"Manopt.RecordActionFactory","text":"RecordActionFactory(s::AbstractManoptSolverState, t::Tuple{Symbol, T}) where {T}\n\ncreate a RecordAction where\n\n(:Subsolver, s) creates a RecordSubsolver with record= set to the second tuple entry\n\nFor other symbol the second entry is ignored and the symbol is used to generate a RecordEntry recording the field with the name symbol of s.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordFactory-Tuple{AbstractManoptSolverState, Vector}","page":"Recording values","title":"Manopt.RecordFactory","text":"RecordFactory(s::AbstractManoptSolverState, a)\n\nGenerate a dictionary of RecordActions.\n\nFirst all Symbols String, RecordActions and numbers are collected, excluding :Stop and :WhenActive. This collected vector is added to the :Iteration => [...] pair. :Stop is added as :StoppingCriterion to the :Stop => [...] pair. If any of these two pairs does not exist, it is pairs are created when adding the corresponding symbols\n\nFor each Pair of a Symbol and a Vector, the RecordGroupFactory is called for the Vector and the result is added to the debug dictionary's entry with said symbol. This is wrapped into the RecordWhenActive, when the :WhenActive symbol is present\n\nReturn value\n\nA dictionary for the different entry points where debug can happen, each containing a RecordAction to call.\n\nNote that upon the initialisation all dictionaries but the :StartAlgorithm one are called with an i=0 for reset.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordGroupFactory-Tuple{AbstractManoptSolverState, Vector}","page":"Recording values","title":"Manopt.RecordGroupFactory","text":"RecordGroupFactory(s::AbstractManoptSolverState, a)\n\nGenerate a [RecordGroup] of RecordActions. The following rules are used\n\nAny Symbol contained in a is passed to RecordActionFactory\nAny RecordAction is included as is.\n\nAny Pair of a RecordAction and a symbol, that is in order RecordCost() => :A is handled, that the corresponding record action can later be accessed as g[:A], where gis the record group generated here.\n\nIf this results in more than one RecordAction a RecordGroup of these is build.\n\nIf any integers are present, the last of these is used to wrap the group in a RecordEvery(k).\n\nIf :WhenActive is present, the resulting Action is wrapped in RecordWhenActive, making it deactivatable by its parent solver.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.record_or_reset!-Tuple{RecordAction, Any, Int64}","page":"Recording values","title":"Manopt.record_or_reset!","text":"record_or_reset!(r, v, k)\n\neither record (k>0 and not Inf) the value v within the RecordAction r or reset (k<0) the internal storage, where v has to match the internal value type of the corresponding RecordAction.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.set_parameter!-Tuple{RecordSolverState, Val{:Record}, Vararg{Any}}","page":"Recording values","title":"Manopt.set_parameter!","text":"set_parameter!(ams::RecordSolverState, ::Val{:Record}, args...)\n\nSet certain values specified by args... into the elements of the recordDictionary\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, RecordSolverState}","page":"Recording values","title":"Manopt.initialize_solver!","text":"initialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState)\n\nExtend the initialization of the solver by a hook to run records that were added to the :Start entry.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.step_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","page":"Recording values","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, k)\n\nExtend the ith step of the solver by a hook to run records, that were added to the :Iteration entry.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","page":"Recording values","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, rss::RecordSolverStatek k)\n\nExtend the call to the stopping criterion by a hook to run records, that were added to the :Stop entry.\n\n\n\n\n\n","category":"method"},{"location":"solvers/adaptive-regularization-with-cubics/#Adaptive-regularization-with-cubics","page":"Adaptive Regularization with Cubics","title":"Adaptive regularization with cubics","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#State","page":"Adaptive Regularization with Cubics","title":"State","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Sub-solvers","page":"Adaptive Regularization with Cubics","title":"Sub solvers","text":"There are several ways to approach the subsolver. The default is the first one.","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#arc-Lanczos","page":"Adaptive Regularization with Cubics","title":"Lanczos iteration","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#(Conjugate)-gradient-descent","page":"Adaptive Regularization with Cubics","title":"(Conjugate) gradient descent","text":"There is a generic objective, that implements the sub problem\n\nSince the sub problem is given on the tangent space, you have to provide\n\narc_obj = AdaptiveRegularizationWithCubicsModelObjective(mho, Ïƒ)\nsub_problem = DefaultProblem(TangentSpaceAt(M,p), arc_obj)\n\nwhere mho is the Hessian objective of f to solve. Then use this for the sub_problem keyword and use your favourite gradient based solver for the sub_state keyword, for example a ConjugateGradientDescentState","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Additional-stopping-criteria","page":"Adaptive Regularization with Cubics","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#sec-arc-technical-details","page":"Adaptive Regularization with Cubics","title":"Technical details","text":"The adaptive_regularization_with_cubics requires the following functions of a manifolds to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nif you do not provide an initial regularization parameter Ïƒ, a manifold_dimension is required.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).\ninner(M, p, X, Y) is used within the algorithm step\n\nFurthermore, within the Lanczos subsolver, generating a random vector (at p) using rand!(M, X; vector_at=p) in place of X is required","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Literature","page":"Adaptive Regularization with Cubics","title":"Literature","text":"N.Â Agarwal, N.Â Boumal, B.Â Bullins and C.Â Cartis. Adaptive regularization with cubics on manifolds. MathematicalÂ Programming (2020).\n\n\n\n","category":"section"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.adaptive_regularization_with_cubics","page":"Adaptive Regularization with Cubics","title":"Manopt.adaptive_regularization_with_cubics","text":"adaptive_regularization_with_cubics(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, f, grad_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, mho, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, Hess_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, mho, p; kwargs...)\n\nSolve an optimization problem on the manifold M by iteratively minimizing\n\nm_k(X) = f(p_k) + Xoperatornamegrad f(p^(k))_ + frac12)) XoperatornameHess f(p^(k))X_ + fracÏƒ_k3lVert X rVert^3\n\non the tangent space at the current iterate p_k, where X  T_p_kmathcalM and Ïƒ_k  0 is a regularization parameter.\n\nLet Xp^(k) denote the minimizer of the model m_k and use the model improvement\n\n  Ï_k = fracf(p_k) - f(operatornameretr_p_k(X_k))m_k(0) - m_k(X_k) + fracÏƒ_k3lVert X rVert^3\n\nWith two thresholds Î·_2  Î·_1  0 set p_k+1 = operatornameretr_p_k(X_k) if Ï  Î·_1 and reject the candidate otherwise, that is, set p_k+1 = p_k.\n\nFurther update the regularization parameter using factors 0  Î³_1  1  Î³_2 reads\n\nÏƒ_k+1 =\nbegincases\n    maxÏƒ_min Î³_1Ïƒ_k  text if  Ï geq Î·_2 text   (the model was very successful)\n    Ïƒ_k  text if  Ï  Î·_1 Î·_2)text   (the model was successful)\n    Î³_2Ïƒ_k  text if  Ï  Î·_1text   (the model was unsuccessful)\nendcases\n\nFor more details see [ABBC20].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\n\nthe cost f and its gradient and Hessian might also be provided as a ManifoldHessianObjective\n\nKeyword arguments\n\nÏƒ=100.0 / sqrt(manifold_dimension(M): initial regularization parameter\nÏƒmin=1e-10: minimal regularization value Ïƒ_min\nÎ·1=0.1: lower model success threshold\nÎ·2=0.9: upper model success threshold\nÎ³1=0.1: regularization reduction factor (for the success case)\nÎ³2=2.0: regularization increment factor (for the non-success case)\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninitial_tangent_vector=zero_vector(M, p): initialize any tangent vector data,\nmaxIterLanczos=200: a shortcut to set the stopping criterion in the sub solver,\nÏ_regularization=1e3: a regularization to avoid dividing by zero for small values of cost and model\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions:\nstopping_criterion::StoppingCriterion=StopAfterIteration(40)|StopWhenGradientNormLess(1e-9)|StopWhenAllLanczosVectorsUsed(maxIterLanczos): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=nothing: a shortcut to modify the objective of the subproblem used within in the sub_problem= keyword By default, this is initialized as a AdaptiveRegularizationWithCubicsModelObjective, which can further be decorated by using the sub_kwargs= keyword.\nsub_state::Union{AbstractManoptProblem, F} =LanczosState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.adaptive_regularization_with_cubics!","page":"Adaptive Regularization with Cubics","title":"Manopt.adaptive_regularization_with_cubics!","text":"adaptive_regularization_with_cubics(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, f, grad_f, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics(M, mho, p=rand(M); kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, Hess_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, f, grad_f, p; kwargs...)\nadaptive_regularization_with_cubics!(M, mho, p; kwargs...)\n\nSolve an optimization problem on the manifold M by iteratively minimizing\n\nm_k(X) = f(p_k) + Xoperatornamegrad f(p^(k))_ + frac12)) XoperatornameHess f(p^(k))X_ + fracÏƒ_k3lVert X rVert^3\n\non the tangent space at the current iterate p_k, where X  T_p_kmathcalM and Ïƒ_k  0 is a regularization parameter.\n\nLet Xp^(k) denote the minimizer of the model m_k and use the model improvement\n\n  Ï_k = fracf(p_k) - f(operatornameretr_p_k(X_k))m_k(0) - m_k(X_k) + fracÏƒ_k3lVert X rVert^3\n\nWith two thresholds Î·_2  Î·_1  0 set p_k+1 = operatornameretr_p_k(X_k) if Ï  Î·_1 and reject the candidate otherwise, that is, set p_k+1 = p_k.\n\nFurther update the regularization parameter using factors 0  Î³_1  1  Î³_2 reads\n\nÏƒ_k+1 =\nbegincases\n    maxÏƒ_min Î³_1Ïƒ_k  text if  Ï geq Î·_2 text   (the model was very successful)\n    Ïƒ_k  text if  Ï  Î·_1 Î·_2)text   (the model was successful)\n    Î³_2Ïƒ_k  text if  Ï  Î·_1text   (the model was unsuccessful)\nendcases\n\nFor more details see [ABBC20].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\n\nthe cost f and its gradient and Hessian might also be provided as a ManifoldHessianObjective\n\nKeyword arguments\n\nÏƒ=100.0 / sqrt(manifold_dimension(M): initial regularization parameter\nÏƒmin=1e-10: minimal regularization value Ïƒ_min\nÎ·1=0.1: lower model success threshold\nÎ·2=0.9: upper model success threshold\nÎ³1=0.1: regularization reduction factor (for the success case)\nÎ³2=2.0: regularization increment factor (for the non-success case)\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninitial_tangent_vector=zero_vector(M, p): initialize any tangent vector data,\nmaxIterLanczos=200: a shortcut to set the stopping criterion in the sub solver,\nÏ_regularization=1e3: a regularization to avoid dividing by zero for small values of cost and model\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions:\nstopping_criterion::StoppingCriterion=StopAfterIteration(40)|StopWhenGradientNormLess(1e-9)|StopWhenAllLanczosVectorsUsed(maxIterLanczos): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=nothing: a shortcut to modify the objective of the subproblem used within in the sub_problem= keyword By default, this is initialized as a AdaptiveRegularizationWithCubicsModelObjective, which can further be decorated by using the sub_kwargs= keyword.\nsub_state::Union{AbstractManoptProblem, F} =LanczosState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide the ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nIf you activate tutorial mode (cf. is_tutorial_mode), this solver provides additional debug warnings.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.AdaptiveRegularizationState","page":"Adaptive Regularization with Cubics","title":"Manopt.AdaptiveRegularizationState","text":"AdaptiveRegularizationState{P,T} <: AbstractHessianSolverState\n\nA state for the adaptive_regularization_with_cubics solver.\n\nFields\n\nÎ·1, Î·1: bounds for evaluating the regularization parameter\nÎ³1, Î³2:  shrinking and expansion factors for regularization parameter Ïƒ\nH: the current Hessian evaluation\ns: the current solution from the subsolver\np::P: a point on the manifold mathcalM  storing the current iterate\nq: a point for the candidates to evaluate model and Ï\nX::T: a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\ns: the tangent vector step resulting from minimizing the model problem in the tangent space T_pmathcalM\nÏƒ: the current cubic regularization parameter\nÏƒmin: lower bound for the cubic regularization parameter\nÏ_regularization: regularization parameter for computing Ï. When approaching convergence Ï may be difficult to compute with numerator and denominator approaching zero. Regularizing the ratio lets Ï go to 1 near convergence.\nÏ: the current regularized ratio of actual improvement and model improvement.\nÏ_denominator: a value to store the denominator from the computation of Ï to allow for a warning or error when this value is non-positive.\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nFurthermore the following integral fields are defined\n\nConstructor\n\nAdaptiveRegularizationState(M, sub_problem, sub_state; kwargs...)\n\nConstruct the solver state with all fields stated as keyword arguments and the following defaults\n\nKeyword arguments\n\nÎ·1=0.1\nÎ·2=0.9\nÎ³1=0.1\nÎ³2=2.0\nÏƒ=100/manifold_dimension(M)\n`Ïƒmin=1e-7\nÏ_regularization=1e3\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\np::P =rand(M): a point on the manifold mathcalM\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.LanczosState","page":"Adaptive Regularization with Cubics","title":"Manopt.LanczosState","text":"LanczosState{P,T,SC,B,I,R,TM,V,Y} <: AbstractManoptSolverState\n\nSolve the adaptive regularized subproblem with a Lanczos iteration\n\nFields\n\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstop_newton::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled used for the inner Newton iteration\nÏƒ:               the current regularization parameter\nX:               the Iterate\nLanczos_vectors: the obtained Lanczos vectors\ntridig_matrix:   the tridiagonal coefficient matrix T\ncoefficients:    the coefficients y_1y_k that determine the solution\nHp:              a temporary tangent vector containing the evaluation of the Hessian\nHp_residual:     a temporary tangent vector containing the residual to the Hessian\nS:               the current obtained / approximated solution\n\nConstructor\n\nLanczosState(TpM::TangentSpace; kwargs...)\n\nKeyword arguments\n\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\nmaxIterLanzcos=200: shortcut to set the maximal number of iterations in the stopping_crtierion=\nÎ¸=0.5: set the parameter in the StopWhenFirstOrderProgress within the default stopping_criterion=.\nstopping_criterion::StoppingCriterion=StopAfterIteration(maxIterLanczos)|StopWhenFirstOrderProgress(Î¸): a functor indicating that the stopping criterion is fulfilled\nstopping_criterion_newton::StoppingCriterion=StopAfterIteration(200): a functor indicating that the stopping criterion is fulfilled used for the inner Newton iteration\nÏƒ=10.0: specify the regularization parameter\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.AdaptiveRegularizationWithCubicsModelObjective","page":"Adaptive Regularization with Cubics","title":"Manopt.AdaptiveRegularizationWithCubicsModelObjective","text":"AdaptiveRegularizationWithCubicsModelObjective\n\nA model for the adaptive regularization with Cubics\n\nm(X) = f(p) + operatornamegrad f(p) X _p + frac12 operatornameHess f(p)X X_p\n       +  fracÏƒ3 lVert X rVert^3\n\ncf. Eq. (33) in [ABBC20]\n\nFields\n\nobjective: an AbstractManifoldHessianObjective proving f, its gradient and Hessian\nÏƒ:         the current (cubic) regularization parameter\n\nConstructors\n\nAdaptiveRegularizationWithCubicsModelObjective(mho, Ïƒ=1.0)\n\nwith either an AbstractManifoldHessianObjective objective or an decorator containing such an objective.\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.StopWhenAllLanczosVectorsUsed","page":"Adaptive Regularization with Cubics","title":"Manopt.StopWhenAllLanczosVectorsUsed","text":"StopWhenAllLanczosVectorsUsed <: StoppingCriterion\n\nWhen an inner iteration has used up all Lanczos vectors, then this stopping criterion is a fallback / security stopping criterion to not access a non-existing field in the array allocated for vectors.\n\nNote that this stopping criterion (for now) is only implemented for the case that an AdaptiveRegularizationState when using a LanczosState subsolver\n\nFields\n\nmaxLanczosVectors: maximal number of Lanczos vectors\nat_iteration indicates at which iteration (including i=0) the stopping criterion was fulfilled and is -1 while it is not fulfilled.\n\nConstructor\n\nStopWhenAllLanczosVectorsUsed(maxLancosVectors::Int)\n\n\n\n\n\n","category":"type"},{"location":"solvers/adaptive-regularization-with-cubics/#Manopt.StopWhenFirstOrderProgress","page":"Adaptive Regularization with Cubics","title":"Manopt.StopWhenFirstOrderProgress","text":"StopWhenFirstOrderProgress <: StoppingCriterion\n\nA stopping criterion related to the Riemannian adaptive regularization with cubics (ARC) solver indicating that the model function at the current (outer) iterate,\n\nm_k(X) = f(p_k) + Xoperatornamegrad f(p^(k))_ + frac12)) XoperatornameHess f(p^(k))X_ + fracÏƒ_k3lVert X rVert^3\n\ndefined on the tangent space T_pmathcalMentSpace))) fulfills at the current iterate X_k that\n\nm(X_k) leq m(0)\nquadtext and quad\nlVert operatornamegrad m(X_k) rVert  Î¸ lVert X_k rVert^2\n\nFields\n\nÎ¸:      the factor Î¸ in the second condition\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\n\nConstructor\n\nStopWhenAllLanczosVectorsUsed(Î¸)\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#The-Riemannian-trust-regions-solver","page":"Trust-Regions Solver","title":"The Riemannian trust regions solver","text":"Minimize a function\n\noperatorname*argmin_p  mathcalM f(p)\n\nby using the Riemannian trust-regions solver following [ABG06] a model is build by lifting the objective at the kth iterate p_k by locally mapping the cost function f to the tangent space as f_k T_p_kmathcal M  â„ as f_k(X) = f(operatornameretr_p_k(X)). The trust region subproblem is then defined as\n\noperatorname*argmin_X  T_p_kmathcal M m_k(X)\n\nwhere\n\nbeginalign*\nm_k T_p_Kmathcal M  â„\nm_k(X) = f(p_k) + operatornamegrad f(p_k) X_p_k + frac12langle mathcal H_k(X)X_p_k\ntextsuch that lVert X rVert_p_k  Î”_k\nendalign*\n\nHere Î”_k is a trust region radius, that is adapted every iteration, and mathcal H_k is some symmetric linear operator that approximates the Hessian operatornameHess f of f.","category":"section"},{"location":"solvers/trust_regions/#Interface","page":"Trust-Regions Solver","title":"Interface","text":"","category":"section"},{"location":"solvers/trust_regions/#State","page":"Trust-Regions Solver","title":"State","text":"","category":"section"},{"location":"solvers/trust_regions/#Approximation-of-the-Hessian","page":"Trust-Regions Solver","title":"Approximation of the Hessian","text":"Several different methods to approximate the Hessian are available.\n\nas well as their (non-exported) common supertype","category":"section"},{"location":"solvers/trust_regions/#sec-tr-technical-details","page":"Trust-Regions Solver","title":"Technical details","text":"The trust_regions solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nif you do not provide an initial max_trust_region_radius, a manifold_dimension is required.\nA copyto!(M, q, p) and copy(M,p) for points.\nBy default the tangent vectors are initialized calling zero_vector(M,p).","category":"section"},{"location":"solvers/trust_regions/#Literature","page":"Trust-Regions Solver","title":"Literature","text":"P.-A.Â Absil, C.Â Baker and K.Â Gallivan. Trust-Region Methods on Riemannian Manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 7, 303â€“330 (2006).\n\n\n\nA.Â R.Â Conn, N.Â I.Â Gould and P.Â L.Â Toint. Trust Region Methods (Society for Industrial and Applied Mathematics, 2000).\n\n\n\n","category":"section"},{"location":"solvers/trust_regions/#Manopt.trust_regions","page":"Trust-Regions Solver","title":"Manopt.trust_regions","text":"trust_regions(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ntrust_regions(M, f, grad_f, p=rand(M); kwargs...)\ntrust_regions!(M, f, grad_f, Hess_f, p; kwargs...)\ntrust_regions!(M, f, grad_f, p; kwargs...)\n\nrun the Riemannian trust-regions solver for optimization on manifolds to minimize f, see on [ABG06, CGT00].\n\nFor the case that no Hessian is provided, the Hessian is computed using finite differences, see ApproxHessianFiniteDifference. For solving the inner trust-region subproblem of finding an update-vector, by default the truncated_conjugate_gradient_descent is used.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nacceptance_rate:        accept/reject threshold: if Ï (the performance ratio for the iterate) is at least the acceptance rate Ï', the candidate is accepted. This value should  be between 0 and rac14\naugmentation_threshold=0.75: trust-region augmentation threshold: if Ï is larger than this threshold, a solution is on the trust region boundary and negative curvature, and the radius is extended (augmented)\naugmentation_factor=2.0: trust-region augmentation factor\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎº=0.1: the linear convergence target rate of the tCG method   truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\nmax_trust_region_radius: the maximum trust-region radius\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nÏ_regularization=1e3: regularize the performance evaluation Ï to avoid numerical inaccuracies.\nreduction_factor=0.25: trust-region reduction factor\nreduction_threshold=0.1: trust-region reduction threshold: if Ï is below this threshold, the trust region radius is reduced by reduction_factor.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion::StoppingCriterion=( see truncated_conjugate_gradient_descent): a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M,ConstrainedManifoldObjective(subcost, subgrad; evaluation=evaluation)):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. , where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸ of the tCG-method truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nFor the case that no Hessian is provided, the Hessian is computed using finite difference, see ApproxHessianFiniteDifference.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntruncated_conjugate_gradient_descent\n\n\n\n\n\n","category":"function"},{"location":"solvers/trust_regions/#Manopt.trust_regions!","page":"Trust-Regions Solver","title":"Manopt.trust_regions!","text":"trust_regions(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ntrust_regions(M, f, grad_f, p=rand(M); kwargs...)\ntrust_regions!(M, f, grad_f, Hess_f, p; kwargs...)\ntrust_regions!(M, f, grad_f, p; kwargs...)\n\nrun the Riemannian trust-regions solver for optimization on manifolds to minimize f, see on [ABG06, CGT00].\n\nFor the case that no Hessian is provided, the Hessian is computed using finite differences, see ApproxHessianFiniteDifference. For solving the inner trust-region subproblem of finding an update-vector, by default the truncated_conjugate_gradient_descent is used.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nacceptance_rate:        accept/reject threshold: if Ï (the performance ratio for the iterate) is at least the acceptance rate Ï', the candidate is accepted. This value should  be between 0 and rac14\naugmentation_threshold=0.75: trust-region augmentation threshold: if Ï is larger than this threshold, a solution is on the trust region boundary and negative curvature, and the radius is extended (augmented)\naugmentation_factor=2.0: trust-region augmentation factor\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎº=0.1: the linear convergence target rate of the tCG method   truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\nmax_trust_region_radius: the maximum trust-region radius\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nÏ_regularization=1e3: regularize the performance evaluation Ï to avoid numerical inaccuracies.\nreduction_factor=0.25: trust-region reduction factor\nreduction_threshold=0.1: trust-region reduction threshold: if Ï is below this threshold, the trust region radius is reduced by reduction_factor.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion::StoppingCriterion=( see truncated_conjugate_gradient_descent): a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M,ConstrainedManifoldObjective(subcost, subgrad; evaluation=evaluation)):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. , where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸ of the tCG-method truncated_conjugate_gradient_descent, and is used in a stopping criterion therein\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nFor the case that no Hessian is provided, the Hessian is computed using finite difference, see ApproxHessianFiniteDifference.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntruncated_conjugate_gradient_descent\n\n\n\n\n\n","category":"function"},{"location":"solvers/trust_regions/#Manopt.TrustRegionsState","page":"Trust-Regions Solver","title":"Manopt.TrustRegionsState","text":"TrustRegionsState <: AbstractHessianSolverState\n\nStore the state of the trust-regions solver.\n\nFields\n\nacceptance_rate:         a lower bound of the performance ratio for the iterate that decides if the iteration is accepted or not.\nHX, HY, HZ:          interim storage (to avoid allocation) of `\\operatorname{Hess} f(p)[â‹…] of X, Y, Z\nmax_trust_region_radius: the maximum trust-region radius\np::P: a point on the manifold mathcalM  storing the current iterate\nproject!:                for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nrandomize:               indicate whether X is initialised to a random vector or not\nÏ_regularization:        regularize the model fitness Ï to avoid division by zero\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nÏƒ:                       Gaussian standard deviation when creating the random initial tangent vector This field has no effect, when randomize is false.\ntrust_region_radius: the trust-region radius\nX::T: a tangent vector at the point p on the manifold mathcalM\nY:                       the solution (tangent vector) of the subsolver\nZ:                       the Cauchy point (only used if random is activated)\n\nConstructors\n\nTrustRegionsState(M, mho::AbstractManifoldHessianObjective; kwargs...)\nTrustRegionsState(M, sub_problem, sub_state; kwargs...)\nTrustRegionsState(M, sub_problem; evaluation=AllocatingEvaluation(), kwargs...)\n\ncreate a trust region state.\n\ngiven a AbstractManifoldHessianObjective mho, the default sub solver, a TruncatedConjugateGradientState with mho used to define the problem on a tangent space is created\ngiven a sub_problem and an evaluation= keyword, the sub problem solver is assumed to be the closed form solution, where evaluation determines how to call the sub function.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\nacceptance_rate=0.1\nmax_trust_region_radius=sqrt(manifold_dimension(M))\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nproject!=copyto!\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nrandomize=false\nÏ_regularization=10000.0\nÎ¸=1.0\ntrust_region_radius=max_trust_region_radius / 8\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nSee also\n\ntrust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianFiniteDifference","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianFiniteDifference","text":"ApproxHessianFiniteDifference{E, P, T, G, RTR, VTR, R <: Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by a finite difference of gradient evaluation.\n\nGiven a point p and a direction X and the gradient operatornamegrad f(p) of a function f the Hessian is approximated as follows: let c be a stepsize, X  T_pmathcalM a tangent vector and q = operatornameretr_p(fracclVert X rVert_pX) be a step in direction X of length c following a retraction Then the Hessian is approximated by the finite difference of the gradients, where mathcal T_ is a vector transport.\n\noperatornameHessf(p)X \nfraclVert X rVertcBigl(\n  mathcal T_qpbigl( operatornamegradf(q)bigr - operatornamegradf(p)\nBigr)\n\nFields\n\ngradient!!:              the gradient function (either allocating or mutating, see evaluation parameter)\nstep_length:             a step length for the finite difference\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nInternal temporary fields\n\ngrad_tmp:     a temporary storage for the gradient at the current p\ngrad_dir_tmp: a temporary storage for the gradient at the current p_dir\np_dir::P:     a temporary storage to the forward direction (or the q in the formula)\n\nConstructor\n\nApproximateFiniteDifference(M, p, grad_f; kwargs...)\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nsteplength=2^{-14} step lengthc`` to approximate the gradient evaluations\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianSymmetricRankOne","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianSymmetricRankOne","text":"ApproxHessianSymmetricRankOne{E, P, G, T, B<:AbstractBasis{â„}, VTR, R<:Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by the symmetric rank one update.\n\nFields\n\ngradient!!: the gradient function (either allocating or mutating, see evaluation parameter).\nÎ½: a small real number to ensure that the denominator in the update does not become too small and thus the method does not break down.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports.\n\nInternal temporary fields\n\np_tmp: a temporary storage the current point p.\ngrad_tmp: a temporary storage for the gradient at the current p.\nmatrix: a temporary storage for the matrix representation of the approximating operator.\nbasis: a temporary storage for an orthonormal basis at the current p.\n\nConstructor\n\nApproxHessianSymmetricRankOne(M, p, gradF; kwargs...)\n\nKeyword arguments\n\ninitial_operator (Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M))) the matrix representation of the initial approximating operator.\nbasis (DefaultOrthonormalBasis()) an orthonormal basis in the tangent space of the initial iterate p.\nnu (-1)\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianBFGS","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianBFGS","text":"ApproxHessianBFGS{E, P, G, T, B<:AbstractBasis{â„}, VTR, R<:Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by the BFGS update.\n\nFields\n\ngradient!! the gradient function (either allocating or mutating, see evaluation parameter).\nscale\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nInternal temporary fields\n\np_tmp a temporary storage the current point p.\ngrad_tmp a temporary storage for the gradient at the current p.\nmatrix a temporary storage for the matrix representation of the approximating operator.\nbasis a temporary storage for an orthonormal basis at the current p.\n\nConstructor\n\nApproxHessianBFGS(M, p, gradF; kwargs...)\n\nKeyword arguments\n\ninitial_operator (Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M))) the matrix representation of the initial approximating operator.\nbasis (DefaultOrthonormalBasis()) an orthonormal basis in the tangent space of the initial iterate p.\nnu (-1)\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.AbstractApproxHessian","page":"Trust-Regions Solver","title":"Manopt.AbstractApproxHessian","text":"AbstractApproxHessian <: Function\n\nAn abstract supertype for approximate Hessian functions, declares them also to be functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#sec-debug","page":"Debug Output","title":"Debug output","text":"Debug output can easily be added to any solver run. On the high level interfaces, like gradient_descent, you can just use the debug= keyword.","category":"section"},{"location":"plans/debug/#Technical-details","page":"Debug Output","title":"Technical details","text":"The decorator to print debug during the iterations can be activated by decorating the state of a solver and implementing your own DebugActions. For example printing a gradient from the GradientDescentState is automatically available, as explained in the gradient_descent solver.","category":"section"},{"location":"plans/debug/#Manopt.DebugAction","page":"Debug Output","title":"Manopt.DebugAction","text":"DebugAction\n\nA DebugAction is a small functor to print/issue debug output. The usual call is given by (p::AbstractManoptProblem, s::AbstractManoptSolverState, k) -> s, where i is the current iterate.\n\nBy convention i=0 is interpreted as \"For Initialization only,\" only debug info that prints initialization reacts, i<0 triggers updates of variables internally but does not trigger any output.\n\nFields (assumed by subtypes to exist)\n\nprint method to perform the actual print. Can for example be set to a file export,\n\nor to @info. The default is the print function on the default Base.stdout.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugCallback","page":"Debug Output","title":"Manopt.DebugCallback","text":"DebugCallback <: DebugAction\n\nDebug for a simple callback function, mainly for compatibility to other solvers and if a user already has a callback function or functor available\n\nThe expected format of the is that it is a function with signature (problem, state, iteration) -> nothing A simple callback of the signature () -> nothing can be specified by simple=true. In this case the callback is wrapped in a function of the generic form\n\nnote: Note\nThis is for now an internal struct, since its name might still change before it is made public. The functionality with the factory (callback=f) will still work, but this debug actions name might still change its name in the future.\n\nConstructor\n\nDebugCallback(callback; simple=false)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugChange","page":"Debug Output","title":"Manopt.DebugChange","text":"DebugChange(M=DefaultManifold(); kwargs...)\n\ndebug for the amount of change of the iterate (stored in get_iterate(o) of the AbstractManoptSolverState) during the last iteration. See DebugEntryChange for the general case\n\nKeyword parameters\n\nstorage=StoreStateAction( [:Gradient] ) storage of the previous action\nprefix=\"Last Change:\": prefix of the debug output (ignored if you set format)\nio=stdout: default stream to print the debug to.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nthe inverse retraction   to be used for approximating distance.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugCost","page":"Debug Output","title":"Manopt.DebugCost","text":"DebugCost <: DebugAction\n\nprint the current cost function value, see get_cost.\n\nConstructors\n\nDebugCost()\n\nParameters\n\nformat=\"$prefix %f\": format to print the output\nio=stdout: default stream to print the debug to.\nlong=false: short form to set the format to f(x): (default) or current cost: and the cost\nat_init=true: whether to print also at initialization\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugDivider","page":"Debug Output","title":"Manopt.DebugDivider","text":"DebugDivider <: DebugAction\n\nprint a small divider (default \" | \").\n\nConstructor\n\nDebugDivider(div, io=stdout, at_init=true)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEntry","page":"Debug Output","title":"Manopt.DebugEntry","text":"DebugEntry <: DebugAction\n\nprint a certain fields entry during the iterates, where a format can be specified how to print the entry.\n\nAdditional fields\n\nfield: symbol the entry can be accessed with within AbstractManoptSolverState\nat_init: whether to print also at initialization\n\nConstructor\n\nDebugEntry(f; prefix=\"$f:\", format = \"$prefix %s\", io=stdout, at_init=true)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEntryChange","page":"Debug Output","title":"Manopt.DebugEntryChange","text":"DebugEntryChange{T} <: DebugAction\n\nprint a certain entries change during iterates\n\nAdditional fields\n\nprint:    function to print the result\nprefix:   prefix to the print out\nformat:   format to print (uses the prefix by default and scientific notation)\nfield:    Symbol the field can be accessed with within AbstractManoptSolverState\ndistance: function (p,o,x1,x2) to compute the change/distance between two values of the entry\nstorage:  a StoreStateAction to store the previous value of :f\n\nConstructors\n\nDebugEntryChange(f,d)\n\nKeyword arguments\n\nio=stdout:                      an IOStream used for the debug\nprefix=\"Change of $f\":          the prefix\nstorage=StoreStateAction((f,)): a StoreStateAction\ninitial_value=NaN:              an initial value for the change of o.field.\nformat=\"$prefix %e\":            format to print the change\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEvery","page":"Debug Output","title":"Manopt.DebugEvery","text":"DebugEvery <: DebugAction\n\nevaluate and print debug only every kth iteration. Otherwise no print is performed. Whether internal variables are updates is determined by always_update.\n\nThis method does not perform any print itself but relies on it's children's print.\n\nIt also sets the sub solvers active parameter, see |DebugWhenActive}(#ref). Here, the activation_offset can be used to specify whether it refers to this iteration, the ith, when this call is before the iteration, then the offset should be 0, for the next iteration, that is if this is called after an iteration, it has to be set to 1. Since usual debug is happening after the iteration, 1 is the default.\n\nConstructor\n\nDebugEvery(d::DebugAction, every=1, always_update=true, activation_offset=1)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugFeasibility","page":"Debug Output","title":"Manopt.DebugFeasibility","text":"DebugFeasibility <: DebugAction\n\nDisplay information about the feasibility of the current iterate\n\nFields\n\nformat: a vector of symbols and string formatting the output\nio:     default stream to print the debug to.\nat_init: whether to print also at initialization\n\nThe following symbols are filled with values\n\n:Feasible display true or false depending on whether the iterate is feasible\n:FeasibleEq display = or â‰  equality constraints are fulfilled or not\n:FeasibleIneq display â‰¤ or â‰° inequality constraints are fulfilled or not\n:NumEq display the number of equality constraints infeasible\n:NumEqNz display the number of equality constraints infeasible if exists\n:NumIneq display the number of inequality constraints infeasible\n:NumIneqNz display the number of inequality constraints infeasible if exists\n:TotalEq display the sum of how much the equality constraints are violated\n:TotalInEq display the sum of how much the inequality constraints are violated\n\nformat to print the output.\n\nConstructor\n\nDebugFeasibility(     format=[\"feasible: \", :Feasible];     io::IO=stdout,     at_init::Bool=true, )\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugGradientChange","page":"Debug Output","title":"Manopt.DebugGradientChange","text":"DebugGradientChange()\n\ndebug for the amount of change of the gradient (stored in get_gradient(o) of the AbstractManoptSolverState o) during the last iteration. See DebugEntryChange for the general case\n\nKeyword parameters\n\nstorage=StoreStateAction( (:Gradient,) ): storage of the action for previous data\nprefix=\"Last Change:\": prefix of the debug output (ignored if you set format:\nio=stdout: default stream to print the debug to.\nformat=\"$prefix %f\": format to print the output\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugGroup","page":"Debug Output","title":"Manopt.DebugGroup","text":"DebugGroup <: DebugAction\n\ngroup a set of DebugActions into one action, where the internal prints are removed by default and the resulting strings are concatenated\n\nConstructor\n\nDebugGroup(g)\n\nconstruct a group consisting of an Array of DebugActions g, that are evaluated en bloque; the method does not perform any print itself, but relies on the internal prints. It still concatenates the result and returns the complete string\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIfEntry","page":"Debug Output","title":"Manopt.DebugIfEntry","text":"DebugIfEntry <: DebugAction\n\nIssue a warning, info, or error if a certain field does not pass a the check.\n\nThe message is printed in this case. If it contains a @printf argument identifier, that one is filled with the value of the field. That way you can print the value in this case as well.\n\nFields\n\nio:    an IO stream\ncheck: a function that takes the value of the field as input and returns a boolean\nfield: symbol the entry can be accessed with within AbstractManoptSolverState\nmsg:   if the check fails, this message is displayed\ntype: symbol specifying the type of display, possible values :print, : warn, :info, :error,           where :print prints to io.\nat_init: whether to print also at initialization\n\nConstructor\n\nDebugIfEntry(field, check=(>(0)); type=:warn, message=\":$f is nonnegative\", io=stdout, at_init=true)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIterate","page":"Debug Output","title":"Manopt.DebugIterate","text":"DebugIterate <: DebugAction\n\ndebug for the current iterate (stored in get_iterate(o)).\n\nConstructor\n\nDebugIterate(; kwargs...)\n\nKeyword arguments\n\nio=stdout:           default stream to print the debug to.\nformat=\"$prefix %s\": format how to print the current iterate\nlong=false:          whether to have a long (\"current iterate:\") or a short (\"p:\") prefix default\nprefix:              (see long for default) set a prefix to be printed before the iterate\nat_init=true:        whether to print also at initialization\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIteration","page":"Debug Output","title":"Manopt.DebugIteration","text":"DebugIteration <: DebugAction\n\nConstructor\n\nDebugIteration()\n\nKeyword parameters\n\nformat=\"# %-6d\": format to print the output\nio=stdout: default stream to print the debug to.\n\ndebug for the current iteration (prefixed with # by )\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugMessages","page":"Debug Output","title":"Manopt.DebugMessages","text":"DebugMessages <: DebugAction\n\nAn AbstractManoptSolverState or one of its sub steps like a Stepsize might generate warnings throughout their computations. This debug can be used to :print them display them as :info or :warnings or even :error, depending on the message type.\n\nConstructor\n\nDebugMessages(mode=:Info, warn=:Once; io::IO=stdout)\n\nInitialize the messages debug to a certain mode. Available modes are\n\n:Error:   issue the messages as an error and hence stop at any issue occurring\n:Info:    issue the messages as an @info\n:Print:   print messages to the steam io.\n:Warning: issue the messages as a warning\n\nThe warn level can be set to :Once to only display only the first message, to :Always to report every message, one can set it to :No, to deactivate this, then this DebugAction is inactive. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugSolverState","page":"Debug Output","title":"Manopt.DebugSolverState","text":"DebugSolverState <: AbstractManoptSolverState\n\nThe debug state appends debug to any state, they act as a decorator pattern. Internally a dictionary is kept that stores a DebugAction for several occasions using a Symbol as reference.\n\nThe original options can still be accessed using the get_state function.\n\nFields\n\noptions:         the options that are extended by debug information\ndebugDictionary: a Dict{Symbol,DebugAction} to keep track of Debug for different actions\n\nConstructors\n\nDebugSolverState(o,dA)\n\nconstruct debug decorated options, where dD can be\n\na DebugAction, then it is stored within the dictionary at :Iteration\nan Array of DebugActions.\na Dict{Symbol,DebugAction}.\nan Array of Symbols, String and an Int for the DebugFactory\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugStoppingCriterion","page":"Debug Output","title":"Manopt.DebugStoppingCriterion","text":"DebugStoppingCriterion <: DebugAction\n\nprint the Reason provided by the stopping criterion. Usually this should be empty, unless the algorithm stops.\n\nFields\n\nprefix=\"\": format to print the output\nio=stdout: default stream to print the debug to.\n\nConstructor\n\nDebugStoppingCriterion(prefix = \"\"; io::IO=stdout)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugTime","page":"Debug Output","title":"Manopt.DebugTime","text":"DebugTime()\n\nMeasure time and print the intervals. Using start=true you can start the timer on construction, for example to measure the runtime of an algorithm overall (adding)\n\nThe measured time is rounded using the given time_accuracy and printed after canonicalization.\n\nKeyword parameters\n\nio=stdout:             default stream to print the debug to.\nformat=\"$prefix %s\":   format to print the output, where %s is the canonicalized time`.\nmode=:cumulative:      whether to display the total time or reset on every call using :iterative.\nprefix=\"Last Change:\": prefix of the debug output (ignored if you set format:\nstart=false:           indicate whether to start the timer on creation or not.  Otherwise it might only be started on first call.\ntime_accuracy=Millisecond(1): round the time to this period before printing the canonicalized time\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfCostIncreases","page":"Debug Output","title":"Manopt.DebugWarnIfCostIncreases","text":"DebugWarnIfCostIncreases <: DebugAction\n\nprint a warning if the cost increases.\n\nNote that this provides an additional warning for gradient descent with its default constant step size.\n\nConstructor\n\nDebugWarnIfCostIncreases(warn=:Once; tol=1e-13)\n\nInitialize the warning to warning level (:Once) and introduce a tolerance for the test of 1e-13.\n\nThe warn level can be set to :Once to only warn the first time the cost increases, to :Always to report an increase every time it happens, and it can be set to :No to deactivate the warning, then this DebugAction is inactive. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfCostNotFinite","page":"Debug Output","title":"Manopt.DebugWarnIfCostNotFinite","text":"DebugWarnIfCostNotFinite <: DebugAction\n\nA debug to see when a field (value or array within the AbstractManoptSolverState is or contains values that are not finite, for example Inf or Nan.\n\nConstructor\n\nDebugWarnIfCostNotFinite(field::Symbol, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfFieldNotFinite","page":"Debug Output","title":"Manopt.DebugWarnIfFieldNotFinite","text":"DebugWarnIfFieldNotFinite <: DebugAction\n\nA debug to see when a field from the options is not finite, for example Inf or Nan\n\nConstructor\n\nDebugWarnIfFieldNotFinite(field::Symbol, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\nExample\n\nDebugWarnIfFieldNotFinite(:Gradient)\n\nCreates a [DebugAction] to track whether the gradient does not get Nan or Inf.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfGradientNormTooLarge","page":"Debug Output","title":"Manopt.DebugWarnIfGradientNormTooLarge","text":"DebugWarnIfGradientNormTooLarge{T} <: DebugAction\n\nA debug to warn when an evaluated gradient at the current iterate is larger than (a factor times) the maximal (recommended) stepsize at the current iterate.\n\nConstructor\n\nDebugWarnIfGradientNormTooLarge(factor::T=1.0, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\nExample\n\nDebugWarnIfFieldNotFinite(:Gradient)\n\nCreates a [DebugAction] to track whether the gradient does not get Nan or Inf.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfStepsizeCollapsed","page":"Debug Output","title":"Manopt.DebugWarnIfStepsizeCollapsed","text":"DebugWarnIfStepsizeCollapsed <: DebugAction\n\nprint a warning if the backtracking stopped because the stepsize fell below a given threshold. This threshold is specified by the stop_when_stepsize_less field.\n\nConstructor\n\nDebugWarnIfStepsizeCollapsed(tol::T=1e-8,warn=:Once;)\n\nInitialize the warning to warning level (:Once) with a tolerance for stop_when_stepsize_less set to tol (1e-8).\n\nThe warn level can be set to :Once to only warn the first time the cost increases, to :Always to report an increase every time it happens, and it can be set to :No to deactivate the warning, then this DebugAction is inactive. All other symbols are handled as if they were :Always\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWhenActive","page":"Debug Output","title":"Manopt.DebugWhenActive","text":"DebugWhenActive <: DebugAction\n\nevaluate and print debug only if the active boolean is set. This can be set from outside and is for example triggered by DebugEvery on debugs on the subsolver.\n\nThis method does not perform any print itself but relies on it's children's prints.\n\nFor now, the main interaction is with DebugEvery which might activate or deactivate this debug\n\nFields\n\nactive:        a boolean that can (de-)activated from outside to turn on/off debug\nalways_update: whether or not to call the order debugs with iteration <=0 inactive state\n\nConstructor\n\nDebugWhenActive(d::DebugAction, active=true, always_update=true)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{String}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(s)\n\ncreate a DebugAction where\n\na Stringyields the corresponding divider\na DebugAction is passed through\na [Symbol] creates DebugEntry of that symbol, with the exceptions of :Change, :Iterate, :Iteration, and :Cost.\na Tuple{Symbol,String} creates a DebugEntry of that symbol where the String specifies the format.\na <:Function creates a DebugCallback with the function as callback.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{Symbol}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(s::Symbol)\n\nConvert certain Symbols in the debug=[ ... ] vector to DebugActions Currently the following ones are done. Note that the Shortcut symbols should all start with a capital letter.\n\n:Cost creates a DebugCost\n:Change creates a DebugChange\n:Feasibility creates a DebugFeasibility\n:Gradient creates a DebugGradient\n:GradientChange creates a DebugGradientChange\n:GradientNorm creates a DebugGradientNorm\n:Iterate creates a DebugIterate\n:Iteration creates a DebugIteration\n:IterativeTime creates a DebugTime(:Iterative)\n:Stepsize creates a DebugStepsize\n:Stop creates a StoppingCriterion()\n:WarnStepsize creates a DebugWarnIfStepsizeCollapsed\n:WarnBundle creates a DebugWarnIfLagrangeMultiplierIncreases\n:WarnCost creates a DebugWarnIfCostNotFinite\n:WarnGradient creates a DebugWarnIfFieldNotFinite for the ::Gradient.\n:Time creates a DebugTime\n:WarningMessages creates a DebugMessages(:Warning)\n:InfoMessages creates a DebugMessages(:Info)\n:ErrorMessages creates a DebugMessages(:Error)\n:Messages creates a DebugMessages() (the same as :InfoMessages)\n\nany other symbol creates a DebugEntry(s) to print the entry (o.:s) from the options.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{Tuple{Symbol, Any}}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(t::Tuple{Symbol,String)\n\nConvert certain Symbols in the debug=[ ... ] vector to DebugActions Currently the following ones are done, where the string in t[2] is passed as the format the corresponding debug. Note that the Shortcut symbols t[1] should all start with a capital letter.\n\n:Change creates a DebugChange\n:Cost creates a DebugCost\n:Feasibility creates a DebugFeasibility\n:Gradient creates a DebugGradient\n:GradientChange creates a DebugGradientChange\n:GradientNorm creates a DebugGradientNorm\n:Iterate creates a DebugIterate\n:Iteration creates a DebugIteration\n:Stepsize creates a DebugStepsize\n:Stop creates a DebugStoppingCriterion\n:Time creates a DebugTime\n:IterativeTime creates a DebugTime(:Iterative)\n\nany other symbol creates a DebugEntry(s) to print the entry (o.:s) from the options.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugFactory-Tuple{Vector}","page":"Debug Output","title":"Manopt.DebugFactory","text":"DebugFactory(a::Vector)\n\nGenerate a dictionary of DebugActions.\n\nFirst all Symbols String, DebugActions and numbers are collected, excluding :Stop and :WhenActive. This collected vector is added to the :Iteration => [...] pair. :Stop is added as :StoppingCriterion to the :Stop => [...] pair. If necessary, these pairs are created\n\nFor each Pair of a Symbol and a Vector, the DebugGroupFactory is called for the Vector and the result is added to the debug dictionary's entry with said symbol. This is wrapped into the DebugWhenActive, when the :WhenActive symbol is present\n\nReturn value\n\nA dictionary for the different entry points where debug can happen, each containing a DebugAction to call.\n\nNote that upon the initialisation all dictionaries but the :StartAlgorithm one are called with an i=0 for reset.\n\nExamples\n\nProviding a simple vector of symbols, numbers and strings like\n[:Iterate, \" | \", :Cost, :Stop, 10]\nAdds a group to :Iteration of three actions (DebugIteration, DebugDivider(\" | \"),  and[DebugCost](@ref)) as a [DebugGroup](@ref) inside an [DebugEvery](@ref) to only be executed every 10th iteration. It also adds the [DebugStoppingCriterion](@ref) to the:EndAlgorithm` entry of the dictionary.\nThe same can also be written a bit more precise as\nDebugFactory([:Iteration => [:Iterate, \" | \", :Cost, 10], :Stop])\nWe can even make the stopping criterion concrete and pass Actions directly, for example explicitly Making the stop more concrete, we get\nDebugFactory([:Iteration => [:Iterate, \" | \", DebugCost(), 10], :Stop => [:Stop]])\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugGroupFactory-Tuple{Vector}","page":"Debug Output","title":"Manopt.DebugGroupFactory","text":"DebugGroupFactory(a::Vector)\n\nGenerate a DebugGroup of DebugActions. The following rules are used\n\nAny Symbol is passed to DebugActionFactory\nAny (Symbol, String) generates similar actions as in 1., but the string is used for format=, see DebugActionFactory\nAny String is passed to DebugActionFactory\nAny Function generates a DebugCallback.\nAny DebugAction is included as is.\n\nIf this results in more than one DebugAction a DebugGroup of these is build.\n\nIf any integers are present, the last of these is used to wrap the group in a DebugEvery(k).\n\nIf :WhenActive is present, the resulting Action is wrapped in DebugWhenActive, making it deactivatable by its parent solver.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.reset!-Tuple{DebugTime}","page":"Debug Output","title":"Manopt.reset!","text":"reset!(d::DebugTime)\n\nreset the internal time of a DebugTime, that is start from now again.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.set_parameter!-Tuple{DebugSolverState, Val{:Debug}, Vararg{Any}}","page":"Debug Output","title":"Manopt.set_parameter!","text":"set_parameter!(ams::DebugSolverState, ::Val{:Debug}, args...)\n\nSet certain values specified by args... into the elements of the debugDictionary\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.stop!-Tuple{DebugTime}","page":"Debug Output","title":"Manopt.stop!","text":"stop!(d::DebugTime)\n\nstop the reset the internal time of a DebugTime, that is set the time to 0 (undefined)\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, DebugSolverState}","page":"Debug Output","title":"Manopt.initialize_solver!","text":"initialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState)\n\nExtend the initialization of the solver by a hook to run the DebugAction that was added to the :Start entry of the debug lists. All others are triggered (with iteration number 0) to trigger possible resets\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.step_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Any}","page":"Debug Output","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, k)\n\nExtend the ith step of the solver by a hook to run debug prints, that were added to the :BeforeIteration and :Iteration entries of the debug lists.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Int64}","page":"Debug Output","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, k)\n\nExtend the stop_solver!, whether to stop the solver by a hook to run debug, that were added to the :Stop entry of the debug lists.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Sec-Stepsize","page":"Stepsize","title":"Stepsize and line search","text":"Most iterative algorithms determine a direction along which the algorithm shall proceed and determine a step size to find the next iterate. How advanced the step size computation can be implemented depends (among others) on the properties the corresponding problem provides.\n\nWithin Manopt.jl, the step size determination is implemented as a functor which is a subtype of Stepsize based on\n\nUsually, a constructor should take the manifold M as its first argument, for consistency, to allow general step size functors to be set up based on default values that might depend on the manifold currently under consideration.\n\nCurrently, the following step sizes are available\n\nAdditionally, initial stepsize guesses are handled by subtypes of AbstractInitialLinesearchGuess:\n\nOwn implementations can also (just) be functions.\n\nSome step sizes use max_stepsize function as a rough upper estimate for the trust region size. It is by default equal to injectivity radius of the exponential map but in some cases a different value is used. For the FixedRankMatrices manifold an estimate from Manopt is used. Tangent bundle with the Sasaki metric has 0 injectivity radius, so the maximum stepsize of the underlying manifold is used instead. Hyperrectangle also has 0 injectivity radius and an estimate based on maximum of dimensions along each index is used instead. For manifolds with corners, however, a line search capable of handling break points along the projected search direction should be used, and such algorithms do not call max_stepsize.\n\nInternally these step size functions create a ManifoldDefaultsFactory. Internally these use\n\nSome solvers have a different iterate from the one used for the line search. Then the following state can be used to wrap these locally\n\nThe Hager-Zhang initial guess uses two helper functions to determine initial stepsize in the first iteration on manifolds which have \"expected minimizer\", for example the zero point on the Euclidean manifold:","category":"section"},{"location":"plans/stepsize/#Literature","page":"Stepsize","title":"Literature","text":"D.Â P.Â Bertsekas. Convex Optimization Algorithms (Athena Scientific, 2015); p.Â 576.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nD.Â Dodd, L.Â Sharrock and C.Â Nemeth. Learning-rate-free stochastic optimization over Riemannian manifolds, arXivÂ preprintÂ arXiv:2406.02296 (2024).\n\n\n\nG.Â N.Â Grapiglia and G.Â F.Â Stella. An Adaptive Riemannian Gradient Method Without Function Evaluations. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 197, 1140â€“1160 (2023).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. Algorithm 851: CG_DESCENT, a conjugate gradient method with guaranteed descent. ACMÂ TransactionsÂ onÂ MathematicalÂ Software 32, 113â€“137 (2006).\n\n\n\nW.Â W.Â Hager. A derivative-based bracketing scheme for univariate minimization and the conjugate gradient method. ComputersÂ &Â MathematicsÂ withÂ Applications 18, 779â€“795 (1989).\n\n\n\nW.Â Huang. Optimization algorithms on Riemannian manifolds with applications. Ph.D. Thesis, Florida State University (2014).\n\n\n\nB.Â Iannazzo and M.Â Porcelli. The Riemannian Barzilaiâ€“Borwein method with nonmonotone line search and the matrix geometric mean computation. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 38, 495â€“517 (2017).\n\n\n\nJ.Â Nocedal and S.Â J.Â Wright. Numerical Optimization. 2Â Edition (Springer, New York, 2006).\n\n\n\n","category":"section"},{"location":"plans/stepsize/#Manopt.Stepsize","page":"Stepsize","title":"Manopt.Stepsize","text":"Stepsize\n\nAn abstract type for the functors representing step sizes. These are callable structures. The naming scheme is TypeOfStepSize, for example ConstantStepsize.\n\nEvery Stepsize has to provide a constructor and its function has to have the interface (p,o,i) where a AbstractManoptProblem as well as AbstractManoptSolverState and the current number of iterations are the arguments and returns a number, namely the stepsize to use.\n\nThe functor usually should accept arbitrary keyword arguments. Common ones used are\n\ngradient=nothing: to pass a pre-calculated gradient, otherwise it is computed.\n\nFor most it is advisable to employ a ManifoldDefaultsFactory. Then the function creating the factory should either be called TypeOf or if that is confusing or too generic, TypeOfLength\n\nSee also\n\nLinesearch\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.AdaptiveWNGradient","page":"Stepsize","title":"Manopt.AdaptiveWNGradient","text":"AdaptiveWNGradient(; kwargs...)\nAdaptiveWNGradient(M::AbstractManifold; kwargs...)\n\nA stepsize based on the adaptive gradient method introduced by [GS23].\n\nGiven a positive threshold hatc  â„•, an minimal bound b_textmin  0, an initial b_0  b_textmin, and a gradient reduction factor threshold Î±  01).\n\nSet c_0=0 and use Ï‰_0 = lVert operatornamegrad f(p_0) rVert_p_0.\n\nFor the first iterate use the initial step size s_0 = frac1b_0.\n\nThen, given the last gradient X_k-1 = operatornamegrad f(x_k-1), and a previous Ï‰_k-1, the values (b_k Ï‰_k c_k) are computed using X_k = operatornamegrad f(p_k) and the following cases\n\nIf lVert X_k rVert_p_k  Î±Ï‰_k-1, then let hatb_k-1  b_textminb_k-1 and set\n\n(b_k Ï‰_k c_k) = begincases   bigl(hatb_k-1 lVert X_k rVert_p_k 0 bigr)  text if  c_k-1+1 = hatc    bigl( b_k-1 + fraclVert X_k rVert_p_k^2b_k-1 Ï‰_k-1 c_k-1+1 Bigr)  text if  c_k-1+1hatcendcases\n\nIf lVert X_k rVert_p_k  Î±Ï‰_k-1, the set\n\n(b_k Ï‰_k c_k) = Bigl( b_k-1 + fraclVert X_k rVert_p_k^2b_k-1 Ï‰_k-1 0 Bigr)\n\nand return the step size s_k = frac1b_k.\n\nNote that for Î±=0 this is the Riemannian variant of WNGRad.\n\nKeyword arguments\n\nadaptive=true: switches the gradient_reductionÎ±(iftrue) to0`.\nalternate_bound = (bk, hat_c) ->  min(gradient_bound == 0 ? 1.0 : gradient_bound, max(minimal_bound, bk / (3 * hat_c)): how to determine hatk_k as a function of (bmin, bk, hat_c) -> hat_bk\ncount_threshold=4:  an Integer for hatc\ngradient_reduction::R=adaptive ? 0.9 : 0.0: the gradient reduction factor threshold Î±  01)\ngradient_bound=norm(M, p, X): the bound b_k.\nminimal_bound=1e-4: the value b_textmin\np::P =rand(M): a point on the manifold mathcalM only used to define the gradient_bound\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM only used to define the gradient_bound\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.ArmijoLinesearch","page":"Stepsize","title":"Manopt.ArmijoLinesearch","text":"ArmijoLinesearch(; kwargs...)\nArmijoLinesearch(M::AbstractManifold; kwargs...)\n\nSpecify a step size that performs an Armijo line search. Given a Function fmathcalMnifold))nifold))nifold)))â„ and its Riemannian Gradient operatornamegradf mathcalMnifold))nifold))nifold)))TmathcalM, the current point pmathcalMnifold))nifold))) and a search direction XT_pmathcalM.\n\nThen the step size s is found by reducing the initial step size s until\n\nf(operatornameretr_p(sX))  f(p) - Ï„s  X operatornamegradf(p) _p\n\nis fulfilled. for a sufficient decrease value Ï„  (01).\n\nTo be a bit more optimistic, if s already fulfils this, a first search is done, increasing the given s until for a first time this step does not hold.\n\nOverall, we look for step size, that provides enough decrease, see [Bou23, p. 58] for more information.\n\nKeyword arguments\n\nadditional_decrease_condition=(M, p) -> true: specify an additional criterion that has to be met to accept a step size in the decreasing loop\nadditional_increase_condition::IF=(M, p) -> true: specify an additional criterion that has to be met to accept a step size in the (initial) increase loop\ncandidate_point=allocate_result(M, rand): specify a point to be used as memory for the candidate points.\ncontraction_factor=0.95: how to update s in the decrease step\ninitial_stepsize=1.0: specify an initial step size\ninitial_guess=ArmijoInitialGuess(): Compute the initial step size of a line search based on this function. See AbstractInitialLinesearchGuess for details.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: a safeguard, stop when the decreasing step is below this (nonnegative) bound.\nstop_when_stepsize_exceeds=max_stepsize(M): a safeguard to not choose a too long step size when initially increasing\nstop_increasing_at_step=100: stop the initial increasing loop after this amount of steps. Set to 0 to never increase in the beginning\nstop_decreasing_at_step=1000: maximal number of Armijo decreases / tests to perform\nsufficient_decrease=0.1: the sufficient decrease parameter Ï„\n\nFor the stop safe guards you can pass :Messages to a debug= to see @info messages when these happen.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ArmijoLinesearchStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.ConstantLength","page":"Stepsize","title":"Manopt.ConstantLength","text":"ConstantLength(s; kwargs...)\nConstantLength(M::AbstractManifold, s; kwargs...)\n\nSpecify a Stepsize that is constant.\n\nInput\n\nM (optional)\ns=min( injectivity_radius(M)/2, 1.0) : the length to use.\n\nKeyword argument\n\ntype::Symbol=:relative specify the type of constant step size. Possible values are\n:relative â€“ scale the gradient tangent vector X to s*X\n:absolute â€“ scale the gradient to an absolute step length s, that is fracslVert X rVertX\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for ConstantStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.CubicBracketingLinesearch","page":"Stepsize","title":"Manopt.CubicBracketingLinesearch","text":"CubicBracketingLinesearch(; kwargs...)\nCubicBracketingLinesearch(M::AbstractManifold; kwargs...)\n\nA functor representing the curvature minimizing cubic bracketing scheme introduced in [Hag89]. Firstly, a bracket ab is generated by multiplying t_0 chosen as last_stepsize (or in case of the first iteration initial_stepsize) repeatedly with the stepsize_increase > 1 until the bracket conditions\n\n    Ï•(a)(b-a)  0  quad textand quad Ï•(a)  Ï•(b)\n\nis satisfied by either ab = t_k-1t_k, ab = t_kt_k-1, ab = 0t_k, or ab = t_k0. Here, Ï•(t) denotes the cost function when performing a step with size t into direction Î·. Over the iteration, the bracket ab is repeatedly updated using a cubic polynomial using values of Ï• Ï• at ab. The update value c is the local minimum of the polynomial, and the bracket condition ensures that it lies in between a and b. We note that the update strategy taken from [Hag89] ensures that the updated bracket satisfies the bracket condition.\n\nIf the parameter hybrid is set to true, the hybrid approach from [Hag89] is activated, which prevents slow convergence in edge cases.\n\nThe algorithm terminates if at any point the found candidate stepsize suffices the curvature condition induced by sufficient_curvatureor the bracket[a,b]is smaller than theminbracketwidth`.\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM to store an interim result\np=allocate_result(M, rand): to store an interim result\ninitial_stepsize=1.0: the step size to start the search with\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize_increase=1.1:  step size increase factor 1\nmax_iterations=100: maximum number of iterations\nsufficient_curvature=0.2: target reduction of the curvature (01)\nmin_bracket_width=1e-4: minimal size of the bracket ab\nhybrid=true: use the hybrid strategy\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for CubicBracketingLinesearch. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.DecreasingLength","page":"Stepsize","title":"Manopt.DecreasingLength","text":"DegreasingLength(; kwargs...)\nDecreasingLength(M::AbstractManifold; kwargs...)\n\nSpecify a [Stepsize]  that is decreasing as ``s_k = \\frac{(l - ak)f^i}{(k+s)^e} with the following\n\nKeyword arguments\n\nexponent=1.0:   the exponent e in the denominator\nfactor=1.0:     the factor f in the nominator\nlength=min(injectivity_radius(M)/2, 1.0): the initial step size l.\nsubtrahend=0.0: a value a that is subtracted every iteration\nshift=0.0:      shift the denominator iterator k by s.\ntype::Symbol=relative specify the type of constant step size.\n:relative â€“ scale the gradient tangent vector X to s_k*X\n:absolute â€“ scale the gradient to an absolute step length s_k, that is fracs_klVert X rVertX\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for DecreasingStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.DistanceOverGradients","page":"Stepsize","title":"Manopt.DistanceOverGradients","text":"DistanceOverGradients(; kwargs...)\nDistanceOverGradients(M::AbstractManifold; kwargs...)\n\nCreate a factory for the DistanceOverGradientsStepsize, the Riemannian Distance over Gradients (RDoG) learning-rate-free stepsize from [DSN24]. It adapts via the maximum distance from the start point and the accumulated gradient norms, optionally corrected by the geometric curvature term Î¶_Îº. It adapts without manual tuning by combining a distance proxy from the start point with accumulated gradient norms.\n\nDefinitions used by the implementation:\n\nbar r_t = max(Ïµ max_0le sle t d(p_0 p_s)) tracks the maximum geodesic distance from the initial point p_0 using the current iterate p_t.\nG_t = displaystylesum_s=0^t lVert g_s rVert^2, where g_s = operatornamegrad f(p_s).\n\nAt iteration t the stepsize used here is\n\nÎ·_t =\nbegincases\nfracbar r_tsqrtG_t  textif we do not use curvature\nfracbar r_tsqrtÎ¶_Îº(bar r_t)sqrtG_t  textif we use curvature\nendcases\n\nwith the geometric curvature function Î¶_Îº(d) defined in geometric_curvature_function. The initialization in this implementation follows the paper: on the first call (t=0), we set G_0=lVert g_0rVert^2, bar r_0 = Ïµ and take\n\nÎ·_0 =\nbegincases\nfracÏµlVert g_0rVert  textif we do not use curvature\nfracÏµsqrtÎ¶_Îº(Ïµ)lVert g_0rVert  textif we use curvature\nendcases\n\nOn subsequent calls, the state is updated as implemented: G_t  G_t-1 + lVert g_trVert^2 and bar r_t  max(bar r_t-1 d(p_0p_t)).\n\nKeyword arguments\n\ninitial_distance=1e-3: initial distance estimate Ïµ\nuse_curvature=false: whether to include Î¶_Îº\nsectional_curvature_bound=0.0: curvature lower bound Îº (if known)\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for DistanceOverGradientsStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.NonmonotoneLinesearch","page":"Stepsize","title":"Manopt.NonmonotoneLinesearch","text":"NonmonotoneLinesearch(; kwargs...)\nNonmonotoneLinesearch(M::AbstractManifold; kwargs...)\n\nA functor representing a nonmonotone line search using the Barzilai-Borwein step size [IP17].\n\nThis method first computes\n\n(x -> p, F-> f)\n\ny_k = operatornamegradf(p_k) - mathcal T_p_k-1p_koperatornamegradf(p_k-1)\n\nand\n\ns_k = - Î±_k-1  mathcal T_p_k-1p_koperatornamegradf(p_k-1)\n\nwhere Î±_k-1 is the step size computed in the last iteration and mathcal T_ is a vector transport. Then the Barzilaiâ€”Borwein step size is\n\nÎ±_k^textBB = begincases   min(Î±_textmax max(Î±_textmin Ï„_k))  textif s_k y_k_p_k  0    Î±_textmax  textelseendcases\n\nwhere\n\nÏ„_k = fracs_k s_k_p_ks_k y_k_p_k\n\nif the direct strategy is chosen, or\n\nÏ„_k =  fracs_k y_k_p_ky_k y_k_p_k\n\nin case of the inverse strategy or an alternation between the two in cases for the alternating strategy. Then find the smallest h = 0 1 2  such that\n\nf(operatornameretr_p_k(- Ïƒ^h Î±_k^textBB operatornamegradf(p_k)))  \nmax_1  j  max(k+1m) f(p_k+1-j) - Î³ Ïƒ^h Î±_k^textBB operatornamegradF(p_k) operatornamegradF(p_k)_p_k\n\nwhere Ïƒ  (01) is a step length reduction factor , m is the number of iterations after which the function value has to be lower than the current one and Î³  (01) is the sufficient decrease parameter. Finally the step size is computed as\n\nÎ±_k = Ïƒ^h Î±_k^textBB\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM to store an interim result\np=allocate_result(M, rand): to store an interim result\ninitial_stepsize=1.0: the step size to start the search with\nmemory_size=10: number of iterations after which the cost value needs to be lower than the current one\nbb_min_stepsize=1e-3: lower bound for the Barzilai-Borwein step size greater than zero\nbb_max_stepsize=1e3: upper bound for the Barzilai-Borwein step size greater than min_stepsize\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstrategy=direct: defines if the new step size is computed using the :direct, :indirect or :alternating strategy\nstorage=StoreStateAction(M; store_fields=[:Iterate, :Gradient]): increase efficiency by using a StoreStateAction for :Iterate and :Gradient.\nstepsize_reduction=0.5:  step size reduction factor contained in the interval (01)\nsufficient_decrease=1e-4: sufficient decrease parameter contained in the interval (01)\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds=max_stepsize(M, p)): largest stepsize when to stop to avoid leaving the injectivity radius\nstop_increasing_at_step=100:  last step to increase the stepsize (phase 1),\nstop_decreasing_at_step=1000: last step size to decrease the stepsize (phase 2),\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.Polyak","page":"Stepsize","title":"Manopt.Polyak","text":"Polyak(; kwargs...)\nPolyak(M::AbstractManifold; kwargs...)\n\nCompute a step size according to a method proposed by Polyak, cf. the Dynamic step size discussed in Section 3.2 of [Ber15]. This has been generalised here to both the Riemannian case and to approximate the minimum cost value.\n\nLet f_textbest be the best cost value seen until now during some iterative optimisation algorithm and let Î³_k be a sequence of numbers that is square summable, but not summable.\n\nThen the step size computed here reads\n\ns_k = fracf(p^(k)) - f_textbest + Î³_klVert f(p^(k)) rVert\n\nwhere f denotes a nonzero-subgradient of f at the current iterate p^(k).\n\nConstructor\n\nPolyak(; Î³ = k -> 1/k, initial_cost_estimate=0.0)\n\ninitialize the Polyak stepsize to a certain sequence and an initial estimate of f_\textbest.\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for PolyakStepsize. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.WolfePowellLinesearch","page":"Stepsize","title":"Manopt.WolfePowellLinesearch","text":"WolfePowellLinesearch(; kwargs...)\nWolfePowellLinesearch(M::AbstractManifold; kwargs...)\n\nPerform a linesearch to fulfill both the Armijo-Goldstein conditions\n\nfbigl( operatornameretr_p(Î±X) bigr)  f(p) + c_1 Î±_k operatornamegrad f(p) X_p\n\nas well as the Wolfe conditions\n\nfracmathrmdmathrmdt fbigl(operatornameretr_p(tX)bigr)\nBigvert_t=Î±\n c_2 fracmathrmdmathrmdt fbigl(operatornameretr_p(tX)bigr)Bigvert_t=0\n\nfor some given sufficient decrease coefficient c_1 and some sufficient curvature condition coefficientc_2.\n\nThis is adopted from [NW06, Section 3.1]\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\np::P =rand(M): a point on the manifold mathcalM as temporary storage for candidates\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM as type of memory allocated for the candidates direction and tangent\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nstop_increasing_at_step=100: for the initial increase test (s_plus), stop after these many steps\nstop_decreasing_at_step=1000: for the initial decrease test (s_minus), stop after these many steps\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.WolfePowellBinaryLinesearch","page":"Stepsize","title":"Manopt.WolfePowellBinaryLinesearch","text":"WolfePowellBinaryLinesearch(; kwargs...)\nWolfePowellBinaryLinesearch(M::AbstractManifold; kwargs...)\n\nPerform a linesearch to fulfill both the Armijo-Goldstein conditions for some given sufficient decrease coefficient c_1 and some sufficient curvature condition coefficientc_2. Compared to WolfePowellLinesearch which tries a simpler method, this linesearch performs the following algorithm\n\nWith\n\nA(t) = f(p_+)  c_1 t operatornamegradf(p) X_x\nquadtext and quad\nW(t) = operatornamegradf(x_+) mathcal T_pp_+X_p_+  c_2 X operatornamegradf(x)_x\n\nwhere p_+ =operatornameretr_p(tX) is the current trial point, and mathcal T_ denotes a vector transport. Then the following Algorithm is performed similar to Algorithm 7 from [Hua14]\n\nset Î±=0, Î²= and t=1.\nWhile either A(t) does not hold or W(t) does not hold do steps 3-5.\nIf A(t) fails, set Î²=t.\nIf A(t) holds but W(t) fails, set Î±=t.\nIf Î² set t=fracÎ±+Î²2, otherwise set t=2Î±.\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.AbstractInitialLinesearchGuess","page":"Stepsize","title":"Manopt.AbstractInitialLinesearchGuess","text":"AbstractInitialLinesearchGuess\n\nAn abstract type for initial line search guess strategies. These are functors that map (problem, state, k, last_stepsize, Î·) -> Î±_0, where Î±_0 is the initial step size, based on\n\nan AbstractManoptProblem problem\nan AbstractManoptSolverState state\nthe current iterate k\nthe last step size last_stepsize\nthe search direction Î·\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.ConstantInitialGuess","page":"Stepsize","title":"Manopt.ConstantInitialGuess","text":"ConstantInitialGuess{TF} <: AbstractInitialLinesearchGuess\n\nImplement a constant initial guess for line searches.\n\nConstructor\n\nConstantInitialGuess(Î±::TF)\n\nwhere Î± is the constant initial step size.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.ArmijoInitialGuess","page":"Stepsize","title":"Manopt.ArmijoInitialGuess","text":"ArmijoInitialGuess <: AbstractInitialLinesearchGuess\n\nImplement the initial guess for an Armijo line search.\n\nThe initial step size is chosen as min(l, max_stepsize(M, p) / norm(M, p, Î·)), where l is the last step size used, p the current point and Î· the search direction.\n\nThe default provided is based on the max_stepsize(M).\n\nConstructor\n\nArmijoInitialGuess()\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.HagerZhangInitialGuess","page":"Stepsize","title":"Manopt.HagerZhangInitialGuess","text":"HagerZhangInitialGuess{TF <: Real, TPN, TVN} <: AbstractInitialLinesearchGuess\n\nInitial line search guess from the paper [HZ06b], following the procedure initial. The line search was adapted to the Riemannian setting by introducing customizable norms for point and tangent vectors and maximum stepsize alphamax.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.reset_messages!-Tuple{NamedTuple}","page":"Stepsize","title":"Manopt.reset_messages!","text":"reset_messages!(messages::NamedTuple)\n\nGiven a named tuple of [StepsizeMessage](@ref)s, reset all messages to default values, i.e. at_iteration = -1, bound = 0, value = 0.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.set_message!-Tuple{NamedTuple, Symbol}","page":"Stepsize","title":"Manopt.set_message!","text":"set_message!(messages::NamedTuple, key::Symbol; at=nothing, bound=nothing, value=nothing)\n\nGiven a named tuple of [StepsizeMessage](@ref)s, set the message identified by key to the provided values, i.e. if they are not nothing.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.set_message!-Union{Tuple{Manopt.StepsizeMessage{TBound, TS}}, Tuple{TS}, Tuple{TBound}, Tuple{Manopt.StepsizeMessage{TBound, TS}, Union{Nothing, Int64}}, Tuple{Manopt.StepsizeMessage{TBound, TS}, Union{Nothing, Int64}, Union{Nothing, TBound}}, Tuple{Manopt.StepsizeMessage{TBound, TS}, Union{Nothing, Int64}, Union{Nothing, TBound}, Union{Nothing, TS}}} where {TBound<:Real, TS<:Real}","page":"Stepsize","title":"Manopt.set_message!","text":"set_message!(message::StepsizeMessage, at=nothing, bound=nothing, value=nothing)\n\nGiven a named tuple of [StepsizeMessage](@ref)s, set the message identified by key to the provided values, i.e. if they are not nothing.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.StepsizeMessage","page":"Stepsize","title":"Manopt.StepsizeMessage","text":"StepsizeMessage{TBound, TS}\n\nA message struct to hold stepsize information, when e.g. a step size underflow happens at a certain iteration\n\nFields\n\nat_iteration::Int: The iteration at which the message was set\nbound::TBound: The bound that was hit\nvalue::TS: The corresponding value that either caused the message or provides additional information\n\nConstructor\n\nStepsizeMessage(; bound::TBound = 0.0, value::TS = 0.0)\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{<:AbstractManoptSolverState}}","page":"Stepsize","title":"Manopt.default_stepsize","text":"default_stepsize(M::AbstractManifold, ams::AbstractManoptSolverState)\n\nReturns the default Stepsize functor used when running the solver specified by the AbstractManoptSolverState ams running with an objective on the AbstractManifold M.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.linesearch_backtrack!-Union{Tuple{T}, Tuple{TF}, Tuple{AbstractManifold, Any, TF, Any, Any, Any, Any, T}} where {TF, T}","page":"Stepsize","title":"Manopt.linesearch_backtrack!","text":"s = linesearch_backtrack(M, F, p, s, decrease, contract, Î·; kwargs...)\ns = linesearch_backtrack!(M, q, F, p, s, decrease, contract, Î·; kwargs...)\n\nperform a line search along ll_f(s) = f(operatornameretr_p(sÎ·) to find a stepsize s. See [NW06, Section 3] for details.\n\nThe linesearch starts with a first phase where the stepsize is increased as s  s  Ïƒ until\n\nf(operatornameretr_p(sÎ·))  f(p) + a * s * Df(p)Î·\n\n\nwhere a is the decrease parameter and Df(p)Î· is the directional derivative\n\nThen the actual backtracking phase starts where the stepsize is decreased as s  Ïƒ s\nuntil\n\nmath f(\\operatorname{retr}_p(sÎ·)) â‰¤ f(p) + b * s * Df(p)[Î·] ```\n\nwhere b is the decrease parameter.\n\nThis can be done in-place, where q is the point to store the point reached in.\n\nBoth phases have a safeguard on the maximal number of steps to perform as well as an upper and lower bound for the stepsize, respectively. The upper bound is a special case on manifolds to avoid exceeding the injectivity radius. Furthermore, both phases can be equipped with additional conditions to be fulfilled in order to accept the current stepsize.\n\nArguments\n\non manifold M\nfor the cost function f,\nat the current point p\nan initial stepsize s\na sufficient decrease\na contraction factor Ïƒ\na search direction Î·\n\nKeyword arguments\n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nadditional_increase_condition=(M,p) -> true: impose an additional condition for an increased step size to be accepted\nadditional_decrease_condition=(M,p) -> true: impose an additional condition for an decreased step size to be accepted\nDlf0: precomputed directional derivative at point p in direction Î· if the gradient is specified, this is computed as the real part of inner(M, p, gradient, Î·), otherwise it it nothing\nlf0 = f(M, p): the function value at the initial point p\ngradient = nothing: precomputed gradient at point p\nreport_messages_in::NamedTuple = (; ): a named tuple of StepsizeMessages to report messages in. currently supported keywords are :non_descent_direction, :stepsize_exceeds, :stepsize_less, :stop_increasing, :stop_decreasing\nstop_when_stepsize_less=0.0: to avoid numerical underflow\nstop_when_stepsize_exceeds=max_stepsize(M, p) / norm(M, p, Î·)) to avoid leaving the injectivity radius on a manifold\nstop_increasing_at_step=100: stop the initial increase of step size after these many steps\nstop_decreasing_at_step=1000`: stop the decreasing search after these many steps\nThese keywords are used as safeguards, where only the max stepsize is a very manifold specific one.\n\nReturn value\n\nA stepsize s and a message msg (in case any of the 4 criteria hit)\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.linesearch_backtrack-Tuple{AbstractManifold, Vararg{Any, 6}}","page":"Stepsize","title":"Manopt.linesearch_backtrack","text":"s = linesearch_backtrack(M, F, p, s, decrease, contract, Î·; kwargs...)\ns = linesearch_backtrack!(M, q, F, p, s, decrease, contract, Î·; kwargs...)\n\nperform a line search along ll_f(s) = f(operatornameretr_p(sÎ·) to find a stepsize s. See [NW06, Section 3] for details.\n\nThe linesearch starts with a first phase where the stepsize is increased as s  s  Ïƒ until\n\nf(operatornameretr_p(sÎ·))  f(p) + a * s * Df(p)Î·\n\n\nwhere a is the decrease parameter and Df(p)Î· is the directional derivative\n\nThen the actual backtracking phase starts where the stepsize is decreased as s  Ïƒ s\nuntil\n\nmath f(\\operatorname{retr}_p(sÎ·)) â‰¤ f(p) + b * s * Df(p)[Î·] ```\n\nwhere b is the decrease parameter.\n\nThis can be done in-place, where q is the point to store the point reached in.\n\nBoth phases have a safeguard on the maximal number of steps to perform as well as an upper and lower bound for the stepsize, respectively. The upper bound is a special case on manifolds to avoid exceeding the injectivity radius. Furthermore, both phases can be equipped with additional conditions to be fulfilled in order to accept the current stepsize.\n\nArguments\n\non manifold M\nfor the cost function f,\nat the current point p\nan initial stepsize s\na sufficient decrease\na contraction factor Ïƒ\na search direction Î·\n\nKeyword arguments\n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nadditional_increase_condition=(M,p) -> true: impose an additional condition for an increased step size to be accepted\nadditional_decrease_condition=(M,p) -> true: impose an additional condition for an decreased step size to be accepted\nDlf0: precomputed directional derivative at point p in direction Î· if the gradient is specified, this is computed as the real part of inner(M, p, gradient, Î·), otherwise it it nothing\nlf0 = f(M, p): the function value at the initial point p\ngradient = nothing: precomputed gradient at point p\nreport_messages_in::NamedTuple = (; ): a named tuple of StepsizeMessages to report messages in. currently supported keywords are :non_descent_direction, :stepsize_exceeds, :stepsize_less, :stop_increasing, :stop_decreasing\nstop_when_stepsize_less=0.0: to avoid numerical underflow\nstop_when_stepsize_exceeds=max_stepsize(M, p) / norm(M, p, Î·)) to avoid leaving the injectivity radius on a manifold\nstop_increasing_at_step=100: stop the initial increase of step size after these many steps\nstop_decreasing_at_step=1000`: stop the decreasing search after these many steps\nThese keywords are used as safeguards, where only the max stepsize is a very manifold specific one.\n\nReturn value\n\nA stepsize s and a message msg (in case any of the 4 criteria hit)\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.max_stepsize-Tuple{AbstractManifold, Any}","page":"Stepsize","title":"Manopt.max_stepsize","text":"max_stepsize(M::AbstractManifold, p)\nmax_stepsize(M::AbstractManifold)\n\nGet the maximum stepsize (at point p) on manifold M. It should be used to limit the distance an algorithm is trying to move in a single step.\n\nBy default, this returns injectivity_radius(M), if this exists. If this is not available on the the method returns Inf.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.Linesearch","page":"Stepsize","title":"Manopt.Linesearch","text":"Linesearch <: Stepsize\n\nAn abstract functor to represent line search type step size determinations, see Stepsize for details. One example is the ArmijoLinesearchStepsize functor.\n\nCompared to simple step sizes, the line search functors provide an interface of the form (p,o,i,X) -> s with an additional (but optional) fourth parameter to provide a search direction; this should default to something reasonable, most prominently the negative gradient.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.cubic_polynomial_argmin-Union{Tuple{R}, Tuple{Manopt.UnivariateTriple{R}, Manopt.UnivariateTriple{R}}} where R","page":"Stepsize","title":"Manopt.cubic_polynomial_argmin","text":"cubic_polynomial_argmin(a::UnivariateTriple, b::UnivariateTriple; warn::Bool = true)\n\nReturns the local minimizer of the cubic polynomial p with p(at)=af, p(bt)=bf, p(at)=adf, p(bt)=bdf.\n\nInput\n\na::UnivariateTriple{R}: triple of bracket value a\nb::UnivariateTriple{R}: triple bracket value b\n\nKeyword arguments\n\nwarn::Bool: Boolean value if warnings should be displayed\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.cubic_stepsize_update_step-NTuple{4, Real}","page":"Stepsize","title":"Manopt.cubic_stepsize_update_step","text":"cubic_stepsize_update_step(a::Real, b::Real, c::Real, Ï„::Real)\n\nStep function to determine the stepsize update c described in [Hag89].\n\nInput\n\na::Real: first value of the bracket\nb::Real: second value of the bracket\nc::Real: update value\nÏ„::Real: minimal step tolerance\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.geometric_curvature_function-Tuple{Real, Real}","page":"Stepsize","title":"Manopt.geometric_curvature_function","text":"geometric_curvature_function(Îº::Real, d::Real)\n\nCompute the geometric curvature function Î¶_Îº(d) used by the RDoG stepsize:\n\nÎ¶_Îº(d) =\nbegincases\n1  textif  Îº ge 04pt\ndfracsqrtÎºdtanh(sqrtÎºd)  textif  Îº  0\nendcases\n\nFor small arguments, a Taylor approximation is used for numerical stability.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_last_stepsize-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Vararg{Any}}","page":"Stepsize","title":"Manopt.get_last_stepsize","text":"get_last_stepsize(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, vars...)\n\nreturn the last computed stepsize stored within AbstractManoptSolverState ams when solving the AbstractManoptProblem amp.\n\nThis method takes into account that ams might be decorated. In case this returns NaN, a concrete call to the stored stepsize is performed. For this, usually, the first of the vars... should be the current iterate.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_last_stepsize-Tuple{Stepsize, Vararg{Any}}","page":"Stepsize","title":"Manopt.get_last_stepsize","text":"get_last_stepsize(::Stepsize, vars...)\n\nreturn the last computed stepsize from within the stepsize. If no last step size is stored, this returns NaN.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_stepsize-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Vararg{Any}}","page":"Stepsize","title":"Manopt.get_stepsize","text":"get_stepsize(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, vars...)\n\nreturn the stepsize stored within AbstractManoptSolverState ams when solving the AbstractManoptProblem amp. This method also works for decorated options and the Stepsize function within the options, by default stored in ams.stepsize.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_univariate_triple!-Tuple{AbstractManoptProblem, Manopt.CubicBracketingLinesearchStepsize, Any, Any, Any}","page":"Stepsize","title":"Manopt.get_univariate_triple!","text":"Get the UnivariateTriple of the problem mp related to the step with stepsize t from p in direction Î·.\n\nInput\n\nmp::AbstractManoptProblem\ncbls:::CubicBracketingLinesearchStepsize: containing retraction_method, vector_transport and the temporary candidate_point and candidate_direction\np: point in the manifold of mp\nÎ·: search direction at p\nt::Real: step size\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.secant-Union{Tuple{R}, Tuple{Manopt.UnivariateTriple{R}, Manopt.UnivariateTriple{R}}} where R","page":"Stepsize","title":"Manopt.secant","text":"secant(a::UnivariateTriple, b::UnivariateTriple)\n\nReturns the extremal of the quadratic polynomial p with p(at)=adf, p(bt)=bdf.\n\nInput\n\na::UnivariateTriple{R}: triple of bracket value a\nb::UnivariateTriple{R}: triple bracket value b\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.update_bracket-Union{Tuple{R}, Tuple{Manopt.UnivariateTriple{R}, Manopt.UnivariateTriple{R}, Manopt.UnivariateTriple{R}}} where R","page":"Stepsize","title":"Manopt.update_bracket","text":"update_bracket(a::UnivariateTriple, b::UnivariateTriple, c::UnivariateTriple)\n\nUpdates bracket w.r.t. the bracketing strategy in [Hag89] (R3) - (R5).\n\nInput\n\na::UnivariateTriple{R}: triple of bracket value a\nb::UnivariateTriple{R}: triple bracket value b\nc::UnivariateTriple{R}: triple of update value\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.AdaptiveWNGradientStepsize","page":"Stepsize","title":"Manopt.AdaptiveWNGradientStepsize","text":"AdaptiveWNGradientStepsize{I<:Integer,R<:Real,F<:Function} <: Stepsize\n\nA functor problem, state, k, X) -> s to an adaptive gradient method introduced by [GrapigliaStella:2023](@cite). See [AdaptiveWNGradient`](@ref) for the mathematical details.\n\nFields\n\ncount_threshold::I: an Integer for hatc\nminimal_bound::R: the value for b_textmin\nalternate_bound::F: how to determine hatk_k as a function of (bmin, bk, hat_c) -> hat_bk\ngradient_reduction::R: the gradient reduction factor threshold Î±  01)\ngradient_bound::R: the bound b_k.\nweight::R: Ï‰_k initialised to Ï‰_0 =norm(M, p, X) if this is not zero, 1.0 otherwise.\ncount::I: c_k, initialised to c_0 = 0.\n\nConstructor\n\nAdaptiveWNGrad(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\nadaptive=true: switches the gradient_reductionÎ±(iftrue) to0`.\nalternate_bound = (bk, hat_c) ->  min(gradient_bound == 0 ? 1.0 : gradient_bound, max(minimal_bound, bk / (3 * hat_c))\ncount_threshold=4\ngradient_reduction::R=adaptive ? 0.9 : 0.0\ngradient_bound=norm(M, p, X)\nminimal_bound=1e-4\np::P =rand(M): a point on the manifold mathcalM only used to define the gradient_bound\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM only used to define the gradient_bound\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.ArmijoLinesearchStepsize","page":"Stepsize","title":"Manopt.ArmijoLinesearchStepsize","text":"ArmijoLinesearchStepsize <: Linesearch\n\nA functor problem, state, k, X; kwargs...) -> s to provide an Armijo line search to compute step size, based on the search directionX`.\n\nThis functor accepts the following keyword arguments:\n\nFields\n\nadditional_decrease_condition: specify a condition a new point has to additionally fulfill. The default accepts all points.\nadditional_increase_condition: specify a condition that additionally to checking a valid increase has to be fulfilled. The default accepts all points.\ncandidate_point:               to store an interim result\ninitial_stepsize:              and initial step size\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ncontraction_factor:            exponent for line search reduction\nsufficient_decrease:           gain within Armijo's rule\nlast_stepsize:                 the last step size to start the search with\ninitial_guess: a function to provide an initial guess for the step size,\nit maps (problem, state, k, last_stepsize, Î·) -> Î±_0 based on\na AbstractManoptProblem problem\na AbstractManoptSolverState state\nthe current iterate k\nthe last step size last_stepsize\nthe search direction Î·\nand should at least accept the keywords\nlf0 =get_cost(problem, get_iterate(state)) the current cost at ^phere interpreted as the initial point offalong the line search direction\nDlf0 =get_differential(problem, get_iterate(state), Î·) the directional derivative at point p in direction Î·\nmessages::NamedTuple:          a named tuple to store possible StepsizeMessage about the stepsize search.\nstop_when_stepsize_less:       smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds:    largest stepsize when to stop.\nstop_increasing_at_step:       last step to increase the stepsize (phase 1),\nstop_decreasing_at_step:       last step size to decrease the stepsize (phase 2),\n\nPass :Messages to a debug= to see @infos when these happen.\n\nConstructor\n\nArmijoLinesearchStepsize(M::AbstractManifold; kwarg...)\n\nwith the fields keyword arguments and the retraction is set to the default retraction on M.\n\nKeyword arguments\n\ncandidate_point=(allocate_result(M, rand))\ninitial_stepsize=1.0\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ncontraction_factor=0.95\nsufficient_decrease=0.1\nlast_stepsize=initialstepsize\ninitial_guess=ArmijoInitialGuess()\nstop_when_stepsize_less=0.0: stop when the stepsize decreased below this version.\nstop_when_stepsize_exceeds=[max_step](@ref)(M)`: provide an absolute maximal step size.\nstop_increasing_at_step=100: for the initial increase test, stop after these many steps\nstop_decreasing_at_step=1000: in the backtrack, stop after these many steps\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.ConstantStepsize","page":"Stepsize","title":"Manopt.ConstantStepsize","text":"ConstantStepsize <: Stepsize\n\nA functor (problem, state, ...) -> s to provide a constant step size s.\n\nFields\n\nlength: constant value for the step size\ntype:   a symbol that indicates whether the stepsize is relatively (:relative),   with respect to the gradient norm, or absolutely (:absolute) constant.\n\nConstructors\n\nConstantStepsize(s::Real, t::Symbol=:relative)\n\ninitialize the stepsize to a constant s of type t.\n\nConstantStepsize(\n    M::AbstractManifold=DefaultManifold(),\n    s=min(1.0, injectivity_radius(M)/2);\n    type::Symbol=:relative\n)\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.CubicBracketingLinesearchStepsize","page":"Stepsize","title":"Manopt.CubicBracketingLinesearchStepsize","text":"CubicBracketingLinesearchStepsize{P,T,R<:Real} <: Linesearch\n\nDo a bracketing line search to find a step size Î± that finds a local minimum along the  search direction X starting from p, utilizing cubic polynomial interpolation. See CubicBracketingLinesearch for the mathematical details.\n\nFields\n\ncandidate_point::P: a point on the manifold mathcalM as temporary storage for candidates\ninitial_stepsize::R: the step size to start the search with\nlast_stepsize::R\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize_increase::R:  step size increase factor 1\nmax_iterations::I: maximum number of iterations\nsufficient_curvature::R: target reduction of the curvature (01)\nmin_bracket_width::R: minimal size of the bracket ab\nhybrid::Bool: use the hybrid strategy\nmax_stepsize::R: maximal stepsize\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nCubicBracketingLinesearchStepsize(M::AbstractManifold; kwargs...)\nCubicBracketingLinesearchStepsize(M::AbstractManifold, p; kwargs...)\n\nKeyword arguments\n\ncandidate_point::P =rand(M): a point on the manifold mathcalM as temporary storage for candidates\ninitial_stepsize=1.0: the step size to start the search with\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize_increase=1.1:  step size increase factor 1\nmax_iterations=100: maximum number of iterations\nsufficient_curvature=0.2: target reduction of the curvature (01)\nmin_bracket_width=1e-4: minimal size of the bracket ab\nhybrid=true: use the hybrid strategy\nmax_stepsize= max_stepsize(M): maximal stepsize\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.DecreasingStepsize","page":"Stepsize","title":"Manopt.DecreasingStepsize","text":"DecreasingStepsize()\n\nA functor (problem, state, ...) -> s to provide a constant step size s.\n\nFields\n\nexponent:   a value e the current iteration numbers eth exponential is taken of\nfactor:     a value f to multiply the initial step size with every iteration\nlength:     the initial step size l.\nsubtrahend: a value a that is subtracted every iteration\nshift:      shift the denominator iterator i by s`.\ntype:       a symbol that indicates whether the stepsize is relatively (:relative),   with respect to the gradient norm, or absolutely (:absolute) constant.\n\nIn total the complete formulae reads for the ith iterate as\n\ns_i = frac(l - i a)f^i(i+s)^e\n\nand hence the default simplifies to just s_i = \fracli\n\nConstructor\n\nDecreasingStepsize(M::AbstractManifold;\n    length=min(injectivity_radius(M)/2, 1.0),\n    factor=1.0,\n    subtrahend=0.0,\n    exponent=1.0,\n    shift=0.0,\n    type=:relative,\n)\n\ninitializes all fields, where none of them is mandatory and the length is set to half and to 1 if the injectivity radius is infinite.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.DistanceOverGradientsStepsize","page":"Stepsize","title":"Manopt.DistanceOverGradientsStepsize","text":"DistanceOverGradientsStepsize{R<:Real} <: Stepsize\n\nFields\n\ninitial_distance::R: initial distance estimate Ïµ0\nmax_distance::R: tracked maximum distance bar r_t\ngradient_sum::R: accumulated sum G_t\ninitial_point: stored start point p_0\nuse_curvature::Bool: toggle curvature correction Î¶_Îº\nsectional_curvature_bound::R: lower bound Îº used in Î¶_Îº when use_curvature=true\nlast_stepsize::R: last computed stepsize\n\nConstructor\n\nDistanceOverGradientsStepsize(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\ninitial_distance=1e-3: initial estimate Ïµ\nuse_curvature=false: whether to use Î¶_Îº\nsectional_curvature_bound=0.0: lower curvature bound Îº (if known)\np: initial point, used to track distance\n\nReferences\n\n[DSN24]: Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds (RDoG).\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.NonmonotoneLinesearchStepsize","page":"Stepsize","title":"Manopt.NonmonotoneLinesearchStepsize","text":"NonmonotoneLinesearchStepsize{P,T,R<:Real} <: Linesearch\n\nA functor representing a nonmonotone line search using the Barzilai-Borwein step size [IP17].\n\nFields\n\ninitial_guess: a function to provide an initial guess for the step size,\nit maps (problem, state, k, last_stepsize, Î·) -> Î±_0 based on\na AbstractManoptProblem problem\na AbstractManoptSolverState state\nthe current iterate k\nthe last step size last_stepsize\nthe search direction Î·\nand should at least accept the keywords\nlf0 =get_cost(problem, get_iterate(state)) the current cost at ^phere interpreted as the initial point offalong the line search direction\nDlf0 =get_differential(problem, get_iterate(state), Î·) the directional derivative at point p in direction Î·\nmemory_size:           number of iterations after which the cost value needs to be lower than the current one\nbb_min_stepsize=1e-3:     lower bound for the Barzilai-Borwein step size greater than zero\nbb_max_stepsize=1e3:      upper bound for the Barzilai-Borwein step size greater than min_stepsize\nlast_stepsize:     the last computed stepsize\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstrategy=direct:          defines if the new step size is computed using the :direct, :indirect or :alternating strategy\nstorage:                  (for :Iterate and :Gradient) a StoreStateAction\nstepsize_reduction:       step size reduction factor contained in the interval (0,1)\nsufficient_decrease:     sufficient decrease parameter contained in the interval (0,1)\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\ncandidate_point:          to store an interim result\nstop_when_stepsize_less:    smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds: largest stepsize when to stop.\nstop_increasing_at_step:    last step to increase the stepsize (phase 1),\nstop_decreasing_at_step:    last step size to decrease the stepsize (phase 2),\n\nConstructor\n\nNonmonotoneLinesearchStepsize(M::AbstractManifold; kwargs...)\nNonmonotoneLinesearchStepsize(M::AbstractManifold, p; kwargs...)\n\nKeyword arguments\n\np=allocate_result(M, rand): to store an interim result\ninitial_guess = (problem, state, k, last_stepsize, Î·) -> k == 0 ? 1.0 : last_stepsize  function to provide an initial guess for the stepsize\nmemory_size=10\nbb_min_stepsize=1e-3\nbb_max_stepsize=1e3\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstrategy=direct\nstorage=StoreStateAction(M; store_fields=[:Iterate, :Gradient])\nstepsize_reduction=0.5\nsufficient_decrease=1e-4\nstop_when_stepsize_less=0.0\nstop_when_stepsize_exceeds=max_stepsize(M, p))\nstop_increasing_at_step=100\nstop_decreasing_at_step=1000\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.PolyakStepsize","page":"Stepsize","title":"Manopt.PolyakStepsize","text":"PolyakStepsize <: Stepsize\n\nA functor (problem, state, ...) -> s to provide a step size due to Polyak, cf. Section 3.2 of [Ber15].\n\nFields\n\nÎ³               : a function k -> ... representing a seuqnce.\nbest_cost_value : storing the best cost value\n\nConstructor\n\nPolyakStepsize(;\n    Î³ = i -> 1/i,\n    initial_cost_estimate=0.0\n)\n\nConstruct a stepsize of Polyak type.\n\nSee also\n\nPolyak\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.UnivariateTriple","page":"Stepsize","title":"Manopt.UnivariateTriple","text":"UnivariateTriple{R <: Real}\n\nTriple of stepsize, function value und derivative value\n\nFields\n\nt::R: stepsize\nf::R: cost at stepsize t\ndf::R: derivative of the cost at stepsize t\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.WolfePowellBinaryLinesearchStepsize","page":"Stepsize","title":"Manopt.WolfePowellBinaryLinesearchStepsize","text":"WolfePowellBinaryLinesearchStepsize{R} <: Linesearch\n\nDo a backtracking line search to find a step size Î± that fulfils the Wolfe conditions along a search direction X starting from p. See WolfePowellBinaryLinesearch for the math details.\n\nFields\n\nsufficient_decrease::R, sufficient_curvature::R two constants in the line search\nlast_stepsize::R\nmax_stepsize::R\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less::R: a safeguard to stop when the stepsize gets too small\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nWolfePowellBinaryLinesearchStepsize(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.WolfePowellLinesearchStepsize","page":"Stepsize","title":"Manopt.WolfePowellLinesearchStepsize","text":"WolfePowellLinesearchStepsize{R<:Real} <: Linesearch\n\nDo a backtracking line search to find a step size Î± that fulfils the Wolfe conditions along a search direction X starting from p. See WolfePowellLinesearch for the math details\n\nFields\n\nsufficient_decrease::R, sufficient_curvature::R two constants in the line search\ncandidate_direction::T: a tangent vector at the point p on the manifold mathcalM\ncandidate_point::P: a point on the manifold mathcalM as temporary storage for candidates\ncandidate_tangent::T: a tangent vector at the point p on the manifold mathcalM\nlast_stepsize::R\nmax_stepsize::R\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less::R: a safeguard to stop when the stepsize gets too small\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nWolfePowellLinesearchStepsize(M::AbstractManifold; kwargs...)\nWolfePowellLinesearchStepsize(M::AbstractManifold, p; kwargs...)\n\nKeyword arguments\n\nsufficient_decrease=10^(-4)\nsufficient_curvature=0.999\np::P =rand(M): a point on the manifold mathcalM to store an interim result\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM as type of memory allocated for the candidates direction and tangent\nmax_stepsize=max_stepsize(M, p): largest stepsize allowed here.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstop_when_stepsize_less=0.0: smallest stepsize when to stop (the last one before is taken)\nstop_increasing_at_step=100: for the initial increase test (s_plus), stop after these many steps\nstop_decreasing_at_step=1000: for the initial decrease test (s_minus), stop after these many steps\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.StepsizeState","page":"Stepsize","title":"Manopt.StepsizeState","text":"StepsizeState{P,T} <: AbstractManoptSolverState\n\nA state to store a point and a descent direction used within a linesearch, if these are different from the iterate and search direction of the main solver.\n\nFields\n\np::P: a point on a manifold\nX::T: a tangent vector at p.\n\nConstructor\n\nStepsizeState(p,X)\nStepsizeState(M::AbstractManifold; p=rand(M), x=zero_vector(M,p)\n\nSee also\n\ninterior_point_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.default_vector_norm","page":"Stepsize","title":"Manopt.default_vector_norm","text":"default_point_distance(::AbstractManifold, p)\n\nThe default Hager-Zhang guess for distance between p the solution to the optimization problem along the descent direction. There is no default implementation because it is only needed for manifolds with a specific default_point_distance method.\n\n\n\n\n\n","category":"function"},{"location":"plans/stepsize/#Manopt.default_point_distance","page":"Stepsize","title":"Manopt.default_point_distance","text":"default_point_distance(::DefaultManifold, p)\n\nFollowing [HZ06b], the expected distance to the optimal solution from p on DefaultManifold is the Inf norm of p.\n\n\n\n\n\ndefault_point_distance(::AbstractManifold, p)\n\nThe default Hager-Zhang guess for distance between p the solution to the optimization problem. The default is 0, which deactivates heuristic I0 (a). On each manifold with default_point_distance, you need to also implement default_vector_norm.\n\n\n\n\n\ndefault_point_distance(::DefaultManifold, p)\n\nFollowing [HZ06b], the expected distance to the optimal solution from p on DefaultManifold is the Inf norm of p.\n\n\n\n\n\n","category":"function"},{"location":"#Welcome-to-Manopt.jl","page":"Home","title":"Welcome to Manopt.jl","text":"For a function fmathcal M  â„ defined on a Riemannian manifold mathcal M algorithms in this package aim to solve\n\noperatorname*argmin_p  mathcal M f(p)\n\nor in other words: find the point p on the manifold, where f reaches its minimal function value.\n\nManopt.jl provides a framework for optimization on manifolds as well as a Library of optimization algorithms in Julia. It belongs to the â€œManopt familyâ€, which includes Manopt (Matlab) and pymanopt.org (Python).\n\nIf you want to delve right into Manopt.jl read the ðŸ”ï¸ Get started with Manopt.jl tutorial.\n\nManopt.jl makes it easy to use an algorithm for your favourite manifold as well as a manifold for your favourite algorithm. It already provides many manifolds and algorithms, which can easily be enhanced, for example to record certain data or debug output throughout iterations.\n\nIf you use Manopt.jlin your work, please cite the following\n\n@article{Bergmann2022,\n    Author    = {Ronny Bergmann},\n    Doi       = {10.21105/joss.03866},\n    Journal   = {Journal of Open Source Software},\n    Number    = {70},\n    Pages     = {3866},\n    Publisher = {The Open Journal},\n    Title     = {Manopt.jl: Optimization on Manifolds in {J}ulia},\n    Volume    = {7},\n    Year      = {2022},\n}\n\nTo refer to a certain version or the source code in general cite for example\n\n@software{manoptjl-zenodo-mostrecent,\n    Author    = {Ronny Bergmann},\n    Copyright = {MIT License},\n    Doi       = {10.5281/zenodo.4290905},\n    Publisher = {Zenodo},\n    Title     = {Manopt.jl},\n    Year      = {2024},\n}\n\nfor the most recent version or a corresponding version specific DOI, see the list of all versions.\n\nIf you are also using Manifolds.jl please consider to cite\n\n@article{AxenBaranBergmannRzecki:2023,\n    AUTHOR    = {Axen, Seth D. and Baran, Mateusz and Bergmann, Ronny and Rzecki, Krzysztof},\n    ARTICLENO = {33},\n    DOI       = {10.1145/3618296},\n    JOURNAL   = {ACM Transactions on Mathematical Software},\n    MONTH     = {dec},\n    NUMBER    = {4},\n    TITLE     = {Manifolds.Jl: An Extensible Julia Framework for Data Analysis on Manifolds},\n    VOLUME    = {49},\n    YEAR      = {2023}\n}\n\nNote that both citations are in BibLaTeX format.","category":"section"},{"location":"#Main-features","page":"Home","title":"Main features","text":"","category":"section"},{"location":"#Optimization-algorithms-(solvers)","page":"Home","title":"Optimization algorithms (solvers)","text":"For every optimization algorithm, a solver is implemented based on a AbstractManoptProblem that describes the problem to solve and its AbstractManoptSolverState that set up the solver, and stores values that are required between or for the next iteration. Together they form a plan.","category":"section"},{"location":"#Manifolds","page":"Home","title":"Manifolds","text":"This project is build upon ManifoldsBase.jl, a generic interface to implement manifolds. Certain functions are extended for specific manifolds from Manifolds.jl, but all other manifolds from that package can be used here, too.\n\nThe notation in the documentation aims to follow the same notation from these packages.","category":"section"},{"location":"#Visualization","page":"Home","title":"Visualization","text":"To visualize and interpret results, Manopt.jl aims to provide both easy plot functions as well as exports. Furthermore a system to get debug during the iterations of an algorithms as well as record capabilities, for example to record a specified tuple of values per iteration, most prominently RecordCost and RecordIterate. Take a look at the ðŸ”ï¸ Get started with Manopt.jl tutorial on how to easily activate this.","category":"section"},{"location":"#Literature","page":"Home","title":"Literature","text":"If you want to get started with manifolds, one book is [Car92], and if you want do directly dive into optimization on manifolds, good references are [AMS08] and [Bou23], which are both available online for free\n\nP.-A.Â Absil, R.Â Mahony and R.Â Sepulchre. Optimization Algorithms on Matrix Manifolds (Princeton University Press, 2008), available online at press.princeton.edu/chapters/absil/.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nM.Â P.Â doÂ Carmo. Riemannian Geometry. Mathematics: Theory & Applications (BirkhÃ¤user Boston, Inc., Boston, MA, 1992); p.Â xiv+300.\n\n\n\n","category":"section"},{"location":"#Manopt.Manopt","page":"Home","title":"Manopt.Manopt","text":"ðŸ”ï¸ Manopt.jl: optimization on Manifolds in Julia.\n\nðŸ“š Documentation: manoptjl.org\nðŸ“¦ Repository: github.com/JuliaManifolds/Manopt.jl\nðŸ’¬ Discussions: github.com/JuliaManifolds/Manopt.jl/discussions\nðŸŽ¯ Issues: github.com/JuliaManifolds/Manopt.jl/issues\n\n\n\n\n\n","category":"module"},{"location":"references/#Literature","page":"References","title":"Literature","text":"This is all literature mentioned / referenced in the Manopt.jl documentation. Usually you find a small reference section at the end of every documentation page that contains the corresponding references as well.\n\nP.-A.Â Absil, C.Â Baker and K.Â Gallivan. Trust-Region Methods on Riemannian Manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 7, 303â€“330 (2006).\n\n\n\nP.-A.Â Absil, R.Â Mahony and R.Â Sepulchre. Optimization Algorithms on Matrix Manifolds (Princeton University Press, 2008), available online at press.princeton.edu/chapters/absil/.\n\n\n\nS.Â Adachi, T.Â Okuno and A.Â Takeda. Riemannian Levenberg-Marquardt Method with Global and Local Convergence Properties. ArXivÂ Preprint (2022).\n\n\n\nN.Â Agarwal, N.Â Boumal, B.Â Bullins and C.Â Cartis. Adaptive regularization with cubics on manifolds. MathematicalÂ Programming (2020).\n\n\n\nY.Â T.Â Almeida, J.Â X.Â Cruz Neto, P.Â R.Â Oliveira and J.Â C.Â Oliveira Souza. A modified proximal point method for DC functions on Hadamard manifolds. ComputationalÂ OptimizationÂ andÂ Applications 76, 649â€“673 (2020).\n\n\n\nM.Â BaÄÃ¡k. Computing medians and means in Hadamard spaces. SIAMÂ JournalÂ onÂ Optimization 24, 1542â€“1566 (2014), arXiv:1210.2145.\n\n\n\nE.Â M.Â Beale. A derivation of conjugate gradients. In: Numerical methods for nonlinear optimization, edited by F.Â A.Â Lootsma (Academic Press, London, London, 1972); pp.Â 39â€“43.\n\n\n\nR.Â Bergmann, O.Â P.Â Ferreira, S.Â Z.Â NÃ©meth and J.Â Zhu. On projection mappings and the gradient projection method on hyperbolic space forms. Preprint,Â inÂ preparation (2025).\n\n\n\nR.Â Bergmann, O.Â P.Â Ferreira, E.Â M.Â Santos and J.Â C.Â Souza. The difference of convex algorithm on Hadamard manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications (2024).\n\n\n\nR.Â Bergmann and R.Â Herzog. Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds. SIAMÂ JournalÂ onÂ Optimization 29, 2423â€“2444 (2019), arXiv:1804.06214.\n\n\n\nR.Â Bergmann, R.Â Herzog and H.Â Jasa. The Riemannian Convex Bundle Method, preprint (2024), arXiv:2402.13670.\n\n\n\nR.Â Bergmann, R.Â Herzog, M.Â Silva Louzeiro, D.Â Tenbrinck and J.Â Vidal-NÃºÃ±ez. Fenchel duality theory and a primal-dual algorithm on Riemannian manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 21, 1465â€“1504 (2021), arXiv:1908.02022.\n\n\n\nR.Â Bergmann, H.Â Jasa, P.Â John and M.Â Pfeffer. The Intrinsic Riemannian Proximal Gradient Method for Convex Optimization, preprint (2025), arXiv:2507.16055.\n\n\n\nR.Â Bergmann, H.Â Jasa, P.Â John and M.Â Pfeffer. The Intrinsic Riemannian Proximal Gradient Method for Nonconvex Optimization, preprint (2025), arXiv:2506.09775.\n\n\n\nR.Â Bergmann, J.Â Persch and G.Â Steidl. A parallel Douglas Rachford algorithm for minimizing ROF-like functionals on images with values in symmetric Hadamard manifolds. SIAMÂ JournalÂ onÂ ImagingÂ Sciences 9, 901â€“937 (2016), arXiv:1512.02814.\n\n\n\nD.Â P.Â Bertsekas. Convex Optimization Algorithms (Athena Scientific, 2015); p.Â 576.\n\n\n\nP.Â B.Â Borckmans, M.Â Ishteva and P.-A.Â Absil. A Modified Particle Swarm Optimization Algorithm for the Best Low Multilinear Rank Approximation of Higher-Order Tensors. In: 7th International Conference on Swarm INtelligence (Springer Berlin Heidelberg, 2010); pp.Â 13â€“23.\n\n\n\nN.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nM.Â P.Â doÂ Carmo. Riemannian Geometry. Mathematics: Theory & Applications (BirkhÃ¤user Boston, Inc., Boston, MA, 1992); p.Â xiv+300.\n\n\n\nA.Â Chambolle and T.Â Pock. A first-order primal-dual algorithm for convex problems with applications to imaging. JournalÂ ofÂ MathematicalÂ ImagingÂ andÂ Vision 40, 120â€“145 (2011).\n\n\n\nS.Â Colutto, F.Â Fruhauf, M.Â Fuchs and O.Â Scherzer. The CMA-ES on Riemannian Manifolds to Reconstruct Shapes in 3-D Voxel Images. IEEEÂ TransactionsÂ onÂ EvolutionaryÂ Computation 14, 227â€“245 (2010).\n\n\n\nA.Â R.Â Conn, N.Â I.Â Gould and P.Â L.Â Toint. Trust Region Methods (Society for Industrial and Applied Mathematics, 2000).\n\n\n\nY.Â H.Â Dai and Y.Â Yuan. A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property. SIAMÂ JournalÂ onÂ Optimization 10, 177â€“182 (1999).\n\n\n\nW.Â Diepeveen and J.Â Lellmann. An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising. SIAMÂ JournalÂ onÂ ImagingÂ Sciences 14, 1565â€“1600 (2021), arXiv:2102.10309.\n\n\n\nD.Â Dodd, L.Â Sharrock and C.Â Nemeth. Learning-rate-free stochastic optimization over Riemannian manifolds, arXivÂ preprintÂ arXiv:2406.02296 (2024).\n\n\n\nD.Â W.Â Dreisigmeyer. Direct Search Algorithms over Riemannian Manifolds (Optimization Online, 2007).\n\n\n\nA.Â S.Â El-Bakry, R.Â A.Â Tapia, T.Â Tsuchiya and Y.Â Zhang. On the formulation and theory of the Newton interior-point method for nonlinear programming. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 89, 507â€“541 (1996).\n\n\n\nS.Â Feng, W.Â Huang, L.Â Song, S.Â Ying and T.Â Zeng. Proximal gradient method for nonconvex and nonsmooth optimization on Hadamard manifolds. OptimizationÂ Letters 16, 2277â€“2297 (2021).\n\n\n\nO.Â Ferreira and P.Â R.Â Oliveira. Subgradient algorithm on Riemannian manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 97, 93â€“104 (1998).\n\n\n\nO.Â Ferreira and P.Â R.Â Oliveira. Proximal point algorithm on Riemannian manifolds. Optimization.Â AÂ JournalÂ ofÂ MathematicalÂ ProgrammingÂ andÂ OperationsÂ Research 51, 257â€“270 (2002).\n\n\n\nR.Â Fletcher. Practical Methods of Optimization. 2Â Edition, A Wiley-Interscience Publication (John Wiley & Sons Ltd., 1987).\n\n\n\nR.Â Fletcher and C.Â M.Â Reeves. Function minimization by conjugate gradients. TheÂ ComputerÂ Journal 7, 149â€“154 (1964).\n\n\n\nJ.Â Glaubitz, A.Â Iske, J.Â Lampert and P.Â Ã–ffner. Why summation by parts is not enough (02 2026), arXiv:2602.10786.\n\n\n\nG.Â N.Â Grapiglia and G.Â F.Â Stella. An Adaptive Riemannian Gradient Method Without Function Evaluations. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 197, 1140â€“1160 (2023).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A survey of nonlinear conjugate gradient methods. PacificÂ JournalÂ ofÂ Optimization 2, 35â€“58 (2006).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. Algorithm 851: CG_DESCENT, a conjugate gradient method with guaranteed descent. ACMÂ TransactionsÂ onÂ MathematicalÂ Software 32, 113â€“137 (2006).\n\n\n\nW.Â W.Â Hager and H.Â Zhang. A New Conjugate Gradient Method with Guaranteed Descent and an Efficient Line Search. SIAMÂ JournalÂ onÂ Optimization 16, 170â€“192 (2005).\n\n\n\nW.Â W.Â Hager. A derivative-based bracketing scheme for univariate minimization and the conjugate gradient method. ComputersÂ &Â MathematicsÂ withÂ Applications 18, 779â€“795 (1989).\n\n\n\nN.Â Hansen. The CMA Evolution Strategy: A Tutorial. ArXivÂ Preprint (2023).\n\n\n\nM.Â Hestenes and E.Â Stiefel. Methods of conjugate gradients for solving linear systems. JournalÂ ofÂ ResearchÂ ofÂ theÂ NationalÂ BureauÂ ofÂ Standards 49, 409 (1952).\n\n\n\nN.Â Hoseini Monjezi, S.Â Nobakhtian and M.Â R.Â Pouryayevali. A proximal bundle algorithm for nonsmooth optimization on Riemannian manifolds. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 43, 293â€“325 (2023).\n\n\n\nW.Â Huang. Optimization algorithms on Riemannian manifolds with applications. Ph.D. Thesis, Florida State University (2014).\n\n\n\nW.Â Huang, P.-A.Â Absil and K.Â A.Â Gallivan. A Riemannian BFGS method without differentiated retraction for nonconvex optimization problems. SIAMÂ JournalÂ onÂ Optimization 28, 470â€“495 (2018).\n\n\n\nW.Â Huang, K.Â A.Â Gallivan and P.-A.Â Absil. A Broyden class of quasi-Newton methods for Riemannian optimization. SIAMÂ JournalÂ onÂ Optimization 25, 1660â€“1685 (2015).\n\n\n\nB.Â Iannazzo and M.Â Porcelli. The Riemannian Barzilaiâ€“Borwein method with nonmonotone line search and the matrix geometric mean computation. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 38, 495â€“517 (2017).\n\n\n\nH.Â Karcher. Riemannian center of mass and mollifier smoothing. CommunicationsÂ onÂ PureÂ andÂ AppliedÂ Mathematics 30, 509â€“541 (1977).\n\n\n\nZ.Â Lai and A.Â Yoshise. Riemannian Interior Point Methods for Constrained Optimization on Manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 201, 433â€“469 (2024), arXiv:2203.09762.\n\n\n\nC.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\nY.Â Liu and C.Â Storey. Efficient generalized conjugate gradient algorithms,  part 1: Theory. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 69, 129â€“137 (1991).\n\n\n\nD.Â Nguyen. Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 198, 135â€“164 (2023), arXiv:2009.10159.\n\n\n\nJ.Â Nocedal and S.Â J.Â Wright. Numerical Optimization. 2Â Edition (Springer, New York, 2006).\n\n\n\nR.Â Peeters. On a Riemannian version of the Levenberg-Marquardt algorithm. Serie Research MemorandaÂ 0011 (VU University Amsterdam, Faculty of Economics, Business Administration and Econometrics, 1993).\n\n\n\nE.Â Polak and G.Â RibiÃ¨re. Note sur la convergence de mÃ©thodes de directions conjuguÃ©es. RevueÂ franÃ§aiseÂ dâ€™informatiqueÂ etÂ deÂ rechercheÂ opÃ©rationnelle 3, 35â€“43 (1969).\n\n\n\nM.Â J.Â Powell. Restart procedures for the conjugate gradient method. MathematicalÂ Programming 12, 241â€“254 (1977).\n\n\n\nH.Â Sakai and H.Â Iiduka. Hybrid Riemannian conjugate gradient methods with global convergence properties. ComputationalÂ OptimizationÂ andÂ Applications 77, 811â€“830 (2020).\n\n\n\nH.Â Sakai and H.Â Iiduka. Sufficient Descent Riemannian Conjugate Gradient Methods. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 190, 130â€“150 (2021).\n\n\n\nJ.Â C.Â Souza and P.Â R.Â Oliveira. A proximal point algorithm for DC functions on Hadamard manifolds. JournalÂ ofÂ GlobalÂ Optimization 63, 797â€“810 (2015).\n\n\n\nM.Â Weber and S.Â Sra. Riemannian Optimization via Frank-Wolfe Methods. MathematicalÂ Programming 199, 525â€“556 (2022).\n\n\n\nL.Â Weigl, R.Â Bergmann and A.Â Schiela. Newton's method for nonlinear mappings into vector bundles Part II: Application to variational problems, preprint (2025), arXiv:2507.13836.\n\n\n\nL.Â Weigl and A.Â Schiela. Newton's method for nonlinear mappings into vector bundles, preprint (2024), arXiv:2404.04073.\n\n\n\nH.Â Zhang and S.Â Sra. Towards Riemannian accelerated gradient methods, arXivÂ Preprint,Â 1806.02812 (2018).\n\n\n\n","category":"section"},{"location":"tutorials/StochasticGradientDescent/#How-to-run-stochastic-gradient-descent","page":"How to run stochastic gradient descent","title":"How to run stochastic gradient descent","text":"Ronny Bergmann\n\nThis tutorial illustrates how to use the stochastic_gradient_descent solver and different DirectionUpdateRules to introduce the average or momentum variant, see Stochastic Gradient Descent.\n\nComputationally, we look at a very simple but large scale problem, the Riemannian Center of Mass or FrÃ©chet mean: for given points p_i mathcal M, i=1N this optimization problem reads\n\noperatorname*argmin_xmathcal M frac12sum_i=1^N\n  operatornamed^2_mathcal M(xp_i)\n\nwhich of course can be (and is) solved by a gradient descent, see the introductory tutorial or Statistics in Manifolds.jl. If N is very large, evaluating the complete gradient might be quite expensive. A remedy is to evaluate only one of the terms at a time and choose a random order for these.\n\nWe first initialize the packages\n\nusing Manifolds, Manopt, Random, BenchmarkTools, ManifoldDiff\nusing ManifoldDiff: grad_distance\nRandom.seed!(42);\n\nWe next generate a (little) large(r) data set\n\nn = 5000\nÏƒ = Ï€ / 12\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];\n\nNote that due to the construction of the points as zero mean tangent vectors, the mean should be very close to our initial point p.\n\nIn order to use the stochastic gradient, we now need a function that returns the vector of gradients. There are two ways to define it in Manopt.jl: either as a single function that returns a vector, or as a vector of functions.\n\nThe first variant is of course easier to define, but the second is more efficient when only evaluating one of the gradients.\n\nFor the mean, the gradient is\n\noperatornamegradf(p) = sum_i=1^N operatornamegradf_i(x) quad textwhere operatornamegradf_i(x) = -log_x p_i\n\nwhich we define in Manopt.jl in two different ways: either as one function returning all gradients as a vector (see gradF), or, maybe more fitting for a large scale problem, as a vector of small gradient functions (see gradf)\n\nF(M, p) = 1 / (2 * n) * sum(map(q -> distance(M, p, q)^2, data))\ngradF(M, p) = [grad_distance(M, p, q) for q in data]\ngradf = [(M, p) -> grad_distance(M, q, p) for q in data];\np0 = 1 / sqrt(3) * [1.0, 1.0, 1.0]\n\n3-element Vector{Float64}:\n 0.5773502691896258\n 0.5773502691896258\n 0.5773502691896258\n\nThe calls are only slightly different, but notice that accessing the second gradient element requires evaluating all logs in the first function, while we only call one of the functions in the second array of functions. So while you can use both gradF and gradf in the following call, the second one is (much) faster:\n\np_opt1 = stochastic_gradient_descent(M, gradF, p)\n\n3-element Vector{Float64}:\n  0.6940527079187876\n -0.37439006629268595\n -0.614917000002404\n\n@benchmark stochastic_gradient_descent($M, $gradF, $p0)\n\nBenchmarkTools.Trial: 1 sample with 1 evaluation per sample.\n Single result which took 6.100 s (10.84% GC) to evaluate,\n with a memory estimate of 7.84 GiB, over 200470602 allocations.\n\np_opt2 = stochastic_gradient_descent(M, gradf, p0)\n\n3-element Vector{Float64}:\n 0.6828818855405706\n 0.1754529371758115\n 0.7091463863243864\n\n@benchmark stochastic_gradient_descent($M, $gradf, $p0)\n\nBenchmarkTools.Trial: 2161 samples with 1 evaluation per sample.\n Range (min â€¦ max):  939.791 Î¼s â€¦ 38.657 ms  â”Š GC (min â€¦ max): 0.00% â€¦ 96.36%\n Time  (median):       1.894 ms              â”Š GC (median):    0.00%\n Time  (mean Â± Ïƒ):     2.310 ms Â±  1.824 ms  â”Š GC (mean Â± Ïƒ):  8.59% Â± 11.50%\n\n  â–„â–†â–…â–…â–ƒâ–ƒâ–â–         â–ˆ                                            \n  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–…â–…â–…â–…â–…â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚ â–ƒ\n  940 Î¼s          Histogram: frequency by time         9.55 ms <\n\n Memory estimate: 955.47 KiB, allocs estimate: 21665.\n\nThis result is reasonably close. But we can improve it by using a DirectionUpdateRule, namely:\n\nOn the one hand MomentumGradient, which requires both the manifold and the initial value, to keep track of the iterate and parallel transport the last direction to the current iterate. The necessary vector_transport_method keyword is set to a suitable default on every manifold, see default_vector_transport_method. We get â€œâ€œâ€\n\np_opt3 = stochastic_gradient_descent(\n    M, gradf, p0; direction=MomentumGradient(; direction=StochasticGradient())\n)\n\n3-element Vector{Float64}:\n  0.469317936755693\n -0.2868289932127861\n  0.8351465756931048\n\nMG = MomentumGradient(; direction=StochasticGradient());\n@benchmark stochastic_gradient_descent($M, $gradf, p=$p0; direction=$MG)\n\nBenchmarkTools.Trial: 833 samples with 1 evaluation per sample.\n Range (min â€¦ max):  4.759 ms â€¦ 51.256 ms  â”Š GC (min â€¦ max):  0.00% â€¦ 90.13%\n Time  (median):     4.926 ms              â”Š GC (median):     0.00%\n Time  (mean Â± Ïƒ):   5.998 ms Â±  3.189 ms  â”Š GC (mean Â± Ïƒ):  12.70% Â± 17.19%\n\n  â–ˆâ–‡â–„â–             â–         â–‚                                \n  â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–…â–â–â–…â–…â–â–â–â–…â–„â–…â–ˆâ–â–…â–„â–„â–â–â–â–â–â–ˆâ–ˆâ–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–„â–‡â–†â–ˆâ–ˆâ–‡â–†â–ˆâ–‡â–†â–…â–„â–… â–‡\n  4.76 ms      Histogram: log(frequency) by time     12.8 ms <\n\n Memory estimate: 8.56 MiB, allocs estimate: 221662.\n\nAnd on the other hand the AverageGradient computes an average of the last n gradients. This is done by\n\np_opt4 = stochastic_gradient_descent(\n    M, gradf, p0; direction=AverageGradient(; n=10, direction=StochasticGradient()), debug=[],\n)\n\n3-element Vector{Float64}:\n  0.8032500797539076\n -0.1388759285422542\n  0.5792260231091728\n\nAG = AverageGradient(; n=10, direction=StochasticGradient(M));\n@benchmark stochastic_gradient_descent($M, $gradf, p=$p0; direction=$AG, debug=[])\n\nBenchmarkTools.Trial: 3 samples with 1 evaluation per sample.\n Range (min â€¦ max):  1.666 s â€¦   1.697 s  â”Š GC (min â€¦ max): 0.00% â€¦ 1.85%\n Time  (median):     1.684 s              â”Š GC (median):    1.07%\n Time  (mean Â± Ïƒ):   1.682 s Â± 15.323 ms  â”Š GC (mean Â± Ïƒ):  0.98% Â± 0.93%\n\n  â–ˆ                                â–ˆ                      â–ˆ  \n  â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ â–\n  1.67 s         Histogram: frequency by time         1.7 s <\n\n Memory estimate: 154.59 MiB, allocs estimate: 2691688.\n\nNote that the default StoppingCriterion is a fixed number of iterations which helps the comparison here.\n\nFor both update rules we have to internally specify that we are still in the stochastic setting, since both rules can also be used with the IdentityUpdateRule within gradient_descent.\n\nFor this not-that-large-scale example we can of course also use a gradient descent with ArmijoLinesearch,\n\nfullGradF(M, p) = 1/n*sum(grad_distance(M, q, p) for q in data)\np_opt5 = gradient_descent(M, F, fullGradF, p0; stepsize=ArmijoLinesearch())\n\n3-element Vector{Float64}:\n  0.7050420976839262\n -0.006374163322665686\n  0.7091368066426853\n\nbut in general it is expected to be a bit slow.\n\nAL = ArmijoLinesearch();\n@benchmark gradient_descent($M, $F, $fullGradF, $p0; stepsize=$AL)\n\nBenchmarkTools.Trial: 46 samples with 1 evaluation per sample.\n Range (min â€¦ max):   95.936 ms â€¦ 169.426 ms  â”Š GC (min â€¦ max):  0.00% â€¦ 16.96%\n Time  (median):     106.848 ms               â”Š GC (median):    12.68%\n Time  (mean Â± Ïƒ):   110.041 ms Â±  15.549 ms  â”Š GC (mean Â± Ïƒ):  11.20% Â±  5.05%\n\n     â–    â–„â–ˆ                                                     \n  â–„â–â–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–ˆâ–ˆâ–ƒâ–â–„â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„ â–\n  95.9 ms          Histogram: frequency by time          169 ms <\n\n Memory estimate: 138.28 MiB, allocs estimate: 3395738.","category":"section"},{"location":"tutorials/StochasticGradientDescent/#Technical-details","page":"How to run stochastic gradient descent","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:34:35.","category":"section"},{"location":"contributing/#Contributing-to-Manopt.jl","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"First, thanks for taking the time to contribute. Any contribution is appreciated and welcome.\n\nThe following is a set of guidelines to Manopt.jl.","category":"section"},{"location":"contributing/#Table-of-contents","page":"Contributing to Manopt.jl","title":"Table of contents","text":"Contributing to Manopt.jl     - Table of Contents\nI just have a question\nHow can I file an issue?\nHow can I contribute?\nAdd a missing method\nProvide a new algorithm\nProvide a new example\nCode style\nConcerning the documentation\nSpell checking","category":"section"},{"location":"contributing/#I-just-have-a-question","page":"Contributing to Manopt.jl","title":"I just have a question","text":"The developer can most easily be reached in the Julia Slack channel #manifolds. You can apply for the Julia Slack workspace here if you haven't joined yet. You can also ask your question on discourse.julialang.org.","category":"section"},{"location":"contributing/#How-can-I-file-an-issue?","page":"Contributing to Manopt.jl","title":"How can I file an issue?","text":"If you found a bug or want to propose a feature, please open an issue in within the GitHub repository.","category":"section"},{"location":"contributing/#How-can-I-contribute?","page":"Contributing to Manopt.jl","title":"How can I contribute?","text":"","category":"section"},{"location":"contributing/#Add-a-missing-method","page":"Contributing to Manopt.jl","title":"Add a missing method","text":"There is still a lot of methods that can be contributed within the optimization framework of Manopt.jl, may it be functions, gradients, differentials, proximal maps, step size rules or stopping criteria. If you notice a method you could contribute or improve an implementation, please do so, and the maintainers try help with the necessary details. Even providing a single new method is a good contribution.","category":"section"},{"location":"contributing/#Provide-a-new-algorithm","page":"Contributing to Manopt.jl","title":"Provide a new algorithm","text":"A main contribution you can provide is another algorithm that is not yet included in the package. An algorithm is always based on a concrete type of a AbstractManoptProblem storing the main information of the task and a concrete type of an AbstractManoptSolverState storing all information that needs to be known to the solver in general. The actual algorithm is split into an initialization phase, see initialize_solver!, and the implementation of the ith step of the solver itself, see  before the iterative procedure, see step_solver!. For these two functions, it would be great if a new algorithm uses functions from the ManifoldsBase.jl interface as generically as possible. For example, if possible use retract!(M,q,p,X) in favor of exp!(M,q,p,X) to perform a step starting in p in direction X (in place of q), since the exponential map might be too expensive to evaluate or might not be available on a certain manifold. See Retractions and inverse retractions for more details. Further, if possible, prefer retract!(M,q,p,X) in favor of retract(M,p,X), since a computation in place of a suitable variable q reduces memory allocations.\n\nUsually, the methods implemented in Manopt.jl also have a high-level interface, that is easier to call, creates the necessary problem and options structure and calls the solver.\n\nThe two technical functions initialize_solver! and step_solver! should be documented with technical details, while the high level interface should usually provide a general description and some literature references to the algorithm at hand.","category":"section"},{"location":"contributing/#Provide-a-new-example","page":"Contributing to Manopt.jl","title":"Provide a new example","text":"Example problems are available at ManoptExamples.jl, where also their reproducible Quarto-Markdown files are stored.","category":"section"},{"location":"contributing/#Code-style","page":"Contributing to Manopt.jl","title":"Code style","text":"Try to follow the documentation guidelines from the Julia documentation as well as oriented on Blue Style. Manopt.jl uses Runic.jl for code formatting.\n\nPlease follow a few internal conventions:\n\nIt is preferred that any subtype of a AbstractManoptProblem's struct contains information about the general structure of the problem.\nAny implemented function should be accompanied by its mathematical formulae if a closed form exists.\nAbstractManoptProblem and helping functions are stored within the plan/ folder and sorted by properties of the problem and/or solver at hand.\nthe solver state is usually stored with the solver itself\nWithin the source code of one algorithm, following the state, the high level interface should be next, then the initialization, then the step.\nOtherwise an alphabetical order of functions is preferable.\nThe preceding implies that the mutating variant of a function follows the non-mutating variant.\nAlways add a newline between things of different types (struct/method/const).\nAlways add a newline between methods for different functions (including mutating/nonmutating variants).\nPrefer to have no newline between methods for the same function; when reasonable, merge the documentation strings. You can also define a string for the common documentation and interpolate it in the docstrings of the methods.\nAll import/using/include should be in the main module file.","category":"section"},{"location":"contributing/#Concerning-the-documentation","page":"Contributing to Manopt.jl","title":"Concerning the documentation","text":"if possible provide both mathematical formulae and literature references using DocumenterCitations.jl and BibTeX where possible\nAlways document all input variables, positional arguments with their defaults, and keyword arguments also with their types and default values.\nif applicable, use DocumenterInterlinks.jl when mentioning functions from other packages in the documentation. If you add a reference to a function from a new package, maybe consider adapting the CSS as well to prefix the links with the package logo.\nWrite a short entry in the Changelog.md to document your changes.\n\nIf you implement a new feature, a tutorial how to use it would be appreciated as well. Tutorials are written as Quarto documents and stored in the tutorials/ folder. This is rendered automatically into the documentation page, you just have to add a menu entry within the tutorial sub menu.\n\nIf you implement an algorithm with a certain numerical example in mind, it would be great, if this could be added to the ManoptExamples.jl package as well.","category":"section"},{"location":"contributing/#Spell-checking","page":"Contributing to Manopt.jl","title":"Spell checking","text":"We use crate-ci/typos for spell checking, which is run automatically on GitHub Actions, but you can also run it locally using their command line tool.","category":"section"},{"location":"contributing/#On-the-use-of-AI","page":"Contributing to Manopt.jl","title":"On the use of AI","text":"Following the Julia Discourse Guidelines â€“ Keep it tidy, please do not open PRs or issues that are pure AI generated. Manopt.jl is in its aspects, especially the code, the documentation, as well as the tests, carefully curated to be concise, well-documented, comprehensive, but in tests also in a (hopefully) good balance between ensuring functionality and â€œover testingâ€.\n\nOf course it is ok to get help from an AI, e.g. when refactoring parts of the code, but please always carefully reflect on the results proposed and do not â€œvibe codeâ€. That usually does not work well nor fit the exact mathematical definitions, reliability and stability as well as and abstractions of the provided algorithms Manopt.jl aims to provide.","category":"section"},{"location":"helpers/checks/#Verifying-gradients-and-Hessians","page":"Checks","title":"Verifying gradients and Hessians","text":"If you have computed a gradient or differential and you are not sure whether it is correct.","category":"section"},{"location":"helpers/checks/#Literature","page":"Checks","title":"Literature","text":"N.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\n","category":"section"},{"location":"helpers/checks/#Manopt.check_Hessian","page":"Checks","title":"Manopt.check_Hessian","text":"check_Hessian(M, f, grad_f, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M, vector_at=p); kwargs...)\n\nVerify numerically whether the Hessian Hess_f(M,p, X) of f(M,p) is correct.\n\nFor this either a second-order retraction or a critical point p of f is required. The approximation is then\n\nf(operatornameretr_p(tX)) = f(p) + toperatornamegrad f(p) X + fract^22operatornameHessf(p)X X + mathcalO(t^3)\n\nor in other words, that the error between the function f and its second order Taylor behaves in error mathcalO(t^3), which indicates that the Hessian is correct, cf. also [Bou23, Section 6.8].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot is generated.\n\nKeyword arguments\n\ncheck_grad=true: verify that operatornamegradf(p)  T_pmathcalM.\ncheck_linearity=true: verify that the Hessian is linear, see is_Hessian_linear using a, b, X, and Y\ncheck_symmetry=true: verify that the Hessian is symmetric, see is_Hessian_symmetric\ncheck_vector=false: verify that \\operatorname{Hess} f(p)[X] âˆˆ T_{p}\\mathcal{M}usingis_vector`.\nmode=:Default: specify the mode for the verification; the default assumption is, that the retraction provided is of second order. Otherwise one can also verify the Hessian if the point p is a critical point. THen set the mode to :CritalPoint to use gradient_descent to find a critical point. Note: this requires (and evaluates) new tangent vectors X and Y\natol, rtol:      (same defaults as isapprox) tolerances that are passed down to all checks\na, b            two real values to verify linearity of the Hessian (if check_linearity=true)\nN=101: number of points to verify within the log_range default range 10^-810^0\nexactness_tol=1e-12: if all errors are below this tolerance, the verification is considered to be exact\nio=nothing: provide an IO to print the result to\ngradient=grad_f(M, p): instead of the gradient function you can also provide the gradient at p directly\nHessian=Hess_f(M, p, X): instead of the Hessian function you can provide the result of operatornameHess f(p)X directly. Note that evaluations of the Hessian might still be necessary for checking linearity and symmetry and/or when using :CriticalPoint mode.\nlimits=(-8.0, 0.0): specify the limits in the log_range\nlog_range=range(limits[1], limits[2]; length=N): specify the range of points (in log scale) to sample the Hessian line\nN=101: number of points to use within the log_range default range 10^-810^0\nplot=false: whether to plot the resulting verification (requires Plots.jl to be loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nslope_tol=0.1: tolerance for the slope (global) of the approximation\nerror=:none: how to handle errors, possible values: :error, :info, :warn\nwindow=nothing: specify window sizes within the log_range that are used for the slope estimation. the default is, to use all window sizes 2:N.\n\nThe kwargs... are also passed down to the check_vector and the check_gradient call, such that tolerances can easily be set.\n\nWhile check_vector is also passed to the inner call to check_gradient as well as the retraction_method, this inner check_gradient is meant to be just for inner verification, so it does not throw an error nor produce a plot itself.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.check_differential","page":"Checks","title":"Manopt.check_differential","text":"check_differential(M, F, dF, p=rand(M), X=rand(M; vector_at=p); kwargs...)\n\nCheck numerically whether the differential dF(M,p,X) of F(M,p) is correct.\n\nThis implements the method described in [Bou23, Section 4.8].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot is generated,\n\nKeyword arguments\n\nexactness_tol=1e-12: if all errors are below this tolerance, the differential is considered to be exact\nio=nothing: provide an IO to print the result to\nlimits=(-8.0, 0.0): specify the limits in the log_range\nlog_range=range(limits[1], limits[2]; length=N): specify the range of points (in log scale) to sample the differential line\nN=101: number of points to verify within the log_range default range 10^-810^0\nname=\"differential\": name to display in the plot\nplot=false: whether to plot the result (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nslope_tol=0.1: tolerance for the slope (global) of the approximation\nthrow_error=false: throw an error message if the differential is wrong\nwindow=nothing: specify window sizes within the log_range that are used for the slope estimation. The default is, to use all window sizes 2:N.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.check_gradient","page":"Checks","title":"Manopt.check_gradient","text":"check_gradient(M, f, grad_f, p=rand(M), X=rand(M; vector_at=p); kwargs...)\n\nVerify numerically whether the gradient grad_f(M,p) of f(M,p) is correct, that is whether\n\nf(operatornameretr_p(tX)) = f(p) + toperatornamegrad f(p) X + mathcalO(t^2)\n\nor in other words, that the error between the function f and its first order Taylor behaves in error mathcalO(t^2), which indicates that the gradient is correct, cf. also [Bou23, Section 4.8].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot is generated.\n\nKeyword arguments\n\ncheck_vector=true: verify that operatornamegradf(p)  T_pmathcalM using is_vector.\nexactness_tol=1e-12: if all errors are below this tolerance, the gradient is considered to be exact\nio=nothing: provide an IO to print the result to\ngradient=grad_f(M, p): instead of the gradient function you can also provide the gradient at p directly\nlimits=(-8.0, 0.0): specify the limits in the log_range\nlog_range=range(limits[1], limits[2]; length=N):\nspecify the range of points (in log scale) to sample the gradient line\nN=101: number of points to verify within the log_range default range 10^-810^0\nplot=false: whether to plot the result (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nslope_tol=0.1: tolerance for the slope (global) of the approximation\natol, rtol: (same defaults as isapprox) tolerances that are passed down to is_vector if check_vector is set to true\nerror=:none: how to handle errors, possible values: :error, :info, :warn\nwindow=nothing: specify window sizes within the log_range that are used for the slope estimation. the default is, to use all window sizes 2:N.\n\nThe remaining keyword arguments are also passed down to the check_vector call, such that tolerances can easily be set.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.is_Hessian_linear","page":"Checks","title":"Manopt.is_Hessian_linear","text":"is_Hessian_linear(M, Hess_f, p,\n    X=rand(M; vector_at=p), Y=rand(M; vector_at=p), a=randn(), b=randn();\n    error=:none, io=nothing, kwargs...\n)\n\nVerify whether the Hessian function Hess_f fulfills linearity,\n\noperatornameHess f(p)aX + bY = boperatornameHess f(p)X\n + boperatornameHess f(p)Y\n\nwhich is checked using isapprox and the keyword arguments are passed to this function.\n\nOptional arguments\n\nerror=:none: how to handle errors, possible values: :error, :info, :warn\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.is_Hessian_symmetric","page":"Checks","title":"Manopt.is_Hessian_symmetric","text":"is_Hessian_symmetric(M, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M; vector_at=p);\nerror=:none, io=nothing, atol::Real=0, rtol::Real=atol>0 ? 0 : âˆšeps\n\n)\n\nVerify whether the Hessian function Hess_f fulfills symmetry, which means that\n\noperatornameHess f(p)X Y = X operatornameHess f(p)Y\n\nwhich is checked using isapprox and the kwargs... are passed to this function.\n\nOptional arguments\n\natol, rtol   with the same defaults as the usual isapprox\nerror=:none: how to handle errors, possible values: :error, :info, :warn\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Difference-of-convex","page":"Difference of Convex","title":"Difference of convex","text":"","category":"section"},{"location":"solvers/difference_of_convex/#solver-difference-of-convex","page":"Difference of Convex","title":"Difference of convex algorithm","text":"","category":"section"},{"location":"solvers/difference_of_convex/#solver-difference-of-convex-proximal-point","page":"Difference of Convex","title":"Difference of convex proximal point","text":"","category":"section"},{"location":"solvers/difference_of_convex/#Solver-states","page":"Difference of Convex","title":"Solver states","text":"","category":"section"},{"location":"solvers/difference_of_convex/#The-difference-of-convex-objective","page":"Difference of Convex","title":"The difference of convex objective","text":"as well as for the corresponding sub problem\n\nas well as for the corresponding sub problems","category":"section"},{"location":"solvers/difference_of_convex/#Helper-functions","page":"Difference of Convex","title":"Helper functions","text":"","category":"section"},{"location":"solvers/difference_of_convex/#sec-cp-technical-details","page":"Difference of Convex","title":"Technical details","text":"The difference_of_convex_algorithm and difference_of_convex_proximal_point solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= or retraction_method_dual= (for mathcal N) does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified.\n\nBy default, one of the stopping criteria is StopWhenChangeLess, which either requires\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= or retraction_method_dual= (for mathcal N) does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.\nA copyto!(M, q, p) and copy(M,p) for points.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).\neverything the subsolver requires, which by default is the trust_regions or if you do not provide a Hessian gradient_descent.","category":"section"},{"location":"solvers/difference_of_convex/#Literature","page":"Difference of Convex","title":"Literature","text":"Y.Â T.Â Almeida, J.Â X.Â Cruz Neto, P.Â R.Â Oliveira and J.Â C.Â Oliveira Souza. A modified proximal point method for DC functions on Hadamard manifolds. ComputationalÂ OptimizationÂ andÂ Applications 76, 649â€“673 (2020).\n\n\n\nR.Â Bergmann, O.Â P.Â Ferreira, E.Â M.Â Santos and J.Â C.Â Souza. The difference of convex algorithm on Hadamard manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications (2024).\n\n\n\nJ.Â C.Â Souza and P.Â R.Â Oliveira. A proximal point algorithm for DC functions on Hadamard manifolds. JournalÂ ofÂ GlobalÂ Optimization 63, 797â€“810 (2015).\n\n\n\n","category":"section"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm","page":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm","text":"difference_of_convex_algorithm(M, f, g, âˆ‚h, p=rand(M); kwargs...)\ndifference_of_convex_algorithm(M, mdco, p; kwargs...)\ndifference_of_convex_algorithm!(M, f, g, âˆ‚h, p; kwargs...)\ndifference_of_convex_algorithm!(M, mdco, p; kwargs...)\n\nCompute the difference of convex algorithm [BFSS24] to minimize\n\n    operatorname*argmin_pmathcalM) g(p) - h(p)\n\nwhere you need to provide f(p) = g(p) - h(p), g and the subdifferential h of h.\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nTake X^(k)   h(p^(k))\nSet the next iterate to the solution of the subproblem\n\n  p^(k+1)  operatorname*argmin_q  mathcalM) g(q) - X^(k) log_p^(k)q\n\nuntil the stopping criterion (see the stopping_criterion keyword is fulfilled.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v total cost function f = g - h\ng: the smooth part g of the cost function\nâˆ‚h: the subgradient h mathcalM  TmathcalM of h as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing:        specify operatornamegrad f, for debug / analysis or enhancing the stopping_criterion=\ngrad_g=nothing:          specify the gradient of g. If specified, a subsolver is automatically set up.\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled\ng=nothing:               specify the function g If specified, a subsolver is automatically set up.\nsub_cost=LinearizedDCCost(g, p, initial_vector): a cost to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=LinearizedDCGrad(grad_g, p, initial_vector; evaluation=evaluation): gradient to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_state::Union{AbstractManoptProblem, F} = ([GradientDescentState](@ref) or [TrustRegionsState](@ref) ifsub_hessis provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_stopping_criterion=StopAfterIteration(300)|StopWhenStepsizeLess(1e-9)|StopWhenGradientNormLess(1e-9): a stopping criterion used within the default sub_state= This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_stepsize=ArmijoLinesearch(M)) specify a step size used within the sub_state. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm!","page":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm!","text":"difference_of_convex_algorithm(M, f, g, âˆ‚h, p=rand(M); kwargs...)\ndifference_of_convex_algorithm(M, mdco, p; kwargs...)\ndifference_of_convex_algorithm!(M, f, g, âˆ‚h, p; kwargs...)\ndifference_of_convex_algorithm!(M, mdco, p; kwargs...)\n\nCompute the difference of convex algorithm [BFSS24] to minimize\n\n    operatorname*argmin_pmathcalM) g(p) - h(p)\n\nwhere you need to provide f(p) = g(p) - h(p), g and the subdifferential h of h.\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nTake X^(k)   h(p^(k))\nSet the next iterate to the solution of the subproblem\n\n  p^(k+1)  operatorname*argmin_q  mathcalM) g(q) - X^(k) log_p^(k)q\n\nuntil the stopping criterion (see the stopping_criterion keyword is fulfilled.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v total cost function f = g - h\ng: the smooth part g of the cost function\nâˆ‚h: the subgradient h mathcalM  TmathcalM of h as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing:        specify operatornamegrad f, for debug / analysis or enhancing the stopping_criterion=\ngrad_g=nothing:          specify the gradient of g. If specified, a subsolver is automatically set up.\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled\ng=nothing:               specify the function g If specified, a subsolver is automatically set up.\nsub_cost=LinearizedDCCost(g, p, initial_vector): a cost to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=LinearizedDCGrad(grad_g, p, initial_vector; evaluation=evaluation): gradient to be used within the default sub_problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_state::Union{AbstractManoptProblem, F} = ([GradientDescentState](@ref) or [TrustRegionsState](@ref) ifsub_hessis provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_stopping_criterion=StopAfterIteration(300)|StopWhenStepsizeLess(1e-9)|StopWhenGradientNormLess(1e-9): a stopping criterion used within the default sub_state= This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_stepsize=ArmijoLinesearch(M)) specify a step size used within the sub_state. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point","page":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point","text":"difference_of_convex_proximal_point(M, grad_h, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point(M, mdcpo, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point!(M, grad_h, p; kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, p; kwargs...)\n\nCompute the difference of convex proximal point algorithm [SO15] to minimize\n\n    operatorname*argmin_pmathcalMnifold))) g(p) - h(p)\n\nwhere you have to provide the subgradient h of h and either\n\nthe proximal map operatornameprox_Î»g of g as a function prox_g(M, Î», p) or  prox_g(M, q, Î», p)\nthe functions g and grad_g to compute the proximal map using a sub solver\nyour own sub-solver, specified by sub_problem=and sub_state=\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nX^(k)   operatornamegrad h(p^(k))\nq^(k) = operatornameretr_p^(k)(Î»_kX^(k))\nr^(k) = operatornameprox_Î»_kg(q^(k))\nX^(k) = operatornameretr^-1_p^(k)(r^(k))\nCompute a stepsize s_k and\nset p^(k+1) = operatornameretr_p^(k)(s_kX^(k)).\n\nuntil the stopping_criterion is fulfilled.\n\nSee [ACOO20] for more details on the modified variant, where steps 4-6 are slightly changed, since here the classical proximal point method for DC functions is obtained for s_k = 1 and one can hence employ usual line search method.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v total cost function f = g - h\ngrad_h: the (Riemannian) gradient operatornamegradh mathcalM  T_pmathcalM of h as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nÎ»:                          ( k -> 1/2 ) a function returning the sequence of prox parameters Î»_k\ncost=nothing: provide the cost f, for debug reasons / analysis\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing: specify operatornamegrad f, for debug / analysis  or enhancing the stopping_criterion\nprox_g=nothing: specify a proximal map for the sub problem or both of the following\ng=nothing: specify the function g.\ngrad_g=nothing: specify the gradient of g. If both gand grad_g are specified, a subsolver is automatically set up.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=ConstantLength(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled A StopWhenGradientNormLess(1e-8) is added with |, when a gradient is provided.\nsub_cost=ProximalDCCost(g, copy(M, p), Î»(1))): cost to be used within the default sub_problem that is initialized as soon as g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=ProximalDCGrad(grad_g, copy(M, p), Î»(1); evaluation=evaluation): gradient to be used within the default sub_problem, that is initialized as soon as grad_g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} = ([GradientDescentState](@ref) or [TrustRegionsState](@ref) ifsub_hessis provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_stopping_criterion::StoppingCriterion= (StopAfterIteration(300)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point!","page":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point!","text":"difference_of_convex_proximal_point(M, grad_h, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point(M, mdcpo, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point!(M, grad_h, p; kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, p; kwargs...)\n\nCompute the difference of convex proximal point algorithm [SO15] to minimize\n\n    operatorname*argmin_pmathcalMnifold))) g(p) - h(p)\n\nwhere you have to provide the subgradient h of h and either\n\nthe proximal map operatornameprox_Î»g of g as a function prox_g(M, Î», p) or  prox_g(M, q, Î», p)\nthe functions g and grad_g to compute the proximal map using a sub solver\nyour own sub-solver, specified by sub_problem=and sub_state=\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01\n\nX^(k)   operatornamegrad h(p^(k))\nq^(k) = operatornameretr_p^(k)(Î»_kX^(k))\nr^(k) = operatornameprox_Î»_kg(q^(k))\nX^(k) = operatornameretr^-1_p^(k)(r^(k))\nCompute a stepsize s_k and\nset p^(k+1) = operatornameretr_p^(k)(s_kX^(k)).\n\nuntil the stopping_criterion is fulfilled.\n\nSee [ACOO20] for more details on the modified variant, where steps 4-6 are slightly changed, since here the classical proximal point method for DC functions is obtained for s_k = 1 and one can hence employ usual line search method.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v total cost function f = g - h\ngrad_h: the (Riemannian) gradient operatornamegradh mathcalM  T_pmathcalM of h as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nÎ»:                          ( k -> 1/2 ) a function returning the sequence of prox parameters Î»_k\ncost=nothing: provide the cost f, for debug reasons / analysis\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ngradient=nothing: specify operatornamegrad f, for debug / analysis  or enhancing the stopping_criterion\nprox_g=nothing: specify a proximal map for the sub problem or both of the following\ng=nothing: specify the function g.\ngrad_g=nothing: specify the gradient of g. If both gand grad_g are specified, a subsolver is automatically set up.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=ConstantLength(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled A StopWhenGradientNormLess(1e-8) is added with |, when a gradient is provided.\nsub_cost=ProximalDCCost(g, copy(M, p), Î»(1))): cost to be used within the default sub_problem that is initialized as soon as g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=ProximalDCGrad(grad_g, copy(M, p), Î»(1); evaluation=evaluation): gradient to be used within the default sub_problem, that is initialized as soon as grad_g is provided. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_hess:              (a finite difference approximation using sub_grad by default):  specify a Hessian of the sub_cost, which the default solver, see sub_state= needs.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective:         a gradient or Hessian objective based on sub_cost=, sub_grad=, and sub_hessif provided  the objective used within sub_problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} = ([GradientDescentState](@ref) or [TrustRegionsState](@ref) ifsub_hessis provided):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_stopping_criterion::StoppingCriterion= (StopAfterIteration(300)|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.DifferenceOfConvexState","page":"Difference of Convex","title":"Manopt.DifferenceOfConvexState","text":"DifferenceOfConvexState{Pr,St,P,T,SC<:StoppingCriterion} <:\n           AbstractManoptSolverState\n\nA struct to store the current state of the [difference_of_convex_algorithm])(@ref). It comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\nX::T: a tangent vector at the point p on the manifold mathcalM storing a subgradient at the current iterate\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nThe sub task consists of a method to solve\n\n    operatorname*argmin_qmathcalMnifold))) g(p) - X log_p q\n\nis needed. Besides a problem and a state, one can also provide a function and an AbstractEvaluationType, respectively, to indicate a closed form solution for the sub task.\n\nConstructors\n\nDifferenceOfConvexState(M, sub_problem, sub_state; kwargs...)\nDifferenceOfConvexState(M, sub_solver; evaluation=InplaceEvaluation(), kwargs...)\n\nGenerate the state either using a solver from Manopt, given by an AbstractManoptProblem sub_problem and an AbstractManoptSolverState sub_state, or a closed form solution sub_solver for the sub-problem the function expected to be of the form (M, p, X) -> q or (M, q, p, X) -> q, where by default its AbstractEvaluationType evaluation is in-place of q. Here the elements passed are the current iterate p and the subgradient X of h can be passed to that function.\n\nfurther keyword arguments\n\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstopping_criterion::StoppingCriterion=StopAfterIteration(200): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.DifferenceOfConvexProximalState","page":"Difference of Convex","title":"Manopt.DifferenceOfConvexProximalState","text":"DifferenceOfConvexProximalState{P, T, Pr, St, S<:Stepsize, SC<:StoppingCriterion, RTR<:AbstractRetractionMethod, ITR<:AbstractInverseRetractionMethod}\n    <: AbstractSubProblemSolverState\n\nA struct to store the current state of the algorithm as well as the form. It comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np::P: a point on the manifold mathcalM  storing the current iterate\nq::P: a point on the manifold mathcalM\n\nstoring the gradient step\n\nr::P: a point on the manifold mathcalM storing the result of the proximal map\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nX, Y: the current gradient and descent direction, respectively their common type is set by the keyword X\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nConstructor\n\nDifferenceOfConvexProximalState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\n\nconstruct an difference of convex proximal point state\n\nDifferenceOfConvexProximalState(M::AbstractManifold, sub_problem;\n    evaluation=AllocatingEvaluation(), kwargs...\n\n)\n\nconstruct an difference of convex proximal point state, where sub_problem is a closed form solution with evaluation as type of evaluation.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=ConstantLength(): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopWhenChangeLess`(1e-8): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexObjective","page":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexObjective","text":"ManifoldDifferenceOfConvexObjective{E} <: AbstractManifoldCostObjective{E}\n\nSpecify an objective for a difference_of_convex_algorithm.\n\nThe objective f mathcalMnifold)))  â„ is given as\n\n    f(p) = g(p) - h(p)\n\nwhere both g and h are convex, lower semicontinuous and proper. Furthermore the subdifferential h of h is required.\n\nFields\n\ncost: an implementation of f(p) = g(p)-h(p) as a function f(M,p).\nâˆ‚h!!: a deterministic version of h mathcalM TmathcalM), in the sense that calling âˆ‚h(M, p) returns a subgradient of h at p and if there is more than one, it returns a deterministic choice.\n\nNote that the subdifferential might be given in two possible signatures\n\nâˆ‚h(M,p) which does an AllocatingEvaluation\nâˆ‚h!(M, X, p) which does an InplaceEvaluation in place of X.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.LinearizedDCCost","page":"Difference of Convex","title":"Manopt.LinearizedDCCost","text":"LinearizedDCCost\n\nA functor (M,q) â†’ â„ to represent the inner problem of a ManifoldDifferenceOfConvexObjective. This is a cost function of the form\n\n    F_p_kX_k(p) = g(p) - X_k log_p_kp\n\nfor a point p_k and a tangent vector X_k at p_k (for example outer iterates) that are stored within this functor as well.\n\nFields\n\ng a function\npk a point on a manifold\nXk a tangent vector at pk\n\nBoth interim values can be set using set_parameter!(::LinearizedDCCost, ::Val{:p}, p) and set_parameter!(::LinearizedDCCost, ::Val{:X}, X), respectively.\n\nConstructor\n\nLinearizedDCCost(g, p, X)\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.LinearizedDCGrad","page":"Difference of Convex","title":"Manopt.LinearizedDCGrad","text":"LinearizedDCGrad\n\nA functor (M,X,p) â†’ â„ to represent the gradient of the inner problem of a ManifoldDifferenceOfConvexObjective. This is a gradient function of the form\n\n    F_p_kX_k(p) = g(p) - X_k log_p_kp\n\nits gradient is given by using F=F_1(F_2(p)), where F_1(X) = X_kX and F_2(p) = log_p_kp and the chain rule as well as the adjoint differential of the logarithmic map with respect to its argument for D^*F_2(p)\n\n    operatornamegrad F(q) = operatornamegradf(q) - DF_2^*(q)X\n\nfor a point pk and a tangent vector Xk at pk (the outer iterates) that are stored within this functor as well\n\nFields\n\ngrad_g!! the gradient of g (see also LinearizedDCCost)\npk a point on a manifold\nXk a tangent vector at pk\n\nBoth interim values can be set using set_parameter!(::LinearizedDCGrad, ::Val{:p}, p) and set_parameter!(::LinearizedDCGrad, ::Val{:X}, X), respectively.\n\nConstructor\n\nLinearizedDCGrad(grad_g, p, X; evaluation=AllocatingEvaluation())\n\nWhere you specify whether grad_g is AllocatingEvaluation or InplaceEvaluation, while this function still provides both signatures.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexProximalObjective","page":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexProximalObjective","text":"ManifoldDifferenceOfConvexProximalObjective{E} <: Problem\n\nSpecify an objective difference_of_convex_proximal_point algorithm. The problem is of the form\n\n    operatorname*argmin_pmathcalM g(p) - h(p)\n\nwhere both g and h are convex, lower semicontinuous and proper.\n\nFields\n\ncost:     implementation of f(p) = g(p)-h(p)\ngradient: the gradient of the cost\ngrad_h!!: a function operatornamegradh mathcalM)  TmathcalM),\n\nNote that both the gradients might be given in two possible signatures as allocating or in-place.\n\nConstructor\n\nManifoldDifferenceOfConvexProximalObjective(gradh; cost=nothing, gradient=nothing)\n\nan note that neither cost nor gradient are required for the algorithm, just for eventual debug or stopping criteria.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.ProximalDCCost","page":"Difference of Convex","title":"Manopt.ProximalDCCost","text":"ProximalDCCost\n\nA functor (M, p) â†’ â„ to represent the inner cost function of a ManifoldDifferenceOfConvexProximalObjective. This is the cost function of the proximal map of g.\n\n    F_p_k(p) = frac12Î»d_mathcalM)(p_kp)^2 + g(p)\n\nfor a point pk and a proximal parameter Î».\n\nFields\n\ng  - a function\npk - a point on a manifold\nÎ»  - the prox parameter\n\nBoth interim values can be set using set_parameter!(::ProximalDCCost, ::Val{:p}, p) and set_parameter!(::ProximalDCCost, ::Val{:Î»}, Î»), respectively.\n\nConstructor\n\nProximalDCCost(g, p, Î»)\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.ProximalDCGrad","page":"Difference of Convex","title":"Manopt.ProximalDCGrad","text":"ProximalDCGrad\n\nA functor (M,X,p) â†’ â„ to represent the gradient of the inner cost function of a ManifoldDifferenceOfConvexProximalObjective. This is the gradient function of the proximal map cost function of g. Based on\n\n    F_p_k(p) = frac12Î»d_mathcalM)(p_kp)^2 + g(p)\n\nit reads\n\n    operatornamegrad F_p_k(p) = operatornamegrad g(p) - frac1Î»log_p p_k\n\nfor a point pk and a proximal parameter Î».\n\nFields\n\ngrad_g  - a gradient function\npk - a point on a manifold\nÎ»  - the prox parameter\n\nBoth interim values can be set using set_parameter!(::ProximalDCGrad, ::Val{:p}, p) and set_parameter!(::ProximalDCGrad, ::Val{:Î»}, Î»), respectively.\n\nConstructor\n\nProximalDCGrad(grad_g, pk, Î»; evaluation=AllocatingEvaluation())\n\nWhere you specify whether grad_g is AllocatingEvaluation or InplaceEvaluation, while this function still always provides both signatures.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.get_subtrahend_gradient","page":"Difference of Convex","title":"Manopt.get_subtrahend_gradient","text":"X = get_subtrahend_gradient(amp, q)\nget_subtrahend_gradient!(amp, X, q)\n\nEvaluate the (sub)gradient of the subtrahend h from within a ManifoldDifferenceOfConvexObjective amp at the point q (in place of X).\n\nThe evaluation is done in place of X for the !-variant. The T=AllocatingEvaluation problem might still allocate memory within. When the non-mutating variant is called with a T=InplaceEvaluation memory for the result is allocated.\n\n\n\n\n\nX = get_subtrahend_gradient(M::AbstractManifold, dcpo::ManifoldDifferenceOfConvexProximalObjective, p)\nget_subtrahend_gradient!(M::AbstractManifold, X, dcpo::ManifoldDifferenceOfConvexProximalObjective, p)\n\nEvaluate the gradient of the subtrahend h from within a ManifoldDifferenceOfConvexProximalObjectivePat the pointp` (in place of X).\n\n\n\n\n\n","category":"function"},{"location":"solvers/interior_point_Newton/#Interior-point-Newton-method","page":"Interior Point Newton","title":"Interior point Newton method","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#State","page":"Interior Point Newton","title":"State","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Subproblem-functions","page":"Interior Point Newton","title":"Subproblem functions","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Helpers","page":"Interior Point Newton","title":"Helpers","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#Additional-stopping-criteria","page":"Interior Point Newton","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/interior_point_Newton/#References","page":"Interior Point Newton","title":"References","text":"A.Â S.Â El-Bakry, R.Â A.Â Tapia, T.Â Tsuchiya and Y.Â Zhang. On the formulation and theory of the Newton interior-point method for nonlinear programming. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 89, 507â€“541 (1996).\n\n\n\nZ.Â Lai and A.Â Yoshise. Riemannian Interior Point Methods for Constrained Optimization on Manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 201, 433â€“469 (2024), arXiv:2203.09762.\n\n\n\n","category":"section"},{"location":"solvers/interior_point_Newton/#Manopt.interior_point_Newton","page":"Interior Point Newton","title":"Manopt.interior_point_Newton","text":"interior_point_Newton(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ninterior_point_Newton(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\ninterior_point_Newton!(M, f, grad]_f, Hess_f, p; kwargs...)\ninterior_point_Newton(M, ConstrainedManifoldObjective, p; kwargs...)\n\nperform the interior point Newton method following [LY24].\n\nIn order to solve the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nThis algorithms iteratively solves the linear system based on extending the KKT system by a slack variable s.\n\n  operatornameJ F(p Î¼ Î» s)X Y Z W = -F(p Î¼ Î» s)\n  text where \n  X  T_pmathcalM YW  â„^m Z  â„^n\n\nsee CondensedKKTVectorFieldJacobian and CondensedKKTVectorField, respectively, for the reduced form, this is usually solved in. From the resulting X and Z in the reduced form, the other two, Y, W, are then computed.\n\nFrom the gradient (XYZW) at the current iterate (p Î¼ Î» s), a line search is performed using the KKTVectorFieldNormSq norm of the KKT vector field (squared) and its gradient KKTVectorFieldNormSqGradient together with the InteriorPointCentralityCondition.\n\nNote that since the vector field F includes the gradients of the constraint functions g h, its gradient or Jacobian requires the Hessians of the constraints.\n\nFor that search direction a line search is performed, that additionally ensures that the constraints are further fulfilled.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\n\nor a ConstrainedManifoldObjective cmo containing f, grad_f, Hess_f, and the constraints\n\nKeyword arguments\n\nThe keyword arguments related to the constraints (the first eleven) are ignored if you pass a ConstrainedManifoldObjective cmo\n\ncentrality_condition=missing; an additional condition when to accept a step size. This can be used to ensure that the resulting iterate is still an interior point if you provide a check (N,q) -> true/false, where N is the manifold of the step_problem.\nequality_constraints=nothing: the number n of equality constraints.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ng=nothing: the inequality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\ngradient_range=nothing: specify how gradients are represented, where nothing is equivalent to NestedPowerRepresentation\ngradient_equality_range=gradient_range: specify how the gradients of the equality constraints are represented\ngradient_inequality_range=gradient_range: specify how the gradients of the inequality constraints are represented\nh=nothing: the equality constraints\nHess_g=nothing: the Hessian of the inequality constraints\nHess_h=nothing: the Hessian of the equality constraints\ninequality_constraints=nothing: the number m of inequality constraints.\nÎ»=ones(length(h(M, p))): the Lagrange multiplier with respect to the equality constraints h\nÎ¼=ones(length(g(M, p))): the Lagrange multiplier with respect to the inequality constraints g\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nÏ=Î¼'s / length(Î¼):  store the orthogonality Î¼'s/m to compute the barrier parameter Î² in the sub problem.\ns=copy(Î¼): initial value for the slack variables\nÏƒ=calculate_Ïƒ(M, cmo, p, Î¼, Î», s):  scaling factor for the barrier parameter Î² in the sub problem, which is updated during the iterations\nstep_objective: a ManifoldGradientObjective of the norm of the KKT vector field KKTVectorFieldNormSq and its gradient KKTVectorFieldNormSqGradient\nstep_problem: the manifold mathcalMnifold)))  â„^m  â„^n  â„^m together with the step_objective as the problem the linesearch stepsize= employs for determining a step size\nstep_state: the StepsizeState with point and search direction\nstepsize::Stepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size with the centrality_condition keyword as additional criterion to accept a step, if this is provided\"))\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenKKTResidualLess(1e-8): a functor indicating that the stopping criterion is fulfilled a stopping criterion, by default depending on the residual of the KKT vector field or a maximal number of steps, which ever hits first.\nsub_kwargs=(;): keyword arguments to decorate the sub options, for example debug, that automatically respects the main solvers debug options (like sub-sampling) as well\nsub_objective: The SymmetricLinearSystemObjective modelling the system of equations to use in the sub solver, includes the CondensedKKTVectorFieldJacobian mathcalA(X) and the CondensedKKTVectorField b in mathcalA(X) + b = 0 we aim to solve. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_stopping_criterion=StopAfterIteration(manifold_dimension(M))|StopWhenRelativeResidualLess(c,1e-8), where c = lVert b rVert from the system to solve. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =ConjugateResidualState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_space=Rn a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nX=zero_vector(M,p): the initial gradient with respect to p.\nY=zero(Î¼): the initial gradient with respect to Î¼\nZ=zero(Î»): the initial gradient with respect to Î»\nW=zero(s): the initial gradient with respect to s\nis_feasible_error=:error: specify how to handle infeasible starting points, see is_feasible for options.\n\nAs well as internal keywords used to set up these given keywords like _step_M, _step_p, _sub_M, _sub_p, and _sub_X, that should not be changed.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective, respectively.\n\nnote: Note\nThe centrality_condition=missing disables to check centrality during the line search, but you can pass InteriorPointCentralityCondition(cmo, Î³), where Î³ is a constant, to activate this check.\n\nOutput\n\nThe obtained approximate constrained minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/interior_point_Newton/#Manopt.interior_point_Newton!","page":"Interior Point Newton","title":"Manopt.interior_point_Newton!","text":"interior_point_Newton(M, f, grad_f, Hess_f, p=rand(M); kwargs...)\ninterior_point_Newton(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\ninterior_point_Newton!(M, f, grad]_f, Hess_f, p; kwargs...)\ninterior_point_Newton(M, ConstrainedManifoldObjective, p; kwargs...)\n\nperform the interior point Newton method following [LY24].\n\nIn order to solve the constrained problem\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nThis algorithms iteratively solves the linear system based on extending the KKT system by a slack variable s.\n\n  operatornameJ F(p Î¼ Î» s)X Y Z W = -F(p Î¼ Î» s)\n  text where \n  X  T_pmathcalM YW  â„^m Z  â„^n\n\nsee CondensedKKTVectorFieldJacobian and CondensedKKTVectorField, respectively, for the reduced form, this is usually solved in. From the resulting X and Z in the reduced form, the other two, Y, W, are then computed.\n\nFrom the gradient (XYZW) at the current iterate (p Î¼ Î» s), a line search is performed using the KKTVectorFieldNormSq norm of the KKT vector field (squared) and its gradient KKTVectorFieldNormSqGradient together with the InteriorPointCentralityCondition.\n\nNote that since the vector field F includes the gradients of the constraint functions g h, its gradient or Jacobian requires the Hessians of the constraints.\n\nFor that search direction a line search is performed, that additionally ensures that the constraints are further fulfilled.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\n\nor a ConstrainedManifoldObjective cmo containing f, grad_f, Hess_f, and the constraints\n\nKeyword arguments\n\nThe keyword arguments related to the constraints (the first eleven) are ignored if you pass a ConstrainedManifoldObjective cmo\n\ncentrality_condition=missing; an additional condition when to accept a step size. This can be used to ensure that the resulting iterate is still an interior point if you provide a check (N,q) -> true/false, where N is the manifold of the step_problem.\nequality_constraints=nothing: the number n of equality constraints.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ng=nothing: the inequality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\ngradient_range=nothing: specify how gradients are represented, where nothing is equivalent to NestedPowerRepresentation\ngradient_equality_range=gradient_range: specify how the gradients of the equality constraints are represented\ngradient_inequality_range=gradient_range: specify how the gradients of the inequality constraints are represented\nh=nothing: the equality constraints\nHess_g=nothing: the Hessian of the inequality constraints\nHess_h=nothing: the Hessian of the equality constraints\ninequality_constraints=nothing: the number m of inequality constraints.\nÎ»=ones(length(h(M, p))): the Lagrange multiplier with respect to the equality constraints h\nÎ¼=ones(length(g(M, p))): the Lagrange multiplier with respect to the inequality constraints g\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nÏ=Î¼'s / length(Î¼):  store the orthogonality Î¼'s/m to compute the barrier parameter Î² in the sub problem.\ns=copy(Î¼): initial value for the slack variables\nÏƒ=calculate_Ïƒ(M, cmo, p, Î¼, Î», s):  scaling factor for the barrier parameter Î² in the sub problem, which is updated during the iterations\nstep_objective: a ManifoldGradientObjective of the norm of the KKT vector field KKTVectorFieldNormSq and its gradient KKTVectorFieldNormSqGradient\nstep_problem: the manifold mathcalMnifold)))  â„^m  â„^n  â„^m together with the step_objective as the problem the linesearch stepsize= employs for determining a step size\nstep_state: the StepsizeState with point and search direction\nstepsize::Stepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size with the centrality_condition keyword as additional criterion to accept a step, if this is provided\"))\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenKKTResidualLess(1e-8): a functor indicating that the stopping criterion is fulfilled a stopping criterion, by default depending on the residual of the KKT vector field or a maximal number of steps, which ever hits first.\nsub_kwargs=(;): keyword arguments to decorate the sub options, for example debug, that automatically respects the main solvers debug options (like sub-sampling) as well\nsub_objective: The SymmetricLinearSystemObjective modelling the system of equations to use in the sub solver, includes the CondensedKKTVectorFieldJacobian mathcalA(X) and the CondensedKKTVectorField b in mathcalA(X) + b = 0 we aim to solve. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_stopping_criterion=StopAfterIteration(manifold_dimension(M))|StopWhenRelativeResidualLess(c,1e-8), where c = lVert b rVert from the system to solve. This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =ConjugateResidualState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_space=Rn a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nX=zero_vector(M,p): the initial gradient with respect to p.\nY=zero(Î¼): the initial gradient with respect to Î¼\nZ=zero(Î»): the initial gradient with respect to Î»\nW=zero(s): the initial gradient with respect to s\nis_feasible_error=:error: specify how to handle infeasible starting points, see is_feasible for options.\n\nAs well as internal keywords used to set up these given keywords like _step_M, _step_p, _sub_M, _sub_p, and _sub_X, that should not be changed.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective, respectively.\n\nnote: Note\nThe centrality_condition=missing disables to check centrality during the line search, but you can pass InteriorPointCentralityCondition(cmo, Î³), where Î³ is a constant, to activate this check.\n\nOutput\n\nThe obtained approximate constrained minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/interior_point_Newton/#Manopt.InteriorPointNewtonState","page":"Interior Point Newton","title":"Manopt.InteriorPointNewtonState","text":"InteriorPointNewtonState{P,T} <: AbstractHessianSolverState\n\nFields\n\nÎ»:           the Lagrange multiplier with respect to the equality constraints\nÎ¼:           the Lagrange multiplier with respect to the inequality constraints\np::P: a point on the manifold mathcalM  storing the current iterate\ns:           the current slack variable\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nX:           the current gradient with respect to p\nY:           the current gradient with respect to Î¼\nZ:           the current gradient with respect to Î»\nW:           the current gradient with respect to s\nÏ:           store the orthogonality Î¼'s/m to compute the barrier parameter Î² in the sub problem\nÏƒ:           scaling factor for the barrier parameter Î² in the sub problem\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstep_problem: an AbstractManoptProblem storing the manifold and objective for the line search\nstep_state: storing iterate and search direction in a state for the line search, see StepsizeState\n\nConstructor\n\nInteriorPointNewtonState(\n    M::AbstractManifold,\n    cmo::ConstrainedManifoldObjective,\n    sub_problem::Pr,\n    sub_state::St;\n    kwargs...\n)\n\nInitialize the state, where both the AbstractManifold and the ConstrainedManifoldObjective are used to fill in reasonable defaults for the keywords.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\ncmo:         a ConstrainedManifoldObjective\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\nLet m and n denote the number of inequality and equality constraints, respectively\n\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nÎ¼=ones(m)\nX=zero_vector(M,p)\nY=zero(Î¼)\nÎ»=zeros(n)\nZ=zero(Î»)\ns=ones(m)\nW=zero(s)\nÏ=Î¼'s/m\nÏƒ=calculate_Ïƒ(M, cmo, p, Î¼, Î», s)\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstep_objective=ManifoldGradientObjective(KKTVectorFieldNormSq(cmo), KKTVectorFieldNormSqGradient(cmo); evaluation=InplaceEvaluation())\nvector_space=Rn: a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nstep_problem: wrap the manifold mathcalM  â„^m  â„^n  â„^m\nstep_state: the StepsizeState with point and search direction\nstepsize::Stepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size with the InteriorPointCentralityCondition as additional condition to accept a step\"))\nis_feasible_error=:error: specify how to handle infeasible starting points, see is_feasible for options.\n\nand internally _step_M and _step_p for the manifold and point in the stepsize.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.CondensedKKTVectorField","page":"Interior Point Newton","title":"Manopt.CondensedKKTVectorField","text":"CondensedKKTVectorField{O<:ConstrainedManifoldObjective,T,R} <: AbstractConstrainedSlackFunctor{T,R}\n\nGiven the constrained optimization problem\n\nbeginalignedn   min_p  mathcalMnifold)))  f(p)    text subject to  g_i(p)  0 quad text for  i= 1  m    quad  h_j(p) = 0 quadtext for  j=1nnendalignedn\n\nThen reformulating the KKT conditions of the Lagrangian from the optimality conditions of the Lagrangian\n\nmathcalL(p Î¼ Î») = f(p) + sum_j=1^n Î»_jh_j(p) + sum_i=1^m Î¼_ig_i(p)\n\nin a perturbed / barrier method in a condensed form using a slack variable s  â„^m and a barrier parameter Î² and the Riemannian gradient of the Lagrangian with respect to the first parameter operatornamegrad_p L(p Î¼ Î»).\n\nLet mathcalN = mathcalM)  â„^n. We obtain the linear system\n\nmathcalA(pÎ»)XY = -b(pÎ»)qquad textwhere  (XY)  T_(pÎ»)mathcalN\n\nwhere mathcalA T_(pÎ»)mathcalN  T_(pÎ»)mathcalN is a linear operator and this struct models the right hand side b(pÎ»)  T_(pÎ»)mathcalM) given by\n\nb(pÎ») = beginpmatrix operatornamegrad f(p) + displaystylesum_j=1^n Î»_j operatornamegrad h_j(p) + displaystylesum_i=1^m Î¼_i operatornamegrad g_i(p) + displaystylesum_i=1^m fracÎ¼_is_ibigl( Î¼_i(g_i(p)+s_i) + Î² - Î¼_is_i bigr)operatornamegrad g_i(p) h(p)endpmatrix\n\nFields\n\ncmo the ConstrainedManifoldObjective\nÎ¼::T the vector in â„^m of coefficients for the inequality constraints\ns::T the vector in â„^m of sclack variables\nÎ²::R the barrier parameter Î²â„\n\nConstructor\n\nCondensedKKTVectorField(cmo, Î¼, s, Î²)\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.CondensedKKTVectorFieldJacobian","page":"Interior Point Newton","title":"Manopt.CondensedKKTVectorFieldJacobian","text":"CondensedKKTVectorFieldJacobian{O<:ConstrainedManifoldObjective,T,R}  <: AbstractConstrainedSlackFunctor{T,R}\n\nGiven the constrained optimization problem\n\nbeginalignedn   min_p  mathcalM)  f(p)    textsubject to  g_i(p)  0 quadtext for  i= 1  m    quad  h_j(p)=0 quad text for  j=1nnendalignedn\n\nwe reformulate the KKT conditions of the Lagrangian from the optimality conditions of the Lagrangian\n\nmathcalL(p Î¼ Î») = f(p) + sum_j=1^n Î»_jh_j(p) +sum_i=1^m Î¼_ig_i(p)\n\nin a perturbed / barrier method enhanced as well as condensed form as using operatornamegrad_o L(p Î¼ Î») the Riemannian gradient of the Lagrangian with respect to the first parameter.\n\nLet mathcalN = mathcalM)  â„^n. We obtain the linear system\n\nmathcalA(pÎ»)XY = -b(pÎ»)qquad textwhere  X  T_pmathcalM) Y  â„^n\n\nwhere mathcalA T_(pÎ»)mathcalN  T_(pÎ»)mathcalN is a linear operator on T_(pÎ»)mathcalN = T_pmathcalM)  â„^n given by\n\nmathcalA(pÎ»)XY =\nbeginpmatrix operatornameHess_pmathcalL(p Î¼ Î»)X + displaystylesum_i=1^m fracÎ¼_is_i operatornamegrad g_i(p) Xoperatornamegrad g_i(p) + displaystylesum_j=1^n Y_j operatornamegrad h_j(p) Bigl( operatornamegrad h_j(p) X Bigr)_j=1^nendpmatrix\n\nFields\n\ncmo the ConstrainedManifoldObjective\nÎ¼::V the vector in â„^m of coefficients for the inequality constraints\ns::V the vector in â„^m of slack variables\nÎ²::R the barrier parameter Î²â„\n\nConstructor\n\nCondensedKKTVectorFieldJacobian(cmo, Î¼, s, Î²)\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorField","page":"Interior Point Newton","title":"Manopt.KKTVectorField","text":"KKTVectorField{O<:ConstrainedManifoldObjective}\n\nImplement the vector field F KKT-conditions, including a slack variable for the inequality constraints.\n\nGiven the LagrangianCost\n\nmathcalL(p Î¼ Î») = f(p) + sum_i=1^m Î¼_ig_i(p) + sum_j=1^n Î»_jh_j(p)\n\nthe LagrangianGradient\n\noperatornamegradmathcalL(p Î¼ Î») = operatornamegradf(p) + sum_j=1^n Î»_j operatornamegrad h_j(p) + sum_i=1^m Î¼_i operatornamegrad g_i(p)\n\nand introducing the slack variables s=-g(p)  â„^m the vector field is given by\n\nF(p Î¼ Î» s) = beginpmatrix operatornamegrad_p mathcalL(p Î¼ Î») g(p) + s h(p) Î¼  sendpmatrix\n\nwhere p  mathcalMnifold))nifold))), Î¼ s  â„^m and Î»  â„^n, and  denotes the Hadamard (or elementwise) product\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nWhile the point p is arbitrary and usually not needed, it serves as internal memory in the computations. Furthermore Both fields together also clarify the product manifold structure to use.\n\nConstructor\n\nKKTVectorField(cmo::ConstrainedManifoldObjective)\n\nExample\n\nDefine F = KKTVectorField(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcalMnifold)))â„^mâ„^nâ„^m. Then, you can call this cost as F(N, q) or as the in-place variant F(N, Y, q), where q is a point on N and Y is a tangent vector at q for the result.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldJacobian","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldJacobian","text":"KKTVectorFieldJacobian{O<:ConstrainedManifoldObjective}\n\nImplement the Jacobian of the vector field F of the KKT-conditions, including a slack variable for the inequality constraints, see KKTVectorField and KKTVectorFieldAdjointJacobian..\n\noperatornameJ F(p Î¼ Î» s)X Y Z W =\nbeginpmatrix operatornameHess_p mathcalL(p Î¼ Î»)X + displaystylesum_i=1^m Y_i operatornamegrad g_i(p) + displaystylesum_j=1^n Z_j operatornamegrad h_j(p) Bigl( operatornamegrad g_i(p) X + W_iBigr)_i=1^m Bigl( operatornamegrad h_j(p) X Bigr)_j=1^n Î¼  W + s  Yendpmatrix\n\nwhere  denotes the Hadamard (or elementwise) product\n\nSee also the LagrangianHessian operatornameHess_p mathcalL(p Î¼ Î»)X.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldJacobian(cmo::ConstrainedManifoldObjective)\n\nGenerate the Jacobian of the KKT vector field related to some ConstrainedManifoldObjective cmo.\n\nExample\n\nDefine JF = KKTVectorFieldJacobian(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcalMnifold)))â„^mâ„^nâ„^m. Then, you can call this cost as JF(N, q, Y) or as the in-place variant JF(N, Z, q, Y), where q is a point on N and Y and Z are a tangent vector at q.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldAdjointJacobian","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldAdjointJacobian","text":"KKTVectorFieldAdjointJacobian{O<:ConstrainedManifoldObjective}\n\nImplement the Adjoint of the Jacobian of the vector field F of the KKT-conditions, including a slack variable for the inequality constraints, see KKTVectorField and KKTVectorFieldJacobian.\n\noperatornameJ^*\nF(p Î¼ Î» s)X Y Z W = beginpmatrix operatornameHess_p mathcalL(p Î¼ Î»)X + displaystylesum_i=1^m Y_i operatornamegrad g_i(p) + displaystylesum_j=1^n Z_j operatornamegrad h_j(p) Bigl( operatornamegrad g_i(p) X + s_iW_iBigr)_i=1^m Bigl( operatornamegrad h_j(p) X Bigr)_j=1^n Î¼  W + Yendpmatrix\n\nwhere  denotes the Hadamard (or elementwise) product\n\nSee also the LagrangianHessian operatornameHess_p mathcalL(p Î¼ Î»)X.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldAdjointJacobian(cmo::ConstrainedManifoldObjective)\n\nGenerate the Adjoint Jacobian of the KKT vector field related to some ConstrainedManifoldObjective cmo.\n\nExample\n\nDefine AdJF = KKTVectorFieldAdjointJacobian(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcalM)â„^mâ„^nâ„^m. Then, you can call this cost as AdJF(N, q, Y) or as the in-place variant AdJF(N, Z, q, Y), where q is a point on N and Y and Z are a tangent vector at q.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldNormSq","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldNormSq","text":"KKTVectorFieldNormSq{O<:ConstrainedManifoldObjective}\n\nImplement the square of the norm of the vector field F of the KKT-conditions, including a slack variable for the inequality constraints, see KKTVectorField, where this functor applies the norm to. In [LY24] this is called the merit function.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldNormSq(cmo::ConstrainedManifoldObjective)\n\nExample\n\nDefine f = KKTVectorFieldNormSq(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcalMnifold)))â„^mâ„^nâ„^m. Then, you can call this cost as f(N, q), where q is a point on N.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.KKTVectorFieldNormSqGradient","page":"Interior Point Newton","title":"Manopt.KKTVectorFieldNormSqGradient","text":"KKTVectorFieldNormSqGradient{O<:ConstrainedManifoldObjective}\n\nCompute the gradient of the KKTVectorFieldNormSq Ï†(pÎ¼Î»s) = lVert F(pÎ¼Î»s) rVert^2, that is of the norm squared of the KKTVectorField F.\n\nThis is given in [LY24] as the gradient of their merit function, which we can write with the adjoint J^* of the Jacobian\n\noperatornamegrad Ï† = 2operatornameJ^* F(p Î¼ Î» s)F(p Î¼ Î» s)\n\nand hence is computed with KKTVectorFieldAdjointJacobian and KKTVectorField.\n\nFor completeness, the gradient reads, using the LagrangianGradient L = operatornamegrad_p mathcalL(pÎ¼Î»)  T_pmathcalM), for a shorthand of the first component of F, as\n\noperatornamegrad Ï†\n=\n2\nbeginpmatrix operatornamegrad_p mathcalL(pÎ¼Î»)L + (g_i(p) + s_i)operatornamegrad g_i(p) + h_j(p)operatornamegrad h_j(p) Bigl( operatornamegrad g_i(p) L + s_iBigr)_i=1^m + Î¼  s  s Bigl( operatornamegrad h_j(p) L Bigr)_j=1^n g + s + Î¼  Î¼  sendpmatrix\n\nwhere  denotes the Hadamard (or elementwise) product.\n\nFields\n\ncmo the ConstrainedManifoldObjective\n\nConstructor\n\nKKTVectorFieldNormSqGradient(cmo::ConstrainedManifoldObjective)\n\nExample\n\nDefine grad_f = KKTVectorFieldNormSqGradient(cmo) for some ConstrainedManifoldObjective cmo and let N be the product manifold of mathcalM)â„^mâ„^nâ„^m. Then, you can call this cost as grad_f(N, q) or as the in-place variant grad_f(N, Y, q), where q is a point on N and Y is a tangent vector at q returning the resulting gradient at.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.InteriorPointCentralityCondition","page":"Interior Point Newton","title":"Manopt.InteriorPointCentralityCondition","text":"InteriorPointCentralityCondition{CO,R}\n\nA functor to check the centrality condition.\n\nIn order to obtain a step in the linesearch performed within the interior_point_Newton, Section 6 of [LY24] propose the following additional conditions to hold inspired by the Euclidean case described in Section 6 [ETTZ96]:\n\nFor a given ConstrainedManifoldObjective assume consider the KKTVectorField F, that is we are at a point q = (p Î» Î¼ s)  on mathcalM)  â„^m  â„^n  â„^mand a search direction V = (X Y Z W).\n\nThen, let\n\nÏ„_1 = fracmminsetÎ¼  sÎ¼^mathrmTs\nquadtext and quad\nÏ„_2 = fracÎ¼^mathrmTslVert F(q) rVert\n\nwhere  denotes the Hadamard (or elementwise) product.\n\nFor a new candidate q(Î±) = bigl(p(Î±) Î»(Î±) Î¼(Î±) s(Î±)bigr = (operatornameretr_p(Î±X) Î»+Î±Y Î¼+Î±Z s+Î±W), we then define two functions\n\nc_1(Î±) = minsetÎ¼(Î±)  s(Î±) - fracÎ³Ï„_1 Î¼(Î±)^mathrmTs(Î±)m\nquadtext and quad\nc_2(Î±) = Î¼(Î±)^mathrmTs(Î±)  Î³Ï„_2 lVert F(q(Î±)) rVert\n\nWhile the paper now states that the (Armijo) line search starts at a point tilde Î±, it is easier to include the condition that c_1(Î±)  0 and c_2(Î±)  0 into the line search as well.\n\nThe functor InteriorPointCentralityCondition(cmo, Î³, Î¼, s, normKKT)(N,qÎ±) defined here evaluates this condition and returns true if both c_1 and c_2 are non-negative.\n\nFields\n\ncmo: a ConstrainedManifoldObjective\nÎ³: a constant\nÏ„1, Ï„2: the constants given in the formula.\n\nConstructor\n\nInteriorPointCentralityCondition(cmo, Î³)\nInteriorPointCentralityCondition(cmo, Î³, Ï„1, Ï„2)\n\nInitialise the centrality conditions. The parameters Ï„1, Ï„2 are initialise to zero if not provided.\n\nnote: Note\nBesides get_parameter for all three constants, and set_parameter! for Î³, to update Ï„_1 and Ï„_2, call set_parameter(ipcc, :Ï„, N, q) to update both Ï„_1 and Ï„_2 according to the formulae above.\n\n\n\n\n\n","category":"type"},{"location":"solvers/interior_point_Newton/#Manopt.calculate_Ïƒ","page":"Interior Point Newton","title":"Manopt.calculate_Ïƒ","text":"calculate_Ïƒ(M, cmo, p, Î¼, Î», s; kwargs...)\n\nCompute the new Ïƒ factor for the barrier parameter in interior_point_Newton as\n\nminsetfrac12 lVert F(p Î¼ Î» s) rVert^frac12\n\nwhere F is the KKT vector field, hence the KKTVectorFieldNormSq is used.\n\nKeyword arguments\n\nvector_space=Rn a function that, given an integer, returns the manifold to be used for the vector space components â„^mâ„^n\nN the manifold mathcalM)  â„^m  â„^n  â„^m the vector field lives on (generated using vector_space)\nq provide memory on N for interims evaluation of the vector field\n\n\n\n\n\n","category":"function"},{"location":"solvers/interior_point_Newton/#Manopt.StopWhenKKTResidualLess","page":"Interior Point Newton","title":"Manopt.StopWhenKKTResidualLess","text":"StopWhenKKTResidualLess <: StoppingCriterion\n\nStop when the KKT residual\n\nr^2\n= \\lVert \\operatorname{grad}_p \\mathcal{L}(p, Î¼, Î»)  \\rVert^2\n+ \\sum_{i=1}^{m} [Î¼_i]_{-}^2 + [g_i(p)]_+^2 + \\lvert Î¼_i g_i(p) \\rvert^2\n+ \\sum_{j=1}^{n} \\lvert h_i(p) \\rvert^2.\n\nis less than a given threshold r  Îµ. We use v_+ = maxset0v and v_- = minset0t for the positive and negative part of v, respectively\n\nFields\n\nÎµ: a threshold\nresidual: store the last residual if the stopping criterion is hit.\nat_iteration:\n\n\n\n\n\n","category":"type"},{"location":"solvers/primal_dual_semismooth_Newton/#solver-pdrssn","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton algorithm","text":"The Primal-dual Riemannian semismooth Newton Algorithm is a second-order method derived from the ChambollePock.\n\nThe aim is to solve an optimization problem on a manifold with a cost function of the form\n\nF(p) + G(Î›(p))\n\nwhere Fmathcal M  overlineâ„, Gmathcal N  overlineâ„, and Î›mathcal M mathcal N. If the manifolds mathcal M or mathcal N are not Hadamard, it has to be considered locally only, that is on geodesically convex sets mathcal C subset mathcal M and mathcal D subsetmathcal N such that Î›(mathcal C) subset mathcal D.\n\nThe algorithm comes down to applying the Riemannian semismooth Newton method to the rewritten primal-dual optimality conditions. Define the vector field X mathcalM times mathcalT_n^* mathcalN rightarrow mathcalT mathcalM times mathcalT_n^* mathcalN as\n\nXleft(p xi_nright)=left(beginarrayc\n-log _p operatornameprox_sigma Fleft(exp _pleft(mathcalP_p leftarrow mleft(-sigmaleft(D_m Lambdaright)^*leftmathcalP_Lambda(m) leftarrow n xi_nrightright)^sharpright)right) \nxi_n-operatornameprox_tau G_n^*left(xi_n+tauleft(mathcalP_n leftarrow Lambda(m) D_m Lambdaleftlog _m prightright)^flatright)\nendarrayright)\n\nand solve for X(pÎ¾_n)=0.\n\nGiven base points mmathcal C, n=Î›(m)mathcal D, initial primal and dual values p^(0) mathcal C, Î¾_n^(0)  mathcal T_n^*mathcal N, and primal and dual step sizes sigma, tau.\n\nThe algorithms performs the steps k=1 (until a StoppingCriterion is reached)\n\nChoose any element\nV^(k)  _C X(p^(k)Î¾_n^(k))\nof the Clarke generalized covariant derivative\nSolve\nV^(k) (d_p^(k) d_n^(k)) = - X(p^(k)Î¾_n^(k))\nin the vector space mathcalT_p^(k) mathcalM times mathcalT_n^* mathcalN\nUpdate\np^(k+1) = exp_p^(k)(d_p^(k))\nand\nÎ¾_n^(k+1) = Î¾_n^(k) + d_n^(k)\n\nFurthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction and a vector transport.\n\nFinally you can also update the base points m and n during the iterations. This introduces a few additional vector transports. The same holds for the case that Î›(m^(k))neq n^(k) at some point. All these cases are covered in the algorithm.","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/#State","page":"Primal-dual Riemannian semismooth Newton","title":"State","text":"","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/#sec-ssn-technical-details","page":"Primal-dual Riemannian semismooth Newton","title":"Technical details","text":"The primal_dual_semismooth_Newton solver requires the following functions of a manifold to be available for both the manifold mathcal Mand mathcal N\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points.\nA get_basis for the DefaultOrthonormalBasis on mathcal M\nexp and log (on mathcal M)\nA DiagonalizingOrthonormalBasis to compute the differentials of the exponential and logarithmic map\nTangent vectors storing the social and cognitive vectors are initialized calling zero_vector(M,p).","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/#Literature","page":"Primal-dual Riemannian semismooth Newton","title":"Literature","text":"W.Â Diepeveen and J.Â Lellmann. An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising. SIAMÂ JournalÂ onÂ ImagingÂ Sciences 14, 1565â€“1600 (2021), arXiv:2102.10309.\n\n\n\n","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton","text":"primal_dual_semismooth_Newton(M, N, cost, p, X, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_dual_G, linearized_operator, adjoint_linearized_operator)\n\nPerform the Primal-Dual Riemannian semismooth Newton algorithm.\n\nGiven a cost function mathcal E mathcal M  overlineâ„ of the form\n\nmathcal E(p) = F(p) + G( Î›(p) )\n\nwhere F mathcal M  overlineâ„, G mathcal N  overlineâ„, and Î› mathcal M  mathcal N. The remaining input parameters are\n\np, X:                          primal and dual start points pmathcalMnifold))nifold))nifold)) and X  T_nmathcalN\nm,n:                           base points on mathcalM) and mathcalN, respectively.\nlinearized_forward_operator:   the linearization DÎ›() of the operator Î›().\nadjoint_linearized_operator:   the adjoint DÎ›^* of the linearized operator DÎ›(m)  T_mmathcalM  T_Î›(m)mathcalN\nprox_F, prox_G_Dual:           the proximal maps of F and G^ast_n\ndiff_prox_F, diff_prox_dual_G: the (Clarke Generalized) differentials of the proximal maps of F and G^ast_n\n\nFor more details on the algorithm, see [DL21].\n\nKeyword arguments\n\ndual_stepsize=1/sqrt(8): proximal parameter of the dual prox\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the exact operator, that is required if Î›(m)=n does not hold; missing indicates, that the forward operator is exact.\nprimal_stepsize=1/sqrt(8): proximal parameter of the primal prox\nreg_param=1e-5: regularisation parameter for the Newton matrix Note that this changes the arguments the forward_operator is called.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(50): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton!","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton!","text":"primal_dual_semismooth_Newton(M, N, cost, p, X, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_dual_G, linearized_operator, adjoint_linearized_operator)\n\nPerform the Primal-Dual Riemannian semismooth Newton algorithm.\n\nGiven a cost function mathcal E mathcal M  overlineâ„ of the form\n\nmathcal E(p) = F(p) + G( Î›(p) )\n\nwhere F mathcal M  overlineâ„, G mathcal N  overlineâ„, and Î› mathcal M  mathcal N. The remaining input parameters are\n\np, X:                          primal and dual start points pmathcalMnifold))nifold))nifold)) and X  T_nmathcalN\nm,n:                           base points on mathcalM) and mathcalN, respectively.\nlinearized_forward_operator:   the linearization DÎ›() of the operator Î›().\nadjoint_linearized_operator:   the adjoint DÎ›^* of the linearized operator DÎ›(m)  T_mmathcalM  T_Î›(m)mathcalN\nprox_F, prox_G_Dual:           the proximal maps of F and G^ast_n\ndiff_prox_F, diff_prox_dual_G: the (Clarke Generalized) differentials of the proximal maps of F and G^ast_n\n\nFor more details on the algorithm, see [DL21].\n\nKeyword arguments\n\ndual_stepsize=1/sqrt(8): proximal parameter of the dual prox\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the exact operator, that is required if Î›(m)=n does not hold; missing indicates, that the forward operator is exact.\nprimal_stepsize=1/sqrt(8): proximal parameter of the primal prox\nreg_param=1e-5: regularisation parameter for the Newton matrix Note that this changes the arguments the forward_operator is called.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(50): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.PrimalDualSemismoothNewtonState","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.PrimalDualSemismoothNewtonState","text":"PrimalDualSemismoothNewtonState <: AbstractPrimalDualSolverState\n\nFields\n\nm::P: a point on the manifold mathcalM\nn::Q: a point on the manifold mathcalN\np::P: a point on the manifold mathcalM  storing the current iterate\nX::T: a tangent vector at the point p on the manifold mathcalM\nprimal_stepsize::Float64:  proximal parameter of the primal prox\ndual_stepsize::Float64:    proximal parameter of the dual prox\nreg_param::Float64:        regularisation parameter for the Newton matrix\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base:        function to update the primal base\nupdate_dual_base:          function to update the dual base\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nwhere for the update functions a AbstractManoptProblem amp, AbstractManoptSolverState ams and the current iterate i are the arguments. If you activate these to be different from the default identity, you have to provide p.Î› for the algorithm to work (which might be missing).\n\nConstructor\n\nPrimalDualSemismoothNewtonState(M::AbstractManifold; kwargs...)\n\nGenerate a state for the primal_dual_semismooth_Newton.\n\nKeyword arguments\n\nm=rand(M)\nn=rand(N)\np=rand(M)\nX=zero_vector(M, p)\nprimal_stepsize=1/sqrt(8)\ndual_stepsize=1/sqrt(8)\nreg_param=1e-5\nupdate_primal_base=(amp, ams, k) -> o.m\nupdate_dual_base=(amp, ams, k) -> o.n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstopping_criterion::StoppingCriterion=StopAfterIteration(50)`: a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\n\n\n\n\n","category":"type"},{"location":"solvers/DouglasRachford/#Douglasâ€”Rachford-algorithm","page":"Douglasâ€”Rachford","title":"Douglasâ€”Rachford algorithm","text":"The (Parallel) Douglasâ€”Rachford ((P)DR) algorithm was generalized to Hadamard manifolds in [BPS16].\n\nThe aim is to minimize the sum\n\nf(p) = g(p) + h(p)\n\non a manifold, where the two summands have proximal maps operatornameprox_Î» g operatornameprox_Î» h that are easy to evaluate (maybe in closed form, or not too costly to approximate). Further, define the reflection operator at the proximal map as\n\noperatornamerefl_Î» g(p) = operatornameretr_operatornameprox_Î» g(p) bigl( -operatornameretr^-1_operatornameprox_Î» g(p) p bigr)\n\nLet alpha_k   01 with sum_k  â„• alpha_k(1-alpha_k) =  infty and Î»  0 (which might depend on iteration k as well) be given.\n\nThen the (P)DRA algorithm for initial data p^(0)  mathcal M as","category":"section"},{"location":"solvers/DouglasRachford/#Initialization","page":"Douglasâ€”Rachford","title":"Initialization","text":"Initialize q^(0) = p^(0) and k=0","category":"section"},{"location":"solvers/DouglasRachford/#Iteration","page":"Douglasâ€”Rachford","title":"Iteration","text":"Repeat until a convergence criterion is reached\n\nCompute r^(k) = operatornamerefl_Î» goperatornamerefl_Î» h(q^(k))\nWithin that operation, store p^(k+1) = operatornameprox_Î» h(q^(k)) which is the prox the inner reflection reflects at.\nCompute q^(k+1) = g(alpha_k q^(k) r^(k)), where g is a curve approximating the shortest geodesic, provided by a retraction and its inverse\nSet k = k+1","category":"section"},{"location":"solvers/DouglasRachford/#Result","page":"Douglasâ€”Rachford","title":"Result","text":"The result is given by the last computed p^(K) at the last iterate K.\n\nFor the parallel version, the first proximal map is a vectorial version where in each component one prox is applied to the corresponding copy of t_k and the second proximal map corresponds to the indicator function of the set, where all copies are equal (in mathcal M^n, where n is the number of copies), leading to the second prox being the Riemannian mean.","category":"section"},{"location":"solvers/DouglasRachford/#Interface","page":"Douglasâ€”Rachford","title":"Interface","text":"","category":"section"},{"location":"solvers/DouglasRachford/#State","page":"Douglasâ€”Rachford","title":"State","text":"For specific DebugActions and RecordActions see also Cyclic Proximal Point.\n\nFurthermore, this solver has a short hand notation for the involved reflection.","category":"section"},{"location":"solvers/DouglasRachford/#sec-dr-technical-details","page":"Douglasâ€”Rachford","title":"Technical details","text":"The DouglasRachford solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points.\n\nBy default, one of the stopping criteria is StopWhenChangeLess, which requires\n\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.","category":"section"},{"location":"solvers/DouglasRachford/#Literature","page":"Douglasâ€”Rachford","title":"Literature","text":"","category":"section"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachford","page":"Douglasâ€”Rachford","title":"Manopt.DouglasRachford","text":"DouglasRachford(M, f, proxes_f, p)\nDouglasRachford(M, mpo, p)\nDouglasRachford!(M, f, proxes_f, p)\nDouglasRachford!(M, mpo, p)\n\nCompute the Douglas-Rachford algorithm on the manifold mathcalMnifold))), starting from p given the (two) proximal maps proxes_f, see [BPS16].\n\nFor k2 proximal maps, the problem is reformulated using the parallel Douglas Rachford: a vectorial proximal map on the power manifold mathcalM)^k is introduced as the first proximal map and the second proximal map of the is set to the mean (Riemannian center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, that is, component wise in a vector.\n\nnote: Note\nThe parallel Douglas Rachford does not work in-place for now, since while creating the new staring point p' on the power manifold, a copy of p Is created\n\nIf you provide a ManifoldProximalMapObjective mpo instead, the proximal maps are kept unchanged.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nproxes_f: functions of the form (M, Î», p)-> q performing a proximal maps, where â Î» denotes the proximal parameter, for each of the summands of F. These can also be given in the InplaceEvaluation variants (M, q, Î» p) -> q computing in place of q.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nÎ±= k -> 0.9: relaxation of the step from old to new iterate, to be precise p^(k+1) = g(Î±_k p^(k) q^(k)), where q^(k) is the result of the double reflection involved in the DR algorithm and g is a curve induced by the retraction and its inverse.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nÎ»= k -> 1.0: function to provide the value for the proximal parameter Î»_k\nR=reflect(!):           method employed in the iteration to perform the reflection of p at the prox of p. This uses by default reflect or reflect! depending on reflection_evaluation and the retraction and inverse retraction specified by retraction_method and inverse_retraction_method, respectively.\nreflection_evaluation: (AllocatingEvaluation whether R works in-place or allocating\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-5): a functor indicating that the stopping criterion is fulfilled\nparallel=false: indicate whether to use a parallel Douglas-Rachford or not.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\nDouglasRachford(M, f, proxes_f, p; kwargs...)\n\na doc string with some math t_k+1 = g(Î±_k t_k s_k)\n\n\n\n\n\n","category":"function"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachford!","page":"Douglasâ€”Rachford","title":"Manopt.DouglasRachford!","text":"DouglasRachford(M, f, proxes_f, p)\nDouglasRachford(M, mpo, p)\nDouglasRachford!(M, f, proxes_f, p)\nDouglasRachford!(M, mpo, p)\n\nCompute the Douglas-Rachford algorithm on the manifold mathcalMnifold))), starting from p given the (two) proximal maps proxes_f, see [BPS16].\n\nFor k2 proximal maps, the problem is reformulated using the parallel Douglas Rachford: a vectorial proximal map on the power manifold mathcalM)^k is introduced as the first proximal map and the second proximal map of the is set to the mean (Riemannian center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, that is, component wise in a vector.\n\nnote: Note\nThe parallel Douglas Rachford does not work in-place for now, since while creating the new staring point p' on the power manifold, a copy of p Is created\n\nIf you provide a ManifoldProximalMapObjective mpo instead, the proximal maps are kept unchanged.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nproxes_f: functions of the form (M, Î», p)-> q performing a proximal maps, where â Î» denotes the proximal parameter, for each of the summands of F. These can also be given in the InplaceEvaluation variants (M, q, Î» p) -> q computing in place of q.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nÎ±= k -> 0.9: relaxation of the step from old to new iterate, to be precise p^(k+1) = g(Î±_k p^(k) q^(k)), where q^(k) is the result of the double reflection involved in the DR algorithm and g is a curve induced by the retraction and its inverse.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nÎ»= k -> 1.0: function to provide the value for the proximal parameter Î»_k\nR=reflect(!):           method employed in the iteration to perform the reflection of p at the prox of p. This uses by default reflect or reflect! depending on reflection_evaluation and the retraction and inverse retraction specified by retraction_method and inverse_retraction_method, respectively.\nreflection_evaluation: (AllocatingEvaluation whether R works in-place or allocating\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions This is used both in the relaxation step as well as in the reflection, unless you set R yourself.\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenChangeLess(1e-5): a functor indicating that the stopping criterion is fulfilled\nparallel=false: indicate whether to use a parallel Douglas-Rachford or not.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachfordState","page":"Douglasâ€”Rachford","title":"Manopt.DouglasRachfordState","text":"DouglasRachfordState <: AbstractManoptSolverState\n\nStore all options required for the DouglasRachford algorithm,\n\nFields\n\nÎ±:                         relaxation of the step from old to new iterate, to be precise x^(k+1) = g(Î±(k) x^(k) t^(k)), where t^(k) is the result of the double reflection involved in the DR algorithm\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ»:                         function to provide the value for the proximal parameter during the calls\nparallel:                  indicate whether to use a parallel Douglas-Rachford or not.\nR:                          method employed in the iteration to perform the reflection of x at the prox p.\np::P: a point on the manifold mathcalM  storing the current iterate For the parallel Douglas-Rachford, this is not a value from the PowerManifold manifold but the mean.\nreflection_evaluation:     whether R works in-place or allocating\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\ns:                         the last result of the double reflection at the proximal maps relaxed by Î±.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nConstructor\n\nDouglasRachfordState(M::AbstractManifold; kwargs...)\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\n\nKeyword arguments\n\nÎ±= k -> 0.9: relaxation of the step from old to new iterate, to be precise x^(k+1) = g(Î±(k) x^(k) t^(k)), where t^(k) is the result of the double reflection involved in the DR algorithm\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ»= k -> 1.0: function to provide the value for the proximal parameter during the calls\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nR=reflect(!): method employed in the iteration to perform the reflection of p at the prox of p, which function is used depends on reflection_evaluation.\nreflection_evaluation=AllocatingEvaluation()) specify whether the reflection works in-place or allocating (default)\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(300): a functor indicating that the stopping criterion is fulfilled\nparallel=false: indicate whether to use a parallel Douglas-Rachford or not.\n\n\n\n\n\n","category":"type"},{"location":"solvers/DouglasRachford/#Manopt.reflect","page":"Douglasâ€”Rachford","title":"Manopt.reflect","text":"reflect(M, f, x; kwargs...)\nreflect!(M, q, f, x; kwargs...)\n\nreflect the point x from the manifold M at the point f(x) of the function f mathcalM)  mathcalM), given by\n\noperatornamerefl_f(x) = operatornamerefl_f(x)(x)\n\nCompute the result in q.\n\nsee also reflect(M,p,x), to which the keywords are also passed to.\n\n\n\n\n\nreflect(M, p, x, kwargs...)\nreflect!(M, q, p, x, kwargs...)\n\nReflect the point x from the manifold M at point p, given by\n\noperatornamerefl\n\nwhere operatornameretr and operatornameretr^-1 denote a retraction and an inverse retraction, respectively. This can also be done in place of q.\n\nKeyword Arguments\n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nand for the reflect! additionally\n\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM as temporary memory to compute the inverse retraction in place. otherwise this is the memory that would be allocated anyways.\n\n\n\n\n\nreflect(M, f, x; kwargs...)\nreflect!(M, q, f, x; kwargs...)\n\nreflect the point x from the manifold M at the point f(x) of the function f mathcalM)  mathcalM), given by\n\n    operatornamerefl_f(x) = operatornamerefl_f(x)(x)\n\nCompute the result in q.\n\nsee also reflect(M,p,x), to which the keywords are also passed to.\n\n\n\n\n\nreflect(M, p, x, kwargs...)\nreflect!(M, q, p, x, kwargs...)\n\nReflect the point x from the manifold M at point p, given by\n\noperatornamerefl_p(q) = operatornameretr_p(-operatornameretr^-1_p q)\n\nwhere operatornameretr and operatornameretr^-1 denote a retraction and an inverse retraction, respectively.\n\nThis can also be done in place of q.\n\nKeyword Arguments\n\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\n\nand for the reflect! additionally\n\nX=zero_vector(M,p): a temporary memory to compute the inverse retraction in place. otherwise this is the memory that would be allocated anyways.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/CountAndCache/#How-to-count-and-cache-function-calls","page":"Count and use a cache","title":"How to count and cache function calls","text":"Ronny Bergmann\n\nIn this tutorial, we want to investigate the caching and counting (statistics) features of Manopt.jl. We reuse the optimization tasks from the introductory tutorial ðŸ”ï¸ Get started with Manopt.jl.","category":"section"},{"location":"tutorials/CountAndCache/#Introduction","page":"Count and use a cache","title":"Introduction","text":"There are surely many ways to keep track for example of how often the cost function is called, for example with a functor, as we used in an example in How to Record Data\n\nmutable struct MyCost{I<:Integer}\n    count::I\nend\nMyCost() = MyCost{Int64}(0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    # [ .. Actual implementation of the cost here ]\nend\n\nThis still leaves a bit of work to the user, especially for tracking more than just the number of cost function evaluations.\n\nWhen a function like the objective or gradient is expensive to compute, it may make sense to cache its results. Manopt.jl tries to minimize the number of repeated calls but sometimes they are necessary and harmless when the function is cheap to compute. Caching of expensive function calls can for example be added using Memoize.jl by the user. The approach in the solvers of Manopt.jl aims to simplify adding both these capabilities on the level of calling a solver.","category":"section"},{"location":"tutorials/CountAndCache/#Technical-background","page":"Count and use a cache","title":"Technical background","text":"The two ingredients for a solver in Manopt.jl are the AbstractManoptProblem and the AbstractManoptSolverState, where the former consists of the domain, that is the AbstractManifold and AbstractManifoldObjective.\n\nBoth recording and debug capabilities are implemented in a decorator pattern to the solver state. They can be easily added using the record= and debug= in any solver call. This pattern was recently extended, such that also the objective can be decorated. This is how both caching and counting are implemented, as decorators of the AbstractManifoldObjective and hence for example changing/extending the behaviour of a call to get_cost.\n\nLetâ€™s finish off the technical background by loading the necessary packages. Besides Manopt.jl and Manifolds.jl we also need LRUCaches.jl which are (since Julia 1.9) a weak dependency and provide the least recently used strategy for our caches.\n\nusing Manopt, Manifolds, Random, LRUCache, LinearAlgebra, ManifoldDiff\nusing ManifoldDiff: grad_distance","category":"section"},{"location":"tutorials/CountAndCache/#Counting","page":"Count and use a cache","title":"Counting","text":"We first define our task, the Riemannian Center of Mass from the ðŸ”ï¸ Get started with Manopt.jl tutorial.\n\nn = 100\nÏƒ = Ï€ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\nRandom.seed!(42)\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)));\n\nto now count how often the cost and the gradient are called, we use the count= keyword argument that works in any solver to specify the elements of the objective whose calls we want to count calls to. A full list is available in the documentation of the AbstractManifoldObjective. To also see the result, we have to set return_objective=true. This returns (objective, p) instead of just the solver result p. We can further also set return_state=true to get even more information about the solver run.\n\ngradient_descent(M, f, grad_f, data[1]; count=[:Cost, :Gradient], return_objective=true, return_state=true)\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 67 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: No\n\n## Statistics on function calls\n  * :Gradient : 135\n  * :Cost     : 278\n\nAnd we see that statistics are shown in the end.","category":"section"},{"location":"tutorials/CountAndCache/#Caching","page":"Count and use a cache","title":"Caching","text":"To now also cache these calls, we can use the cache= keyword argument. Since now both the cache and the count â€œextendâ€ the capability of the objective, the order is important: on the high-level interface, the count is treated first, which means that only actual function calls and not cache look-ups are counted. With the proper initialisation, you can use any caches here that support the get!(function, cache, key)! update. All parts of the objective that can currently be cached are listed at ManifoldCachedObjective. The solver call has a keyword cache that takes a tuple(c, vs, n) of three arguments, where c is a symbol for the type of cache, vs is a vector of symbols, which calls to cache and n is the size of the cache. If the last element is not provided, a suitable default (currentlyn=10) is used.\n\nHere we want to use c=:LRU caches for vs=[Cost, :Gradient] with a size of n=25.\n\nr = gradient_descent(M, f, grad_f, data[1];\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true, return_state=true)\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 67 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: No\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 67\n  * :Cost     : 148\n\nSince the default setup with ArmijoLinesearch needs the gradient and the cost, and similarly the stopping criterion might (independently) evaluate the gradient, the caching is quite helpful here.\n\nAnd of course also for this advanced return value of the solver, we can still access the result as usual:\n\nget_solver_result(r)\n\n3-element Vector{Float64}:\n 0.6868392759384782\n 0.006531603309348398\n 0.7267799854058424","category":"section"},{"location":"tutorials/CountAndCache/#Advanced-caching-examples","page":"Count and use a cache","title":"Advanced caching examples","text":"There are more options other than caching single calls to specific parts of the objective. For example you may want to cache intermediate results of computing the cost and share that with the gradient computation. We present three solutions to this:\n\nAn easy approach from within Manopt.jl: the ManifoldCostGradientObjective\nA shared storage approach using a functor\nA shared (internal) cache approach also using a functor\n\nFor that we switch to another example: the Rayleigh quotient. We aim to maximize the Rayleigh quotient displaystylefracx^mathrmTAxx^mathrmTx, for some Aâ„^m+1times m+1 and xâ„^m+1 but since we consider this on the sphere and Manopt.jl (as many other optimization toolboxes) minimizes, we consider\n\ng(p) = -p^mathrmTApqquad pmathbb S^m\n\nThe Euclidean gradient (that is in $ R^{m+1}$) is actually just nabla g(p) = -2Ap, the Riemannian gradient the projection of nabla g(p) onto the tangent space T_pmathbb S^m.\n\nm = 25\nRandom.seed!(42)\nA = randn(m + 1, m + 1)\nA = Symmetric(A)\np_star = eigvecs(A)[:, end] # minimizer (or similarly -p)\nf_star = -eigvals(A)[end] # cost (note that we get - the largest Eigenvalue)\n\nN = Sphere(m);\n\ng(M, p) = -p' * A*p\nâˆ‡g(p) = -2 * A * p\ngrad_g(M,p) = project(M, p, âˆ‡g(p))\ngrad_g!(M,X, p) = project!(M, X, p, âˆ‡g(p))\n\ngrad_g! (generic function with 1 method)\n\nBut since both the cost and the gradient require the computation of the matrix-vector product Ap, it might be beneficial to only compute this once.","category":"section"},{"location":"tutorials/CountAndCache/#The-[ManifoldCostGradientObjective](@ref)-approach","page":"Count and use a cache","title":"The ManifoldCostGradientObjective approach","text":"The ManifoldCostGradientObjective uses a combined function to compute both the gradient and the cost at the same time. We define the in-place variant as\n\nfunction g_grad_g!(M::AbstractManifold, X, p)\n    X .= -A*p\n    c = p'*X\n    X .*= 2\n    project!(M, X, p, X)\n    return (c, X)\nend\n\ng_grad_g! (generic function with 1 method)\n\nwhere we only compute the matrix-vector product once. The small disadvantage might be, that we always compute both, the gradient and the cost. Luckily, the cache we used before, takes this into account and caches both results, such that we indeed end up computing A*p only once when asking to a cost and a gradient.\n\nLetâ€™s compare both methods\n\np0 = [(1/5 .* ones(5))..., zeros(m-4)...];\n@time s1 = gradient_descent(N, g, grad_g!, p0;\n    stopping_criterion =Â StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)\n\n  1.208344 seconds (2.30 M allocations: 115.452 MiB, 99.63% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 601\n  * :Cost     : 1382\n\nTo access the solver result, call `get_solver_result` on this variable.\n\nversus\n\nobj = ManifoldCostGradientObjective(g_grad_g!; evaluation=InplaceEvaluation())\n@time s2 = gradient_descent(N, obj, p0;\n    stopping_criterion=StopWhenGradientNormLess(1e-5),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)\n\n  0.759279 seconds (1.03 M allocations: 62.543 MiB, 99.04% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 601\n  * :Cost     : 1983\n\nTo access the solver result, call `get_solver_result` on this variable.\n\nfirst of all both yield the same result\n\np1 = get_solver_result(s1)\np2 = get_solver_result(s2)\n[distance(N, p1, p2), g(N, p1), g(N, p2), f_star]\n\n4-element Vector{Float64}:\n  0.0\n -7.803295763777179\n -7.803295763777179\n -7.803295763793949\n\nand we can see that the combined number of evaluations is once 2051, once just the number of cost evaluations 1449. Note that the involved additional 847 gradient evaluations are merely a multiplication with 2. On the other hand, the additional caching of the gradient in these cases might be less beneficial. It is beneficial, when the gradient and the cost are very often required together.","category":"section"},{"location":"tutorials/CountAndCache/#A-shared-storage-approach-using-a-functor","page":"Count and use a cache","title":"A shared storage approach using a functor","text":"An alternative to the previous approach is the usage of a functor that introduces a â€œshared storageâ€ of the result of computing A*p. We additionally have to store p though, since we have to make sure that we are still evaluating the cost and/or gradient at the same point at which the cached A*p was computed. We again consider the (more efficient) in-place variant. This can be done as follows\n\nstruct StorageG{T,M}\n    A::M\n    Ap::T\n    p::T\nend\nfunction (g::StorageG)(::Val{:Cost}, M::AbstractManifold, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    return -g.p'*g.Ap\nend\nfunction (g::StorageG)(::Val{:Gradient}, M::AbstractManifold, X, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    X .= -2 .* g.Ap\n    project!(M, X, p, X)\n    return X\nend\n\nHere we use the first parameter to distinguish both functions. For the mutating case the signatures are different regardless of the additional argument but for the allocating case, the signatures of the cost and the gradient function are the same.\n\n#Define the new functor\nstorage_g = StorageG(A, zero(p0), zero(p0))\n# and cost and gradient that use this functor as\ng3(M,p) = storage_g(Val(:Cost), M, p)\ngrad_g3!(M, X, p) = storage_g(Val(:Gradient), M, X, p)\n@time s3 = gradient_descent(N, g3, grad_g3!, p0;\n    stopping_criterion =Â StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 2),\n    return_objective=true#, return_state=true\n)\n\n  0.713635 seconds (951.69 k allocations: 48.258 MiB, 99.39% compilation time)\n\n## Cache\n  * :Cost     : 2/2 entries of type Float64 used\n  * :Gradient : 2/2 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 601\n  * :Cost     : 1382\n\nTo access the solver result, call `get_solver_result` on this variable.\n\nThis of course still yields the same result\n\np3 = get_solver_result(s3)\ng(N, p3) - f_star\n\n1.6770584920777765e-11\n\nAnd while we again have a split off the cost and gradient evaluations, we can observe that the allocations are less than half of the previous approach.","category":"section"},{"location":"tutorials/CountAndCache/#A-local-cache-approach","page":"Count and use a cache","title":"A local cache approach","text":"This variant is very similar to the previous one, but uses a whole cache instead of just one place to store A*p. This makes the code a bit nicer, and it is possible to store more than just the last p either cost or gradient was called with.\n\nstruct CacheG{C,M}\n    A::M\n    cache::C\nend\nfunction (g::CacheG)(::Val{:Cost}, M, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    return -p'*Ap\nend\nfunction (g::CacheG)(::Val{:Gradient}, M, X, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    X .= -2 .* Ap\n    project!(M, X, p, X)\n    return X\nend\n\nHowever, the resulting solver run is not always faster, since the whole cache instead of storing just Ap and p is a bit more costly. Then the tradeoff is, whether this pays off.\n\n#Define the new functor\ncache_g = CacheG(A, LRU{typeof(p0),typeof(p0)}(; maxsize=25))\n# and cost and gradient that use this functor as\ng4(M,p) = cache_g(Val(:Cost), M, p)\ngrad_g4!(M, X, p) = cache_g(Val(:Gradient), M, X, p)\n@time s4 = gradient_descent(N, g4, grad_g4!, p0;\n    stopping_criterion =Â StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)\n\n  0.705111 seconds (834.89 k allocations: 42.862 MiB, 99.23% compilation time)\n\n## Cache\n  * :Cost     : 25/25 entries of type Float64 used\n  * :Gradient : 25/25 entries of type Vector{Float64} used\n\n## Statistics on function calls\n  * :Gradient : 601\n  * :Cost     : 1382\n\nTo access the solver result, call `get_solver_result` on this variable.\n\nand for safety letâ€™s verify that we are reasonably close\n\np4 = get_solver_result(s4)\ng(N, p4) - f_star\n\n1.6770584920777765e-11\n\nFor this example, or maybe even gradient_descent in general it seems, this additional (second, inner) cache does not improve the result further, it is about the same effort both time and allocation-wise.","category":"section"},{"location":"tutorials/CountAndCache/#Summary","page":"Count and use a cache","title":"Summary","text":"While the second approach of ManifoldCostGradientObjective is very easy to implement, both the storage and the (local) cache approach are more efficient. All three are an improvement over the first implementation without sharing interim results. The results with storage or cache have further advantage of being more flexible, since the stored information could also be reused in a third function, for example when also computing the Hessian.","category":"section"},{"location":"tutorials/CountAndCache/#Technical-details","page":"Count and use a cache","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:30:22.","category":"section"},{"location":"tutorials/InplaceGradient/#Speedup-using-in-place-evaluation","page":"Speedup using in-place computations","title":"Speedup using in-place evaluation","text":"Ronny Bergmann\n\nWhen it comes to time critical operations, a main ingredient in Julia is given by mutating functions, that is those that compute in place without additional memory allocations. In the following, we illustrate how to do this with Manopt.jl.\n\nLetâ€™s start with the same function as in ðŸ”ï¸ Get started with Manopt.jl and compute the mean of some points, only that here we use the sphere mathbb S^30 and n=800 points.\n\nFrom the aforementioned example.\n\nWe first load all necessary packages.\n\nusing Manopt, Manifolds, Random, BenchmarkTools\nusing ManifoldDiff: grad_distance, grad_distance!\nRandom.seed!(42);\n\nAnd setup our data\n\nRandom.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nÏƒ = Ï€ / 8\np = zeros(Float64, m + 1)\np[2] = 1.0\ndata = [exp(M, p, Ïƒ * rand(M; vector_at=p)) for i in 1:n];","category":"section"},{"location":"tutorials/InplaceGradient/#Classical-definition","page":"Speedup using in-place computations","title":"Classical definition","text":"The variant from the previous tutorial defines a cost f(x) and its gradient operatornamegradf(p) â€œâ€œâ€\n\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)))\n\ngrad_f (generic function with 1 method)\n\nWe further set the stopping criterion to be a little more strict. Then we obtain\n\nsc = StopWhenGradientNormLess(3e-10)\np0 = zeros(Float64, m + 1); p0[1] = 1/sqrt(2); p0[2] = 1/sqrt(2)\nm1 = gradient_descent(M, f, grad_f, p0; stopping_criterion=sc);\n\nWe can also benchmark this as\n\n@benchmark gradient_descent($M, $f, $grad_f, $p0; stopping_criterion=$sc)\n\nBenchmarkTools.Trial: 90 samples with 1 evaluation per sample.\n Range (min â€¦ max):  51.678 ms â€¦ 134.204 ms  â”Š GC (min â€¦ max):  9.64% â€¦ 38.77%\n Time  (median):     53.536 ms               â”Š GC (median):    11.71%\n Time  (mean Â± Ïƒ):   55.776 ms Â±   9.262 ms  â”Š GC (mean Â± Ïƒ):  12.53% Â±  3.19%\n\n  â–ˆâ–‡â–â–‡â–â–…â–‚     â–                                                 \n  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–…â–†â–†â–†â–ˆâ–â–ƒâ–†â–…â–ƒâ–ƒâ–…â–ƒâ–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–…â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–… â–\n  51.7 ms         Histogram: frequency by time         71.5 ms <\n\n Memory estimate: 173.76 MiB, allocs estimate: 1167364.","category":"section"},{"location":"tutorials/InplaceGradient/#In-place-computation-of-the-gradient","page":"Speedup using in-place computations","title":"In-place computation of the gradient","text":"We can reduce the memory allocations by implementing the gradient to be evaluated in-place. We do this by using a functor. The motivation is twofold: on one hand, we want to avoid variables from the global scope, for example the manifold M or the data, being used within the function. Considering to do the same for more complicated cost functions might also be worth pursuing.\n\nHere, we store the data (as reference) and one introduce temporary memory to avoid reallocation of memory per grad_distance computation. We get\n\nstruct GradF!{TD,TTMP}\n    data::TD\n    tmp::TTMP\nend\nfunction (grad_f!::GradF!)(M, X, p)\n    fill!(X, 0)\n    for di in grad_f!.data\n        grad_distance!(M, grad_f!.tmp, di, p)\n        X .+= grad_f!.tmp\n    end\n    X ./= length(grad_f!.data)\n    return X\nend\n\nFor the actual call to the solver, we first have to generate an instance of GradF! and tell the solver, that the gradient is provided in an InplaceEvaluation. We can further also use gradient_descent! to even work in-place of the initial point we pass.\n\ngrad_f2! = GradF!(data, similar(data[1]))\nm2 = deepcopy(p0)\ngradient_descent!(\n    M, f, grad_f2!, m2; evaluation=InplaceEvaluation(), stopping_criterion=sc\n);\n\nWe can again benchmark this\n\n@benchmark gradient_descent!(\n    $M, $f, $grad_f2!, m2; evaluation=$(InplaceEvaluation()), stopping_criterion=$sc\n) setup = (m2 = deepcopy($p0))\n\nBenchmarkTools.Trial: 137 samples with 1 evaluation per sample.\n Range (min â€¦ max):  35.297 ms â€¦ 49.118 ms  â”Š GC (min â€¦ max): 0.00% â€¦ 25.92%\n Time  (median):     35.863 ms              â”Š GC (median):    0.00%\n Time  (mean Â± Ïƒ):   36.604 ms Â±  1.640 ms  â”Š GC (mean Â± Ïƒ):  0.67% Â±  2.89%\n\n   â–‡â–‡â–ˆ                                                         \n  â–‡â–ˆâ–ˆâ–ˆâ–ƒâ–…â–„â–…â–„â–ƒâ–ƒâ–…â–…â–…â–ƒâ–ˆâ–‡â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒ â–ƒ\n  35.3 ms         Histogram: frequency by time        44.1 ms <\n\n Memory estimate: 3.72 MiB, allocs estimate: 6879.\n\nwhich is faster by about a factor of 2 compared to the first solver-call. Note that the results m1 and m2 are of course the same.\n\ndistance(M, m1, m2)\n\n4.8317610992693745e-11","category":"section"},{"location":"tutorials/InplaceGradient/#Technical-details","page":"Speedup using in-place computations","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/Repositories/Julia/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.14.0\n  [6e4b80f9] BenchmarkTools v1.6.0\n  [5ae59095] Colors v0.13.0\n  [31c24e10] Distributions v0.25.119\n  [26cc04aa] FiniteDifferences v0.12.32\n  [7073ff75] IJulia v1.27.0\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.2\n  [1cead3c2] Manifolds v0.10.17\n  [3362f125] ManifoldsBase v1.1.0\n  [0fc0a36d] Manopt v0.5.14 `..`\n  [91a5bcdd] Plots v1.40.13\n  [731186ca] RecursiveArrayTools v3.33.0\n\nThis tutorial was last rendered May 2, 2025, 15:48:41.","category":"section"},{"location":"plans/state/#sec-solver-state","page":"Solver State","title":"Solver state","text":"Given an AbstractManoptProblem, that is a certain optimisation task, the state specifies the solver to use. It contains the parameters of a solver and all fields necessary during the algorithm, for example the current iterate, a StoppingCriterion or a Stepsize.\n\nSince every subtype of an AbstractManoptSolverState directly relate to a solver, the concrete states are documented together with the corresponding solvers. This page documents the general features available for every state.\n\nA first example is to obtain or set, the current iterate. This might be useful to continue investigation at the current iterate, or to set up a solver for a next experiment, respectively.\n\nAn internal function working on the state and elements within a state is used to pass messages from (sub) activities of a state to the corresponding DebugMessages\n\nFurthermore, to access the stopping criterion use","category":"section"},{"location":"plans/state/#Decorators-for-AbstractManoptSolverStates","page":"Solver State","title":"Decorators for AbstractManoptSolverStates","text":"A solver state can be decorated using the following trait and function to initialize\n\nA simple example is the\n\nas well as DebugSolverState and RecordSolverState.","category":"section"},{"location":"plans/state/#State-actions","page":"Solver State","title":"State actions","text":"A state action is a struct for callback functions that can be attached within for example the just mentioned debug decorator or the record decorator.\n\nSeveral state decorators or actions might store intermediate values like the (last) iterate to compute some change or the last gradient. In order to minimise the storage of these, there is a generic StoreStateAction that acts as generic common storage that can be shared among different actions.\n\nas well as two internal functions","category":"section"},{"location":"plans/state/#Abstract-states","page":"Solver State","title":"Abstract states","text":"In a few cases it is useful to have a hierarchy of types. These are\n\nFor the sub problem state, there are two access functions","category":"section"},{"location":"plans/state/#Manopt.AbstractManoptSolverState","page":"Solver State","title":"Manopt.AbstractManoptSolverState","text":"AbstractManoptSolverState\n\nA general super type for all solver states.\n\nFields\n\nThe following fields are assumed to be default. If you use different ones, adapt the the access functions get_iterate and get_stopping_criterion accordingly\n\np::P: a point on the manifold mathcalM  storing the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.get_state","page":"Solver State","title":"Manopt.get_state","text":"get_state(s::AbstractManoptSolverState, recursive::Bool=true)\n\nreturn the (one step) undecorated AbstractManoptSolverState of the (possibly) decorated s. As long as your decorated state stores the state within s.state and the dispatch_objective_decorator is set to Val{true}, the internal state are extracted automatically.\n\nBy default the state that is stored within a decorated state is assumed to be at s.state. Overwrite _get_state(s, ::Val{true}, recursive) to change this behaviour for your states` for both the recursive and the direct case.\n\nIf recursive is set to false, only the most outer decorator is taken away instead of all.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_count","page":"Solver State","title":"Manopt.get_count","text":"get_count(ams::AbstractManoptSolverState, ::Symbol)\n\nObtain the count for a certain countable size, for example the :Iterations. This function returns 0 if there was nothing to count\n\nAvailable symbols from within the solver state\n\n:Iterations is passed on to the stop field to obtain the iteration at which the solver stopped.\n\n\n\n\n\nget_count(co::ManifoldCountObjective, s::Symbol, mode::Symbol=:None)\n\nGet the number of counts for a certain symbol s.\n\nDepending on the mode different results appear if the symbol does not exist in the dictionary\n\n:None:  (default) silent mode, returns -1 for non-existing entries\n:warn:  issues a warning if a field does not exist\n:error: issues an error if a field does not exist\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.has_converged-Tuple{AbstractManoptSolverState}","page":"Solver State","title":"Manopt.has_converged","text":"has_converged(ams::AbstractManoptSolverState)\n\nReturn whether the solver has converged, based on the internal StoppingCriterion.\n\n\n\n\n\n","category":"method"},{"location":"plans/state/#Manopt.get_iterate","page":"Solver State","title":"Manopt.get_iterate","text":"get_iterate(O::AbstractManoptSolverState)\n\nreturn the (last stored) iterate within AbstractManoptSolverStates`. This should usually refer to a single point on the manifold the solver is working on\n\nBy default this also removes all decorators of the state beforehand.\n\n\n\n\n\nget_iterate(agst::AbstractGradientSolverState)\n\nreturn the iterate stored within gradient options. THe default returns agst.p.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.set_iterate!","page":"Solver State","title":"Manopt.set_iterate!","text":"set_iterate!(s::AbstractManoptSolverState, M::AbstractManifold, p)\n\nset the iterate within an AbstractManoptSolverState to some (start) value p.\n\n\n\n\n\nset_iterate!(agst::AbstractGradientSolverState, M, p)\n\nset the (current) iterate stored within an AbstractGradientSolverState to p. The default function modifies s.p.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_gradient-Tuple{AbstractManoptSolverState}","page":"Solver State","title":"Manopt.get_gradient","text":"get_gradient(s::AbstractManoptSolverState)\n\nreturn the (last stored) gradient within AbstractManoptSolverStates`. By default also undecorates the state beforehand\n\n\n\n\n\n","category":"method"},{"location":"plans/state/#Manopt.set_gradient!","page":"Solver State","title":"Manopt.set_gradient!","text":"set_gradient!(s::AbstractManoptSolverState, M::AbstractManifold, p, X)\n\nset the gradient within an (possibly decorated) AbstractManoptSolverState to some (start) value X in the tangent space at p.\n\n\n\n\n\nset_gradient!(agst::AbstractGradientSolverState, M, p, X)\n\nset the (current) gradient stored within an AbstractGradientSolverState to X. The default function modifies s.X.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_message","page":"Solver State","title":"Manopt.get_message","text":"get_message(a)\n\nGiven a certain structure a from within Manopt.jl, retrieve its last message of information, e.g. warnings from a step size. If no message is available, an empty string is returned.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_stopping_criterion","page":"Solver State","title":"Manopt.get_stopping_criterion","text":"get_stopping_criterion(ams::AbstractManoptSolverState)\n\nReturn the StoppingCriterion stored within the AbstractManoptSolverState ams.\n\nFor an undecorated state, this is assumed to be in ams.stop. Overwrite _get_stopping_criterion(yms::YMS) to change this for your manopt solver (yms) assuming it has type YMS`.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.dispatch_state_decorator","page":"Solver State","title":"Manopt.dispatch_state_decorator","text":"dispatch_state_decorator(s::AbstractManoptSolverState)\n\nIndicate internally, whether an AbstractManoptSolverState s is of decorating type, and stores (encapsulates) a state in itself, by default in the field s.state.\n\nDecorators indicate this by returning Val{true} for further dispatch.\n\nThe default is Val{false}, so by default a state is not decorated.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.is_state_decorator","page":"Solver State","title":"Manopt.is_state_decorator","text":"is_state_decorator(s::AbstractManoptSolverState)\n\nIndicate, whether AbstractManoptSolverState s are of decorator type.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.decorate_state!","page":"Solver State","title":"Manopt.decorate_state!","text":"decorate_state!(s::AbstractManoptSolverState)\n\ndecorate the AbstractManoptSolverStates with specific decorators.\n\nOptional arguments\n\noptional arguments provide necessary details on the decorators.\n\ncallback=missing add an arbitrary (simple) callback function cb() to be called every iteration.\ndebug=Array{Union{Symbol,DebugAction,String,Int, Function},1}(): a set of symbols representing DebugActions, Strings used as dividers and a sub-sampling integer. These are passed as a DebugGroup within :Iteration to the DebugSolverState decorator dictionary. A function is added as a (non-simple) callback within a DebugCallback. Only exception is :Stop that is passed to :Stop.\nrecord=Array{Union{Symbol,RecordAction,Int},1}(): specify recordings by using Symbols or RecordActions directly. An integer can again be used for only recording every ith iteration.\nreturn_state=false: indicate whether to wrap the options in a ReturnSolverState, indicating that the solver should return options and not (only) the minimizer.\n\nother keywords are ignored.\n\nSee also\n\nDebugSolverState, RecordSolverState, ReturnSolverState\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.ReturnSolverState","page":"Solver State","title":"Manopt.ReturnSolverState","text":"ReturnSolverState{O<:AbstractManoptSolverState} <: AbstractManoptSolverState\n\nThis internal type is used to indicate that the contained AbstractManoptSolverState state should be returned at the end of a solver instead of the usual minimizer.\n\nSee also\n\nget_solver_result\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractStateAction","page":"Solver State","title":"Manopt.AbstractStateAction","text":"AbstractStateAction\n\na common Type for AbstractStateActions that might be triggered in decorators, for example within the DebugSolverState or within the RecordSolverState.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.StoreStateAction","page":"Solver State","title":"Manopt.StoreStateAction","text":"StoreStateAction <: AbstractStateAction\n\ninternal storage for AbstractStateActions to store a tuple of fields from an AbstractManoptSolverStates\n\nThis functor possesses the usual interface of functions called during an iteration and acts on (p, s, k), where p is a AbstractManoptProblem, s is an AbstractManoptSolverState and k is the current iteration.\n\nFields\n\nvalues:        a dictionary to store interim values based on certain Symbols\nkeys:          a Vector of Symbols to refer to fields of AbstractManoptSolverState\npoint_values:  a NamedTuple of mutable values of points on a manifold to be stored in StoreStateAction. Manifold is later determined by AbstractManoptProblem passed to update_storage!.\npoint_init:    a NamedTuple of boolean values indicating whether a point in point_values with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector keys.\nvector_values: a NamedTuple of mutable values of tangent vectors on a manifold to be stored in StoreStateAction. Manifold is later determined by AbstractManoptProblem passed to update_storage!. It is not specified at which point the vectors are tangent but for storage it should not matter.\nvector_init:   a NamedTuple of boolean values indicating whether a tangent vector in vector_values: with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector keys.\nonce:          whether to update the internal values only once per iteration\nlastStored:    last iterate, where this AbstractStateAction was called (to determine once)\n\nTo handle the general storage, use get_storage and has_storage with keys as Symbols. For the point storage use PointStorageKey. For tangent vector storage use VectorStorageKey. Point and tangent storage have been optimized to be more efficient.\n\nConstructors\n\nStoreStateAction(s::Vector{Symbol})\n\nThis is equivalent as providing s to the keyword store_fields, just that here, no manifold is necessity for the construction.\n\nStoreStateAction(M)\n\nKeyword arguments\n\nstore_fields (Symbol[])\nstore_points (Symbol[])\nstore_vectors (Symbol[])\n\nas vectors of symbols each referring to fields of the state (lower case symbols) or semantic ones (upper case).\n\np_init (rand(M)) but making sure this is not a number but a (mutable) array\nX_init (zero_vector(M, p_init))\n\nare used to initialize the point and vector storage, change these if you use other types (than the default) for your points/vectors on M.\n\nonce (true) whether to update internal storage only once per iteration or on every update call\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.get_storage","page":"Solver State","title":"Manopt.get_storage","text":"get_storage(a::AbstractStateAction, key::Symbol)\n\nReturn the internal value of the AbstractStateAction a at the Symbol key.\n\n\n\n\n\nget_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key}\n\nReturn the internal value of the AbstractStateAction a at the Symbol key that represents a point.\n\n\n\n\n\nget_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key}\n\nReturn the internal value of the AbstractStateAction a at the Symbol key that represents a vector.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.has_storage","page":"Solver State","title":"Manopt.has_storage","text":"has_storage(a::AbstractStateAction, key::Symbol)\n\nReturn whether the AbstractStateAction a has a value stored at the Symbol key.\n\n\n\n\n\nhas_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key}\n\nReturn whether the AbstractStateAction a has a point value stored at the Symbol key.\n\n\n\n\n\nhas_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key}\n\nReturn whether the AbstractStateAction a has a point value stored at the Symbol key.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.update_storage!","page":"Solver State","title":"Manopt.update_storage!","text":"update_storage!(a::AbstractStateAction, amp::AbstractManoptProblem, s::AbstractManoptSolverState)\n\nUpdate the AbstractStateAction a internal values to the ones given on the AbstractManoptSolverState s. Optimized using the information from amp\n\n\n\n\n\nupdate_storage!(a::AbstractStateAction, d::Dict{Symbol,<:Any})\n\nUpdate the AbstractStateAction a internal values to the ones given in the dictionary d. The values are merged, where the values from d are preferred.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.PointStorageKey","page":"Solver State","title":"Manopt.PointStorageKey","text":"struct PointStorageKey{key} end\n\nRefer to point storage of StoreStateAction in get_storage and has_storage functions\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.VectorStorageKey","page":"Solver State","title":"Manopt.VectorStorageKey","text":"struct VectorStorageKey{key} end\n\nRefer to tangent storage of StoreStateAction in get_storage and has_storage functions\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt._storage_copy_vector","page":"Solver State","title":"Manopt._storage_copy_vector","text":"_storage_copy_vector(M::AbstractManifold, X)\n\nMake a copy of tangent vector X from manifold M for storage in StoreStateAction.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt._storage_copy_point","page":"Solver State","title":"Manopt._storage_copy_point","text":"_storage_copy_point(M::AbstractManifold, p)\n\nMake a copy of point p from manifold M for storage in StoreStateAction.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.AbstractSubProblemSolverState","page":"Solver State","title":"Manopt.AbstractSubProblemSolverState","text":"AbstractSubProblemSolverState <: AbstractManoptSolverState\n\nAn abstract type for solvers that involve a subsolver.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractGradientSolverState","page":"Solver State","title":"Manopt.AbstractGradientSolverState","text":"AbstractGradientSolverState <: AbstractManoptSolverState\n\nA generic AbstractManoptSolverState type for gradient based options data.\n\nIt assumes that\n\nthe iterate is stored in the field p\nthe gradient at p is stored in X.\n\nSee also\n\nGradientDescentState, StochasticGradientDescentState, SubGradientMethodState, QuasiNewtonState.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractHessianSolverState","page":"Solver State","title":"Manopt.AbstractHessianSolverState","text":"AbstractHessianSolverState <: AbstractGradientSolverState\n\nAn AbstractManoptSolverState type to represent algorithms that employ the Hessian. These options are assumed to have a field (gradient) to store the current gradient operatornamegradf(x)\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractPrimalDualSolverState","page":"Solver State","title":"Manopt.AbstractPrimalDualSolverState","text":"AbstractPrimalDualSolverState\n\nA general type for all primal dual based options to be used within primal dual based algorithms\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.get_sub_problem","page":"Solver State","title":"Manopt.get_sub_problem","text":"get_sub_problem(ams::AbstractSubProblemSolverState)\n\nAccess the sub problem of a solver state that involves a sub optimisation task. By default this returns ams.sub_problem.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_sub_state","page":"Solver State","title":"Manopt.get_sub_state","text":"get_sub_state(ams::AbstractSubProblemSolverState)\n\nAccess the sub state of a solver state that involves a sub optimisation task. By default this returns ams.sub_state.\n\n\n\n\n\n","category":"function"},{"location":"about/#About","page":"About","title":"About","text":"Manopt.jl inherited its name from Manopt, a Matlab toolbox for optimization on manifolds. This Julia package was started and is currently maintained by Ronny Bergmann.","category":"section"},{"location":"about/#Contributors","page":"About","title":"Contributors","text":"Thanks to the following contributors to Manopt.jl:\n\nConstantin Ahlmann-Eltze implemented the gradient and differential check functions\nRenÃ©e Dornig implemented the particle swarm, the Riemannian Augmented Lagrangian Method, the Exact Penalty Method, as well as the NonmonotoneLinesearch. These solvers are also the first one with modular/exchangable sub solvers.\nWillem Diepeveen implemented the primal-dual Riemannian semismooth Newton solver.\nHajg Jasa implemented the convex bundle method and the proximal bundle method and a default subsolver each of them.\nEven Stephansen KjemsÃ¥s contributed to the implementation of the Frank Wolfe Method solver.\nMathias Ravn Munkvold contributed most of the implementation of the Adaptive Regularization with Cubics solver as well as its Lanczos subsolver\nSander Engen Oddsen contributed to the implementation of the LTMADS solver.\nJonas PÃ¼schel contributed restart rules for the conjugate gradient solver.\nTom-Christian Riemer implemented the trust regions and quasi Newton solvers as well as the truncated conjugate gradient descent subsolver.\nMarkus A. Stokkenes contributed most of the implementation of the Interior Point Newton Method as well as its default Conjugate Residual subsolver\nLaura Weigl implemented the Vector bundle Newton Method.\nManuel Weiss implemented most of the conjugate gradient update rules\n\nas well as various contributors providing small extensions, finding small bugs and mistakes and fixing them by opening PRs. Thanks to all of you.\n\nIf you want to contribute a manifold or algorithm or have any questions, visit the GitHub repository to clone/fork the repository or open an issue.","category":"section"},{"location":"about/#Work-using-Manopt.jl","page":"About","title":"Work using Manopt.jl","text":"The following packages are using Manopt.jl:\n\nExponentialFamilyProjection.jl package uses Manopt.jl to project arbitrary functions onto the closest exponential family distributions. The package also integrates with RxInfer.jl to enable Bayesian inference in a larger set of probabilistic models.\nCaesar.jl within non-Gaussian factor graph inference algorithms\nSummationByPartsOperatorsExtra.jl uses Manopt.jl to construct function space summation by parts operators for the numerical solution of partial differential equations.\n\nThe following papers are using Manopt.jl:\n\nGlaubitz, Iske, Lampert and Ã–ffner [GILO26]\n\nIf you are missing a package or paper, that uses Manopt.jl, please open an issue. It would be great to collect anything and anyone using Manopt.jl in this list.","category":"section"},{"location":"about/#Further-packages","page":"About","title":"Further packages","text":"Manopt.jl belongs to the Manopt family:\n\nmanopt.org The Matlab version of Manopt, see also their :octocat: GitHub repository\npymanopt.org The Python version of Manopt providing also several AD backends, see also their :octocat: GitHub repository\n\nbut there are also more packages providing tools on manifolds in other languages\n\nJax Geometry (Python/Jax) for differential geometry and stochastic dynamics with deep learning\nGeomstats (Python with several backends) focusing on statistics and machine learning :octocat: GitHub repository\nGeoopt (Python & PyTorch) Riemannian ADAM & SGD. :octocat: GitHub repository\nMcTorch (Python & PyToch) Riemannian SGD, Adagrad, ASA & CG.\nROPTLIB (C++) a Riemannian OPTimization LIBrary :octocat: GitHub repository\nTF Riemopt (Python & TensorFlow) Riemannian optimization using TensorFlow","category":"section"},{"location":"tutorials/ImplementASolver/#How-to-implementing-your-own-solver","page":"Implement a solver","title":"How to implementing your own solver","text":"Ronny Bergmann\n\nWhen you have used a few solvers from Manopt.jl for example like in the opening tutorial Get started: optimize you might come to the idea of implementing a solver yourself.\n\nAfter a short introduction of the algorithm we aim to implement, this tutorial first discusses the structural details, for example what a solver consists of and â€œworks withâ€. Afterwards, we show how to implement the algorithm. Finally, we discuss how to make the algorithm both nice for the user as well as initialized in a way, that it can benefit from features already available in Manopt.jl.\n\nnote: Note\nIf you have implemented your own solver, we would be very happy to have that within Manopt.jl as well, so maybe consider opening a Pull Request\n\nusing Manopt, Manifolds, Random","category":"section"},{"location":"tutorials/ImplementASolver/#Our-guiding-example:-a-random-walk-minimization","page":"Implement a solver","title":"Our guiding example: a random walk minimization","text":"Since most serious algorithms should be implemented in Manopt.jl themselves directly, we implement a solver that randomly walks on the manifold and keeps track of the lowest point visited. As for algorithms in Manopt.jl we aim to implement this generically for any manifold that is implemented using ManifoldsBase.jl.\n\nThe random walk minimization\n\nGiven:\n\na manifold mathcal M\na starting point p=p^(0)\na cost function f mathcal M  â„.\na parameter sigma  0.\na retraction operatornameretr_p(X) that maps X  T_pmathcal M to the manifold.\n\nWe can run the following steps of the algorithm\n\nset k=0\nset our best point q = p^(0)\nRepeat until a stopping criterion is fulfilled\nChoose a random tangent vector X^(k)  T_p^(k)mathcal M of length lVert X^(k) rVert = sigma\nâ€œWalkâ€ along this direction, that is p^(k+1) = operatornameretr_p^(k)(X^(k))\nIf f(p^(k+1))  f(q) set q = p^{(k+1)}$ as our new best visited point\nReturn q as the resulting best point we visited","category":"section"},{"location":"tutorials/ImplementASolver/#Preliminaries:-elements-a-solver-works-on","page":"Implement a solver","title":"Preliminaries: elements a solver works on","text":"There are two main ingredients a solver needs: a problem to work on and the state of a solver, which â€œidentifiesâ€ the solver and stores intermediate results.","category":"section"},{"location":"tutorials/ImplementASolver/#Specifying-the-task:-an-AbstractManoptProblem","page":"Implement a solver","title":"Specifying the task: an AbstractManoptProblem","text":"A problem in Manopt.jl usually consists of a manifold (an AbstractManifold) and an AbstractManifoldObjective describing the function we have and its features. In our case the objective is (just) a ManifoldCostObjective that stores cost function f(M,p) -> R. More generally, it might for example store a gradient function or the Hessian or any other information we have about our task.\n\nThis is something independent of the solver itself, since it only identifies the problem we want to solve independent of how we want to solve it,Â or in other words, this type contains all information that is static and independent of the specific solver at hand.\n\nUsually the problems variable is called mp.","category":"section"},{"location":"tutorials/ImplementASolver/#Specifying-a-solver:-an-AbstractManoptSolverState","page":"Implement a solver","title":"Specifying a solver: an AbstractManoptSolverState","text":"Everything that is needed by a solver during the iterations, all its parameters, interim values that are needed beyond just one iteration, is stored in a subtype of the AbstractManoptSolverState. This identifies the solver uniquely.\n\nIn our case we want to store five things\n\nthe current iterate p=p^(k)\nthe best visited point q\nthe variable sigma  0\nthe retraction operatornameretr to use (cf.Â retractions and inverse retractions)\na criterion, when to stop: a StoppingCriterion\n\nWe can defined this as\n\nmutable struct RandomWalkState{\n    P,\n    R<:AbstractRetractionMethod,\n    S<:StoppingCriterion,\n} <: AbstractManoptSolverState\n  p::P\n  q::P\n  Ïƒ::Float64\n  retraction_method::R\n  stop::S\nend\n\nThe stopping criterion is usually stored in the stateâ€™s stop field. If you have a reason to do otherwise, you have one more function to implement (see next section). For ease of use, a constructor can be provided, that for example chooses a good default for the retraction based on a given manifold.\n\nfunction RandomWalkState(M::AbstractManifold, p::P=rand(M);\n    Ïƒ = 0.1,\n    retraction_method::R=default_retraction_method(M, typeof(p)),\n    stopping_criterion::S=StopAfterIteration(200)\n) where {P, R<:AbstractRetractionMethod, S<:StoppingCriterion}\n    return RandomWalkState{P,R,S}(p, copy(M, p), Ïƒ, retraction_method, stopping_criterion)\nend\n\nParametrising the state avoid that we have abstract typed fields. The keyword arguments for the retraction and stopping criterion are the ones usually used in Manopt.jl and provide an easy way to construct this state now.\n\nStates usually have a shortened name as their variable, we use rws for our state here.","category":"section"},{"location":"tutorials/ImplementASolver/#Implementing-your-solver","page":"Implement a solver","title":"Implementing your solver","text":"There is basically only two methods we need to implement for our solver\n\ninitialize_solver!(mp, rws) which initialises the solver before the first iteration\nstep_solver!(mp, rws, i) which implements the ith iteration, where i is given to you as the third parameter\nget_iterate(rws) which accesses the iterate from other places in the solver\nget_solver_result(rws) returning the solvers final (best) point we reached. By default this would return the last iterate rws.p (or more precisely calls get_iterate), but since we randomly walk and remember our best point in q, this has to return rws.q.\n\nThe first two functions are in-place functions, that is they modify our solver state rws. You implement these by multiple dispatch on the types after importing said functions from Manopt:\n\nimport Manopt: initialize_solver!, step_solver!, get_iterate, get_solver_result\n\nThe state we defined before has two fields where we use the common names used in Manopt.jl, that is the StoppingCriterion is usually in stop and the iterate in p. If your choice is different, you need to reimplement\n\nstop_solver!(mp, rws, i) to determine whether or not to stop after the ith iteration.\nget_iterate(rws) to access the current iterate\n\nWe recommend to follow the general scheme with the stop field. If you have specific criteria when to stop, consider implementing your own stopping criterion instead.","category":"section"},{"location":"tutorials/ImplementASolver/#Initialization-and-iterate-access","page":"Implement a solver","title":"Initialization and iterate access","text":"For our solver, there is not so much to initialize, just to be safe we should copy over the initial value in p we start with, to q. We do not have to care about remembering the iterate, that is done by Manopt.jl. For the iterate access we just have to pass p.\n\nfunction initialize_solver!(mp::AbstractManoptProblem, rws::RandomWalkState)\n    copyto!(M, rws.q, rws.p) # Set p^{(0)} = q\n    return rws\nend\nget_iterate(rws::RandomWalkState) = rws.p\nget_solver_result(rws::RandomWalkState) = rws.q\n\nand similarly we implement the step. Here we make use of the fact that the problem (and also the objective in fact) have access functions for their elements, the one we need is get_cost.\n\nfunction step_solver!(mp::AbstractManoptProblem, rws::RandomWalkState, i)\n    M = get_manifold(mp) # for ease of use get the manifold from the problem\n    X = rand(M; vector_at=p)     # generate a direction\n    X .*= rws.Ïƒ/norm(M, p, X)\n    # Walk\n    retract!(M, rws.p, rws.p, X, rws.retraction_method)\n    # is the new point better? Then store it\n    if get_cost(mp, rws.p) < get_cost(mp, rws.q)\n        copyto!(M, rws.p, rws.q)\n    end\n    return rws\nend\n\nPerformance wise we could improve the number of allocations by making X also a field of our rws but letâ€™s keep it simple here. We could also store the cost of q in the state, but we shall see how to easily also enable this solver to allow for caching. In practice, however, it is preferable to cache intermediate values like cost of q in the state when it can be easily achieved. This way we do not have to deal with overheads of an external cache.\n\nNow we can just run the solver already. We take the same example as for the other tutorials\n\nWe first define our task, the Riemannian Center of Mass from the Get started: optimize tutorial.\n\nRandom.seed!(23)\nn = 100\nÏƒ = Ï€ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  Ïƒ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\n\nWe can now generate the problem with its objective and the state\n\nmp = DefaultManoptProblem(M, ManifoldCostObjective(f))\ns = RandomWalkState(M; Ïƒ = 0.2)\n\nsolve!(mp, s)\nget_solver_result(s)\n\n3-element Vector{Float64}:\n -0.2412674850987521\n  0.8608618657176527\n -0.44800317943876844\n\nThe function solve! works also in place of s, but the last line illustrates how to access the result in general; we could also just look at s.p, but the function get_iterate is also used in several other places.\n\nWe could for example easily set up a second solver to work from a specified starting point with a different Ïƒ like\n\ns2 = RandomWalkState(M, [1.0, 0.0, 0.0];  Ïƒ = 0.1)\nsolve!(mp, s2)\nget_solver_result(s2)\n\n3-element Vector{Float64}:\n 1.0\n 0.0\n 0.0","category":"section"},{"location":"tutorials/ImplementASolver/#Ease-of-use-I:-a-high-level-interface","page":"Implement a solver","title":"Ease of use I: a high level interface","text":"Manopt.jl offers a few additional features for solvers in their high level interfaces, for example debug= for debug, record= keywords for debug and recording within solver states or count= and cache keywords for the objective.\n\nWe can introduce these here as well with just a few lines of code. There are usually two steps. We further need three internal function from Manopt.jl\n\nusing Manopt: get_solver_return, indicates_convergence, status_summary","category":"section"},{"location":"tutorials/ImplementASolver/#A-high-level-interface-using-the-objective","page":"Implement a solver","title":"A high level interface using the objective","text":"This could be considered as an interim step to the high-level interface: if objective,Â a ManifoldCostObjective is already initialized, the high level interface consists of the steps\n\npossibly decorate the objective\ngenerate the problem\ngenerate and possibly generate the state\ncall the solver\ndetermine the return value\n\nWe illustrate the step with an in-place variant here. A variant that keeps the given start point unchanged would just add a copy(M, p) upfront. Manopt.jl provides both variants.\n\nfunction random_walk_algorithm!(\n    M::AbstractManifold,\n    mgo::ManifoldCostObjective,\n    p;\n    Ïƒ = 0.1,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n    stopping_criterion::StoppingCriterion=StopAfterIteration(200),\n    kwargs...,\n)\n    dmgo = decorate_objective!(M, mgo; kwargs...)\n    dmp = DefaultManoptProblem(M, dmgo)\n    s = RandomWalkState(M, [1.0, 0.0, 0.0];\n        Ïƒ=0.1,\n        retraction_method=retraction_method, stopping_criterion=stopping_criterion,\n    )\n    ds = decorate_state!(s; kwargs...)\n    solve!(dmp, ds)\n    return get_solver_return(get_objective(dmp), ds)\nend\n\nrandom_walk_algorithm! (generic function with 1 method)","category":"section"},{"location":"tutorials/ImplementASolver/#The-high-level-interface","page":"Implement a solver","title":"The high level interface","text":"Starting from the last section, the usual call a user would prefer is just passing a manifold M the cost f and maybe a start point p.\n\nfunction random_walk_algorithm!(M::AbstractManifold, f, p=rand(M); kwargs...)\n    mgo = ManifoldCostObjective(f)\n    return random_walk_algorithm!(M, mgo, p; kwargs...)\nend\n\nrandom_walk_algorithm! (generic function with 3 methods)","category":"section"},{"location":"tutorials/ImplementASolver/#Ease-of-Use-II:-the-state-summary","page":"Implement a solver","title":"Ease of Use II: the state summary","text":"For the case that you set return_state=true the solver should return a summary of the run. When a show method is provided, users can easily read such summary in a terminal. It should reflect its main parameters, if they are not too verbose and provide information about the reason it stopped and whether this indicates convergence.\n\nHere it would for example look like\n\nimport Base: show\nfunction show(io::IO, rws::RandomWalkState)\n    i = get_count(rws, :Iterations)\n    Iter = (i > 0) ? \"After $i iterations\\n\" : \"\"\n    Conv = indicates_convergence(rws.stop) ? \"Yes\" : \"No\"\n    s = \"\"\"\n    # Solver state for `Manopt.jl`s Tutorial Random Walk\n    $Iter\n    ## Parameters\n    * retraction method: $(rws.retraction_method)\n    * Ïƒ                : $(rws.Ïƒ)\n\n    ## Stopping criterion\n\n    $(status_summary(rws.stop))\n    This indicates convergence: $Conv\"\"\"\n    return print(io, s)\nend\n\nNow the algorithm can be easily called and provides all features of a Manopt.jl algorithm. For example to see the summary, we could now just call\n\nq = random_walk_algorithm!(M, f; return_state=true)\n\n# Solver state for `Manopt.jl`s Tutorial Random Walk\nAfter 200 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n* Ïƒ                : 0.1\n\n## Stopping criterion\n\nMax Iteration 200:  reached\nThis indicates convergence: No","category":"section"},{"location":"tutorials/ImplementASolver/#Conclusion-and-beyond","page":"Implement a solver","title":"Conclusion & beyond","text":"We saw in this tutorial how to implement a simple cost-based algorithm, to illustrate how optimization algorithms are covered in Manopt.jl.\n\nOne feature we did not cover is that most algorithms allow for in-place and allocation functions, as soon as they work on more than just the cost, for example use gradients, proximal maps or Hessians. This is usually a keyword argument of the objective and hence also part of the high-level interfaces.","category":"section"},{"location":"tutorials/ImplementASolver/#Technical-details","page":"Implement a solver","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:32:27.","category":"section"},{"location":"solvers/FrankWolfe/#Frankâ€”Wolfe-method","page":"Frank-Wolfe","title":"Frankâ€”Wolfe method","text":"","category":"section"},{"location":"solvers/FrankWolfe/#State","page":"Frank-Wolfe","title":"State","text":"","category":"section"},{"location":"solvers/FrankWolfe/#Helpers","page":"Frank-Wolfe","title":"Helpers","text":"For the inner sub-problem you can easily create the corresponding cost and gradient using\n\nM.Â Weber and S.Â Sra. Riemannian Optimization via Frank-Wolfe Methods. MathematicalÂ Programming 199, 525â€“556 (2022).\n\n\n\n","category":"section"},{"location":"solvers/FrankWolfe/#Manopt.Frank_Wolfe_method","page":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method","text":"Frank_Wolfe_method(M, f, grad_f, p=rand(M))\nFrank_Wolfe_method(M, gradient_objective, p=rand(M); kwargs...)\nFrank_Wolfe_method!(M, f, grad_f, p; kwargs...)\nFrank_Wolfe_method!(M, gradient_objective, p; kwargs...)\n\nPerform the Frank-Wolfe algorithm to compute for mathcalC  mathcalM the constrained problem\n\n    operatorname*argmin_pmathcalC f(p)\n\nwhere the main step is a constrained optimisation is within the algorithm, that is the sub problem (Oracle)\n\n   operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq\n\nfor every iterate p_k together with a stepsize s_k1. The algorithm can be performed in-place of p.\n\nThis algorithm is inspired by but slightly more general than [WS22].\n\nThe next iterate is then given by p_k+1 = Î³_p_kq_k(s_k), where by default Î³ is the shortest geodesic between the two points but can also be changed to use a retraction and its inverse.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldFirstOrderObjective gradient_objective directly.\n\nKeyword arguments\n\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=DecreasingStepsize(; length=2.0, shift=2): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6): a functor indicating that the stopping criterion is fulfilled\nsub_cost=FrankWolfeCost(p, X): the cost of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=FrankWolfeGradient(p, X): the gradient of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=ManifoldGradientObjective(sub_cost, sub_gradient): the objective for the Frank-Wolfe sub problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =GradientDescentState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\nsub_stopping_criterion::StoppingCriterion=StopAfterIteration(300)|StopWhenStepsizeLess(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide a ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/FrankWolfe/#Manopt.Frank_Wolfe_method!","page":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method!","text":"Frank_Wolfe_method(M, f, grad_f, p=rand(M))\nFrank_Wolfe_method(M, gradient_objective, p=rand(M); kwargs...)\nFrank_Wolfe_method!(M, f, grad_f, p; kwargs...)\nFrank_Wolfe_method!(M, gradient_objective, p; kwargs...)\n\nPerform the Frank-Wolfe algorithm to compute for mathcalC  mathcalM the constrained problem\n\n    operatorname*argmin_pmathcalC f(p)\n\nwhere the main step is a constrained optimisation is within the algorithm, that is the sub problem (Oracle)\n\n   operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq\n\nfor every iterate p_k together with a stepsize s_k1. The algorithm can be performed in-place of p.\n\nThis algorithm is inspired by but slightly more general than [WS22].\n\nThe next iterate is then given by p_k+1 = Î³_p_kq_k(s_k), where by default Î³ is the shortest geodesic between the two points but can also be changed to use a retraction and its inverse.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nAlternatively to f and grad_f you can provide the corresponding AbstractManifoldFirstOrderObjective gradient_objective directly.\n\nKeyword arguments\n\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=DecreasingStepsize(; length=2.0, shift=2): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenGradientNormLess(1.0e-6): a functor indicating that the stopping criterion is fulfilled\nsub_cost=FrankWolfeCost(p, X): the cost of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_grad=FrankWolfeGradient(p, X): the gradient of the Frank-Wolfe sub problem. This is used to define the sub_objective= keyword and has hence no effect, if you set sub_objective directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_objective=ManifoldGradientObjective(sub_cost, sub_gradient): the objective for the Frank-Wolfe sub problem. This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_problem::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M, sub_objective):  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =GradientDescentState(M, copy(M,p)):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\nsub_stopping_criterion::StoppingCriterion=StopAfterIteration(300)|StopWhenStepsizeLess(1e-8): a functor indicating that the stopping criterion is fulfilled This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nIf you provide a ManifoldFirstOrderObjective directly, the evaluation= keyword is ignored. The decorations are still applied to the objective.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeState","page":"Frank-Wolfe","title":"Manopt.FrankWolfeState","text":"FrankWolfeState <: AbstractManoptSolverState\n\nA struct to store the current state of the Frank_Wolfe_method\n\nIt comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\nX::T: a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nThe sub task requires a method to solve\n\n   operatorname*argmin_q  C operatornamegrad f(p_k) log_p_kq\n\nConstructor\n\nFrankWolfeState(M, sub_problem, sub_state; kwargs...)\n\nInitialise the Frank Wolfe method state.\n\nFrankWolfeState(M, sub_problem; evaluation=AllocatingEvaluation(), kwargs...)\n\nInitialise the Frank Wolfe method state, where sub_problem is a closed form solution with evaluation as type of evaluation.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nKeyword arguments\n\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=default_stepsize(M,FrankWolfeState): a functor inheriting from Stepsize to determine a step size\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nwhere the remaining fields from before are keyword arguments.\n\n\n\n\n\n","category":"type"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeCost","page":"Frank-Wolfe","title":"Manopt.FrankWolfeCost","text":"FrankWolfeCost{P,T}\n\nA structure to represent the oracle sub problem in the Frank_Wolfe_method. The cost function reads\n\nF(q) = X log_p q\n\nThe values p and X are stored within this functor and should be references to the iterate and gradient from within FrankWolfeState.\n\n\n\n\n\n","category":"type"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeGradient","page":"Frank-Wolfe","title":"Manopt.FrankWolfeGradient","text":"FrankWolfeGradient{P,T}\n\nA structure to represent the gradient of the oracle sub problem in the Frank_Wolfe_method, that is for a given point p and a tangent vector X the function reads\n\nF(q) = X log_p q\n\nIts gradient can be computed easily using adjoint_differential_log_argument.\n\nThe values p and X are stored within this functor and should be references to the iterate and gradient from within FrankWolfeState.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/HowToDebug/#How-to-print-debug-output","page":"Print debug output","title":"How to print debug output","text":"Ronny Bergmann\n\nThis tutorial aims to illustrate how to perform debug output. For that we consider an example that includes a subsolver, to also consider their debug capabilities.\n\nThe problem itself is hence not the main focus. We consider a nonnegative PCA which we can write as a constraint problem on the Sphere\n\nLetâ€™s first load the necessary packages.\n\nusing Manopt, Manifolds, Random, LinearAlgebra\nRandom.seed!(42);\n\nd = 4\nM = Sphere(d - 1)\nv0 = project(M, [ones(2)..., zeros(d - 2)...])\nZ = v0 * v0'\n#Cost and gradient\nf(M, p) = -tr(transpose(p) * Z * p) / 2\ngrad_f(M, p) = project(M, p, -transpose.(Z) * p / 2 - Z * p / 2)\n# Constraints\ng(M, p) = -p # now p â‰¥ 0\nmI = -Matrix{Float64}(I, d, d)\n# Vector of gradients of the constraint components\ngrad_g(M, p) = [project(M, p, mI[:, i]) for i in 1:d]\n\nThen we can take a starting point\n\np0 = project(M, [ones(2)..., zeros(d - 3)..., 0.1])","category":"section"},{"location":"tutorials/HowToDebug/#Simple-debug-output","page":"Print debug output","title":"Simple debug output","text":"Any solver accepts the keyword debug=, which in the simplest case can be set to an array of strings, symbols and a number.\n\nStrings are printed in every iteration as is (cf.Â DebugDivider) and should be used to finish the array with a line break.\nthe last number in the array is used with DebugEvery to print the debug only every ith iteration.\nAny Symbol is converted into certain debug prints\n\nCertain symbols starting with a capital letter are mapped to certain prints, for example :Cost is mapped to DebugCost() to print the current cost function value. A full list is provided in the DebugActionFactory. A special keyword is :Stop, which is only added to the final debug hook to print the stopping criterion.\n\nAny symbol with a small letter is mapped to fields of the AbstractManoptSolverState which is used. This way you can easily print internal data, if you know their names.\n\nLetâ€™s look at an example first: if we want to print the current iteration number, the current cost function value as well as the value Ïµ from the ExactPenaltyMethodState. To keep the amount of print at a reasonable level, we want to only print the debug every twenty-fifth iteration.\n\nThen we can write\n\np1 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [:Iteration, :Cost, \" | \", (:Ïµ,\"Ïµ: %.8f\"), 25, \"\\n\", :Stop]\n);\n\nInitial f(x): -0.497512 | Ïµ: 0.00100000\n# 25    f(x): -0.499449 | Ïµ: 0.00017783\n# 50    f(x): -0.499996 | Ïµ: 0.00003162\n# 75    f(x): -0.500000 | Ïµ: 0.00000562\n# 100   f(x): -0.500000 | Ïµ: 0.00000100\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.","category":"section"},{"location":"tutorials/HowToDebug/#Specifying-when-to-print-something","page":"Print debug output","title":"Specifying when to print something","text":"While in the last step, we specified what to print, this can be extend to even specify when to print it. Currently the following four â€œplacesâ€ are available, ordered by when they appear in an algorithm run.\n\n:Start to print something at the start of the algorithm. At this place all other (the following) places are â€œresetâ€, by triggering each of them with an iteration number 0\n:BeforeIteration to print something before an iteration starts\n:Iteration to print something after an iteration. For example the group of prints from the last code block [:Iteration, :Cost, \" | \", :Ïµ, 25,] is added to this entry.\n:Stop to print something when the algorithm stops. In the example, the :Stop adds the DebugStoppingCriterion is added to this place.\n\nSpecifying something especially for one of these places is done by specifying a Pair, so for example :BeforeIteration => :Iteration would add the display of the iteration number to be printed before the iteration is performed.\n\nChanging this in the run does not change the output. Being more precise for the other entries, we could also write\n\np1 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [\n        :BeforeIteration => [:Iteration],\n        :Iteration => [:Cost, \" | \", :Ïµ, \"\\n\"],\n        :Stop => DebugStoppingCriterion(),\n        25,\n    ],\n);\n\nInitial f(x): -0.497512 | Ïµ: 0.001\n# 25    f(x): -0.499449 | Ïµ: 0.0001778279410038921\n# 50    f(x): -0.499996 | Ïµ: 3.1622776601683734e-5\n# 75    f(x): -0.500000 | Ïµ: 5.623413251903474e-6\n# 100   f(x): -0.500000 | Ïµ: 1.0e-6\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.\n\nThis also illustrates, that instead of Symbols we can also always pass down a DebugAction directly, for example when there is a reason to create or configure the action more individually than the default from the symbol. Note that the number (25) yields that all but :Start and :Stop are only displayed every twenty-fifth iteration.","category":"section"},{"location":"tutorials/HowToDebug/#Subsolver-debug","page":"Print debug output","title":"Subsolver debug","text":"Sub solvers have a sub_kwargs keyword, such that you can pass keywords to the sub solver as well. This works well if you do not plan to change the subsolver. If you do you can wrap your own solver_state= argument in a decorate_state! and pass a debug= password to this function call. Keywords in a keyword have to be passed as pairs (:debug => [...]).\n\nFor most debugs, there further exists a longer form to specify the format to print. We want to use this to specify the format to print Ïµ. This is done by putting the corresponding symbol together with the string to use in formatting into a tuple like (:Ïµ,\" | Ïµ: %.8f\"), where we can already include the divider as well.\n\nA main problem now is, that this debug is issued every sub solver call or initialisation, as the following print of just a . per sub solver test/call illustrates\n\np3 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [\"\\n\",:Iteration, DebugCost(), (:Ïµ,\" | Ïµ: %.8f\"), 25, \"\\n\", :Stop],\n    sub_kwargs = [:debug => [\".\"]]\n);\n\nInitial f(x): -0.497512 | Ïµ: 0.00100000\n....................................................................................\n# 25    f(x): -0.499449 | Ïµ: 0.00017783\n.......................................................................\n# 50    f(x): -0.499996 | Ïµ: 0.00003162\n..................................................\n# 75    f(x): -0.500000 | Ïµ: 0.00000562\n..................................................\n# 100   f(x): -0.500000 | Ïµ: 0.00000100\n....The value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.\n\nThe different lengths of the dotted lines come from the fact that â€”at least in the beginningâ€” the subsolver performs a few steps and each sub solvers step prints a dot.\n\nFor this issue, there is the next symbol (similar to the :Stop) to indicate that a debug set is a subsolver set :WhenActive, which introduces a DebugWhenActive that is only activated when the outer debug is actually active, or another words DebugEvery is active itself. Furthermore, we want to print the iteration number before printing the sub solvers steps, so we put this into a Pair, but we can leave the remaining ones as single entries. Finally we also prefix :Stop with \" | \" and print the iteration number at the time we stop. We get\n\np4 = exact_penalty_method(\n    M,\n    f,\n    grad_f,\n    p0;\n    g=g,\n    grad_g=grad_g,\n    debug=[\n        :BeforeIteration => [:Iteration, \"\\n\"],\n        :Iteration => [DebugCost(), (:Ïµ, \" | Ïµ: %.8f\"), \"\\n\"],\n        :Stop,\n        25,\n    ],\n    sub_kwargs=[\n        :debug => [\n            \" | \",\n            :Iteration,\n            :Cost,\n            \"\\n\",\n            :WhenActive,\n            :Stop => [(:Stop, \" | \"), \" | stopped after iteration \", :Iteration, \"\\n\"],\n        ],\n    ],\n);\n\nInitial \nf(x): -0.497512 | Ïµ: 0.00100000\n | Initial f(x): -0.498944\n | # 1     f(x): -0.498969\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (3.4995246389889393e-5) is less than 0.001.\n | stopped after iteration # 1     \n# 25    \nf(x): -0.499449 | Ïµ: 0.00017783\n | Initial f(x): -0.499992\n | # 1     f(x): -0.499992\n | # 2     f(x): -0.499992\n | The algorithm reached approximately critical point after 2 iterations; the gradient norm (0.00027436723916614357) is less than 0.001.\n | stopped after iteration # 2     \n# 50    \nf(x): -0.499996 | Ïµ: 0.00003162\n | Initial f(x): -0.500000\n | # 1     f(x): -0.500000\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (5.000404403276731e-6) is less than 0.001.\n | stopped after iteration # 1     \n# 75    \nf(x): -0.500000 | Ïµ: 0.00000562\n | Initial f(x): -0.500000\n | # 1     f(x): -0.500000\n | The algorithm reached approximately critical point after 1 iterations; the gradient norm (4.202215558182484e-6) is less than 0.001.\n | stopped after iteration # 1     \n# 100   \nf(x): -0.500000 | Ïµ: 0.00000100\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.\n\nwhere we now see that the subsolver always only requires one step. Note that since debug of an iteration is happening after a step, we see the sub solver run before the debug for an iteration number.","category":"section"},{"location":"tutorials/HowToDebug/#Advanced-debug-output","page":"Print debug output","title":"Advanced debug output","text":"There is two more advanced variants that can be used. The first is a tuple of a symbol and a string, where the string is used as the format print, that most DebugActions have. The second is, to directly provide a DebugAction.\n\nWe can for example change the way the :Ïµ is printed by adding a format string and use DebugCost() which is equivalent to using :Cost. Especially with the format change, the lines are more consistent in length.\n\np2 = exact_penalty_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug = [:Iteration, DebugCost(), (:Ïµ,\" | Ïµ: %.8f\"), 25, \"\\n\", :Stop]\n);\n\nInitial f(x): -0.497512 | Ïµ: 0.00100000\n# 25    f(x): -0.499449 | Ïµ: 0.00017783\n# 50    f(x): -0.499996 | Ïµ: 0.00003162\n# 75    f(x): -0.500000 | Ïµ: 0.00000562\n# 100   f(x): -0.500000 | Ïµ: 0.00000100\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (4.2533629774851707e-7) less than 1.0e-6.\n\nYou can also write your own DebugAction functor, where the function to implement has the same signature as the step function, that is an AbstractManoptProblem, an AbstractManoptSolverState, as well as the current iterate. For example the already mentionedDebugDivider(s) is given as\n\nmutable struct DebugDivider{TypeIO<:IO} <: DebugAction\n    io::TypeIO\n    divider::String\n    DebugDivider(divider=\" | \"; io::IO=stdout) = new{typeof(io)}(io, divider)\nend\nfunction (d::DebugDivider)(::AbstractManoptProblem, ::AbstractManoptSolverState, k::Int)\n    (k >= 0) && (!isempty(d.divider)) && (print(d.io, d.divider))\n    return nothing\nend","category":"section"},{"location":"tutorials/HowToDebug/#Using-callbacks","page":"Print debug output","title":"Using callbacks","text":"If you prefer to write debugs as callbacks, this is also possible since Manopt 0.5.18. There are two variants, a simple and a default variant, that maybe fits a bit better the scheme introduced before.\n\nFor the simple variant, you can just implement a function cb() to perform what ever you like. We illustrate this as follows, where we wrap the code in a function for better scoping. Here we just count the number of iterations.\n\nfunction run_with_callback()\n    n = 0\n    callback() = (n += 1)\n    exact_penalty_method(M, f, grad_f, p0; g=g, grad_g=grad_g, callback=callback);\n    return n\nend\nrun_with_callback()\n\n103\n\nThis â€œsimpleâ€ mode has the disadvantage, that we do not have access to anything else from â€œwithinâ€ the solver and it is called both in the initialisation (at â€œiterate 0â€), hence it counts one step more than the previous stopping criterion. Therefore, passing a function to debug= is the way to activate the (extended) variant, where the callback has to have the same form as the action functor. The following example stores the last gradient the subsolver computed in last_X, to illustrate how to access elements from even the subsolvers state.\n\nfunction run_with_callback2()\n    last_X = zero_vector(M, p0)\n    callback2(problem, state, k) = copyto!(M, last_X, get_iterate(state), get_gradient(state.sub_state))\n    exact_penalty_method(M, f, grad_f, p0; g=g, grad_g=grad_g, debug=callback2);\n    return last_X\nend\nrun_with_callback2()\n\n4-element Vector{Float64}:\n  1.7887803827258762e-11\n  1.7887803827258762e-11\n -1.1196817936117585e-6\n -1.1196817936117585e-6\n\nThe full form here would also be possible, calling Manopt.DebugCallback(callback2) or analogously Manopt.DebugCallback(callback; simple=true) and use that in arrays or DebugGroups as before. The callback2 can also be part of a whole debug = [...] array, similarly within a dictionary to add callbacks only to the end of an algorithm (:Stop => callback2) or to :BeforeIteration as illustrated.","category":"section"},{"location":"tutorials/HowToDebug/#Technical-details","page":"Print debug output","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:31:33.","category":"section"},{"location":"solvers/particle_swarm/#Particle-swarm-optimization","page":"Particle Swarm Optimization","title":"Particle swarm optimization","text":"","category":"section"},{"location":"solvers/particle_swarm/#State","page":"Particle Swarm Optimization","title":"State","text":"","category":"section"},{"location":"solvers/particle_swarm/#Stopping-criteria","page":"Particle Swarm Optimization","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/particle_swarm/#sec-arc-technical-details","page":"Particle Swarm Optimization","title":"Technical details","text":"The particle_swarm solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= does not have to be specified.\nBy default the stopping criterion uses the norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nTangent vectors storing the social and cognitive vectors are initialized calling zero_vector(M,p).\nA copyto!(M, q, p) and copy(M,p) for points.\nThe distance(M, p, q) when using the default stopping criterion, which uses StopWhenChangeLess.","category":"section"},{"location":"solvers/particle_swarm/#Literature","page":"Particle Swarm Optimization","title":"Literature","text":"P.Â B.Â Borckmans, M.Â Ishteva and P.-A.Â Absil. A Modified Particle Swarm Optimization Algorithm for the Best Low Multilinear Rank Approximation of Higher-Order Tensors. In: 7th International Conference on Swarm INtelligence (Springer Berlin Heidelberg, 2010); pp.Â 13â€“23.\n\n\n\n","category":"section"},{"location":"solvers/particle_swarm/#Manopt.particle_swarm","page":"Particle Swarm Optimization","title":"Manopt.particle_swarm","text":"patricle_swarm(M, f; kwargs...)\npatricle_swarm(M, f, swarm; kwargs...)\npatricle_swarm(M, mco::AbstractManifoldCostObjective; kwargs..)\npatricle_swarm(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\nparticle_swarm!(M, f, swarm; kwargs...)\nparticle_swarm!(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\n\nperform the particle swarm optimization algorithm (PSO) to solve\n\noperatorname*argmin_p  mathcalM f(p)\n\nPSO starts with an initial swarm [BIA10] of points on the manifold. If no swarm is provided, the swarm_size keyword is used to generate random points. The computation can be performed in-place of swarm.\n\nTo this end, a swarm S = s_1 s_n of particles is moved around the manifold M in the following manner. For every particle s_k^(i) the new particle velocities X_k^(i) are computed in every step i of the algorithm by\n\nX_k^(i) = Ï‰ mathcal T_s_k^(i-1)s_k^(i) X_k^(i-1) + c r_1  operatornameretr^-1_s_k^(i)(p_k^(i)) + s r_2 operatornameretr^-1_s_k^(i)(p)\n\nwhere\n\ns_k^(i) is the current particle position,\nÏ‰ denotes the inertia,\nc and s are a cognitive and a social weight, respectively,\nr_j, j=12 are random factors which are computed new for each particle and step\n\\mathcal T_{â‹…â†â‹…} is a vector transport, and\n\\operatorname{retr}^{-1} is an inverse retraction\n\nThen the position of the particle is updated as\n\ns_k^(i+1) = operatornameretr_s_k^(i)(X_k^(i))\n\nThen the single particles best entries p_k^(i) are updated as\n\np_k^(i+1) = begincases\ns_k^(i+1)   textif  F(s_k^(i+1))F(p_k^(i))\np_k^(i)  textelse\nendcases\n\nand the global best position\n\ng^(i+1) = begincases\np_k^(i+1)   textif  F(p_k^(i+1))F(g_k^(i))\ng_k^(i)  textelse\nendcases\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nswarm = [rand(M) for _ in 1:swarm_size]: an initial swarm of points.\n\nInstead of a cost function f you can also provide an AbstractManifoldCostObjective mco.\n\nKeyword Arguments\n\ncognitive_weight=1.4: a cognitive weight factor\ninertia=0.65: the inertia of the particles\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nsocial_weight=1.4: a social weight factor\nswarm_size=100: swarm size, if it should be generated randomly\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenChangeLess(1e-4): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvelocity:                  a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles, per default a random tangent vector per initial position\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively. If you provide the objective directly, these decorations can still be specified\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/particle_swarm/#Manopt.particle_swarm!","page":"Particle Swarm Optimization","title":"Manopt.particle_swarm!","text":"patricle_swarm(M, f; kwargs...)\npatricle_swarm(M, f, swarm; kwargs...)\npatricle_swarm(M, mco::AbstractManifoldCostObjective; kwargs..)\npatricle_swarm(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\nparticle_swarm!(M, f, swarm; kwargs...)\nparticle_swarm!(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\n\nperform the particle swarm optimization algorithm (PSO) to solve\n\noperatorname*argmin_p  mathcalM f(p)\n\nPSO starts with an initial swarm [BIA10] of points on the manifold. If no swarm is provided, the swarm_size keyword is used to generate random points. The computation can be performed in-place of swarm.\n\nTo this end, a swarm S = s_1 s_n of particles is moved around the manifold M in the following manner. For every particle s_k^(i) the new particle velocities X_k^(i) are computed in every step i of the algorithm by\n\nX_k^(i) = Ï‰ mathcal T_s_k^(i-1)s_k^(i) X_k^(i-1) + c r_1  operatornameretr^-1_s_k^(i)(p_k^(i)) + s r_2 operatornameretr^-1_s_k^(i)(p)\n\nwhere\n\ns_k^(i) is the current particle position,\nÏ‰ denotes the inertia,\nc and s are a cognitive and a social weight, respectively,\nr_j, j=12 are random factors which are computed new for each particle and step\n\\mathcal T_{â‹…â†â‹…} is a vector transport, and\n\\operatorname{retr}^{-1} is an inverse retraction\n\nThen the position of the particle is updated as\n\ns_k^(i+1) = operatornameretr_s_k^(i)(X_k^(i))\n\nThen the single particles best entries p_k^(i) are updated as\n\np_k^(i+1) = begincases\ns_k^(i+1)   textif  F(s_k^(i+1))F(p_k^(i))\np_k^(i)  textelse\nendcases\n\nand the global best position\n\ng^(i+1) = begincases\np_k^(i+1)   textif  F(p_k^(i+1))F(g_k^(i))\ng_k^(i)  textelse\nendcases\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nswarm = [rand(M) for _ in 1:swarm_size]: an initial swarm of points.\n\nInstead of a cost function f you can also provide an AbstractManifoldCostObjective mco.\n\nKeyword Arguments\n\ncognitive_weight=1.4: a cognitive weight factor\ninertia=0.65: the inertia of the particles\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nsocial_weight=1.4: a social weight factor\nswarm_size=100: swarm size, if it should be generated randomly\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenChangeLess(1e-4): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvelocity:                  a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles, per default a random tangent vector per initial position\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively. If you provide the objective directly, these decorations can still be specified\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/particle_swarm/#Manopt.ParticleSwarmState","page":"Particle Swarm Optimization","title":"Manopt.ParticleSwarmState","text":"ParticleSwarmState{P,T} <: AbstractManoptSolverState\n\nDescribes a particle swarm optimizing algorithm, with\n\nFields\n\ncognitive_weight: a cognitive weight factor\ninertia:          the inertia of the particles\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nsocial_weight:    a social weight factor\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nvelocity:         a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles\n\nInternal and temporary fields\n\ncognitive_vector: temporary storage for a tangent vector related to cognitive_weight\np::P: a point on the manifold mathcalM storing the best point visited by all particles\npositional_best:  storing the best position p_i every single swarm participant visited\nq::P: a point on the manifold mathcalM serving as temporary storage for interims results; avoids allocations\nsocial_vec:       temporary storage for a tangent vector related to social_weight\nswarm:            a set of points (of type AbstractVector{P}) on a manifold a_i_i=1^N\n\nConstructor\n\nParticleSwarmState(M, initial_swarm, velocity; kawrgs...)\n\nconstruct a particle swarm solver state for the manifold M starting with the initial population initial_swarm with velocities. The p used in the following defaults is the type of one point from the swarm.\n\nKeyword arguments\n\ncognitive_weight=1.4\ninertia=0.65\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nsocial_weight=1.4\nstopping_criterion::StoppingCriterion=StopAfterIteration(500)|StopWhenChangeLess(1e-4): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nSee also\n\nparticle_swarm\n\n\n\n\n\n","category":"type"},{"location":"solvers/particle_swarm/#Manopt.StopWhenSwarmVelocityLess","page":"Particle Swarm Optimization","title":"Manopt.StopWhenSwarmVelocityLess","text":"StopWhenSwarmVelocityLess <: StoppingCriterion\n\nStopping criterion for particle_swarm, when the velocity of the swarm is less than a threshold.\n\nFields\n\nthreshold:      the threshold\nat_iteration:   store the iteration the stopping criterion was (last) fulfilled\nreason:         store the reason why the stopping criterion was fulfilled, see get_reason\nvelocity_norms: interim vector to store the norms of the velocities before computing its norm\n\nConstructor\n\nStopWhenSwarmVelocityLess(tolerance::Float64)\n\ninitialize the stopping criterion to a certain tolerance.\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/#Stochastic-gradient-descent","page":"Stochastic Gradient Descent","title":"Stochastic gradient descent","text":"","category":"section"},{"location":"solvers/stochastic_gradient_descent/#State","page":"Stochastic Gradient Descent","title":"State","text":"Additionally, the options share a DirectionUpdateRule, so you can also apply MomentumGradient and AverageGradient here. The most inner one should always be.\n\nwhich internally uses","category":"section"},{"location":"solvers/stochastic_gradient_descent/#sec-sgd-technical-details","page":"Stochastic Gradient Descent","title":"Technical details","text":"The stochastic_gradient_descent solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.","category":"section"},{"location":"solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent","page":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent","text":"stochastic_gradient_descent(M, grad_f, p=rand(M); kwargs...)\nstochastic_gradient_descent(M, msgo; kwargs...)\nstochastic_gradient_descent!(M, grad_f, p; kwargs...)\nstochastic_gradient_descent!(M, msgo, p; kwargs...)\n\nperform a stochastic gradient descent. This can be performed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\ngrad_f: a gradient function, that either returns a vector of the gradients or is a vector of gradient functions\np::P: a point on the manifold mathcalM\n\nalternatively to the gradient you can provide an ManifoldStochasticGradientObjective msgo, then using the cost= keyword does not have any effect since if so, the cost is already within the objective.\n\nKeyword arguments\n\ncost=missing: you can provide a cost function for example to track the function value\ndirection=StochasticGradient([zerovector](@extrefManifoldsBase.zerovector-Tuple{AbstractManifold, Any})(M, p)`)\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Random: specify whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Linear) or the default :Random one.\norder_type=:RandomOrder: a type of ordering of gradient evaluations. Possible values are :RandomOrder, a :FixedPermutation, :LinearOrder\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=default_stepsize(M,StochasticGradientDescentState): a functor inheriting from Stepsize to determine a step size\norder=[1:n]: the initial permutation, where n is the number of gradients in gradF.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent!","page":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent!","text":"stochastic_gradient_descent(M, grad_f, p=rand(M); kwargs...)\nstochastic_gradient_descent(M, msgo; kwargs...)\nstochastic_gradient_descent!(M, grad_f, p; kwargs...)\nstochastic_gradient_descent!(M, msgo, p; kwargs...)\n\nperform a stochastic gradient descent. This can be performed in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\ngrad_f: a gradient function, that either returns a vector of the gradients or is a vector of gradient functions\np::P: a point on the manifold mathcalM\n\nalternatively to the gradient you can provide an ManifoldStochasticGradientObjective msgo, then using the cost= keyword does not have any effect since if so, the cost is already within the objective.\n\nKeyword arguments\n\ncost=missing: you can provide a cost function for example to track the function value\ndirection=StochasticGradient([zerovector](@extrefManifoldsBase.zerovector-Tuple{AbstractManifold, Any})(M, p)`)\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Random: specify whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Linear) or the default :Random one.\norder_type=:RandomOrder: a type of ordering of gradient evaluations. Possible values are :RandomOrder, a :FixedPermutation, :LinearOrder\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=default_stepsize(M,StochasticGradientDescentState): a functor inheriting from Stepsize to determine a step size\norder=[1:n]: the initial permutation, where n is the number of gradients in gradF.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradientDescentState","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradientDescentState","text":"StochasticGradientDescentState <: AbstractGradientDescentSolverState\n\nStore the following fields for a default stochastic gradient descent algorithm, see also ManifoldStochasticGradientObjective and stochastic_gradient_descent.\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\ndirection:  a direction update to use\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nevaluation_order: specify whether to use a randomly permuted sequence (:FixedRandom:), a per cycle permuted sequence (:Linear) or the default, a :Random sequence.\norder: stores the current permutation\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructor\n\nStochasticGradientDescentState(M::AbstractManifold; kwargs...)\n\nCreate a StochasticGradientDescentState with start point p.\n\nKeyword arguments\n\ndirection=StochasticGradientRule(M, [zerovector](@extrefManifoldsBase.zerovector-Tuple{AbstractManifold, Any})(M, p)`)\norder_type=:RandomOrder`\norder=Int[]: specify how to store the order of indices for the next epoche\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=default_stepsize(M,StochasticGradientDescentState): a functor inheriting from Stepsize to determine a step size\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{StochasticGradientDescentState}}","page":"Stochastic Gradient Descent","title":"Manopt.default_stepsize","text":"default_stepsize(M::AbstractManifold, ::Type{StochasticGradientDescentState})\n\nDeinfe the default step size computed for the StochasticGradientDescentState, which is ConstantStepsizeM.\n\n\n\n\n\n","category":"method"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradient","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradient","text":"StochasticGradient(; kwargs...)\nStochasticGradient(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\ninitial_gradient::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for StochasticGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/#Manopt.AbstractGradientGroupDirectionRule","page":"Stochastic Gradient Descent","title":"Manopt.AbstractGradientGroupDirectionRule","text":"AbstractStochasticGradientDescentSolverState <: AbstractManoptSolverState\n\nA generic type for all options related to gradient descent methods working with parts of the total gradient\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradientRule","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradientRule","text":"StochasticGradientRule<: AbstractGradientGroupDirectionRule\n\nCreate a functor (problem, state k) -> (s,X) to evaluate the stochatsic gradient, that is chose a random index from the state and use the internal field for evaluation of the gradient in-place.\n\nThe default gradient processor, which just evaluates the (stochastic) gradient or a subset thereof.\n\nFields\n\nX::T: a tangent vector at the point p on the manifold mathcalM\n\nConstructor\n\nStochasticGradientRule(M::AbstractManifold; p=rand(M), X=zero_vector(M, p))\n\nInitialize the stochastic gradient processor with tangent vector type of X, where both M and p are just help variables.\n\nSee also\n\nstochastic_gradient_descent, [StochasticGradient])@ref)\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_bundle_method/#Proximal-bundle-method","page":"Proximal bundle method","title":"Proximal bundle method","text":"","category":"section"},{"location":"solvers/proximal_bundle_method/#State","page":"Proximal bundle method","title":"State","text":"","category":"section"},{"location":"solvers/proximal_bundle_method/#Helpers-and-internal-functions","page":"Proximal bundle method","title":"Helpers and internal functions","text":"","category":"section"},{"location":"solvers/proximal_bundle_method/#Literature","page":"Proximal bundle method","title":"Literature","text":"N.Â Hoseini Monjezi, S.Â Nobakhtian and M.Â R.Â Pouryayevali. A proximal bundle algorithm for nonsmooth optimization on Riemannian manifolds. IMAÂ JournalÂ ofÂ NumericalÂ Analysis 43, 293â€“325 (2023).\n\n\n\n","category":"section"},{"location":"solvers/proximal_bundle_method/#Manopt.proximal_bundle_method","page":"Proximal bundle method","title":"Manopt.proximal_bundle_method","text":"proximal_bundle_method(M, f, âˆ‚f, p=rand(M), kwargs...)\nproximal_bundle_method!(M, f, âˆ‚f, p, kwargs...)\n\nperform a proximal bundle method p^(k+1) = operatornameretr_p^(k)(-d_k), where operatornameretr is a retraction and\n\nd_k = frac1mu_k sum_jin J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nwith X_q_j  f(q_j), p_k the last serious iterate, mu_k a proximal parameter, and the Î»_j^k as solutions to the quadratic subproblem provided by the sub solver, see for example the proximal_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details see [HNP23].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nâˆ‚f: the subgradient f mathcalM  TmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nÎ±â‚€=1.2:          initialization value for Î±, used to update Î·\nbundle_size=50:  the maximal size of the bundle\nÎ´=1.0:           parameter for updating Î¼: if Î´  0 then Î¼ = log(i + 1), else Î¼ += Î´ Î¼\nÎµ=1e-2:          stepsize-like parameter related to the injectivity radius of the manifold\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nm=0.0125:        a real number that controls the decrease of the cost function\nÎ¼=0.5:           initial proximal parameter for the subproblem\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000)`: a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} =proximal_bundle_method_subsolver``:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_bundle_method/#Manopt.proximal_bundle_method!","page":"Proximal bundle method","title":"Manopt.proximal_bundle_method!","text":"proximal_bundle_method(M, f, âˆ‚f, p=rand(M), kwargs...)\nproximal_bundle_method!(M, f, âˆ‚f, p, kwargs...)\n\nperform a proximal bundle method p^(k+1) = operatornameretr_p^(k)(-d_k), where operatornameretr is a retraction and\n\nd_k = frac1mu_k sum_jin J_k Î»_j^k mathrmP_p_kq_jX_q_j\n\nwith X_q_j  f(q_j), p_k the last serious iterate, mu_k a proximal parameter, and the Î»_j^k as solutions to the quadratic subproblem provided by the sub solver, see for example the proximal_bundle_method_subsolver.\n\nThough the subdifferential might be set valued, the argument âˆ‚f should always return one element from the subdifferential, but not necessarily deterministic.\n\nFor more details see [HNP23].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\nâˆ‚f: the subgradient f mathcalM  TmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place. This function should always only return one element from the subgradient.\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nÎ±â‚€=1.2:          initialization value for Î±, used to update Î·\nbundle_size=50:  the maximal size of the bundle\nÎ´=1.0:           parameter for updating Î¼: if Î´  0 then Î¼ = log(i + 1), else Î¼ += Î´ Î¼\nÎµ=1e-2:          stepsize-like parameter related to the injectivity radius of the manifold\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nm=0.0125:        a real number that controls the decrease of the cost function\nÎ¼=0.5:           initial proximal parameter for the subproblem\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000)`: a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} =proximal_bundle_method_subsolver``:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/proximal_bundle_method/#Manopt.ProximalBundleMethodState","page":"Proximal bundle method","title":"Manopt.ProximalBundleMethodState","text":"ProximalBundleMethodState <: AbstractManoptSolverState\n\nstores option values for a proximal_bundle_method solver.\n\nFields\n\nÎ±:                        curvature-dependent parameter used to update Î·\nÎ±â‚€:                       initialization value for Î±, used to update Î·\napprox_errors:            approximation of the linearization errors at the last serious step\nbundle:                   bundle that collects each iterate with the computed subgradient at the iterate\nbundle_size:              the maximal size of the bundle\nc:                        convex combination of the approximation errors\nd:                        descent direction\nÎ´:                        parameter for updating Î¼: if Î´  0 then Î¼ = log(i + 1), else Î¼ += Î´ Î¼\nÎµ:                        stepsize-like parameter related to the injectivity radius of the manifold\nÎ·:                        curvature-dependent term for updating the approximation errors\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ»:                        convex coefficients that solve the subproblem\nm:                        the parameter to test the decrease of the cost\nÎ¼:                        (initial) proximal parameter for the subproblem\nÎ½:                        the stopping parameter given by Î½ = - Î¼ d^2 - c\np::P: a point on the manifold mathcalM  storing the current iterate\np_last_serious:           last serious iterate\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\ntransported_subgradients: subgradients of the bundle that are transported to p_last_serious\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nX::T: a tangent vector at the point p on the manifold mathcalM storing a subgradient at the current iterate\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\n\nConstructor\n\nProximalBundleMethodState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\nProximalBundleMethodState(M::AbstractManifold, sub_problem=proximal_bundle_method_subsolver; evaluation=AllocatingEvaluation(), kwargs...)\n\nGenerate the state for the proximal_bundle_method on the manifold M\n\nKeyword arguments\n\nÎ±â‚€=1.2\nbundle_size=50\nÎ´=1.0\nÎµ=1e-2\nÎ¼=0.5\nm=0.0125\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstopping_criterion::StoppingCriterion=StopWhenLagrangeMultiplierLess(1e-8)|StopAfterIteration(5000): a functor indicating that the stopping criterion is fulfilled\nsub_problem::Union{AbstractManoptProblem, F} =proximal_bundle_method_subsolver:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F} =AllocatingEvaluation:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the type of tangent vector to use.\n\n\n\n\n\n","category":"type"},{"location":"solvers/proximal_bundle_method/#Manopt.proximal_bundle_method_subsolver","page":"Proximal bundle method","title":"Manopt.proximal_bundle_method_subsolver","text":"Î» = proximal_bundle_method_subsolver(M, p_last_serious, Î¼, approximation_errors, transported_subgradients)\nproximal_bundle_method_subsolver!(M, Î», p_last_serious, Î¼, approximation_errors, transported_subgradients)\n\nsolver for the subproblem of the proximal bundle method.\n\nThe subproblem for the proximal bundle method is\n\nbeginalign*\n    operatorname*argmin_Î»  â„^lvert L_l rvert \n    frac12 Î¼_l Bigl lVert sum_j  L_l Î»_j mathrmP_p_kq_j X_q_jBigr\rVert^2\n    + sum_j  L_l Î»_j  c_j^k\n    \n    texts t quad \n    sum_j  L_l Î»_j = 1\n    quad Î»_j  0\n    quad textfor all  j  L_l\nendalign*\n\nwhere L_l = setk if q_k is a serious iterate, and L_l = L_l-1   setk otherwise. See [HNP23].\n\ntip: Tip\nA default subsolver based on RipQP.jl and QuadraticModels is available if these two packages are loaded.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cyclic_proximal_point/#Cyclic-proximal-point","page":"Cyclic Proximal Point","title":"Cyclic proximal point","text":"The Cyclic Proximal Point (CPP) algorithm aims to minimize\n\nF(x) = sum_i=1^c f_i(x)\n\nassuming that the proximal maps operatornameprox_Î» f_i(x) are given in closed form or can be computed efficiently (at least approximately).\n\nThe algorithm then cycles through these proximal maps, where the type of cycle might differ and the proximal parameter Î»_k changes after each cycle k.\n\nFor a convergence result on Hadamard manifolds see BaÄÃ¡k [Bac14].","category":"section"},{"location":"solvers/cyclic_proximal_point/#sec-cppa-technical-details","page":"Cyclic Proximal Point","title":"Technical details","text":"The cyclic_proximal_point solver requires no additional functions to be available for your manifold, besides the ones you use in the proximal maps.\n\nBy default, one of the stopping criteria is StopWhenChangeLess, which either requires\n\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.","category":"section"},{"location":"solvers/cyclic_proximal_point/#State","page":"Cyclic Proximal Point","title":"State","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/#Debug-functions","page":"Cyclic Proximal Point","title":"Debug functions","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/#Record-functions","page":"Cyclic Proximal Point","title":"Record functions","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/#Literature","page":"Cyclic Proximal Point","title":"Literature","text":"M.Â BaÄÃ¡k. Computing medians and means in Hadamard spaces. SIAMÂ JournalÂ onÂ Optimization 24, 1542â€“1566 (2014), arXiv:1210.2145.\n\n\n\n","category":"section"},{"location":"solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point","page":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point","text":"cyclic_proximal_point(M, f, proxes_f, p; kwargs...)\ncyclic_proximal_point(M, mpo, p; kwargs...)\ncyclic_proximal_point!(M, f, proxes_f; kwargs...)\ncyclic_proximal_point!(M, mpo; kwargs...)\n\nperform a cyclic proximal point algorithm. This can be done in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf:        a cost function f mathcalMnifold)))â„ to minimize\nproxes_f: an Array of proximal maps (Functions) (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nwhere f and the proximal maps proxes_f can also be given directly as a ManifoldProximalMapObjective mpo\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Random) or the default linear one.\nÎ»=iter -> 1/iter:         a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion::StoppingCriterion=StopAfterIteration(5000)|StopWhenChangeLess(1e-12): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point!","page":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point!","text":"cyclic_proximal_point(M, f, proxes_f, p; kwargs...)\ncyclic_proximal_point(M, mpo, p; kwargs...)\ncyclic_proximal_point!(M, f, proxes_f; kwargs...)\ncyclic_proximal_point!(M, mpo; kwargs...)\n\nperform a cyclic proximal point algorithm. This can be done in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf:        a cost function f mathcalMnifold)))â„ to minimize\nproxes_f: an Array of proximal maps (Functions) (M,Î»,p) -> q or (M, q, Î», p) -> q for the summands of f (see evaluation)\n\nwhere f and the proximal maps proxes_f can also be given directly as a ManifoldProximalMapObjective mpo\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom:, a per cycle permuted sequence (:Random) or the default linear one.\nÎ»=iter -> 1/iter:         a function returning the (square summable but not summable) sequence of Î»_i\nstopping_criterion::StoppingCriterion=StopAfterIteration(5000)|StopWhenChangeLess(1e-12): a functor indicating that the stopping criterion is fulfilled\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cyclic_proximal_point/#Manopt.CyclicProximalPointState","page":"Cyclic Proximal Point","title":"Manopt.CyclicProximalPointState","text":"CyclicProximalPointState <: AbstractManoptSolverState\n\nstores options for the cyclic_proximal_point algorithm. These are the\n\nFields\n\np::P: a point on the manifold mathcalM  storing the current iterate\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nÎ»:         a function for the values of Î»_k per iteration(cycle k\norder_type: whether to use a randomly permuted sequence (:FixedRandomOrder), a per cycle permuted sequence (:RandomOrder) or the default linear one.\n\nConstructor\n\nCyclicProximalPointState(M::AbstractManifold; kwargs...)\n\nGenerate the options\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\n\nKeyword arguments\n\nevaluation_order=:LinearOrder: soecify the order_type\nÎ»=i -> 1.0 / i a function to compute the Î»_k k  mathcalN,\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nstopping_criterion::StoppingCriterion=StopAfterIteration(2000): a functor indicating that the stopping criterion is fulfilled\n\nSee also\n\ncyclic_proximal_point\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Manopt.DebugProximalParameter","page":"Cyclic Proximal Point","title":"Manopt.DebugProximalParameter","text":"DebugProximalParameter <: DebugAction\n\nprint the current iterates proximal point algorithm parameter given by AbstractManoptSolverStates o.Î».\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Manopt.RecordProximalParameter","page":"Cyclic Proximal Point","title":"Manopt.RecordProximalParameter","text":"RecordProximalParameter <: RecordAction\n\nrecord the current iterates proximal point algorithm parameter given by in AbstractManoptSolverStates o.Î».\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#A-manifold-objective","page":"Objective","title":"A manifold objective","text":"The Objective describes that actual cost function and all its properties.\n\nWhich has two main different possibilities for its containing functions concerning the evaluation mode, not necessarily the cost, but for example gradient in an AbstractManifoldFirstOrderObjective.","category":"section"},{"location":"plans/objective/#Decorators-for-objectives","page":"Objective","title":"Decorators for objectives","text":"An objective can be decorated using the following trait and function to initialize","category":"section"},{"location":"plans/objective/#subsection-embedded-objectives","page":"Objective","title":"Embedded objectives","text":"","category":"section"},{"location":"plans/objective/#subsection-scaled-objectives","page":"Objective","title":"Scaled objectives","text":"","category":"section"},{"location":"plans/objective/#subsection-cache-objective","page":"Objective","title":"Cache objective","text":"Since single function calls, for example to the cost or the gradient, might be expensive, a simple cache objective exists as a decorator, that caches one cost value or gradient.\n\nIt can be activated/used with the cache= keyword argument available for every solver.","category":"section"},{"location":"plans/objective/#A-simple-cache","page":"Objective","title":"A simple cache","text":"A first generic cache is always available, but it only caches one gradient and one cost function evaluation (for the same point).","category":"section"},{"location":"plans/objective/#A-generic-cache","page":"Objective","title":"A generic cache","text":"For the more advanced cache, you need to implement some type of cache yourself, that provides a get! and implement init_caches. This is for example provided if you load LRUCache.jl. Then you obtain","category":"section"},{"location":"plans/objective/#subsection-count-objective","page":"Objective","title":"Count objective","text":"","category":"section"},{"location":"plans/objective/#Internal-decorators-and-functions","page":"Objective","title":"Internal decorators and functions","text":"","category":"section"},{"location":"plans/objective/#Specific-Objective-typed-and-their-access-functions","page":"Objective","title":"Specific Objective typed and their access functions","text":"","category":"section"},{"location":"plans/objective/#Cost-objective","page":"Objective","title":"Cost objective","text":"","category":"section"},{"location":"plans/objective/#Access-functions","page":"Objective","title":"Access functions","text":"and internally","category":"section"},{"location":"plans/objective/#First-order-objectives","page":"Objective","title":"First order objectives","text":"While the ManifoldFirstOrderObjective allows to provide different first order information, there are also its shortcuts, mainly for historical reasons, but also since these are the most commonly used ones.","category":"section"},{"location":"plans/objective/#Access-functions-2","page":"Objective","title":"Access functions","text":"and internally","category":"section"},{"location":"plans/objective/#Subgradient-objective","page":"Objective","title":"Subgradient objective","text":"","category":"section"},{"location":"plans/objective/#Access-functions-3","page":"Objective","title":"Access functions","text":"and internally","category":"section"},{"location":"plans/objective/#Proximal-map-objective","page":"Objective","title":"Proximal map objective","text":"","category":"section"},{"location":"plans/objective/#Access-functions-4","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Hessian-objective","page":"Objective","title":"Hessian objective","text":"","category":"section"},{"location":"plans/objective/#Access-functions-5","page":"Objective","title":"Access functions","text":"and internally","category":"section"},{"location":"plans/objective/#Primal-dual-based-objectives","page":"Objective","title":"Primal-dual based objectives","text":"","category":"section"},{"location":"plans/objective/#Access-functions-6","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Constrained-objective","page":"Objective","title":"Constrained objective","text":"It might be beneficial to use the adapted problem to specify different ranges for the gradients of the constraints\n\nas well as the helper functions","category":"section"},{"location":"plans/objective/#Access-functions-7","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Internal-functions","page":"Objective","title":"Internal functions","text":"","category":"section"},{"location":"plans/objective/#Vectorial-objectives","page":"Objective","title":"Vectorial objectives","text":"","category":"section"},{"location":"plans/objective/#Access-functions-8","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Internal-functions-2","page":"Objective","title":"Internal functions","text":"","category":"section"},{"location":"plans/objective/#Subproblem-objective","page":"Objective","title":"Subproblem objective","text":"This objective can be use when the objective of a sub problem solver still needs access to the (outer/main) objective.","category":"section"},{"location":"plans/objective/#Access-functions-9","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/#Proximal-gradient-objective","page":"Objective","title":"Proximal gradient objective","text":"","category":"section"},{"location":"plans/objective/#Manopt.AbstractManifoldObjective","page":"Objective","title":"Manopt.AbstractManifoldObjective","text":"AbstractManifoldObjective{E<:AbstractEvaluationType}\n\nDescribe the collection of the optimization function f mathcalMnifold))nifold)))  â„ (or even a vectorial range) and its corresponding elements, which might for example be a gradient or (one or more) proximal maps.\n\nAll these elements should usually be implemented as functions (M, p) -> ..., or (M, X, p) -> ... that is\n\nthe first argument of these functions should be the manifold M they are defined on\nthe argument X is present, if the computation is performed in-place of X (see InplaceEvaluation)\nthe argument p is the place the function (f or one of its elements) is evaluated at.\n\nthe type T indicates the global AbstractEvaluationType.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractDecoratedManifoldObjective","page":"Objective","title":"Manopt.AbstractDecoratedManifoldObjective","text":"AbstractDecoratedManifoldObjective{E<:AbstractEvaluationType,O<:AbstractManifoldObjective}\n\nA common supertype for all decorators of AbstractManifoldObjectives to simplify dispatch.     The second parameter should refer to the undecorated objective (the most inner one).\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractEvaluationType","page":"Objective","title":"Manopt.AbstractEvaluationType","text":"AbstractEvaluationType\n\nAn abstract type to specify the kind of evaluation a AbstractManifoldObjective supports.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AllocatingEvaluation","page":"Objective","title":"Manopt.AllocatingEvaluation","text":"AllocatingEvaluation <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem or a Function indicating that the problem contains or the function(s) allocate memory for their result, they work out of place.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AllocatingInplaceEvaluation","page":"Objective","title":"Manopt.AllocatingInplaceEvaluation","text":"AllocatingInplaceEvaluation <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem or a Function indicating that the problem contains or the function(s) that provides both an allocating variant and one, that does not allocate memory but work on their input, in place.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.InplaceEvaluation","page":"Objective","title":"Manopt.InplaceEvaluation","text":"InplaceEvaluation <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem or a Function indicating that the problem contains or the function(s) do not allocate memory but work on their input, in place.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ParentEvaluationType","page":"Objective","title":"Manopt.ParentEvaluationType","text":"ParentEvaluationType <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem or a Function indicating that the problem contains or the function(s) do inherit their property from a parent AbstractManoptProblem or function.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.evaluation_type","page":"Objective","title":"Manopt.evaluation_type","text":"evaluation_type(mp::AbstractManoptProblem)\n\nGet the AbstractEvaluationType of the objective in AbstractManoptProblem mp.\n\n\n\n\n\nevaluation_type(::AbstractManifoldObjective{Teval})\n\nGet the AbstractEvaluationType of the objective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.dispatch_objective_decorator","page":"Objective","title":"Manopt.dispatch_objective_decorator","text":"dispatch_objective_decorator(o::AbstractManoptSolverState)\n\nIndicate internally, whether an AbstractManifoldObjective o to be of decorating type, it stores (encapsulates) an object in itself, by default in the field o.objective.\n\nDecorators indicate this by returning Val{true} for further dispatch.\n\nThe default is Val{false}, so by default an state is not decorated.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.is_objective_decorator","page":"Objective","title":"Manopt.is_objective_decorator","text":"is_object_decorator(s::AbstractManifoldObjective)\n\nIndicate, whether AbstractManifoldObjective s are of decorator type.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.decorate_objective!","page":"Objective","title":"Manopt.decorate_objective!","text":"decorate_objective!(M, o::AbstractManifoldObjective)\n\ndecorate the AbstractManifoldObjectiveo with specific decorators.\n\nOptional arguments\n\noptional arguments provide necessary details on the decorators. A specific one is used to activate certain decorators.\n\ncache=missing: specify a cache. Currently :Simple is supported and :LRU if you load LRUCache.jl. For this case a tuple specifying what to cache and how many can be provided, has to be specified. For example (:LRU, [:Cost, :Gradient], 10) states that the last 10 used cost function evaluations and gradient evaluations should be stored. See objective_cache_factory for details.\ncount=missing: specify calls to the objective to be called, see ManifoldCountObjective for the full list\nobjective_type=:Riemannian: specify that an objective is :Riemannian or :Euclidean. The :Euclidean symbol is equivalent to specifying it as :Embedded, since in the end, both refer to converting an objective from the embedding (whether its Euclidean or not) to the Riemannian one.\n\nSee also\n\nobjective_cache_factory\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.EmbeddedManifoldObjective","page":"Objective","title":"Manopt.EmbeddedManifoldObjective","text":"EmbeddedManifoldObjective{P, T, E, O2, O1<:AbstractManifoldObjective{E}} <:\n   AbstractDecoratedManifoldObjective{E,O2}\n\nDeclare an objective to be defined in the embedding. This also declares the gradient to be defined in the embedding, and especially being the Riesz representer with respect to the metric in the embedding. The types can be used to still dispatch on also the undecorated objective type O2.\n\nFields\n\nobjective: the objective that is defined in the embedding\np=nothing: a point in the embedding.\nX=nothing: a tangent vector in the embedding\n\nWhen a point in the embedding p is provided, embed! is used in place of this point to reduce memory allocations. Similarly X is used when embedding tangent vectors\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ScaledManifoldObjective","page":"Objective","title":"Manopt.ScaledManifoldObjective","text":"ScaledManifoldObjective{E, O2, O1<:AbstractManifoldObjective{E},F} <:\n   AbstractDecoratedManifoldObjective{E,O2}\n\nDeclare an objective to be defined as a scaled version of an existing objective.\n\nThis rescales all involved functions.\n\nFor now the functions rescaled are\n\nthe cost\nthe gradient\nthe Hessian\n\nFields\n\nobjective: the objective that is defined in the embedding\nscale=1: the scaling applied\n\nConstructors\n\nScaledManifoldObjective(objective, scale::Real=1)\n-objective\nscale*objective\n\nGenerate a scaled manifold objective based on objective with scale being 1 by default in the first, scale=-1 in the second case. The multiplication from the left with a scalar is also overloaded.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.reset_counters!","page":"Objective","title":"Manopt.reset_counters!","text":"reset_counters(co::ManifoldCountObjective, value::Integer=0)\n\nReset all values in the count objective to value.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.objective_cache_factory","page":"Objective","title":"Manopt.objective_cache_factory","text":"objective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Symbol)\n\nGenerate a cached variant of the AbstractManifoldObjective o on the AbstractManifold M based on the symbol cache.\n\nThe following caches are available\n\n:Simple generates a SimpleManifoldCachedObjective\n:LRU generates a ManifoldCachedObjective where you should use the form (:LRU, [:Cost, :Gradient]) to specify what should be cached or (:LRU, [:Cost, :Gradient], 100) to specify the cache size. Here this variant defaults to (:LRU, [:Cost, :Gradient], 100), caching up to 100 cost and gradient values.[1]\n\n[1]: This cache requires LRUCache.jl to be loaded as well.\n\n\n\n\n\nobjective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array, Array})\nobjective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array})\n\nGenerate a cached variant of the AbstractManifoldObjective o on the AbstractManifold M based on the symbol cache[1], where the second element cache[2] are further arguments to the cache and the optional third is passed down as keyword arguments.\n\nFor all available caches see the simpler variant with symbols.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.SimpleManifoldCachedObjective","page":"Objective","title":"Manopt.SimpleManifoldCachedObjective","text":" SimpleManifoldCachedObjective{O<:AbstractManifoldFirstOrderObjective{E}, P, T,C} <: AbstractDecoratedManifoldObjective{E,O}\n\nProvide a simple cache for an AbstractManifoldFirstOrderObjective that is, this cache stores a point p and a gradient operatornamegrad f(p) in X as well as a cost value f(p) in c. It can also easily evaluate the differential based on the cached gradient.\n\nBoth X and c are accompanied by booleans to keep track of their validity.\n\nWhile this does not provide a cache for the differential, it uses the cached gradient as a help to evaluate the differential, if an up-to-date gradient is available. It otherwise does call the original differential.\n\nThis simple cache does not take into account, that some first order objectives have a common function for cost & grad. It only caches the function that is actually called.\n\nConstructor\n\nSimpleManifoldCachedObjective(M::AbstractManifold, obj::AbstractManifoldFirstOrderObjective; kwargs...)\n\nKeyword arguments\n\np=rand(M): a point on the manifold to initialize the cache with\nX=get_gradient(M, obj, p) or zero_vector(M,p): a tangent vector to store the gradient in, see also initialize=\nc=[get_cost](@ref)(M, obj, p)or0.0: a value to store the cost function ininitialize`\ninitialized=true: whether to initialize the cached X and c or not.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldCachedObjective","page":"Objective","title":"Manopt.ManifoldCachedObjective","text":"ManifoldCachedObjective{E,P,O<:AbstractManifoldObjective{<:E},C<:NamedTuple{}} <: AbstractDecoratedManifoldObjective{E,P}\n\nCreate a cache for an objective, based on a NamedTuple that stores some kind of cache.\n\nConstructor\n\nManifoldCachedObjective(M, o::AbstractManifoldObjective, caches::Vector{Symbol}; kwargs...)\n\nCreate a cache for the AbstractManifoldObjective where the Symbols in caches indicate, which function evaluations to cache.\n\nSupported symbols\n\nSymbol Caches calls to (incl. ! variants) Comment\n:Cost get_cost \n:Differential get_differential(M, p, X). \n:EqualityConstraint get_equality_constraint(M, p, i) \n:EqualityConstraints get_equality_constraint(M, p, :) \n:GradEqualityConstraint get_grad_equality_constraint tangent vector per (p,i)\n:GradInequalityConstraint get_inequality_constraint tangent vector per (p,i)\n:Gradient get_gradient(M,p) tangent vectors\n:Hessian get_hessian tangent vectors\n:InequalityConstraint get_inequality_constraint(M, p, j) \n:InequalityConstraints get_inequality_constraint(M, p, :) \n:Preconditioner get_preconditioner tangent vectors\n:ProximalMap get_proximal_map point per (p,Î»,i)\n:StochasticGradients get_gradients vector of tangent vectors\n:StochasticGradient get_gradient(M, p, i) tangent vector per (p,i)\n:SubGradient get_subgradient tangent vectors\n:SubtrahendGradient get_subtrahend_gradient tangent vectors\n\nKeyword arguments\n\np=rand(M): the type of the keys to be used in the caches. Defaults to the default representation on M.\nvalue=get_cost(M, objective, p): the type of values for numeric values in the cache\nX=zero_vector(M,p): the type of values to be cached for gradient and Hessian calls.\ncache=[:Cost]: a vector of symbols indicating which function calls should be cached.\ncache_size=10: number of (least recently used) calls to cache\ncache_sizes=Dict{Symbol,Int}(): a named tuple or dictionary specifying the sizes individually for each cache.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.init_caches","page":"Objective","title":"Manopt.init_caches","text":"init_caches(caches, T::Type{LRU}; kwargs...)\n\nGiven a vector of symbols caches, this function sets up the NamedTuple of caches, where T is the type of cache to use.\n\nKeyword arguments\n\np=rand(M): a point on a manifold, to both infer its type for keys and initialize caches\nvalue=0.0:  a value both typing and initialising number-caches, the default is for (Float) values like the cost.\nX=zero_vector(M, p): a tangent vector at p to both type and initialize tangent vector caches\ncache_size=10: a default cache size to use\ncache_sizes=Dict{Symbol,Int}(): a dictionary of sizes for the caches to specify different (non-default) sizes\n\n\n\n\n\ninit_caches(M::AbstractManifold, caches, T; kwargs...)\n\nGiven a vector of symbols caches, this function sets up the NamedTuple of caches for points/vectors on M, where T is the type of cache to use.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.ManifoldCountObjective","page":"Objective","title":"Manopt.ManifoldCountObjective","text":"ManifoldCountObjective{E,P,O<:AbstractManifoldObjective,I<:Integer} <: AbstractDecoratedManifoldObjective{E,P}\n\nA wrapper for any AbstractManifoldObjective of type O to count different calls to parts of the objective.\n\nFields\n\ncounts a dictionary of symbols mapping to integers keeping the counted values\nobjective the wrapped objective\n\nSupported symbols\n\nSymbol Counts calls to (incl. ! variants) Comment\n:Cost get_cost \n:Differential get_differential. \n:EqualityConstraint get_equality_constraint requires vector of counters\n:EqualityConstraints get_equality_constraint when evaluating all of them with :\n:GradEqualityConstraint get_grad_equality_constraint requires vector of counters\n:GradEqualityConstraints get_grad_equality_constraint when evaluating all of them with :\n:GradInequalityConstraint get_inequality_constraint requires vector of counters\n:GradInequalityConstraints get_inequality_constraint when evaluating all of them with :\n:Gradient get_gradient(M,p) \n:Hessian get_hessian \n:InequalityConstraint get_inequality_constraint requires vector of counters\n:InequalityConstraints get_inequality_constraint when evaluating all of them with :\n:Preconditioner get_preconditioner \n:ProximalMap get_proximal_map \n:StochasticGradients get_gradients \n:StochasticGradient get_gradient(M, p, i) \n:SubGradient get_subgradient \n:SubtrahendGradient get_subtrahend_gradient \n\nConstructors\n\nManifoldCountObjective(objective::AbstractManifoldObjective, counts::Dict{Symbol, <:Integer})\n\nInitialise the ManifoldCountObjective to wrap objective initializing the set of counts\n\nManifoldCountObjective(M::AbstractManifold, objective::AbstractManifoldObjective, count::AbstractVecor{Symbol}, init=0)\n\nCount function calls on objective using the symbols in count initialising all entries to init.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ReturnManifoldObjective","page":"Objective","title":"Manopt.ReturnManifoldObjective","text":"ReturnManifoldObjective{E,O2,O1<:AbstractManifoldObjective{E}} <:\n   AbstractDecoratedManifoldObjective{E,O2}\n\nA wrapper to indicate that get_solver_result should return the inner objective.\n\nThe types are such that one can still dispatch on the undecorated type O2 of the original objective as well.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractManifoldCostObjective","page":"Objective","title":"Manopt.AbstractManifoldCostObjective","text":"AbstractManifoldCostObjective{T<:AbstractEvaluationType} <: AbstractManifoldObjective{T}\n\nRepresenting objectives on manifolds with a cost function implemented.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldCostObjective","page":"Objective","title":"Manopt.ManifoldCostObjective","text":"ManifoldCostObjective{T, TC} <: AbstractManifoldCostObjective{T, TC}\n\nspecify an AbstractManifoldObjective that does only have information about the cost function f  mathcalM)  â„ implemented as a function (M, p) -> c to compute the cost value c at p on the manifold M.\n\ncost: a function f mathcalM)  â„ to minimize\n\nConstructors\n\nManifoldCostObjective(f)\n\nGenerate a problem. While this Problem does not have any allocating functions, the type T can be set for consistency reasons with other problems.\n\nUsed with\n\nNelderMead, particle_swarm\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.get_cost","page":"Objective","title":"Manopt.get_cost","text":"get_cost(amp::AbstractManoptProblem, p)\n\nevaluate the cost function f stored within the AbstractManifoldObjective of an AbstractManoptProblem amp at the point p.\n\n\n\n\n\nget_cost(M::AbstractManifold, obj::AbstractManifoldObjective, p)\n\nevaluate the cost function f defined on M stored within the AbstractManifoldObjective at the point p.\n\n\n\n\n\nget_cost(M::AbstractManifold, mco::AbstractManifoldCostObjective, p)\n\nEvaluate the cost function from within the AbstractManifoldCostObjective on M at p.\n\nBy default this implementation assumed that the cost is stored within mco.cost.\n\n\n\n\n\nget_cost(TpM, trmo::TrustRegionModelObjective, X)\n\nEvaluate the tangent space TrustRegionModelObjective\n\nm(X) = f(p) + operatornamegrad f(p) X _p + frac12 operatornameHess f(p)X X_p\n\n\n\n\n\nget_cost(TpM, trmo::AdaptiveRegularizationWithCubicsModelObjective, X)\n\nEvaluate the tangent space AdaptiveRegularizationWithCubicsModelObjective\n\nm(X) = f(p) + operatornamegrad f(p) X _p + frac12 operatornameHess f(p)X X_p\n       + fracÏƒ3 lVert X rVert^3\n\nat X, cf. Eq. (33) in [ABBC20].\n\n\n\n\n\nget_cost(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\n\nevaluate the cost\n\nf(X) = frac12 lVert mathcalAX + b rVert_p^2qquad X  T_pmathcalM\n\nat X.\n\n\n\n\n\nget_cost(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, i)\n\nEvaluate the ith summand of the cost.\n\nIf you use a single function for the stochastic cost, then only the index Ã¬=1` is available to evaluate the whole cost.\n\n\n\n\n\nget_cost(M::AbstractManifold,emo::EmbeddedManifoldObjective, p)\n\nEvaluate the cost function of an objective defined in the embedding by first embedding p before calling the cost function stored in the EmbeddedManifoldObjective.\n\n\n\n\n\nget_cost(M::AbstractManifold, scaled_objective::ScaledManifoldObjective, p)\n\nEvaluate the scaled objective. s*f(p)\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_cost_function","page":"Objective","title":"Manopt.get_cost_function","text":"get_cost_function(amco::AbstractManifoldCostObjective; recursive=false)\n\nreturn the function to evaluate (just) the cost f(p)=c as a function (M,p) -> c. If amco has more than one decorator, recursive determines whether just one (false) or all wrappers (true) should be â€œunwrappedâ€ at once.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.AbstractManifoldFirstOrderObjective","page":"Objective","title":"Manopt.AbstractManifoldFirstOrderObjective","text":"AbstractManifoldFirstOrderObjective{E<:AbstractEvaluationType, FGD} <: AbstractManifoldCostObjective{E, FGD}\n\nAn abstract type for all objectives that provide\n\na cost\nfirst order information, so either a (full) gradient or a differential, where\n\nE is a AbstractEvaluationType for the gradient function.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldFirstOrderObjective","page":"Objective","title":"Manopt.ManifoldFirstOrderObjective","text":"ManifoldFirstOrderObjective{E<:AbstractEvaluationType, F} <: AbstractManifoldFirstOrderObjective{E, F}\n\nspecify an objective containing a cost and its gradient or differential, where the AbstractEvaluationType E indicates the type of evaluation for a gradient.\n\nFields\n\nfunctions::F: a function or a tuple of functions containing the cost and first order information.\n\nCurrently the following cases are covered, sorted by their popularity\n\na single function fg, i.e. a function or a functor, represents a combined  function (M, p) -> (c, X) that computes the cost c=cost(M,p) and gradient X=grad_f(M,p);\na single function fdf, i.e. a function or a functor, represents a combined function  (M, p) -> (c, d) that computes the cost c=cost(M,p) and differential d=diff_f(M,p);\npairs of single functions (f, g), (f, df) of a cost function f and either its  gradient g or its differential d, respectively\nThe function (fg, d) and (fdf, g)  from 1 and 2, respectively joined by  the other missing third information, the differential for the first or the gradient for the second\na tuple (f, g, d) of three functions, computing cost, f, gradient g,  and differentiald` separately\na (f, gd) of a cost function and a combined function (X, d) = gd(M, p, X)  to compute gradient and differential together\na single function (c, X, d) = fgd(M, p,X)\n\nFor all cases where a gradient is present, also an in-place variant is possible, where the signature has the result Y in second place.\n\nThe cases of a common fg function for cost and gradient and the tuple (f,g) are the most common one. They can also be addressed by their alternate constructors ManifoldCostGradientObjective(fg) and ManifoldGradientObjective(f,g), respectively.\n\nConstructors\n\nManifoldFirstOrderObjective(; kwargs...)\n\nKeyword arguments\n\ncost = nothing the cost function c = f(M,p)\ndifferential = nothing the differential d = df(M, p, X)\ngradient=nothing the gradient function g(M, p) or in-place g!(M, X, p)\ncostgradient = nothing the combined cost and gradient function fg(M,p) or in-place fg!(M, X, p))\ncostdifferential = nothing the combined cost and differential function  fdf(M, p, X)\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\n\nWhere:\n\nAt least one of cost, costgradient or costdifferential must be provided.\nEither gradient, costgradient, differential or costdifferential must be provided.\nIf more than one function provides the same thing (e.g. cost), it is assumed that all such functions return the same value. Optimization algorithms will attempt to make the most efficient use of provided functions.\n\nUsed with\n\ngradient_descent, conjugate_gradient_descent, quasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldAlternatingGradientObjective","page":"Objective","title":"Manopt.ManifoldAlternatingGradientObjective","text":"ManifoldAlternatingGradientObjective{E<:AbstractEvaluationType,F,G} <: AbstractManifoldFirstOrderObjective{E, Tuple{F,G}}\n\nAn alternating gradient objective consists of\n\na cost function F(x)\na gradient operatornamegradF that is either\ngiven as one function operatornamegradF returning a tangent vector X on M or\nan array of gradient functions operatornamegradF_i, Ã¬=1,â€¦,n s each returning a component of the gradient\nwhich might be allocating or mutating variants, but not a mix of both.\n\nnote: Note\nThis Objective is usually defined using the ProductManifold from Manifolds.jl, so Manifolds.jl to be loaded.\n\nConstructors\n\nManifoldAlternatingGradientObjective(F, gradF::Function;\n    evaluation=AllocatingEvaluation()\n)\nManifoldAlternatingGradientObjective(F, gradF::AbstractVector{<:Function};\n    evaluation=AllocatingEvaluation()\n)\n\nCreate a alternating gradient problem with an optional cost and the gradient either as one function (returning an array) or a vector of functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldStochasticGradientObjective","page":"Objective","title":"Manopt.ManifoldStochasticGradientObjective","text":"ManifoldStochasticGradientObjective{E<:AbstractEvaluationType, F, G} <: AbstractManifoldFirstOrderObjective{E, Tuple{F,G}}\n\nA stochastic gradient objective consists of\n\na(n optional) cost function f(p) = displaystylesum_i=1^n f_i(p)\nan array of gradients, operatornamegrad f_i(p) i=1n which can be given in two forms\nas one single function (mathcalMnifold))nifold))) p)  (X_1X_n)  (T_pmathcalMn\nas a vector of functions bigl( (mathcalM) p)  X_1  (mathcalM) p)  X_nbigr).\n\nWhere both variants can also be provided as InplaceEvaluation functions (M, X, p) -> X, where X is the vector of X1,...,Xn and (M, X1, p) -> X1, ..., (M, Xn, p) -> Xn, respectively.\n\nConstructors\n\nManifoldStochasticGradientObjective(\n    grad_f::Function;\n    cost=Missing(),\n    evaluation=AllocatingEvaluation()\n)\nManifoldStochasticGradientObjective(\n    grad_f::AbstractVector{<:Function};\n    cost=Missing(), evaluation=AllocatingEvaluation()\n)\n\nCreate a Stochastic gradient problem with the gradient either as one function (returning an array of tangent vectors) or a vector of functions (each returning one tangent vector).\n\nThe optional cost can also be given as either a single function (returning a number) pr a vector of functions, each returning a value.\n\nUsed with\n\nstochastic_gradient_descent\n\nNote that this can also be used with a gradient_descent, since the (complete) gradient is just the sums of the single gradients.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.NonlinearLeastSquaresObjective","page":"Objective","title":"Manopt.NonlinearLeastSquaresObjective","text":"NonlinearLeastSquaresObjective{E<:AbstractEvaluationType} <: AbstractManifoldObjective{T}\n\nAn objective to model the nonlinear least squares problem\n\noperatorname*argmin_p  mathcalM frac12 sum_i=1^m lvert f_i(p) rvert^2\n\nwhere f mathcalM  â„^m is written with component functions f_i mathcalM  â„, i=1m, and each component function is continuously differentiable.\n\nSpecify a nonlinear least squares problem\n\nFields\n\nobjective: a AbstractVectorGradientFunction{E} containing both the vector of cost functions f_i (or a function returning a vector of costs) as well as their gradients operatornamegrad f_i (or Jacobian of the vector-valued function).\n\nThis NonlinearLeastSquaresObjective then has the same AbstractEvaluationType T as the (inner) objective.\n\nConstructors\n\nNonlinearLeastSquaresObjective(f, jacobian, range_dimension::Integer; kwargs...)\nNonlinearLeastSquaresObjective(vf::AbstractVectorGradientFunction)\n\nArguments\n\nf the vectorial cost function f mathcalMnifold)))  â„^m\njacobian the Jacobian, might also be a vector of gradients of the component functions of f\nrange_dimension::Integer the number of dimensions m the function f maps into\n\nThese three can also be passed as a AbstractVectorGradientFunction vf already.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nfunction_type::AbstractVectorialType=FunctionVectorialType(): specify the format the residuals are given in. By default a function returning a vector.\njacobian_tangent_basis::AbstractBasis=DefaultOrthonormalBasis(); shortcut to specify the basis the Jacobian matrix is build with.\njacobian_type::AbstractVectorialType=CoordinateVectorialType(jacobian_tangent_basis): specify the format the Jacobian is given in. By default a matrix of the differential with respect to a certain basis of the tangent space.\n\nSee also\n\nLevenbergMarquardt, LevenbergMarquardtState\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldGradientObjective","page":"Objective","title":"Manopt.ManifoldGradientObjective","text":"ManifoldGradientObjective(cost, gradient; evaluation::E=AllocatingEvaluation() kwargs...)\n\nGenerate an objective with a function cost and its gradient. Depending on the AbstractEvaluationType E the gradient can have to forms\n\nas a function (M, p) -> X that allocates memory for X, an AllocatingEvaluation\nas a function (M, X, p) -> X that work in place of X, an InplaceEvaluation\n\nInternally this is stored in a ManifoldFirstOrderObjective. The kwargs... are also passed to this representation, which allows to add a special function to evaluate the differential.\n\nUsed with\n\ngradient_descent, conjugate_gradient_descent, quasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldCostGradientObjective","page":"Objective","title":"Manopt.ManifoldCostGradientObjective","text":"ManifoldCostGradientObjective(costgrad; evaluation::E=AllocatingEvaluation(), kwargs...)\n\ncreate an objective containing one function to perform a combined computation of cost and its gradient\n\nDepending on the AbstractEvaluationType E the gradient can have to forms\n\nas a function (M, p) -> (c, X) that allocates memory for the gradient X, an AllocatingEvaluation\nas a function (M, X, p) -> (c, X) that work in place of X, an InplaceEvaluation\n\nInternally this is stored in a ManifoldFirstOrderObjective. The kwargs... are also passed to this representation, which allows to add a special function to evaluate the differential.\n\nUsed with\n\ngradient_descent, conjugate_gradient_descent, quasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.get_gradient","page":"Objective","title":"Manopt.get_gradient","text":"get_gradient(s::AbstractManoptSolverState)\n\nreturn the (last stored) gradient within AbstractManoptSolverStates`. By default also undecorates the state beforehand\n\n\n\n\n\nget_gradient(amp::AbstractManoptProblem, p)\nget_gradient!(amp::AbstractManoptProblem, X, p)\n\nevaluate the gradient of an AbstractManoptProblem amp at the point p.\n\nThe evaluation is done in place of X for the !-variant.\n\n\n\n\n\nget_gradient(agst::AbstractGradientSolverState)\n\nreturn the gradient stored within gradient options. THe default returns agst.X.\n\n\n\n\n\nget_gradient(M::AbstractManifold, mgo::ManifoldProximalGradientObjective, p)\nget_gradient!(M::AbstractManifold, X, mgo::ManifoldProximalGradientObjective, p)\n\nEvaluate the gradient of the smooth part of a ManifoldProximalGradientObjective mgo at p.\n\n\n\n\n\nget_gradient(M::AbstractManifold, vgf::VectorGradientFunction, p, i)\nget_gradient(M::AbstractManifold, vgf::VectorGradientFunction, p, i, range)\nget_gradient!(M::AbstractManifold, X, vgf::VectorGradientFunction, p, i)\nget_gradient!(M::AbstractManifold, X, vgf::VectorGradientFunction, p, i, range)\n\nEvaluate the gradients of the vector function vgf on the manifold M at p and the values given in range, specifying the representation of the gradients.\n\nSince i is assumed to be a linear index, you can provide\n\na single integer\na UnitRange to specify a range to be returned like 1:3\na BitVector specifying a selection\na AbstractVector{<:Integer} to specify indices\n: to return the vector of all gradients\n\n\n\n\n\nget_gradient(TpM, trmo::TrustRegionModelObjective, X)\n\nEvaluate the gradient of the TrustRegionModelObjective\n\noperatornamegrad m(X) = operatornamegrad f(p) + operatornameHess f(p)X\n\n\n\n\n\nget_gradient(TpM, trmo::AdaptiveRegularizationWithCubicsModelObjective, X)\n\nEvaluate the gradient of the AdaptiveRegularizationWithCubicsModelObjective\n\noperatornamegrad m(X) = operatornamegrad f(p) + operatornameHess f(p)X\n       + ÏƒlVert X rVert X\n\nat X, cf. Eq. (37) in [ABBC20].\n\n\n\n\n\nget_gradient(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\nget_gradient!(TpM::TangentSpace, Y, slso::SymmetricLinearSystemObjective, X)\n\nevaluate the gradient of\n\nf(X) = frac12 lVert mathcalAX + b rVert_p^2qquad X  T_pmathcalM\n\nWhich is operatornamegrad f(X) = mathcalAX+b. This can be computed in-place of Y.\n\n\n\n\n\nget_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, k)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, Y, p, k)\n\nEvaluate one of the summands gradients operatornamegradf_k, k  set1n, at p (in place of Y).\n\nIf you use a single function for the stochastic gradient, that works in-place, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\nget_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, X, p)\n\nEvaluate the complete gradient operatornamegrad f = displaystylesum_i=1^n operatornamegrad f_i(p) at p (in place of X).\n\nIf you use a single function for the stochastic gradient, that works in-place, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\nget_gradient(M::AbstractManifold, emo::EmbeddedManifoldObjective, p)\nget_gradient!(M::AbstractManifold, X, emo::EmbeddedManifoldObjective, p)\n\nEvaluate the gradient function of an objective defined in the embedding, that is embed p before calling the gradient function stored in the EmbeddedManifoldObjective.\n\nThe returned gradient is then converted to a Riemannian gradient calling riemannian_gradient.\n\n\n\n\n\nget_gradient(M::AbstractManifold, scaled_objective::ScaledManifoldObjective, p)\nget_gradient!(M::AbstractManifold, X, scaled_objective::ScaledManifoldObjective, p)\n\nEvaluate the scaled gradient. s*operatornamegradf(p)\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_gradients","page":"Objective","title":"Manopt.get_gradients","text":"get_gradients(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradients!(M::AbstractManifold, X, sgo::ManifoldStochasticGradientObjective, p)\n\nEvaluate all summands gradients `\\{\\operatorname{grad}f_i\\}_{i=1}^{n} atp(in place ofX`).\n\nIf you use a single function for the stochastic gradient, that works in-place, then get_gradient is not available, since the length (or number of elements of the gradient) can not be determined.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential","page":"Objective","title":"Manopt.get_differential","text":" get_differential(amp::AbstractManoptProblem, p, X; kwargs...)\n get_differential(M::AbstractManifold, amfo:AbstractManifoldFirstOrderObjective, p, X; kwargs...)\n get_differential(M::AbstractManifold, amfo:AbstractDecoratedManifoldObjective, p, X; kwargs...)\n\nEvaluate the differential Df(p)X of the function f represented by the AbstractManifoldFirstOrderObjective. For AbstractManoptProblem the inner manifold and objectives are used, similarly, any objective decorator would â€œpass thoughâ€ to its inner objective. By default this falls back to ``Df(p)[X] = âŸ¨\\operatorname{grad}f(p), XâŸ©\n\nKeyword arguments\n\ngradient=nothing â€“ pass a tangent vector to be used internally as interims memory, e.g. in the default variant to evaluate the gradient in-place in.\nevaluated=false â€“ indicate whether gradient is just memory (false, default) or already contains the evaluated gradient (true).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_residuals","page":"Objective","title":"Manopt.get_residuals","text":"get_residuals(M::AbstractManifold, nlso::NonlinearLeastSquaresObjective, p)\nget_residuals!(M::AbstractManifold, V, nlso::NonlinearLeastSquaresObjective, p)\n\nCompute the vector of residuals f_i(p), i=1m given the manifold M, the NonlinearLeastSquaresObjective nlso and a current point p on M.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_residuals!","page":"Objective","title":"Manopt.get_residuals!","text":"get_residuals(M::AbstractManifold, nlso::NonlinearLeastSquaresObjective, p)\nget_residuals!(M::AbstractManifold, V, nlso::NonlinearLeastSquaresObjective, p)\n\nCompute the vector of residuals f_i(p), i=1m given the manifold M, the NonlinearLeastSquaresObjective nlso and a current point p on M.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential_function","page":"Objective","title":"Manopt.get_differential_function","text":" get_differential_function(admo::AbstractManifoldFirstOrderObjective, recursive::Bool=false)\n\nReturn the function to evaluate (just) the differential Df(p)X. For a decorated objective, the recursive positional parameter determines whether to directly call this function on the next decorator or whether to get the â€œmost innerâ€ objective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_gradient_function","page":"Objective","title":"Manopt.get_gradient_function","text":"get_gradient_function(amgo::AbstractManifoldFirstOrderObjective, recursive=false)\n\nreturn the function to evaluate (just) the gradient operatornamegrad f(p), where either the gradient function using the decorator or without the decorator is used.\n\nBy default recursive is set to false, since usually to just pass the gradient function somewhere, one still wants for example the cached one or the one that still counts calls.\n\nDepending on the AbstractEvaluationType E this is a function\n\n(M, p) -> X for the AllocatingEvaluation case\n(M, X, p) -> X for the InplaceEvaluation working in-place of X.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.ManifoldSubgradientObjective","page":"Objective","title":"Manopt.ManifoldSubgradientObjective","text":"ManifoldSubgradientObjective{T<:AbstractEvaluationType,C,S} <:AbstractManifoldCostObjective{T, C}\n\nA structure to store information about a objective for a subgradient based optimization problem\n\nFields\n\ncost:        the function f to be minimized\nsubgradient: a function returning a subgradient f of f\n\nConstructor\n\nManifoldSubgradientObjective(f, âˆ‚f)\n\nGenerate the ManifoldSubgradientObjective for a subgradient objective, consisting of a (cost) function f(M, p) and a function âˆ‚f(M, p) that returns a not necessarily deterministic element from the subdifferential at p on a manifold M.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.get_subgradient","page":"Objective","title":"Manopt.get_subgradient","text":"X = get_subgradient(M::AbstractManifold, sgo::AbstractManifoldFirstOrderObjective, p)\nget_subgradient!(M::AbstractManifold, X, sgo::AbstractManifoldFirstOrderObjective, p)\n\nEvaluate the subgradient, which for the case of a objective having a gradient, means evaluating the gradient itself.\n\nWhile in general, the result might not be deterministic, for this case it is.\n\n\n\n\n\nget_subgradient(amp::AbstractManoptProblem, p)\nget_subgradient!(amp::AbstractManoptProblem, X, p)\n\nevaluate the subgradient of an AbstractManoptProblem amp at point p.\n\nThe evaluation is done in place of X for the !-variant. The result might not be deterministic, one element of the subdifferential is returned.\n\n\n\n\n\nX = get_subgradient(M;;AbstractManifold, sgo::ManifoldSubgradientObjective, p)\nget_subgradient!(M;;AbstractManifold, X, sgo::ManifoldSubgradientObjective, p)\n\nEvaluate the (sub)gradient of a ManifoldSubgradientObjective sgo at the point p.\n\nThe evaluation is done in place of X for the !-variant. The result might not be deterministic, one element of the subdifferential is returned.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_subgradient_function","page":"Objective","title":"Manopt.get_subgradient_function","text":"get_subgradient_function(amgo::ManifoldSubgradientObjective, recursive=false)\n\nreturn the function to evaluate (just) the gradient operatornamegrad f(p), where either the gradient function using the decorator or without the decorator is used.\n\nBy default recursive is set to false, since usually to just pass the gradient function somewhere, one still wants for example the cached one or the one that still counts calls.\n\nDepending on the AbstractEvaluationType E this is a function\n\n(M, p) -> X for the AllocatingEvaluation case\n(M, X, p) -> X for the InplaceEvaluation working in-place of X.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.ManifoldProximalMapObjective","page":"Objective","title":"Manopt.ManifoldProximalMapObjective","text":"ManifoldProximalMapObjective{E<:AbstractEvaluationType, TC, TP, V <: Vector{<:Integer}} <: AbstractManifoldCostObjective{E, TC}\n\nspecify a problem for solvers based on the evaluation of proximal maps, which represents proximal maps operatornameprox_Î»f_i for summands f = f_1 + f_2+  + f_N of the cost function f.\n\nFields\n\ncost: a function fmathcalMâ„ to minimize\nproxes: proximal maps operatornameprox_Î»f_imathcalM  mathcalM as functions (M, Î», p) -> q or in-place (M, q, Î», p).\nnumber_of_proxes: number of proximal maps per function, to specify when one of the maps is a combined one such that the proximal maps functions return more than one entry per function, you have to adapt this value. if not specified, it is set to one prox per function.\n\nConstructor\n\nManifoldProximalMapObjective(f, proxes_f::Union{Tuple,AbstractVector}, number_of_proxes=onex(length(proxes));\n   evaluation=Allocating)\n\nGenerate a proximal problem with a tuple or vector of functions, where by default every function computes a single prox of one component of f.\n\nManifoldProximalMapObjective(f, prox_f); evaluation=Allocating)\n\nGenerate a proximal objective for f and its proxial map operatornameprox_Î»f\n\nSee also\n\ncyclic_proximal_point, get_cost, get_proximal_map\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.get_proximal_map","page":"Objective","title":"Manopt.get_proximal_map","text":"q = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Î», p)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Î», p)\nq = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Î», p, i)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Î», p, i)\n\nevaluate the (ith) proximal map of the ManifoldProximalMapObjectivempo at the point p of M with parameter Î»0.\n\n\n\n\n\nq = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalGradientObjective, Î», p)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalGradientObjective, Î», p)\n\nEvaluate proximal map of the nonsmooth component h of the ManifoldProximalGradientObjectivempo at the point p on M with parameter Î»0.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.AbstractManifoldHessianObjective","page":"Objective","title":"Manopt.AbstractManifoldHessianObjective","text":"AbstractManifoldHessianObjective{E<:AbstractEvaluationType,F, G, H} <: AbstractManifoldFirstOrderObjective{E,Tuple{F,G}}\n\nAn abstract type for all objectives that provide a (full) Hessian, where T is a AbstractEvaluationType for the gradient and Hessian functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldHessianObjective","page":"Objective","title":"Manopt.ManifoldHessianObjective","text":"ManifoldHessianObjective{T<:AbstractEvaluationType,C,G,H,Pre} <: AbstractManifoldHessianObjective{T,C,G,H}\n\nspecify a problem for Hessian based algorithms.\n\nFields\n\ncost:           a function fmathcalMnifold)))â„ to minimize\ngradient:       the gradient operatornamegradfmathcalM)  TmathcalM of the cost function f\nhessian:        the Hessian operatornameHessf(x) T_xmathcalM  T_xmathcalM of the cost function f\npreconditioner: the symmetric, positive definite preconditioner as an approximation of the inverse of the Hessian of f, a map with the same input variables as the hessian to numerically stabilize iterations when the Hessian is ill-conditioned\n\nDepending on the AbstractEvaluationType T the gradient and can have to forms\n\nas a function (M, p) -> X  and (M, p, X) -> Y, resp., an AllocatingEvaluation\nas a function (M, X, p) -> X and (M, Y, p, X), resp., an InplaceEvaluation\n\nConstructor\n\nManifoldHessianObjective(f, grad_f, Hess_f, preconditioner = (M, p, X) -> X;\n    evaluation=AllocatingEvaluation())\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.get_hessian","page":"Objective","title":"Manopt.get_hessian","text":"Y = get_hessian(amp::AbstractManoptProblem{T}, p, X)\nget_hessian!(amp::AbstractManoptProblem{T}, Y, p, X)\n\nevaluate the Hessian of an AbstractManoptProblem amp at p applied to a tangent vector X, computing operatornameHessf(q)X, which can also happen in-place of Y.\n\n\n\n\n\nget_hessian(M::AbstractManifold, vgf::VectorHessianFunction, p, X, i)\nget_hessian(M::AbstractManifold, vgf::VectorHessianFunction, p, X, i, range)\nget_hessian!(M::AbstractManifold, X, vgf::VectorHessianFunction, p, X, i)\nget_hessian!(M::AbstractManifold, X, vgf::VectorHessianFunction, p, X, i, range)\n\nEvaluate the Hessians of the vector function vgf on the manifold M at p in direction X and the values given in range, specifying the representation of the gradients.\n\nSince i is assumed to be a linear index, you can provide\n\na single integer\na UnitRange to specify a range to be returned like 1:3\na BitVector specifying a selection\na AbstractVector{<:Integer} to specify indices\n: to return the vector of all Hessian evaluations\n\n\n\n\n\nget_hessian(TpM, trmo::TrustRegionModelObjective, X)\n\nEvaluate the Hessian of the TrustRegionModelObjective\n\noperatornameHess m(X)Y = operatornameHess f(p)Y\n\n\n\n\n\nget_Hessian(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X, V)\nget_Hessian!(TpM::TangentSpace, W, slso::SymmetricLinearSystemObjective, X, V)\n\nevaluate the Hessian of\n\nf(X) = frac12 lVert mathcalAX + b rVert_p^2qquad X  T_pmathcalM\n\nWhich is operatornameHess f(X)Y = mathcalAV. This can be computed in-place of W.\n\n\n\n\n\nget_hessian(M::AbstractManifold, emo::EmbeddedManifoldObjective, p, X)\nget_hessian!(M::AbstractManifold, Y, emo::EmbeddedManifoldObjective, p, X)\n\nEvaluate the Hessian of an objective defined in the embedding, that is embed p and X before calling the Hessian function stored in the EmbeddedManifoldObjective.\n\nThe returned Hessian is then converted to a Riemannian Hessian calling  riemannian_Hessian.\n\n\n\n\n\nget_hessian(M::AbstractManifold, scaled_objective::ScaledManifoldObjective, p, X)\nget_hessian!(M::AbstractManifold, Y, scaled_objective::ScaledManifoldObjective, p, X)\n\nEvaluate the scaled Hessian s*operatornameHessf(p)\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_preconditioner","page":"Objective","title":"Manopt.get_preconditioner","text":"get_preconditioner(amp::AbstractManoptProblem, p, X)\n\nevaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function f) of a AbstractManoptProblem amps objective at the point p applied to a tangent vector X.\n\n\n\n\n\nget_preconditioner(M::AbstractManifold, mho::ManifoldHessianObjective, p, X)\n\nevaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function F) of a ManifoldHessianObjective mho at the point p applied to a tangent vector X.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_hessian_function","page":"Objective","title":"Manopt.get_hessian_function","text":"get_hessian_function(amgo::ManifoldHessianObjective{E<:AbstractEvaluationType})\n\nreturn the function to evaluate (just) the Hessian operatornameHess f(p). Depending on the AbstractEvaluationType E this is a function\n\n(M, p, X) -> Y for the AllocatingEvaluation case\n(M, Y, p, X) -> X for the InplaceEvaluation, working in-place of Y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.AbstractPrimalDualManifoldObjective","page":"Objective","title":"Manopt.AbstractPrimalDualManifoldObjective","text":"AbstractPrimalDualManifoldObjective{E<:AbstractEvaluationType,C,P} <: AbstractManifoldCostObjective{E,C}\n\nA common abstract super type for objectives that consider primal-dual problems.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.PrimalDualManifoldObjective","page":"Objective","title":"Manopt.PrimalDualManifoldObjective","text":"PrimalDualManifoldObjective{T<:AbstractEvaluationType} <: AbstractPrimalDualManifoldObjective{T}\n\nDescribes an Objective linearized or exact Chambolle-Pock algorithm, cf. [BHS+21], [CP11]\n\nFields\n\nAll fields with !! can either be in-place or allocating functions, which should be set depending on the evaluation= keyword in the constructor and stored in T <: AbstractEvaluationType.\n\ncost:                          F + G(Î›()) to evaluate interim cost function values\nlinearized_forward_operator!!: linearized operator for the forward operation in the algorithm DÎ›\nlinearized_adjoint_operator!!: the adjoint differential (DÎ›)^*  mathcalN  TmathcalMnifold))nifold))\nprox_f!!:                      the proximal map belonging to f\nprox_G_dual!!:                 the proximal map belonging to g_n^*\nÎ›!!:                           the  forward operator (if given) Î› mathcalM)  mathcalN\n\nEither the linearized operator DÎ› or Î› are required usually.\n\nConstructor\n\nPrimalDualManifoldObjective(cost, prox_f, prox_G_dual, adjoint_linearized_operator;\n    linearized_forward_operator::Union{Function,Missing}=missing,\n    Î›::Union{Function,Missing}=missing,\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n)\n\nThe last optional argument can be used to provide the 4 or 5 functions as allocating or mutating (in place computation) ones. Note that the first argument is always the manifold under consideration, the mutated one is the second.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.PrimalDualManifoldSemismoothNewtonObjective","page":"Objective","title":"Manopt.PrimalDualManifoldSemismoothNewtonObjective","text":"PrimalDualManifoldSemismoothNewtonObjective{E<:AbstractEvaluationType, TC, LO, TALO, PF, DPF, PG, DPG, L} <: AbstractPrimalDualManifoldObjective{E, TC, PF}\n\nDescribes a Problem for the Primal-dual Riemannian semismooth Newton algorithm. [DL21]\n\nFields\n\ncost:                        F + G(Î›()) to evaluate interim cost function values\nlinearized_operator:         the linearization DÎ›() of the operator Î›().\nlinearized_adjoint_operator: the adjoint differential (DÎ›)^*  mathcalN  TmathcalM\nprox_F:                      the proximal map belonging to F\ndiff_prox_F:                 the (Clarke Generalized) differential of the proximal maps of F\nprox_G_dual:                 the proximal map belonging to G^\\ast_n`\ndiff_prox_dual_G:            the (Clarke Generalized) differential of the proximal maps of G^ast_n\nÎ›:                           the exact forward operator. This operator is required if Î›(m)=n does not hold.\n\nConstructor\n\nPrimalDualManifoldSemismoothNewtonObjective(cost, prox_F, prox_G_dual, forward_operator, adjoint_linearized_operator,Î›)\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.adjoint_linearized_operator","page":"Objective","title":"Manopt.adjoint_linearized_operator","text":"X = adjoint_linearized_operator(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y)\nadjoint_linearized_operator(N::AbstractManifold, X, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y)\n\nEvaluate the adjoint of the linearized forward operator of (DÎ›(m))^*Y stored within the AbstractPrimalDualManifoldObjective (in place of X). Since YT_nmathcalN, both m and n=Î›(m) are necessary arguments, mainly because the forward operator Î› might be missing in p.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.forward_operator","page":"Objective","title":"Manopt.forward_operator","text":"q = forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, p)\nforward_operator!(M::AbstractManifold, N::AbstractManifold, q, apdmo::AbstractPrimalDualManifoldObjective, p)\n\nEvaluate the forward operator of Î›(x) stored within the TwoManifoldProblem (in place of q).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential_dual_prox","page":"Objective","title":"Manopt.get_differential_dual_prox","text":"Î· = get_differential_dual_prox(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, n, Ï„, X, Î¾)\nget_differential_dual_prox!(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, Î·, n, Ï„, X, Î¾)\n\nEvaluate the differential proximal map of G_n^* stored within PrimalDualManifoldSemismoothNewtonObjective\n\nDoperatornameprox_Ï„G_n^*(X)Î¾\n\nwhich can also be computed in place of Î·.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential_primal_prox","page":"Objective","title":"Manopt.get_differential_primal_prox","text":"y = get_differential_primal_prox(M::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective Ïƒ, x)\nget_differential_primal_prox!(p::TwoManifoldProblem, y, Ïƒ, x)\n\nEvaluate the differential proximal map of F stored within AbstractPrimalDualManifoldObjective\n\nDoperatornameprox_ÏƒF(x)X\n\nwhich can also be computed in place of y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_dual_prox","page":"Objective","title":"Manopt.get_dual_prox","text":"Y = get_dual_prox(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, n, Ï„, X)\nget_dual_prox!(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, Y, n, Ï„, X)\n\nEvaluate the proximal map of g_n^* stored within AbstractPrimalDualManifoldObjective\n\n  Y = operatornameprox_Ï„G_n^*(X)\n\nwhich can also be computed in place of Y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_primal_prox","page":"Objective","title":"Manopt.get_primal_prox","text":"q = get_primal_prox(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, Ïƒ, p)\nget_primal_prox!(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, q, Ïƒ, p)\n\nEvaluate the proximal map of F stored within AbstractPrimalDualManifoldObjective\n\noperatornameprox_ÏƒF(x)\n\nwhich can also be computed in place of y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.linearized_forward_operator","page":"Objective","title":"Manopt.linearized_forward_operator","text":"Y = linearized_forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, X, n)\nlinearized_forward_operator!(M::AbstractManifold, N::AbstractManifold, Y, apdmo::AbstractPrimalDualManifoldObjective, m, X, n)\n\nEvaluate the linearized operator (differential) DÎ›(m)X stored within the AbstractPrimalDualManifoldObjective (in place of Y), where n = Î›(m).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.ConstrainedManifoldObjective","page":"Objective","title":"Manopt.ConstrainedManifoldObjective","text":"ConstrainedManifoldObjective{T<:AbstractEvaluationType, C<:ConstraintType} <: AbstractManifoldObjective{T}\n\nDescribes a constrained objective\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nFields\n\nobjective: an AbstractManifoldObjective representing the unconstrained objective, that is containing cost f, the gradient of the cost f and maybe the Hessian.\nequality_constraints: an AbstractManifoldObjective representing the equality constraints\n\nh mathcalM)  â„^n also possibly containing its gradient and/or Hessian\n\ninequality_constraints: an AbstractManifoldObjective representing the inequality constraints\n\ng mathcalM)  â„^m also possibly containing its gradient and/or Hessian\n\nConstructors\n\nConstrainedManifoldObjective(f, grad_f;\n    g=nothing,\n    grad_g=nothing,\n    h=nothing,\n    grad_h=nothing;\n    hess_f=nothing,\n    hess_g=nothing,\n    hess_h=nothing,\n    equality_constraints=nothing,\n    inequality_constraints=nothing,\n    evaluation=AllocatingEvaluation(),\n    M = nothing,\n    p = isnothing(M) ? nothing : rand(M),\n    atol = 0,\n)\n\nGenerate the constrained objective based on all involved single functions f, grad_f, g, grad_g, h, grad_h, and optionally a Hessian for each of these. With equality_constraints and inequality_constraints you have to provide the dimension of the ranges of h and g, respectively. You can also provide a manifold M and a point p to use one evaluation of the constraints to automatically try to determine these sizes.\n\nConstrainedManifoldObjective(mho::AbstractManifoldObjective;\n    equality_constraints = nothing,\n    inequality_constraints = nothing\n)\n\nGenerate the constrained objective either with explicit constraints g and h, and their gradients, or in the form where these are already encapsulated in VectorGradientFunctions.\n\nBoth variants require that at least one of the constraints (and its gradient) is provided. If any of the three parts provides a Hessian, the corresponding object, that is a ManifoldHessianObjective for f or a VectorHessianFunction for g or h, respectively, is created.\n\nFeasibility of points with respect to the constraints is determined up to the tolerance atol.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldConstrainedSetObjective","page":"Objective","title":"Manopt.ManifoldConstrainedSetObjective","text":"ManifoldConstrainedSetObjective{E, MO, PF, IF} <: AbstractManifoldObjective{E}\n\nModel a constrained objective restricted to a set\n\noperatorname*argmin_p  mathcalC f(p)\n\nwhere mathcalC  mathcalM) is a convex closed subset.\n\nFields\n\nobjective::AbstractManifoldObjective the (unconstrained) objective, which contains f and for example its gradient operatornamegrad f.\nproject!!::PF a projection function operatornameproj_mathcalC mathcalM)  mathcalC that projects onto the set mathcalC.\nindicator::IF the indicator function Î¹_mathcalC(p) = begincases   0 text for pmathcalC     text elseendcases\n\nConstructor\n\nManifoldConstrainedSetObjective(f, grad_f, project!!; kwargs...)\n\nGenerate the constrained objective for a given function f its gradient grad_f and a projection project!! operatornameproj_mathcalC.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nindicator=nothing: the indicator function Î¹_mathcalC(p). If not provided a test, whether the projection yields the same point is performed. For the InplaceEvaluation this required one allocation.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ConstrainedManoptProblem","page":"Objective","title":"Manopt.ConstrainedManoptProblem","text":"ConstrainedManoptProblem{\n    TM <: AbstractManifold,\n    O <: AbstractManifoldObjective\n    HR<:Union{AbstractPowerRepresentation,Nothing},\n    GR<:Union{AbstractPowerRepresentation,Nothing},\n    HHR<:Union{AbstractPowerRepresentation,Nothing},\n    GHR<:Union{AbstractPowerRepresentation,Nothing},\n} <: AbstractManoptProblem{TM}\n\nA constrained problem might feature different ranges for the (vectors of) gradients of the equality and inequality constraints.\n\nThe ranges are required in a few places to allocate memory and access elements correctly, they work as follows:\n\nAssume the objective is\n\nbeginaligned\n operatorname*argmin_p  mathcalM)  f(p)\n textsubject to   g_i(p)  0 quad text for all  i=1m\n quad  h_j(p)=0 quad text for all  j=1n\nendaligned\n\nthen the gradients can (classically) be considered as vectors of the components gradients, for example bigl(operatornamegrad g_1(p) operatornamegrad g_2(p)  operatornamegrad g_m(p) bigr).\n\nIn another interpretation, this can be considered a point on the tangent space at P = (pp)  mathcalM)^m, so in the tangent space to the PowerManifold mathcalM)^m. The case where this is a NestedPowerRepresentation this agrees with the interpretation from before, but on power manifolds, more efficient representations exist.\n\nTo then access the elements, the range has to be specified. That is what this problem is for.\n\nConstructor\n\nConstrainedManoptProblem(\n    M::AbstractManifold,\n    co::ConstrainedManifoldObjective;\n    range=NestedPowerRepresentation(),\n    gradient_equality_range=range,\n    gradient_inequality_range=range\n    hessian_equality_range=range,\n    hessian_inequality_range=range\n)\n\nCreates a constrained Manopt problem specifying an AbstractPowerRepresentation for both the gradient_equality_range and the gradient_inequality_range, respectively.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractConstrainedFunctor","page":"Objective","title":"Manopt.AbstractConstrainedFunctor","text":"AbstractConstrainedFunctor{T}\n\nA common supertype for functors that model constraint functions.\n\nThis supertype provides access for the fields Î» and Î¼, the dual variables of constraints of type T.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractConstrainedSlackFunctor","page":"Objective","title":"Manopt.AbstractConstrainedSlackFunctor","text":"AbstractConstrainedSlackFunctor{T,R}\n\nA common supertype for functors that model constraint functions with slack.\n\nThis supertype additionally provides access for the fields\n\nÎ¼::T the dual for the inequality constraints\ns::T the slack parameter, and\nÎ²::R the  the barrier parameter\n\nwhich is also of type T.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.LagrangianCost","page":"Objective","title":"Manopt.LagrangianCost","text":"LagrangianCost{CO,T} <: AbstractConstrainedFunctor{T}\n\nImplement the Lagrangian of a ConstrainedManifoldObjective co.\n\nmathcalL(p Î¼ Î») = f(p) + sum_i=1^m Î¼_ig_i(p) + sum_j=1^n Î»_jh_j(p)\n\nFields\n\nco::CO, Î¼::T, Î»::T as mentioned, where T represents a vector type.\n\nConstructor\n\nLagrangianCost(co, Î¼, Î»)\n\nCreate a functor for the Lagrangian with fixed dual variables.\n\nExample\n\nWhen you directly want to evaluate the Lagrangian mathcalL you can also call\n\nLagrangianCost(co, Î¼, Î»)(M,p)\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.LagrangianGradient","page":"Objective","title":"Manopt.LagrangianGradient","text":"LagrangianGradient{CO,T}\n\nThe gradient of the Lagrangian of a ConstrainedManifoldObjective co with respect to the variable p. The formula reads\n\noperatornamegrad_p mathcalL(p Î¼ Î»)\n= operatornamegrad f(p) + sum_i=1^m Î¼_i operatornamegrad g_i(p) + sum_j=1^n Î»_j operatornamegrad h_j(p)\n\nFields\n\nco::CO, Î¼::T, Î»::T as mentioned, where T represents a vector type.\n\nConstructor\n\nLagrangianGradient(co, Î¼, Î»)\n\nCreate a functor for the Lagrangian with fixed dual variables.\n\nExample\n\nWhen you directly want to evaluate the gradient of the Lagrangian operatornamegrad_p mathcalL you can also call LagrangianGradient(co, Î¼, Î»)(M,p) or LagrangianGradient(co, Î¼, Î»)(M,X,p) for the in-place variant.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.LagrangianHessian","page":"Objective","title":"Manopt.LagrangianHessian","text":"LagrangianHessian{CO, V, T}\n\nThe Hessian of the Lagrangian of a ConstrainedManifoldObjective co with respect to the variable p. The formula reads\n\noperatornameHess_p mathcalL(p Î¼ Î»)X\n= operatornameHess f(p) + sum_i=1^m Î¼_i operatornameHess g_i(p)X + sum_j=1^n Î»_j operatornameHess h_j(p)X\n\nFields\n\nco::CO, Î¼::T, Î»::T as mentioned, where T represents a vector type.\n\nConstructor\n\nLagrangianHessian(co, Î¼, Î»)\n\nCreate a functor for the Lagrangian with fixed dual variables.\n\nExample\n\nWhen you directly want to evaluate the Hessian of the Lagrangian operatornameHess_p mathcalL you can also call LagrangianHessian(co, Î¼, Î»)(M, p, X) or LagrangianHessian(co, Î¼, Î»)(M, Y, p, X) for the in-place variant.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.equality_constraints_length","page":"Objective","title":"Manopt.equality_constraints_length","text":"equality_constraints_length(co::ConstrainedManifoldObjective)\n\nReturn the number of equality constraints of an ConstrainedManifoldObjective. This acts transparently through AbstractDecoratedManifoldObjectives\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.inequality_constraints_length","page":"Objective","title":"Manopt.inequality_constraints_length","text":"inequality_constraints_length(cmo::ConstrainedManifoldObjective)\n\nReturn the number of inequality constraints of an ConstrainedManifoldObjective cmo. This acts transparently through AbstractDecoratedManifoldObjectives\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_equality_constraint","page":"Objective","title":"Manopt.get_equality_constraint","text":"get_equality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_equality_constraint(M::AbstractManifold, objective, p, j=:)\n\nEvaluate equality constraints of a ConstrainedManifoldObjective objective at point p and indices j (by default : which corresponds to all indices).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_equality_constraint","page":"Objective","title":"Manopt.get_grad_equality_constraint","text":"get_grad_equality_constraint(amp::AbstractManoptProblem, p, j)\nget_grad_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\nget_grad_equality_constraint!(amp::AbstractManoptProblem, X, p, j)\nget_grad_equality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\n\nEvaluate the gradient or gradients  of the equality constraint (operatornamegrad h(p))_j or operatornamegrad h_j(p),\n\nSee also the ConstrainedManoptProblem to specify the range of the gradient.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_inequality_constraint","page":"Objective","title":"Manopt.get_grad_inequality_constraint","text":"get_grad_inequality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_grad_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\nget_grad_inequality_constraint!(amp::AbstractManoptProblem, X, p, j=:)\nget_grad_inequality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\n\nEvaluate the gradient or gradients of the inequality constraint (operatornamegrad g(p))_j or operatornamegrad g_j(p),\n\nSee also the ConstrainedManoptProblem to specify the range of the gradient.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_hess_equality_constraint","page":"Objective","title":"Manopt.get_hess_equality_constraint","text":"get_hess_equality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_hess_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\nget_hess_equality_constraint!(amp::AbstractManoptProblem, X, p, j=:)\nget_hess_equality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j, range=NestedPowerRepresentation())\n\nEvaluate the Hessian or Hessians of the equality constraint (operatornameHess h(p))_j or operatornameHess h_j(p),\n\nSee also the ConstrainedManoptProblem to specify the range of the Hessian.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_hess_inequality_constraint","page":"Objective","title":"Manopt.get_hess_inequality_constraint","text":"get_hess_inequality_constraint(amp::AbstractManoptProblem, p, X, j=:)\nget_hess_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\nget_hess_inequality_constraint!(amp::AbstractManoptProblem, Y, p, j=:)\nget_hess_inequality_constraint!(M::AbstractManifold, Y, co::ConstrainedManifoldObjective, p, X, j=:, range=NestedPowerRepresentation())\n\nEvaluate the Hessian or Hessians of the inequality constraint (operatornameHess g(p)X)_j or operatornameHess g_j(p)X,\n\nSee also the ConstrainedManoptProblem to specify the range of the Hessian.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_inequality_constraint","page":"Objective","title":"Manopt.get_inequality_constraint","text":"get_inequality_constraint(amp::AbstractManoptProblem, p, j=:)\nget_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j=:, range=NestedPowerRepresentation())\n\nEvaluate inequality constraints of a ConstrainedManifoldObjective objective at point p and indices j (by default : which corresponds to all indices).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_projected_point","page":"Objective","title":"Manopt.get_projected_point","text":"get_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\nget_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_projected_point!","page":"Objective","title":"Manopt.get_projected_point!","text":"get_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\nget_projected_point(amp::AbstractManoptProblem, p)\nget_projected_point!(amp::AbstractManoptProblem, q, p)\nget_projected_point(M::AbstractManifold, cso::ManifoldConstrainedSetObjective, p)\nget_projected_point!(M::AbstractManifold, q, cso::ManifoldConstrainedSetObjective, p)\n\nProject p with the projection that is stored within the ManifoldConstrainedSetObjective. This can be done in-place of q.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_unconstrained_objective","page":"Objective","title":"Manopt.get_unconstrained_objective","text":"get_unconstrained_objective(co::ConstrainedManifoldObjective)\n\nReturns the internally stored unconstrained AbstractManifoldObjective within the ConstrainedManifoldObjective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.is_feasible","page":"Objective","title":"Manopt.is_feasible","text":"is_feasible(M::AbstractManifold, cmo::ConstrainedManifoldObjective, p, kwargs...)\nis_feasible(M::AbstractManifold, o::AbstractDecoratedManifoldObjective, p, kwargs...)\n\nEvaluate whether a point p on M is feasible with respect to the ConstrainedManifoldObjective cmo. That is for the provided inequality constraints g mathcalM)  â„^m and equality constraints h mathcalM) \to â„^m from within cmo, the point p  mathcalM) is feasible if\n\ng_i(p)  0 \text for all  i=1mquad\text and quad h_j(p) = 0 \text for all  j=1n\n\nKeyword arguments\n\ncheck_point::Bool=true: whether to also verify that `pâˆˆ\\mathcal{M}) holds, using is_point\nerror::Symbol=:none: if the point is not feasible, this symbol determines how to report the error.\n:error: throws an error\n:info: displays the error message as an @info\n:none: (default) the function just returns true/false\n:warn: displays the error message as a @warning.\n\nThe keyword error= and all other kwargs... are passed on to is_point if the point is verified (see check_point).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_feasibility_status","page":"Objective","title":"Manopt.get_feasibility_status","text":"get_feasibility_status(\n    M::AbstractManifold,\n    cmo::ConstrainedManifoldObjective,\n    g = get_inequality_constraints(M, cmo, p),\n    h = get_equality_constraints(M, cmo, p),\n)\n\nGenerate a message about the feasibiliy of p with respect to the ConstrainedManifoldObjective. You can also provide the evaluated vectors for the values of g and h as keyword arguments, in case you had them evaluated before.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.AbstractVectorFunction","page":"Objective","title":"Manopt.AbstractVectorFunction","text":"AbstractVectorFunction{E, FT} <: Function\n\nRepresent an abstract vectorial function fmathcalM)  â„^n with an AbstractEvaluationType E and an AbstractVectorialType to specify the format f is implemented as.\n\nRepresentations of f\n\nThere are three different representations of f, which might be beneficial in one or the other situation:\n\nthe FunctionVectorialType storing a single function f that returns a vector,\nthe ComponentVectorialType storing a vector of functions f_i that return a single value each,\nthe CoordinateVectorialType storing functions with respect to a specific basis of the tangent space for gradients and Hessians. Gradients of this type are usually referred to as Jacobians.\n\nFor the ComponentVectorialType imagine that f could also be written using its component functions,\n\nf(p) = igl( f_1(p) f_2(p) f_n(p) igr)^mathrmT\n\nIn this representation f is given as a vector [f1(M,p), f2(M,p), ..., fn(M,p)] of its component functions. An advantage is that the single components can be evaluated and from this representation one even can directly read of the number n. A disadvantage might be, that one has to implement a lot of individual (component) functions.\n\nFor the  FunctionVectorialType f is implemented as a single function f(M, p), that returns an AbstractArray. And advantage here is, that this is a single function. A disadvantage might be, that if this is expensive even to compute a single component, all of f has to be evaluated\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractVectorGradientFunction","page":"Objective","title":"Manopt.AbstractVectorGradientFunction","text":"VectorGradientFunction{E, FT, JT, F, J, I} <: AbstractManifoldObjective{E}\n\nRepresent an abstract vectorial function fmathcalM)  â„^n that provides a (component wise) gradient. The AbstractEvaluationType E indicates the evaluation type, and the AbstractVectorialTypes FT and JT the formats in which the function and the gradient are provided, see AbstractVectorFunction for an explanation.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.VectorGradientFunction","page":"Objective","title":"Manopt.VectorGradientFunction","text":"VectorGradientFunction{E, FT, JT, F, J, I} <: AbstractVectorGradientFunction{E, FT, JT}\n\nRepresent a function fmathcalM)  â„^n including it first derivative, either as a vector of gradients of a Jacobian\n\nAnd hence has a gradient `\\operatorname{grad} f_i(p) âˆˆ T_{p}\\mathcal{M}. Putting these gradients into a vector the same way as the functions, yields a ComponentVectorialType\n\noperatornamegrad f(p) = Bigl( operatornamegrad f_1(p) operatornamegrad f_2(p)  operatornamegrad f_n(p) Bigr)^mathrmT\n (T_pmathcalM)^n\n\nAnd advantage here is, that again the single components can be evaluated individually\n\nFields\n\nvalue!!::F:          the cost function f, which can take different formats\ncost_type::AbstractVectorialType:     indicating / storing data for the type of f\njacobian!!::G:     the Jacobian of f\njacobian_type::AbstractVectorialType: indicating / storing data for the type of J_f\nparameters:    the number n from, the size of the vector f returns.\n\nConstructor\n\nVectorGradientFunction(f, Jf, range_dimension;\n    evaluation::AbstractEvaluationType=AllocatingEvaluation(),\n    function_type::AbstractVectorialType=FunctionVectorialType(),\n    jacobian_type::AbstractVectorialType=FunctionVectorialType(),\n)\n\nCreate a VectorGradientFunction of f  and its Jacobian (vector of gradients) Jf, where f maps into the Euclidean space of dimension range_dimension. Their types are specified by the function_type, and jacobian_type, respectively. The Jacobian can further be given as an allocating variant or an in-place variant, specified by the evaluation= keyword.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.VectorHessianFunction","page":"Objective","title":"Manopt.VectorHessianFunction","text":"VectorHessianFunction{E, FT, JT, HT, F, J, H, I} <: AbstractVectorGradientFunction{E, FT, JT}\n\nRepresent a function fmathcalM) M  â„^n including it first derivative, either as a vector of gradients of a Jacobian, and the Hessian, as a vector of Hessians of the component functions.\n\nBoth the Jacobian and the Hessian can map into either a sequence of tangent spaces or a single tangent space of the power manifold of length n.\n\nFields\n\nvalue!!::F:          the cost function f, which can take different formats\ncost_type::AbstractVectorialType:     indicating / string data for the type of f\njacobian!!::G:     the Jacobian J_f of f\njacobian_type::AbstractVectorialType: indicating / storing data for the type of J_f\nhessians!!::H:     the Hessians of f (in a component wise sense)\nhessian_type::AbstractVectorialType:  indicating / storing data for the type of H_f\nrange_dimension:    the number n from, the size of the vector f returns.\n\nConstructor\n\nVectorHessianFunction(f, Jf, Hess_f, range_dimension;\n    evaluation::AbstractEvaluationType=AllocatingEvaluation(),\n    function_type::AbstractVectorialType=FunctionVectorialType(),\n    jacobian_type::AbstractVectorialType=FunctionVectorialType(),\n    hessian_type::AbstractVectorialType=FunctionVectorialType(),\n)\n\nCreate a VectorHessianFunction of f  and its Jacobian (vector of gradients) Jf and (vector of) Hessians, where f maps into the Euclidean space of dimension range_dimension. Their types are specified by the function_type, and jacobian_type, and hessian_type, respectively. The Jacobian and Hessian can further be given as an allocating variant or an inplace-variant, specified by the evaluation= keyword.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractVectorialType","page":"Objective","title":"Manopt.AbstractVectorialType","text":"AbstractVectorialType\n\nAn abstract type for different representations of a vectorial function f mathcalMnifold))nifold))nifold)))  â„^m and its (component-wise) gradient/Jacobian\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.CoordinateVectorialType","page":"Objective","title":"Manopt.CoordinateVectorialType","text":"CoordinateVectorialType{B<:AbstractBasis} <: AbstractVectorialType\n\nA type to indicate that gradient of the constraints is implemented as a Jacobian matrix with respect to a certain basis, that is if the vector function is f mathcalMnifold)))  â„^m and we have a basis mathcalB ofTp\\mathcal{M}) atpâˆˆ \\mathcal{M})This can be written asJg(p) = (c1^{\\mathrm{T}},â€¦,cm^{\\mathrm{T}})^{\\mathrm{T}} âˆˆ â„^{m,d} that is every rowci`of this matrix is a set of coefficients such thatgetcoefficients(M, p, c, B)is the tangent vector\\operatorname{grad} g_i(p)for exampleg_i(p) âˆˆ â„^mor\\operatorname{grad} g_i(p) âˆˆ T_p\\mathcal{M},i=1,â€¦,m`.\n\nFields\n\nbasis an AbstractBasis to indicate the basis in which Jacobian is expressed.\n\nConstructor\n\nCoordinateVectorialType(basis=DefaultOrthonormalBasis())\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ComponentVectorialType","page":"Objective","title":"Manopt.ComponentVectorialType","text":"ComponentVectorialType <: AbstractVectorialType\n\nA type to indicate that constraints are implemented as component functions, for example g_i(p)  â„^m or operatornamegrad g_i(p)  T_pmathcalMi=1,â€¦,m``.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.FunctionVectorialType","page":"Objective","title":"Manopt.FunctionVectorialType","text":"FunctionVectorialType{P<:AbstractPowerRepresentation} <: AbstractVectorialType\n\nA type to indicate that constraints are implemented one whole functions, for example g(p)  â„^m or operatornamegrad g(p)  (T_pmathcalM^m.\n\nThis type internally stores the AbstractPowerRepresentation, when it makes sense, especially for Hessian and gradient functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.get_jacobian","page":"Objective","title":"Manopt.get_jacobian","text":"get_jacobian(M::AbstractManifold, vgf::AbstractVectorGradientFunction, p; kwargs...)\nget_jacobian(M::AbstractManifold, J, vgf::AbstractVectorGradientFunction, p; kwargs...)\n\nCompute the Jacobian J_F  â„^mn of the AbstractVectorGradientFunction F at p on the M.\n\nThere are two interpretations of the Jacobian of a vectorial function F mathcalM)  â„^m on a manifold. Both depend on choosing a basis on the tangent space T_pmathcalM) which we denote by Y_1Y_n, where n is the manifold_dimension(M)(M). We can write any tangent vector X = displaystylesum_i c_iY_i\n\nThe Jacobian J_F is the matrix with respect to the basis Y_1Y_n such that\n\nfor any XT_pmathcalM) we have the equality of the differential DF(p)X = Jc.   In other words, the jth column of J is given by DF(p)Y_j\n\nGiven the gradients operatornamegrad F_i(p) of the component functions F_i mathcalM)  â„,\n\nwe define the jacobian function as\n\nmath   J(X) = beginpmatrix operatornamegrad F_1 X_p operatornamegrad F_1 X_p  operatornamegrad F_1 X_pendpmatrix\n\nThen either the jth column of J_F is given by J(Y_i) or the ith row is given by all inner products operatornamegrad F_1 Y_j_p of the ith gradient function with all basis vectors Y_j.\n\nThe computation can be computed in-place of J.\n\nKeyword arguments\n\nbasis::AbstractBasis =get_basis(vgf) for the CoordinateVectorialType of the vectorial functions gradient, this might lead to a change of basis, if this basis and the one the coordinates are given in do not agree.\nrange::AbstractPowerRepresentation =get_range(vgf.jacobian_type) specify the range of the gradients in the case of a FunctionVectorialType, that is, on which type of power manifold the gradient is given on.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_jacobian!","page":"Objective","title":"Manopt.get_jacobian!","text":"get_jacobian(M::AbstractManifold, vgf::AbstractVectorGradientFunction, p; kwargs...)\nget_jacobian(M::AbstractManifold, J, vgf::AbstractVectorGradientFunction, p; kwargs...)\n\nCompute the Jacobian J_F  â„^mn of the AbstractVectorGradientFunction F at p on the M.\n\nThere are two interpretations of the Jacobian of a vectorial function F mathcalM)  â„^m on a manifold. Both depend on choosing a basis on the tangent space T_pmathcalM) which we denote by Y_1Y_n, where n is the manifold_dimension(M)(M). We can write any tangent vector X = displaystylesum_i c_iY_i\n\nThe Jacobian J_F is the matrix with respect to the basis Y_1Y_n such that\n\nfor any XT_pmathcalM) we have the equality of the differential DF(p)X = Jc.   In other words, the jth column of J is given by DF(p)Y_j\n\nGiven the gradients operatornamegrad F_i(p) of the component functions F_i mathcalM)  â„,\n\nwe define the jacobian function as\n\nmath   J(X) = beginpmatrix operatornamegrad F_1 X_p operatornamegrad F_1 X_p  operatornamegrad F_1 X_pendpmatrix\n\nThen either the jth column of J_F is given by J(Y_i) or the ith row is given by all inner products operatornamegrad F_1 Y_j_p of the ith gradient function with all basis vectors Y_j.\n\nThe computation can be computed in-place of J.\n\nKeyword arguments\n\nbasis::AbstractBasis =get_basis(vgf) for the CoordinateVectorialType of the vectorial functions gradient, this might lead to a change of basis, if this basis and the one the coordinates are given in do not agree.\nrange::AbstractPowerRepresentation =get_range(vgf.jacobian_type) specify the range of the gradients in the case of a FunctionVectorialType, that is, on which type of power manifold the gradient is given on.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_value","page":"Objective","title":"Manopt.get_value","text":"get_value(M::AbstractManifold, vgf::AbstractVectorFunction, p[, i=:])\nget_value!(M::AbstractManifold, V, vgf::AbstractVectorFunction, p[, i=:])\n\nEvaluate the vector function VectorGradientFunction vgf at p. The range can be used to specify a potential range, but is currently only present for consistency.\n\nThe i can be a linear index, you can provide\n\na single integer\na UnitRange to specify a range to be returned like 1:3\na BitVector specifying a selection\na AbstractVector{<:Integer} to specify indices\n: to return the vector of all gradients, which is also the default\n\nThis function can perform the evaluation inplace of V.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_value_function","page":"Objective","title":"Manopt.get_value_function","text":"get_value_function(vgf::VectorGradientFunction, recursive=false)\n\nreturn the internally stored function computing get_value.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Base.length-Tuple{VectorGradientFunction}","page":"Objective","title":"Base.length","text":"length(vgf::AbstractVectorFunction)\n\nReturn the length of the vector the function f mathcalM)  â„^n maps into, that is the number n.\n\n\n\n\n\n","category":"method"},{"location":"plans/objective/#Manopt._to_iterable_indices","page":"Objective","title":"Manopt._to_iterable_indices","text":"_to_iterable_indices(A::AbstractVector, i)\n\nConvert index i (integer, colon, vector of indices, etc.) for array A into an iterable structure of indices.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt._change_basis!","page":"Objective","title":"Manopt._change_basis!","text":"_change_basis!(M::AbstractManifold, JF, p, from_basis::B1, to_basis::B; X=zero_vector(M,p))\n\nGiven a jacobian matrix JF on a manifold M at p with respect to the from_basis in the tangent space of p on M. Change the basis of the Jacobian to to_basis in place of JF.\n\nKeyword Arguments\n\nX a temporary vector to store a generated vector, before decomposing it again with respect to the new basis\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#ManifoldsBase.get_basis","page":"Objective","title":"ManifoldsBase.get_basis","text":"get_basis(::AbstractVectorialType)\n\nReturn a basis that fits a vector function representation.\n\nFor the case, where some vectorial data is stored with respect to a basis, this function returns the corresponding basis, most prominently for the CoordinateVectorialType.\n\nIf a type is not with respect to a certain basis, the DefaultOrthonormalBasis is returned.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_range","page":"Objective","title":"Manopt.get_range","text":"get_range(::AbstractVectorialType)\n\nReturn an abstract power manifold representation that fits a vector function's range. Most prominently a FunctionVectorialType returns its internal range.\n\nOtherwise the default NestedPowerRepresentation() is used to work on a vector of data.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.AbstractManifoldSubObjective","page":"Objective","title":"Manopt.AbstractManifoldSubObjective","text":"AbstractManifoldSubObjective{O<:AbstractManifoldObjective} <: AbstractManifoldObjective\n\nAn abstract type for objectives of sub problems within a solver but still store the original objective internally to generate generic objectives for sub solvers.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.get_objective_cost","page":"Objective","title":"Manopt.get_objective_cost","text":"get_objective_cost(M, amso::AbstractManifoldSubObjective, p)\n\nEvaluate the cost of the (original) objective stored within the sub objective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_objective_gradient","page":"Objective","title":"Manopt.get_objective_gradient","text":"X = get_objective_gradient(M, amso::AbstractManifoldSubObjective, p)\nget_objective_gradient!(M, X, amso::AbstractManifoldSubObjective, p)\n\nEvaluate the gradient of the (original) objective stored within the sub objective amso.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_objective_hessian","page":"Objective","title":"Manopt.get_objective_hessian","text":"Y = get_objective_Hessian(M, amso::AbstractManifoldSubObjective, p, X)\nget_objective_Hessian!(M, Y, amso::AbstractManifoldSubObjective, p, X)\n\nEvaluate the Hessian of the (original) objective stored within the sub objective amso.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_objective_preconditioner","page":"Objective","title":"Manopt.get_objective_preconditioner","text":"Y = get_objective_preconditioner(M, amso::AbstractManifoldSubObjective, p, X)\nget_objective_preconditioner(M, Y, amso::AbstractManifoldSubObjective, p, X)\n\nEvaluate the Hessian of the (original) objective stored within the sub objective amso.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.ManifoldProximalGradientObjective","page":"Objective","title":"Manopt.ManifoldProximalGradientObjective","text":"ManifoldProximalGradientObjective{E,<:AbstractEvaluationType, TC, TG, TGG, TP} <: AbstractManifoldObjective{E,TC,TGG}\n\nModel an objective of the form\n\n    f(p) = g(p) + h(p) qquad p  mathcalMnifold)))\n\nwhere g mathcalM)  barmathbb R is a differentiable function and h  barmathbb R is a (possibly) lower semicontinous, and proper function.\n\nThis objective provides the total cost f, its smooth component g, as well as operatornamegrad g and operatornameprox_Î» h.\n\nFields\n\ncost: the overall cost f = g + h\ncost_smooth: the smooth cost component g\ngradient_g!!: the gradient operatornamegrad g\nproximal_map_h!!: the proximal map operatornameprox_Î» h\n\nConstructor\n\nManifoldProximalGradientObjective(f, g, grad_g, prox_h;\n    evalauation=[`AllocatingEvaluation`](@ref)\n)\n\nGenerate the proximal gradient objective given the total cost f = g + h, smooth cost g, the gradient of the smooth component operatornamegrad g, and the proximal map of the nonsmooth component operatornameprox_Î» h.\n\nKeyword arguments\n\nevaluation=AllocatingEvaluation: whether the gradient and proximal map is given as an allocation function or an in-place (InplaceEvaluation).\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#sec-stopping-criteria","page":"Stopping Criteria","title":"Stopping criteria","text":"Stopping criteria are implemented as a functor and inherit from the base type\n\nThey can also be grouped, which is summarized in the type of a set of criteria\n\nThe stopping criteria s might have certain internal values/fields it uses to verify against. This is done when calling them as a function s(amp::AbstractManoptProblem, ams::AbstractManoptSolverState), where the AbstractManoptProblem and the AbstractManoptSolverState together represent the current state of the solver. The functor returns either false when the stopping criterion is not fulfilled or true otherwise. One field all criteria should have is the s.at_iteration, to indicate at which iteration the stopping criterion (last) indicated to stop. 0 refers to an indication before starting the algorithm, while any negative number meant the stopping criterion is not (yet) fulfilled. To can access a string giving the reason of stopping see get_reason.","category":"section"},{"location":"plans/stopping_criteria/#Generic-stopping-criteria","page":"Stopping Criteria","title":"Generic stopping criteria","text":"The following generic stopping criteria are available. Some require that, for example, the corresponding AbstractManoptSolverState have a field gradient when the criterion should access that.\n\nFurther stopping criteria might be available for individual solvers.","category":"section"},{"location":"plans/stopping_criteria/#Functions-for-stopping-criteria","page":"Stopping Criteria","title":"Functions for stopping criteria","text":"There are a few functions to update, combine, and modify stopping criteria, especially to update internal values even for stopping criteria already being used within an AbstractManoptSolverState structure.","category":"section"},{"location":"plans/stopping_criteria/#Manopt.StoppingCriterion","page":"Stopping Criteria","title":"Manopt.StoppingCriterion","text":"StoppingCriterion\n\nAn abstract type for the functors representing stopping criteria, so they are callable structures. The naming Scheme follows functions, see for example StopAfterIteration.\n\nEvery StoppingCriterion has to provide a constructor and its function has to have the interface (p,o,i) where a AbstractManoptProblem as well as AbstractManoptSolverState and the current number of iterations are the arguments and returns a boolean whether to stop or not.\n\nBy default each StoppingCriterion should provide a fields reason to provide details when a criterion is met (and that is empty otherwise).\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.StoppingCriterionSet","text":"StoppingCriterionGroup <: StoppingCriterion\n\nAn abstract type for a Stopping Criterion that itself consists of a set of Stopping criteria. In total it acts as a stopping criterion itself. Examples are StopWhenAny and StopWhenAll that can be used to combine stopping criteria.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopAfter","page":"Stopping Criteria","title":"Manopt.StopAfter","text":"StopAfter <: StoppingCriterion\n\nstore a threshold when to stop looking at the complete runtime. It uses time_ns() to measure the time and you provide a Period as a time limit, for example Minute(15).\n\nFields\n\nthreshold stores the Period after which to stop\nstart stores the starting time when the algorithm is started, that is a call with i=0.\ntime stores the elapsed time\nat_iteration indicates at which iteration (including i=0) the stopping criterion was fulfilled and is -1 while it is not fulfilled.\n\nConstructor\n\nStopAfter(t)\n\ninitialize the stopping criterion to a Period t to stop after.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopAfterIteration","page":"Stopping Criteria","title":"Manopt.StopAfterIteration","text":"StopAfterIteration <: StoppingCriterion\n\nA functor for a stopping criterion to stop after a maximal number of iterations.\n\nFields\n\nmax_iterations  stores the maximal iteration number where to stop at\nat_iteration indicates at which iteration (including i=0) the stopping criterion was fulfilled and is -1 while it is not fulfilled.\n\nConstructor\n\nStopAfterIteration(maxIter)\n\ninitialize the functor to indicate to stop after maxIter iterations.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenAll","page":"Stopping Criteria","title":"Manopt.StopWhenAll","text":"StopWhenAll <: StoppingCriterionSet\n\nstore an array of StoppingCriterion elements and indicates to stop, when all indicate to stop. The reason is given by the concatenation of all reasons.\n\nConstructor\n\nStopWhenAll(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAll(c::StoppingCriterion,...)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenAny","page":"Stopping Criteria","title":"Manopt.StopWhenAny","text":"StopWhenAny <: StoppingCriterionSet\n\nstore an array of StoppingCriterion elements and indicates to stop, when any single one indicates to stop. The reason is given by the concatenation of all reasons (assuming that all non-indicating return \"\").\n\nConstructor\n\nStopWhenAny(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAny(c::StoppingCriterion...)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenChangeLess","text":"StopWhenChangeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the norm of the change of the optimization variable from within a AbstractManoptSolverState s. That ism by accessing get_iterate(s) and comparing successive iterates. For the storage a StoreStateAction is used.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nlast_change::Real: the last change recorded in this stopping criterion\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nstorage::StoreStateAction: a storage to access the previous iterate\nat_iteration::Int: indicate at which iteration this stopping criterion was last active.\ninverse_retraction: An AbstractInverseRetractionMethod that can be passed to approximate the distance by this inverse retraction and a norm on the tangent space. This can be used if neither the distance nor the logarithmic map are available on M.\nlast_change: store the last change\nstorage: A StoreStateAction to access the previous iterate.\nthreshold: the threshold for the change to check (run under to stop)\nouter_norm: if M is a manifold with components, this can be used to specify the norm, that is used to compute the overall distance based on the element-wise distance. You can deactivate this, but setting this value to missing.\n\nExample\n\nOn an AbstractPowerManifold like mathcalMnifold))) = mathcalN^n any point p = (p_1p_n)  mathcalM) is a vector of length n with of points p_i  mathcalN. Then, denoting the outer_norm by r, the distance of two points pq  mathcalM) is given by\n\nmathrmd(pq) = Bigl( sum_k=1^n mathrmd(p_kq_k)^r Bigr)^frac1r\n\nwhere the sum turns into a maximum for the case r=. The outer_norm has no effect on manifolds that do not consist of components.\n\nIf the manifold does not have components, the outer norm is ignored.\n\nConstructor\n\nStopWhenChangeLess(\n    M::AbstractManifold,\n    threshold::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    inverse_retraction_method::IRT=default_inverse_retraction_method(M)\n    outer_norm::Union{Missing,Real}=missing\n)\n\ninitialize the stopping criterion to a threshold Îµ using the StoreStateAction a, which is initialized to just store :Iterate by default. You can also provide an inverseretractionmethod for the distance or a manifold to use its default inverse retraction.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenCostChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenCostChangeLess","text":"StopWhenCostChangeLess <: StoppingCriterion\n\nA stopping criterion to stop when the change of the cost function is less than a certain threshold.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nlast_change::Real: the last change recorded in this stopping criterion\nlast_cost`: the last cost value\n\nConstructor\n\nStopWhenCostChangeLess(tolerance::F)\n\nInitialize the stopping criterion to a threshold tolerance for the change of the cost function.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenCostLess","page":"Stopping Criteria","title":"Manopt.StopWhenCostLess","text":"StopWhenCostLess <: StoppingCriterion\n\nstore a threshold when to stop looking at the cost function of the optimization problem from within a AbstractManoptProblem, i.e get_cost(p,get_iterate(o)).\n\nConstructor\n\nStopWhenCostLess(Îµ)\n\ninitialize the stopping criterion to a threshold Îµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenCostNaN","page":"Stopping Criteria","title":"Manopt.StopWhenCostNaN","text":"StopWhenCostNaN <: StoppingCriterion\n\nstop looking at the cost function of the optimization problem from within a AbstractManoptProblem, i.e get_cost(p,get_iterate(o)).\n\nConstructor\n\nStopWhenCostNaN()\n\ninitialize the stopping criterion to NaN.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenCriterionWithIterationCondition","page":"Stopping Criteria","title":"Manopt.StopWhenCriterionWithIterationCondition","text":"StopWhenCriterionWithCondition <: StoppingCriterion\n\nA stopping criterion, that only evaluates a certain (inner) stopping based on a condition on the iterate k. The condition is a function condition(k) -> Bool.\n\nExample\n\n(k) -> >(n) would only activate that stopping criterion after n iterations.\n\nFields\n\ncriterion: the StoppingCriterion to wrap\ncomp: the number of times the criterion has to indicate to stop\n\nConstructor\n\nStopWhenRepeated(criterion::StoppingCriterion, n=0; comp = (>(n)))\n\nCreate a stopping criterion that indicates to stop when the comp has indicated to check the inner criterion. The n is ignored if you provide a manual functor comp.\n\nExamples\n\nA stopping criterion that indicates to stop when the gradient norm is small but only after the third iteration\n\nStopWhenCriterionWithIterationCondition(StopWhenGradientNormLess(1e-6), 3)\n\nYou can also use the infix operators â‰Ÿ (\\questeq on REPL),  â©» (\\ltquest), and â©¼ (\\gtquest) to create such a criterion:\n\nStopWhenGradientNormLess(1e-6) â‰Ÿ 3\nStopWhenGradientNormLess(1e-6) â©» 3\nStopWhenGradientNormLess(1e-6) â©¼ 3\n\nThese are equivalent to specifying comp = (==(3)), comp = (<(3)), and comp = (>(3)), respectively. Their interpretation is â€œthe stopping criterion is only checked (asked) if the condition is metâ€\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenEntryChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenEntryChangeLess","text":"StopWhenEntryChangeLess\n\nEvaluate whether a certain fields change is less than a certain threshold\n\nFields\n\nfield:     a symbol addressing the corresponding field in a certain subtype of AbstractManoptSolverState to track\ndistance:  a function (problem, state, v1, v2) -> R that computes the distance between two possible values of the field\nstorage:   a StoreStateAction to store the previous value of the field\nthreshold: the threshold to indicate to stop when the distance is below this value\n\nInternal fields\n\nat_iteration: store the iteration at which the stop indication happened\n\nstores a threshold when to stop looking at the norm of the change of the optimization variable from within a AbstractManoptSolverState, i.e get_iterate(o). For the storage a StoreStateAction is used\n\nConstructor\n\nStopWhenEntryChangeLess(\n    field::Symbol\n    distance,\n    threshold;\n    storage::StoreStateAction=StoreStateAction([field]),\n)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenGradientChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenGradientChangeLess","text":"StopWhenGradientChangeLess <: StoppingCriterion\n\nA stopping criterion based on the change of the gradient.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nlast_change::Real: the last change recorded in this stopping criterion\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nstorage::StoreStateAction: a storage to access the previous iterate\nthreshold: the threshold for the change to check (run under to stop)\nouter_norm: if M is a manifold with components, this can be used to specify the norm, that is used to compute the overall distance based on the element-wise distance. You can deactivate this, but setting this value to missing.\n\nExample\n\nOn an AbstractPowerManifold like mathcalM) = mathcalN^n any point p = (p_1p_n)  mathcalM) is a vector of length n with of points p_i  mathcalN. Then, denoting the outer_norm by r, the norm of the difference of tangent vectors like the last and current gradien XY  mathcalM) is given by\n\nlVert X-Y rVert_p = Bigl( sum_k=1^n lVert X_k-Y_k rVert_p_k^r Bigr)^frac1r\n\nwhere the sum turns into a maximum for the case r=. The outer_norm has no effect on manifols, that do not consist of components.\n\nConstructor\n\nStopWhenGradientChangeLess(\n    M::AbstractManifold,\n    Îµ::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    vector_transport_method::IRT=default_vector_transport_method(M),\n    outer_norm::N=missing\n)\n\nCreate a stopping criterion with threshold Îµ for the change gradient, that is, this criterion indicates to stop when get_gradient is in (norm of) its change less than Îµ, where vector_transport_method denotes the vector transport mathcalT used.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenGradientNormLess","page":"Stopping Criteria","title":"Manopt.StopWhenGradientNormLess","text":"StopWhenGradientNormLess <: StoppingCriterion\n\nA stopping criterion based on the current gradient norm.\n\nFields\n\nnorm:      a function (M::AbstractManifold, p, X) -> â„ that computes a norm of the gradient X in the tangent space at p on M. For manifolds with components provide a function (M::AbstractManifold, p, X, r) -> â„.\nthreshold: the threshold to indicate to stop when the distance is below this value\nouter_norm: if M is a manifold with components, this can be used to specify the norm, that is used to compute the overall distance based on the element-wise distance.\n\nInternal fields\n\nlast_change store the last change\nat_iteration store the iteration at which the stop indication happened\n\nExample\n\nOn an AbstractPowerManifold like mathcalM) = mathcalN^n any point p = (p_1p_n)  mathcalM) is a vector of length n with of points p_i  mathcalN. Then, denoting the outer_norm by r, the norm of a tangent vector like the current gradient X  mathcalM) is given by\n\nlVert X rVert_p = Bigl( sum_k=1^n lVert X_k rVert_p_k^r Bigr)^frac1r\n\nwhere the sum turns into a maximum for the case r=. The outer_norm has no effect on manifolds that do not consist of components.\n\nIf you pass in your individual norm, this can be deactivated on such manifolds by passing missing to outer_norm.\n\nConstructor\n\nStopWhenGradientNormLess(Îµ; norm=ManifoldsBase.norm, outer_norm=missing)\n\nCreate a stopping criterion with threshold Îµ for the gradient, that is, this criterion indicates to stop when get_gradient returns a gradient vector of norm less than Îµ, where the norm to use can be specified in the norm= keyword.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenIterateNaN","page":"Stopping Criteria","title":"Manopt.StopWhenIterateNaN","text":"StopWhenIterateNaN <: StoppingCriterion\n\nstop looking at the cost function of the optimization problem from within a AbstractManoptProblem, i.e get_cost(p,get_iterate(o)).\n\nConstructor\n\nStopWhenIterateNaN()\n\ninitialize the stopping criterion to NaN.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenRepeated","page":"Stopping Criteria","title":"Manopt.StopWhenRepeated","text":"StopWhenRepeated <: StoppingCriterion\n\nA stopping Criterion that indicates to stop when the (internal) stopping criterion it wraps, has indicated to stop for n (consecutive) times\n\nFields\n\ncriterion: the StoppingCriterion to wrap\nn: the number of times the criterion has to indicate to stop\ncount: the number of times the criterion has indicated to stop so far\nconsecutive::Bool: indicate whether to count consecutive indications to stop or arbitrary.\n\nConstructor\n\nStopWhenRepeated(criterion::StoppingCriterion, n::Int; consecutive::Bool=true)\ncriterion Ã— n\ncross(sc::StoppingCriterion, n::Int)\n\nCreate a stopping criterion that indicates to stop when the criterion has indicated to stop n times (consecutively, if consecutive=true for the first constructor). Note that the cross product is in general noncommutative, and here only the order sc Ã— n is possible.\n\nExamples\n\nA stopping criterion that indicates to stop whenever the gradient norm is less that 1e-6 for three consecutive iterations:\n\nStopWhenRepeated(StopWhenGradientNormLess(1e-6), 3)\nStopWhenGradientNormLess(1e-6) Ã— 3\n\nA stopping criterion that indicates to stop whenever the gradient norm is less that 1e-6 at three iterations (not necessarily consecutive):\n\nStopWhenRepeated(StopWhenGradientNormLess(1e-6), 3; consecutive=false)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenSmallerOrEqual","page":"Stopping Criteria","title":"Manopt.StopWhenSmallerOrEqual","text":"StopWhenSmallerOrEqual <: StoppingCriterion\n\nA functor for an stopping criterion, where the algorithm if stopped when a variable is smaller than or equal to its minimum value.\n\nFields\n\nvalue    stores the variable which has to fall under a threshold for the algorithm to stop\nminValue stores the threshold where, if the value is smaller or equal to this threshold, the algorithm stops\n\nConstructor\n\nStopWhenSmallerOrEqual(value, minValue)\n\ninitialize the functor to indicate to stop after value is smaller than or equal to minValue.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenStepsizeLess","page":"Stopping Criteria","title":"Manopt.StopWhenStepsizeLess","text":"StopWhenStepsizeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the last step size determined or found during the last iteration from within a AbstractManoptSolverState.\n\nConstructor\n\nStopWhenStepsizeLess(Îµ)\n\ninitialize the stopping criterion to a threshold Îµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenSubgradientNormLess","page":"Stopping Criteria","title":"Manopt.StopWhenSubgradientNormLess","text":"StopWhenSubgradientNormLess <: StoppingCriterion\n\nA stopping criterion based on the current subgradient norm.\n\nConstructor\n\nStopWhenSubgradientNormLess(Îµ::Float64)\n\nCreate a stopping criterion with threshold Îµ for the subgradient, that is, this criterion indicates to stop when get_subgradient returns a subgradient vector of norm less than Îµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Base.:&-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","page":"Stopping Criteria","title":"Base.:&","text":"&(s1,s2)\ns1 & s2\n\nCombine two StoppingCriterion within an StopWhenAll. If either s1 (or s2) is already an StopWhenAll, then s2 (or s1) is appended to the list of StoppingCriterion within s1 (or s2).\n\nExample\n\na = StopAfterIteration(200) & StopWhenChangeLess(M, 1e-6)\nb = a & StopWhenGradientNormLess(1e-6)\n\nIs the same as\n\na = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6))\nb = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6), StopWhenGradientNormLess(1e-6))\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Base.:|-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","page":"Stopping Criteria","title":"Base.:|","text":"|(s1,s2)\ns1 | s2\n\nCombine two StoppingCriterion within an StopWhenAny. If either s1 (or s2) is already an StopWhenAny, then s2 (or s1) is appended to the list of StoppingCriterion within s1 (or s2)\n\nExample\n\na = StopAfterIteration(200) | StopWhenChangeLess(M, 1e-6)\nb = a | StopWhenGradientNormLess(1e-6)\n\nIs the same as\n\na = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6))\nb = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(M, 1e-6), StopWhenGradientNormLess(1e-6))\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_active_stopping_criteria-Tuple{sCS} where sCS<:StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.get_active_stopping_criteria","text":"get_active_stopping_criteria(c)\n\nreturns all active stopping criteria, if any, that are within a StoppingCriterion c, and indicated a stop, that is their reason is nonempty. To be precise for a simple stopping criterion, this returns either an empty array if no stop is indicated or the stopping criterion as the only element of an array. For a StoppingCriterionSet all internal (even nested) criteria that indicate to stop are returned.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_reason-Tuple{AbstractManoptSolverState}","page":"Stopping Criteria","title":"Manopt.get_reason","text":"get_reason(s::AbstractManoptSolverState)\n\nreturn the current reason stored within the StoppingCriterion from within the AbstractManoptSolverState. This reason is empty (\"\") if the criterion has never been met.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_stopping_criteria-Tuple{S} where S<:StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.get_stopping_criteria","text":"get_stopping_criteria(c)\n\nreturn the array of internally stored StoppingCriterions for a StoppingCriterionSet c.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.has_converged-Tuple{StoppingCriterion}","page":"Stopping Criteria","title":"Manopt.has_converged","text":"has_converged(c::StoppingCriterion)\n\nReturn whether a StoppingCriterion that has indicated to stop and is a stopping criterion that allows to conclude that the corresponding solver has converged.\n\nBy default this is given by the static indicates_convergence(c) as well as the test whether the stopping criterion has stopped. For some stopping criteria, for example StopWhenAny a more advanced test can be done, that is more precise.\n\nExamples\n\nWith s1=StopAfterIteration(20) and s2=StopWhenGradientNormLess(1e-7) we obtain\n\nhas_converged(s1) is always false (even if it has stopped)\nhas_converged(s2) is always true as soon as it has stopped\nhas_converged(s1 | s2) is always true if it has stopped and s2 is the reason for that.\nhas_converged(s1 & s2) is true as soon as the algorithm stopped, since here s2 always\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.indicates_convergence-Tuple{StoppingCriterion}","page":"Stopping Criteria","title":"Manopt.indicates_convergence","text":"indicates_convergence(c::StoppingCriterion)\n\nReturn whether a StoppingCriterion does always mean that, when it indicates to stop, the solver has converged to a minimizer or critical point.\n\nNote that this is independent of the actual state of the stopping criterion, whether some of them indicate to stop, but a purely type-based, static decision.\n\nExamples\n\nWith s1=StopAfterIteration(20) and s2=StopWhenGradientNormLess(1e-7) the indicator yields\n\nindicates_convergence(s1) is false\nindicates_convergence(s2) is true\nindicates_convergence(s1 | s2) is false, since this might also stop after 20 iterations, or in other words, for StopWhenAny all its criteria have to indicate convergence, for this to return true.\nindicates_convergence(s1 & s2) is true, since s2 is fulfilled if this stops.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopAfter, Val{:MaxTime}, Dates.Period}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopAfter, :MaxTime, v::Period)\n\nUpdate the time period after which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopAfterIteration, Val{:MaxIteration}, Int64}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopAfterIteration, :;MaxIteration, v::Int)\n\nUpdate the number of iterations after which the algorithm should stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenChangeLess, Val{:MinIterateChange}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenChangeLess, :MinIterateChange, v::Int)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenCostLess, Val{:MinCost}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenCostLess, :MinCost, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenEntryChangeLess, Val{:Threshold}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenEntryChangeLess, :Threshold, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenGradientChangeLess, Val{:MinGradientChange}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenGradientChangeLess, :MinGradientChange, v)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenGradientNormLess, Val{:MinGradNorm}, Float64}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenGradientNormLess, :MinGradNorm, v::Float64)\n\nUpdate the minimal gradient norm when an algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenStepsizeLess, Val{:MinStepsize}, Any}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenStepsizeLess, :MinStepsize, v)\n\nUpdate the minimal step size below which the algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.set_parameter!-Tuple{StopWhenSubgradientNormLess, Val{:MinSubgradNorm}, Float64}","page":"Stopping Criteria","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenSubgradientNormLess, :MinSubgradNorm, v::Float64)\n\nUpdate the minimal subgradient norm when an algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"tutorials/HowToRecord/#How-to-record-data-during-the-iterations","page":"Record values","title":"How to record data during the iterations","text":"Ronny Bergmann\n\nThe recording and debugging features make it possible to record nearly any data during the iterations. This tutorial illustrates how to:\n\nrecord one value during the iterations;\nrecord multiple values during the iterations and access them afterwards;\nrecord within a subsolver\ndefine an own RecordAction to perform individual recordings.\n\nSeveral predefined recordings exist, for example RecordCost or RecordGradient, if the problem the solver uses provides a gradient. For fields of the State the recording can also be done RecordEntry. For other recordings, for example more advanced computations before storing a value, an own RecordAction can be defined.\n\nWe illustrate these using the gradient descent from the Get started: optimize tutorial.\n\nHere the focus is put on ways to investigate the behaviour during iterations by using Recording techniques.\n\nLetâ€™s first load the necessary packages.\n\nusing Manopt, Manifolds, Random, ManifoldDiff, LinearAlgebra\nusing ManifoldDiff: grad_distance\nRandom.seed!(42);","category":"section"},{"location":"tutorials/HowToRecord/#The-objective","page":"Record values","title":"The objective","text":"We generate data and define our cost and gradient:\n\nRandom.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nÏƒ = Ï€ / 8\nx = zeros(Float64, m + 1)\nx[2] = 1.0\ndata = [exp(M, x, Ïƒ * rand(M; vector_at=x)) for i in 1:n]\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)))\n\ngrad_f (generic function with 1 method)","category":"section"},{"location":"tutorials/HowToRecord/#First-examples","page":"Record values","title":"First examples","text":"For the high level interfaces of the solvers, like gradient_descent we have to set return_state to true to obtain the whole solver state and not only the resulting minimizer.\n\nThen we can easily use the record= option to add recorded values. This keyword accepts RecordActions as well as several symbols as shortcuts, for example :Cost to record the cost, or if your options have a field f, :f would record that entry. An overview of the symbols that can be used is given here.\n\nWe first just record the cost after every iteration\n\nR = gradient_descent(M, f, grad_f, data[1]; record=:Cost, return_state=true)\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 58 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordCost(),)\n\nFrom the returned state, we see that the GradientDescentState are encapsulated (decorated) within a RecordSolverState.\n\nFor such a state, one can attach different recorders to some operations, currently to :Start. :Stop, and :Iteration, where :Iteration is the default when using the record= keyword with a RecordAction or a Symbol as we just did. We can access all values recorded during the iterations by calling get_record(R, :Iteration) or since this is the default even shorter\n\nget_record(R)\n\n58-element Vector{Float64}:\n 0.6870172325261713\n 0.6239221496686211\n 0.5900244338953805\n 0.569312079535616\n 0.5518048258655455\n 0.5429045359832493\n 0.5383847696671531\n 0.5360322830268693\n 0.5348144739486791\n 0.5341773307679921\n â‹®\n 0.5334801024530127\n 0.5334801024530104\n 0.5334801024530084\n 0.5334801024530073\n 0.5334801024530067\n 0.5334801024530064\n 0.5334801024530063\n 0.533480102453006\n 0.533480102453006\n\nTo record more than one value, you can pass an array of a mix of symbols and RecordActions which formally introduces RecordGroup. Such a group records a tuple of values in every iteration:\n\nR2 = gradient_descent(M, f, grad_f, data[1]; record=[:Iteration, :Cost], return_state=true)\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 58 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),)\n\nHere, the symbol :Cost is mapped to using the RecordCost action. The same holds for :Iteration obviously records the current iteration number i. To access these you can first extract the group of records (that is where the :Iterations are recorded; note the plural) and then access the :Cost â€œâ€œâ€\n\nget_record_action(R2, :Iteration)\n\nRecordGroup([RecordIteration(), RecordCost()])\n\nSince iteration is the default, we can also omit it here again. To access single recorded values, one can use\n\nget_record_action(R2)[:Cost]\n\n58-element Vector{Float64}:\n 0.6870172325261713\n 0.6239221496686211\n 0.5900244338953805\n 0.569312079535616\n 0.5518048258655455\n 0.5429045359832493\n 0.5383847696671531\n 0.5360322830268693\n 0.5348144739486791\n 0.5341773307679921\n â‹®\n 0.5334801024530127\n 0.5334801024530104\n 0.5334801024530084\n 0.5334801024530073\n 0.5334801024530067\n 0.5334801024530064\n 0.5334801024530063\n 0.533480102453006\n 0.533480102453006\n\nThis can be also done by using a the high level interface get_record\n\nget_record(R2, :Iteration, :Cost)\n\n58-element Vector{Float64}:\n 0.6870172325261713\n 0.6239221496686211\n 0.5900244338953805\n 0.569312079535616\n 0.5518048258655455\n 0.5429045359832493\n 0.5383847696671531\n 0.5360322830268693\n 0.5348144739486791\n 0.5341773307679921\n â‹®\n 0.5334801024530127\n 0.5334801024530104\n 0.5334801024530084\n 0.5334801024530073\n 0.5334801024530067\n 0.5334801024530064\n 0.5334801024530063\n 0.533480102453006\n 0.533480102453006\n\nNote that the first symbol again refers to the point where we record (not to the thing we record). We can also pass a tuple as second argument to have our own order within the tuples returned. Switching the order of recorded cost and Iteration can be done using â€œâ€œâ€\n\nget_record(R2, :Iteration, (:Iteration, :Cost))\n\n58-element Vector{Tuple{Int64, Float64}}:\n (1, 0.6870172325261713)\n (2, 0.6239221496686211)\n (3, 0.5900244338953805)\n (4, 0.569312079535616)\n (5, 0.5518048258655455)\n (6, 0.5429045359832493)\n (7, 0.5383847696671531)\n (8, 0.5360322830268693)\n (9, 0.5348144739486791)\n (10, 0.5341773307679921)\n â‹®\n (50, 0.5334801024530127)\n (51, 0.5334801024530104)\n (52, 0.5334801024530084)\n (53, 0.5334801024530073)\n (54, 0.5334801024530067)\n (55, 0.5334801024530064)\n (56, 0.5334801024530063)\n (57, 0.533480102453006)\n (58, 0.533480102453006)","category":"section"},{"location":"tutorials/HowToRecord/#A-more-complex-example","page":"Record values","title":"A more complex example","text":"To illustrate a complicated example letâ€™s record:\n\nthe iteration number, cost and gradient field, but only every sixth iteration;\nthe iteration at which we stop.\n\nWe first generate the problem and the state, to also illustrate the low-level works when not using the high-level interface gradient_descent.\n\np = DefaultManoptProblem(M, ManifoldGradientObjective(f, grad_f))\ns = GradientDescentState(\n    M;\n    p=copy(data[1]),\n    stopping_criterion=StopAfterIteration(200) | StopWhenGradientNormLess(10.0^-9),\n)\n\n# Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No\n\nWe now first build a RecordGroup to group the three entries we want to record per iteration. We then put this into a RecordEvery to only record this every sixth iteration\n\nrI = RecordEvery(\n    RecordGroup([\n        RecordIteration() => :Iteration,\n        RecordCost() => :Cost,\n        RecordEntry(similar(data[1]), :X) => :Gradient,\n    ]),\n    6,\n)\n\nRecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true)\n\nwhere the notation as a pair with the symbol can be read as â€œIs accessible byâ€. The record= keyword with the symbol :Iteration is actually the same as we specified here for the first group entry. For recording the final iteration number\n\nsI = RecordIteration()\n\nRecordIteration()\n\nWe now combine both into the RecordSolverState decorator. It acts completely the same as any AbstractManoptSolverState but records something in every iteration additionally. This is stored in a dictionary of RecordActions, where :Iteration is the action (here the only every sixth iteration group) and the sI which is executed at stop.\n\nNote that the keyword record= in the high level interface gradient_descent only would fill the :Iteration symbol of said dictionary, but we could also pass pairs like in the following, that is in the form Symbol => RecordAction into that keyword to obtain the same as in\n\nr = RecordSolverState(s, Dict(:Iteration => rI, :Stop => sI))\n\n# Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration())\n\nWe now call the solver\n\nres = solve!(p, r)\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 62 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration())\n\nAnd we can look at the recorded value at :Stop to see how many iterations were performed\n\nget_record(res, :Stop)\n\n1-element Vector{Int64}:\n 62\n\nand the other values during the iterations are\n\nget_record(res, :Iteration, (:Iteration, :Cost))\n\n10-element Vector{Tuple{Int64, Float64}}:\n (6, 0.5429045359832493)\n (12, 0.5336712822308556)\n (18, 0.533484098624334)\n (24, 0.5334801877032025)\n (30, 0.533480104312984)\n (36, 0.5334801024945819)\n (42, 0.5334801024539587)\n (48, 0.5334801024530285)\n (54, 0.5334801024530067)\n (60, 0.5334801024530059)\n\nwhere the last tuple contains the names from the pairs when we generated the record group. So similarly we can use :Gradient as specified before to access the recorded gradient.","category":"section"},{"location":"tutorials/HowToRecord/#Recording-from-a-Subsolver","page":"Record values","title":"Recording from a Subsolver","text":"One can also record from a subsolver. For that we need a problem that actually requires a subsolver. We take the constraint example from the How to print debug tutorial. Maybe read that part for more details on the problem\n\nd = 4\nM2 = Sphere(d - 1)\nv0 = project(M2, [ones(2)..., zeros(d - 2)...])\nZ = v0 * v0'\n#Cost and gradient\nf2(M, p) = -tr(transpose(p) * Z * p) / 2\ngrad_f2(M, p) = project(M, p, -transpose.(Z) * p / 2 - Z * p / 2)\n# Constraints\ng(M, p) = -p # now p â‰¥ 0\nmI = -Matrix{Float64}(I, d, d)\n# Vector of gradients of the constraint components\ngrad_g(M, p) = [project(M, p, mI[:, i]) for i in 1:d]\np0 = project(M2, [ones(2)..., zeros(d - 3)..., 0.1])\n\nWe directly start with recording the sub solvers Iteration. We can specify what to record in the subsolver using the sub_kwargs keyword argument with a Symbol => value pair. Here we specify to record the iteration and the cost in every sub solvers step.\n\nFurthermore, we have to â€œcollectâ€ this recording after every sub solver run. This is done with the :Subsolver keyword in the main record= keyword.\n\ns1 = exact_penalty_method(\n    M2,\n    f2,\n    grad_f2,\n    p0;\n    g = g,\n    grad_g = grad_g,\n    record = [:Iteration, :Cost, :Subsolver],\n    sub_kwargs = [:record => [:Iteration, :Cost]],\n    return_state=true,\n);\n\nThen the first entry of the record contains the iterate, the (main solvers) cost, and the third entry is the recording of the subsolver.\n\nget_record(s1)[1]\n\n(1, -0.4733019623455377, [(1, -0.4288382393589549), (2, -0.43669534259556914), (3, -0.4374036673499917), (4, -0.4374408718086294)])\n\nWhen adding a number to not record on every iteration, the :Subsolver keyword of course still also only â€œcopies overâ€ the subsolver recordings when active. But one could avoid allocations on the other runs. This is done, by specifying the sub solver as :WhenActive\n\ns2 = exact_penalty_method(\n    M2,\n    f2,\n    grad_f2,\n    p0;\n    g = g,\n    grad_g = grad_g,\n    record = [:Iteration, :Cost, :Subsolver, 25],\n    sub_kwargs = [:record => [:Iteration, :Cost, :WhenActive]],\n    return_state=true,\n);\n\nThen\n\nget_record(s2)\n\n4-element Vector{Tuple{Int64, Float64, Vector{Tuple{Int64, Float64}}}}:\n (25, -0.4994494108530985, [(1, -0.4991469152295235)])\n (50, -0.49999564261147317, [(1, -0.49999366842932896)])\n (75, -0.49999997420136083, [(1, -0.4999999614701454)])\n (100, -0.49999999983370474, [(1, -0.49999999981081683)])\n\nFinally, instead of recording iterations, we can also specify to record the stopping criterion and final cost by adding that to :Stop of the sub solvers record. Then we can specify, as usual in a tuple, that the :Subsolver should record :Stop (by default it takes over :Iteration)\n\ns3 = exact_penalty_method(\n    M2,\n    f2,\n    grad_f2,\n    p0;\n    g = g,\n    grad_g = grad_g,\n    record = [:Iteration, :Cost, (:Subsolver, :Stop), 25],\n    sub_kwargs = [:record => [:Stop => [:Stop, :Cost]]],\n    return_state=true,\n);\n\nThen the following displays also the reasons why each of the recorded sub solvers stopped and the corresponding cost\n\nget_record(s3)\n\n4-element Vector{Tuple{Int64, Float64, Vector{Tuple{String, Float64}}}}:\n (25, -0.4994494108530985, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (0.00031307624887101047) is less than 0.001.\\n\", -0.4991469152295235)])\n (50, -0.49999564261147317, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (0.0009767910400237663) is less than 0.001.\\n\", -0.49999366842932896)])\n (75, -0.49999997420136083, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (0.00022396291196612712) is less than 0.001.\\n\", -0.4999999614701454)])\n (100, -0.49999999983370474, [(\"The algorithm reached approximately critical point after 1 iterations; the gradient norm (3.8129640908105984e-6) is less than 0.001.\\n\", -0.49999999981081683)])","category":"section"},{"location":"tutorials/HowToRecord/#Writing-an-own-[RecordAction](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s","page":"Record values","title":"Writing an own RecordActions","text":"Letâ€™s investigate where we want to count the number of function evaluations, again just to illustrate, since for the gradient this is just one evaluation per iteration. We first define a cost, that counts its own calls.\n\nmutable struct MyCost{T}\n    data::T\n    count::Int\nend\nMyCost(data::T) where {T} = MyCost{T}(data, 0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    return sum(1 / (2 * length(c.data)) * distance.(Ref(M), Ref(x), c.data) .^ 2)\nend\n\nand we define an own, new RecordAction, which is a functor, that is a struct that is also a function. The function we have to implement is similar to a single solver step in signature, since it might get called every iteration:\n\nmutable struct RecordCount <: RecordAction\n    recorded_values::Vector{Int}\n    RecordCount() = new(Vector{Int}())\nend\nfunction (r::RecordCount)(p::AbstractManoptProblem, ::AbstractManoptSolverState, i)\n    if i > 0\n        push!(r.recorded_values, Manopt.get_cost_function(get_objective(p)).count)\n    elseif i < 0 # reset if negative\n        r.recorded_values = Vector{Int}()\n    end\nend\n\nNow we can initialize the new cost and call the gradient descent. Note that this illustrates also the last use case since you can pass symbol-action pairs into the record=array.\n\nf3 = MyCost(data)\n\nNow for the plain gradient descent, we have to modify the step (to a constant stepsize) and remove the default debug verification whether the cost increases (setting debug to []). We also only look at the first 20 iterations to keep this example small in recorded values. We call\n\nR3 = gradient_descent(\n    M,\n    f3,\n    grad_f,\n    data[1];\n    record=[:Iteration => [\n        :Iteration,\n        RecordCount() => :Count,\n        :Cost],\n    ],\n    stepsize = ConstantLength(1.0),\n    stopping_criterion=StopAfterIteration(20),\n    debug=[],\n    return_state=true,\n)\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 20 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nConstantLength(1.0; type=:relative)\n\n## Stopping criterion\n\nMax Iteration 20:   reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), Main.Notebook.RecordCount([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]), RecordCost()]),)\n\nFor :Cost we already learned how to access them, the => :Count introduces an action to obtain the :Count symbol as its access. We can again access the whole sets of records\n\nget_record(R3)\n\n20-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 1, 0.5823814423113638)\n (2, 2, 0.5408049802340039)\n (3, 3, 0.5345550944722897)\n (4, 4, 0.5336375289938885)\n (5, 5, 0.5335031591890169)\n (6, 6, 0.5334834802310251)\n (7, 7, 0.5334805973984544)\n (8, 8, 0.5334801749902925)\n (9, 9, 0.5334801130855076)\n (10, 10, 0.5334801040117542)\n (11, 11, 0.5334801026815555)\n (12, 12, 0.5334801024865217)\n (13, 13, 0.5334801024579214)\n (14, 14, 0.5334801024537271)\n (15, 15, 0.5334801024531117)\n (16, 16, 0.5334801024530216)\n (17, 17, 0.5334801024530085)\n (18, 18, 0.5334801024530064)\n (19, 19, 0.5334801024530063)\n (20, 20, 0.5334801024530059)\n\nthis is equivalent to calling R[:Iteration]. Note that since we introduced :Count we can also access a single recorded value using\n\nR3[:Iteration, :Count]\n\n20-element Vector{Int64}:\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n 10\n 11\n 12\n 13\n 14\n 15\n 16\n 17\n 18\n 19\n 20\n\nand we see that the cost function is called once per iteration.\n\nIf we use this counting cost and run the default gradient descent with Armijo line search, we can infer how many Armijo line search backtracks are preformed:\n\nf4 = MyCost(data)\n\nMyCost{Vector{Vector{Float64}}}([[-0.054658825167894595, -0.5592077846510423, -0.04738273828111257, -0.04682080720921302, 0.12279468849667038, 0.07171438895366239, -0.12930045409417057, -0.22102081626380404, -0.31805333254577767, 0.0065859500152017645  â€¦  -0.21999168261518043, 0.19570142227077295, 0.340909965798364, -0.0310802190082894, -0.04674431076254687, -0.006088297671169996, 0.01576037011323387, -0.14523596850249543, 0.14526158060820338, 0.1972125856685378], [-0.08192376929745249, -0.5097715132187676, -0.008339904915541005, 0.07289741328038676, 0.11422036270613797, -0.11546739299835748, 0.2296996932628472, 0.1490467170835958, -0.11124820565850364, -0.11790721606521781  â€¦  -0.16421249630470344, -0.2450575844467715, -0.07570080850379841, -0.07426218324072491, -0.026520181327346338, 0.11555341205250205, -0.0292955762365121, -0.09012096853677576, -0.23470556634911574, -0.026214242996704013], [-0.22951484264859257, -0.6083825348640186, 0.14273766477054015, -0.11947823367023377, 0.05984293499234536, 0.058820835498203126, 0.07577331705863266, 0.1632847202946857, 0.20244385489915745, 0.04389826920203656  â€¦  0.3222365119325929, 0.009728730325524067, -0.12094785371632395, -0.36322323926212824, -0.0689253407939657, 0.23356953371702974, 0.23489531397909744, 0.078303336494718, -0.14272984135578806, 0.07844539956202407], [-0.0012588500237817606, -0.29958740415089763, 0.036738459489123514, 0.20567651907595125, -0.1131046432541904, -0.06032435985370224, 0.3366633723165895, -0.1694687746143405, -0.001987171245125281, 0.04933779858684409  â€¦  -0.2399584473006256, 0.19889267065775063, 0.22468755918787048, 0.1780090580180643, 0.023703860700539356, -0.10212737517121755, 0.03807004103115319, -0.20569120952458983, -0.03257704254233959, 0.06925473452536687], [-0.035534309946938375, -0.06645560787329002, 0.14823972268208874, -0.23913346587232426, 0.038347027875883496, 0.10453333143286662, 0.050933995140290705, -0.12319549375687473, 0.12956684644537844, -0.23540367869989412  â€¦  -0.41471772859912864, -0.1418984610380257, 0.0038321446836859334, 0.23655566917750157, -0.17500681300994742, -0.039189751036839374, -0.08687860620942896, -0.11509948162959047, 0.11378233994840942, 0.38739450723013735], [-0.3122539912469438, -0.3101935557860296, 0.1733113629107006, 0.08968593616209351, -0.1836344261367962, -0.06480023695256802, 0.18165070013886545, 0.19618275767992124, -0.07956460275570058, 0.0325997354656551  â€¦  0.2845492418767769, 0.17406455870721682, -0.053101230371568706, -0.1382082812981627, 0.005830071475508364, 0.16739264037923055, 0.034365814374995335, 0.09107702398753297, -0.1877250428700409, 0.05116494897806923], [-0.04159442361185588, -0.7768029783272633, 0.06303616666722486, 0.08070518925253539, -0.07396265237309446, -0.06008109299719321, 0.07977141629715745, 0.019511027129056415, 0.08629917589924847, -0.11156298867318722  â€¦  0.0792587504128044, -0.016444383900170008, -0.181746064577005, -0.01888129512990984, -0.13523922089388968, 0.11358102175659832, 0.07929049608459493, 0.1689565359083833, 0.07673657951723721, -0.1128480905648813], [-0.21221814304651335, -0.5031823821503253, 0.010326342133992458, -0.12438192100961257, 0.04004758695231872, 0.2280527500843805, -0.2096243232022162, -0.16564828762420294, -0.28325749481138984, 0.17033534605245823  â€¦  -0.13599096505924074, 0.28437770540525625, 0.08424426798544583, -0.1266207606984139, 0.04917635557603396, -0.00012608938533809706, -0.04283220254770056, -0.08771365647566572, 0.14750169103093985, 0.11601120086036351], [0.10683290707435536, -0.17680836277740156, 0.23767458301899405, 0.12011180867097299, -0.029404774462600154, 0.11522028383799933, -0.3318174480974519, -0.17859266746938374, 0.04352373642537759, 0.2530382802667988  â€¦  0.08879861736692073, -0.004412506987801729, 0.19786810509925895, -0.1397104682727044, 0.09482328498485094, 0.05108149065160893, -0.14578343506951633, 0.3167479772660438, 0.10422673169182732, 0.21573150015891313], [-0.024895624707466164, -0.7473912016432697, -0.1392537238944721, -0.14948896791465557, -0.09765393283580377, 0.04413059403279867, -0.13865379004720355, -0.071032040283992, 0.15604054722246585, -0.10744260463413555  â€¦  -0.14748067081342833, -0.14743635071251024, 0.0643591937981352, 0.16138827697852615, -0.12656652133603935, -0.06463635704869083, 0.14329582429103488, -0.01113113793821713, 0.29295387893749997, 0.06774523575259782]  â€¦  [0.011874845316569967, -0.6910596618389588, 0.21275741439477827, -0.014042545524367437, -0.07883613103495014, -0.0021900966696246776, -0.033836430464220496, 0.2925813113264835, -0.04718187201980008, 0.03949680289730036  â€¦  0.0867736586603294, 0.0404682510051544, -0.24779813848587257, -0.28631514602877145, -0.07211767532456789, -0.15072898498180473, 0.017855923621826746, -0.09795357710255254, -0.14755229203084924, 0.1305005778855436], [0.013457629515450426, -0.3750353654626534, 0.12349883726772073, 0.3521803555005319, 0.2475921439420274, 0.006088649842999206, 0.31203183112392907, -0.036869203979483754, -0.07475746464056504, -0.029297797064479717  â€¦  0.16867368684091563, -0.09450564983271922, -0.0587273302122711, -0.1326667940553803, -0.25530237980444614, 0.37556905374043376, 0.04922612067677609, 0.2605362549983866, -0.21871556587505667, -0.22915883767386164], [0.03295085436260177, -0.971861604433394, 0.034748713521512035, -0.0494065013245799, -0.01767479281403355, 0.0465459739459587, 0.007470494722096038, 0.003227960072276129, 0.0058328596338402365, -0.037591237446692356  â€¦  0.03205152122876297, 0.11331109854742015, 0.03044900529526686, 0.017971704993311105, -0.009329252062960229, -0.02939354719650879, 0.022088835776251863, -0.02546111553658854, -0.0026257225461427582, 0.005702111697172774], [0.06968243992532257, -0.7119502191435176, -0.18136614593117445, -0.1695926215673451, 0.01725015359973796, -0.00694164951158388, -0.34621134287344574, 0.024709256792651912, -0.1632255805999673, -0.2158226433583082  â€¦  -0.14153772108081458, -0.11256850346909901, 0.045109821764180706, -0.1162754336222613, -0.13221711766357983, 0.005365354776191061, 0.012750671705879105, -0.018208207549835407, 0.12458753932455452, -0.31843587960340897], [-0.19830349374441875, -0.6086693423968884, 0.08552341811170468, 0.35781519334042255, 0.15790663648524367, 0.02712571268324985, 0.09855601327331667, -0.05840653973421127, -0.09546429767790429, -0.13414717696055448  â€¦  -0.0430935804718714, 0.2678584478951765, 0.08780994289014614, 0.01613469379498457, 0.0516187906322884, -0.07383067566731401, -0.1481272738354552, -0.010532317187265649, 0.06555344745952187, -0.1506167863762911], [-0.04347524125197773, -0.6327981074196994, -0.221116680035191, 0.0282207467940456, -0.0855024881522933, 0.12821801740178346, 0.1779499563280024, -0.10247384887512365, 0.0396432464100116, -0.0582580338112627  â€¦  0.1253893207083573, 0.09628202269764763, 0.3165295473947355, -0.14915034201394833, -0.1376727867817772, -0.004153096613530293, 0.09277957650773738, 0.05917264554031624, -0.12230262590034507, -0.19655728521529914], [-0.10173946348675116, -0.6475660153977272, 0.1260284619729566, -0.11933160462857616, -0.04774310633937567, 0.09093928358804217, 0.041662676324043114, -0.1264739543938265, 0.09605293126911392, -0.16790474428001648  â€¦  -0.04056684573478108, 0.09351665120940456, 0.15259195558799882, 0.0009949298312580497, 0.09461980828206303, 0.3067004514287283, 0.16129258773733715, -0.18893664085007542, -0.1806865244492513, 0.029319680436405825], [-0.251780954320053, -0.39147463259941456, -0.24359579328578626, 0.30179309757665723, 0.21658893985206484, 0.12304585275893232, 0.28281133086451704, 0.029187615341955325, 0.03616243507191924, 0.029375588909979152  â€¦  -0.08071746662465404, -0.2176101928258658, 0.20944684921170825, 0.043033273425352715, -0.040505542460853576, 0.17935596149079197, -0.08454569418519972, 0.0545941597033932, 0.12471741052450099, -0.24314124407858329], [0.28156471341150974, -0.6708572780452595, -0.1410302363738465, -0.08322589397277698, -0.022772599832907418, -0.04447265789199677, -0.016448068022011157, -0.07490911512503738, 0.2778432295769144, -0.10191899088372378  â€¦  -0.057272155080983836, 0.12817478092201395, 0.04623814480781884, -0.12184190164369117, 0.1987855635987229, -0.14533603246124993, -0.16334072868597016, -0.052369977381939437, 0.014904286931394959, -0.2440882678882144], [0.12108727495744157, -0.714787344982596, 0.01632521838262752, 0.04437570556908449, -0.041199280304144284, 0.052984488452616, 0.03796520200156107, 0.2791785910964288, 0.11530429924056099, 0.12178223160398421  â€¦  -0.07621847481721669, 0.18353870423743013, -0.19066653731436745, -0.09423224997242206, 0.14596847781388494, -0.09747986927777111, 0.16041150122587072, -0.02296513951256738, 0.06786878373578588, 0.15296635978447756]], 0)\n\nTo not get too many entries letâ€™s just look at the first 20 iterations again\n\nR4 = gradient_descent(\n    M,\n    f4,\n    grad_f,\n    data[1];\n    record=[RecordCount(),],\n    return_state=true,\n)\n\n# Solver state for `Manopt.jl`s Gradient Descent\nAfter 58 iterations\n\n## Parameters\n* retraction method: StabilizedRetraction()\n\n## Stepsize\nArmijoLinesearch(;\n    initial_stepsize=1.0,\n    retraction_method=StabilizedRetraction(),\n    contraction_factor=0.95,\n    sufficient_decrease=0.1,\n)\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 200:  not reached\n  * |grad f| < 1.0e-8: reached\nOverall: reached\nThis indicates convergence: No\n\n## Record\n(Iteration = Main.Notebook.RecordCount([25, 29, 33, 37, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 223, 226, 230, 235, 238, 240, 244, 246]),)\n\nget_record(R4)\n\n58-element Vector{Int64}:\n  25\n  29\n  33\n  37\n  40\n  44\n  48\n  52\n  56\n  60\n   â‹®\n 220\n 223\n 226\n 230\n 235\n 238\n 240\n 244\n 246\n\nWe can see that the number of cost function calls varies, depending on how many line search backtrack steps were required to obtain a good stepsize.","category":"section"},{"location":"tutorials/HowToRecord/#Technical-details","page":"Record values","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:32:08.","category":"section"},{"location":"solvers/ChambollePock/#The-Riemannian-Chambolle-Pock-algorithm","page":"Chambolle-Pock","title":"The Riemannian Chambolle-Pock algorithm","text":"The Riemannian Chambolleâ€”Pock is a generalization of the Chambolleâ€”Pock algorithm Chambolle and Pock [CP11] It is also known as primal-dual hybrid gradient (PDHG) or primal-dual proximal splitting (PDPS) algorithm.\n\nIn order to minimize over pmathcal M the cost function consisting of In order to minimize a cost function consisting of\n\nF(p) + G(Î›(p))\n\nover pmathcal M\n\nwhere Fmathcal M  overlineâ„, Gmathcal N  overlineâ„, and Î›mathcal M mathcal N. If the manifolds mathcal M or mathcal N are not Hadamard, it has to be considered locally only, that is on geodesically convex sets mathcal C subset mathcal M and mathcal D subsetmathcal N such that Î›(mathcal C) subset mathcal D.\n\nThe algorithm is available in four variants: exact versus linearized (see variant) as well as with primal versus dual relaxation (see relax). For more details, see Bergmann, Herzog, Silva Louzeiro, Tenbrinck and Vidal-NÃºÃ±ez [BHS+21]. In the following description is the case of the exact, primal relaxed Riemannian Chambolleâ€”Pock algorithm.\n\nGiven base points mmathcal C, n=Î›(m)mathcal D, initial primal and dual values p^(0) mathcal C, Î¾_n^(0) T_n^*mathcal N, and primal and dual step sizes sigma_0, tau_0, relaxation theta_0, as well as acceleration gamma.\n\nAs an initialization, perform bar p^(0) gets p^(0).\n\nThe algorithms performs the steps k=1 (until a StoppingCriterion is fulfilled with)\n\nÎ¾^(k+1)_n = operatornameprox_tau_k G_n^*Bigl(Î¾_n^(k) + tau_k bigl(log_n Î› (bar p^(k))bigr)^flatBigr)\np^(k+1) = operatornameprox_sigma_k Fbiggl(exp_p^(k)Bigl( operatornamePT_p^(k)gets mbigl(-sigma_k DÎ›(m)^*Î¾_n^(k+1)bigr)^sharpBigr)biggr)\nUpdate\ntheta_k = (1+2gammasigma_k)^-frac12\nsigma_k+1 = sigma_ktheta_k\ntau_k+1 =  fractau_ktheta_k\nbar p^(k+1)  = exp_p^(k+1)bigl(-theta_k log_p^(k+1) p^(k)bigr)\n\nFurthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction, and a vector transport.\n\nFinally you can also update the base points m and n during the iterations. This introduces a few additional vector transports. The same holds for the case Î›(m^(k))neq n^(k) at some point. All these cases are covered in the algorithm.","category":"section"},{"location":"solvers/ChambollePock/#State","page":"Chambolle-Pock","title":"State","text":"","category":"section"},{"location":"solvers/ChambollePock/#Useful-terms","page":"Chambolle-Pock","title":"Useful terms","text":"","category":"section"},{"location":"solvers/ChambollePock/#Debug","page":"Chambolle-Pock","title":"Debug","text":"","category":"section"},{"location":"solvers/ChambollePock/#Record","page":"Chambolle-Pock","title":"Record","text":"","category":"section"},{"location":"solvers/ChambollePock/#Internals","page":"Chambolle-Pock","title":"Internals","text":"","category":"section"},{"location":"solvers/ChambollePock/#sec-cp-technical-details","page":"Chambolle-Pock","title":"Technical details","text":"The ChambollePock solver requires the following functions of a manifold to be available for both the manifold mathcal Mand mathcal N\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= or retraction_method_dual= (for mathcal N) does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= or vector_transport_method_dual= (for mathcal N) does not have to be specified.\nA copyto!(M, q, p) and copy(M,p) for points.","category":"section"},{"location":"solvers/ChambollePock/#Literature","page":"Chambolle-Pock","title":"Literature","text":"R.Â Bergmann, R.Â Herzog, M.Â Silva Louzeiro, D.Â Tenbrinck and J.Â Vidal-NÃºÃ±ez. Fenchel duality theory and a primal-dual algorithm on Riemannian manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 21, 1465â€“1504 (2021), arXiv:1908.02022.\n\n\n\nA.Â Chambolle and T.Â Pock. A first-order primal-dual algorithm for convex problems with applications to imaging. JournalÂ ofÂ MathematicalÂ ImagingÂ andÂ Vision 40, 120â€“145 (2011).\n\n\n\n","category":"section"},{"location":"solvers/ChambollePock/#Manopt.ChambollePock","page":"Chambolle-Pock","title":"Manopt.ChambollePock","text":"ChambollePock(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\nChambollePock!(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\n\nPerform the Riemannian Chambolleâ€”Pock algorithm.\n\nGiven a cost function mathcalE mathcalM)  â„ of the form\n\nmathcalE(p) = F(p) + G( Î›(p) )\n\nwhere FmathcalM)  â„, GmathcalN  â„, and Î›mathcalM)  mathcalN.\n\nThis can be done inplace of p.\n\nInput parameters\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nN::AbstractManifold: a Riemannian manifold mathcalM\np::P: a point on the manifold mathcalM\nX::T: a tangent vector at the point p on the manifold mathcalM\nm::P: a point on the manifold mathcalM\nn::P: a point on the manifold mathcalN\nadjoint_linearized_operator:  the adjoint DÎ›^* of the linearized operator DÎ› T_mmathcalM)  T_Î›(m)mathcalN)\nprox_F, prox_G_Dual:          the proximal maps of F and G^ast_n\n\nnote that depending on the AbstractEvaluationType evaluation the last three parameters as well as the forward operator Î› and the linearized_forward_operator can be given as allocating functions (Manifolds, parameters) -> result  or as mutating functions (Manifold, result, parameters) -> result` to spare allocations.\n\nBy default, this performs the exact Riemannian Chambolle Pock algorithm, see the optional parameter DÎ› for their linearized variant.\n\nFor more details on the algorithm, see [BHS+21].\n\nKeyword Arguments\n\nacceleration=0.05: acceleration parameter\ndual_stepsize=1/sqrt(8): proximal parameter of the primal prox\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual::AbstractInverseRetractionMethod=default_inverse_retraction_method(N, typeof(n)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the (forward) operator Î›() (required for the :exact variant)\nlinearized_forward_operator=missing: its linearization DÎ›() (required for the :linearized variant)\nprimal_stepsize=1/sqrt(8): proximal parameter of the dual prox\nrelaxation=1.: the relaxation parameter Î³\nrelax=:primal: whether to relax the primal or dual\nvariant=:exact if Î› is missing, otherwise :linearized: variant to use. Note that this changes the arguments the forward_operator is called with.\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual::AbstractVectorTransportMethod=default_vector_transport_method(N, typeof(n)): a vector transport mathcal T_ to use, see the section on vector transports\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.ChambollePock!","page":"Chambolle-Pock","title":"Manopt.ChambollePock!","text":"ChambollePock(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\nChambollePock!(M, N, f, p, X, m, n, prox_G, prox_G_dual, adjoint_linear_operator; kwargs...)\n\nPerform the Riemannian Chambolleâ€”Pock algorithm.\n\nGiven a cost function mathcalE mathcalM)  â„ of the form\n\nmathcalE(p) = F(p) + G( Î›(p) )\n\nwhere FmathcalM)  â„, GmathcalN  â„, and Î›mathcalM)  mathcalN.\n\nThis can be done inplace of p.\n\nInput parameters\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nN::AbstractManifold: a Riemannian manifold mathcalM\np::P: a point on the manifold mathcalM\nX::T: a tangent vector at the point p on the manifold mathcalM\nm::P: a point on the manifold mathcalM\nn::P: a point on the manifold mathcalN\nadjoint_linearized_operator:  the adjoint DÎ›^* of the linearized operator DÎ› T_mmathcalM)  T_Î›(m)mathcalN)\nprox_F, prox_G_Dual:          the proximal maps of F and G^ast_n\n\nnote that depending on the AbstractEvaluationType evaluation the last three parameters as well as the forward operator Î› and the linearized_forward_operator can be given as allocating functions (Manifolds, parameters) -> result  or as mutating functions (Manifold, result, parameters) -> result` to spare allocations.\n\nBy default, this performs the exact Riemannian Chambolle Pock algorithm, see the optional parameter DÎ› for their linearized variant.\n\nFor more details on the algorithm, see [BHS+21].\n\nKeyword Arguments\n\nacceleration=0.05: acceleration parameter\ndual_stepsize=1/sqrt(8): proximal parameter of the primal prox\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual::AbstractInverseRetractionMethod=default_inverse_retraction_method(N, typeof(n)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nÎ›=missing: the (forward) operator Î›() (required for the :exact variant)\nlinearized_forward_operator=missing: its linearization DÎ›() (required for the :linearized variant)\nprimal_stepsize=1/sqrt(8): proximal parameter of the dual prox\nrelaxation=1.: the relaxation parameter Î³\nrelax=:primal: whether to relax the primal or dual\nvariant=:exact if Î› is missing, otherwise :linearized: variant to use. Note that this changes the arguments the forward_operator is called with.\nstopping_criterion::StoppingCriterion=StopAfterIteration(100): a functor indicating that the stopping criterion is fulfilled\nupdate_primal_base=missing: function to update m (identity by default/missing)\nupdate_dual_base=missing: function to update n (identity by default/missing)\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual::AbstractVectorTransportMethod=default_vector_transport_method(N, typeof(n)): a vector transport mathcal T_ to use, see the section on vector transports\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.ChambollePockState","page":"Chambolle-Pock","title":"Manopt.ChambollePockState","text":"ChambollePockState <: AbstractPrimalDualSolverState\n\nstores all options and variables within a linearized or exact Chambolle Pock.\n\nFields\n\nacceleration::R:    acceleration factor\ndual_stepsize::R:   proximal parameter of the dual prox\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nm::P:               base point on mathcalMnifold))nifold)))\nn::Q:               base point on mathcalN\np::P:               an initial point on p^(0)  mathcalMnifold))nifold))nifold))nifold)))\npbar::P:            the relaxed iterate used in the next dual update step (when using :primal relaxation)\nprimal_stepsize::R: proximal parameter of the primal prox\nX::T:               an initial tangent vector X^(0)  T_p^(0)mathcalM)\nXbar::T:            the relaxed iterate used in the next primal update step (when using :dual relaxation)\nrelaxation::R:      relaxation in the primal relaxation step (to compute pbar:\nrelax::Symbol:       which variable to relax (:primalor:dual`:\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nvariant:            whether to perform an :exact or :linearized Chambolle-Pock\nupdate_primal_base: function (pr, st, k) -> m to update the primal base\nupdate_dual_base:  function (pr, st, k) -> n to update the dual base\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nHere, P is a point type on mathcalM), T its tangent vector type, Q a point type on mathcalN, and R<:Real is a real number type\n\nwhere for the last two the functions a AbstractManoptProblemp, AbstractManoptSolverStateo and the current iterate i are the arguments. If you activate these to be different from the default identity, you have to provide p.Î› for the algorithm to work (which might be missing in the linearized case).\n\nConstructor\n\nChambollePockState(M::AbstractManifold, N::AbstractManifold;\n    kwargs...\n) where {P, Q, T, R <: Real}\n\nKeyword arguments\n\nn=[rand](@extref Base.rand-Tuple{AbstractManifold})(N)`\np=rand(M)\nm=rand(M)\nX=zero_vector(M, p)\nacceleration=0.0\ndual_stepsize=1/sqrt(8)\nprimal_stepsize=1/sqrt(8)\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\ninverse_retraction_method_dual::AbstractInverseRetractionMethod=default_inverse_retraction_method(N, typeof(n)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nrelaxation=1.0\nrelax=:primal: relax the primal variable by default\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(300): a functor indicating that the stopping criterion is fulfilled\nvariant=:exact: run the exact Chambolle Pock by default\nupdate_primal_base=missing\nupdate_dual_base=missing\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nvector_transport_method_dual::AbstractVectorTransportMethod=default_vector_transport_method(N, typeof(n)): a vector transport mathcal T_ to use, see the section on vector transports\n\nif Manifolds.jl is loaded, N is also a keyword argument and set to TangentBundle(M) by default.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.primal_residual","page":"Chambolle-Pock","title":"Manopt.primal_residual","text":"primal_residual(p, o, x_old, X_old, n_old)\n\nCompute the primal residual at current iterate k given the necessary values x_k-1 X_k-1, and n_k-1 from the previous iterate.\n\nlVert frac1Ïƒoperatornameretr^-1_x_kx_k-1 - V_x_km_k bigl( DÎ›^*(m_k)biglV_n_k n_k-1X_k-1 - X_k bigrbigr) rVert\n\nwhere V_ is the vector transport used in the ChambollePockState\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.dual_residual","page":"Chambolle-Pock","title":"Manopt.dual_residual","text":"dual_residual(p, o, x_old, X_old, n_old)\n\nCompute the dual residual at current iterate k given the necessary values x_k-1 X_k-1, and n_k-1 from the previous iterate. The formula is slightly different depending on the o.variant used:\n\nFor the :linearized it reads\n\nlVert frac1Ï„bigl( V_n_k n_k-1(X_k-1) - X_k bigr ) - DÎ›(m_k)bigl V_m_k x_koperatornameretr^-1_x_k(x_k-1)bigr rVert\n\nand for the :exact variant\n\nlVert frac1Ï„ V_n_k n_k-1(X_k-1) - operatornameretr^-1_n_kbigl( Î›(operatornameretr_m_k(V_m_k x_koperatornameretr^-1_x_kx_k-1))bigr) rVert\n\nwhere in both cases V_ is the vector transport used in the ChambollePockState.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualBaseIterate","page":"Chambolle-Pock","title":"Manopt.DebugDualBaseIterate","text":"DebugDualBaseIterate(io::IO=stdout)\n\nPrint the dual base variable by using DebugEntry, see their constructors for detail. This method is further set display o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualBaseChange","page":"Chambolle-Pock","title":"Manopt.DebugDualBaseChange","text":"DebugDualChange(; storage=StoreStateAction([:n]), io::IO=stdout)\n\nPrint the change of the dual base variable by using DebugEntryChange, see their constructors for detail, on o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalBaseIterate","page":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseIterate","text":"DebugPrimalBaseIterate()\n\nPrint the primal base variable by using DebugEntry, see their constructors for detail. This method is further set display o.m.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalBaseChange","page":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseChange","text":"DebugPrimalBaseChange(a::StoreStateAction=StoreStateAction([:m]),io::IO=stdout)\n\nPrint the change of the primal base variable by using DebugEntryChange, see their constructors for detail, on o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualChange","page":"Chambolle-Pock","title":"Manopt.DebugDualChange","text":"DebugDualChange(opts...)\n\nPrint the change of the dual variable, similar to DebugChange, see their constructors for detail, but with a different calculation of the change, since the dual variable lives in (possibly different) tangent spaces.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugDualIterate","page":"Chambolle-Pock","title":"Manopt.DebugDualIterate","text":"DebugDualIterate(e)\n\nPrint the dual variable by using DebugEntry, see their constructors for detail. This method is further set display o.X.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualResidual","page":"Chambolle-Pock","title":"Manopt.DebugDualResidual","text":"DebugDualResidual <: DebugAction\n\nA Debug action to print the dual residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugDualResidual(; kwargs...)\n\nKeyword warguments\n\nio=stdout`: stream to perform the debug to\nformat=\"$prefix%s\": format to print the dual residual, using the\nprefix=\"Dual Residual: \": short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalChange","page":"Chambolle-Pock","title":"Manopt.DebugPrimalChange","text":"DebugPrimalChange(opts...)\n\nPrint the change of the primal variable by using DebugChange, see their constructors for detail.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalIterate","page":"Chambolle-Pock","title":"Manopt.DebugPrimalIterate","text":"DebugPrimalIterate(opts...;kwargs...)\n\nPrint the change of the primal variable by using DebugIterate, see their constructors for detail.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalResidual","page":"Chambolle-Pock","title":"Manopt.DebugPrimalResidual","text":"DebugPrimalResidual <: DebugAction\n\nA Debug action to print the primal residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugPrimalResidual(; kwargs...)\n\nKeyword warguments\n\nio=stdout`: stream to perform the debug to\nformat=\"$prefix%s\": format to print the dual residual, using the\nprefix=\"Primal Residual: \": short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalDualResidual","page":"Chambolle-Pock","title":"Manopt.DebugPrimalDualResidual","text":"DebugPrimalDualResidual <: DebugAction\n\nA Debug action to print the primal dual residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugPrimalDualResidual()\n\nwith the keywords\n\nKeyword warguments\n\nio=stdout`: stream to perform the debug to\nformat=\"$prefix%s\": format to print the dual residual, using the\nprefix=\"PD Residual: \": short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.RecordDualBaseIterate","page":"Chambolle-Pock","title":"Manopt.RecordDualBaseIterate","text":"RecordDualBaseIterate(n)\n\nCreate an RecordAction that records the dual base point, an RecordEntry of o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualBaseChange","page":"Chambolle-Pock","title":"Manopt.RecordDualBaseChange","text":"RecordDualBaseChange(e)\n\nCreate an RecordAction that records the dual base point change, an RecordEntryChange of o.n with distance to the last value to store a value.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualChange","page":"Chambolle-Pock","title":"Manopt.RecordDualChange","text":"RecordDualChange()\n\nCreate the action either with a given (shared) Storage, which can be set to the values Tuple, if that is provided).\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualIterate","page":"Chambolle-Pock","title":"Manopt.RecordDualIterate","text":"RecordDualIterate(X)\n\nCreate an RecordAction that records the dual base point, an RecordEntry of o.X.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalBaseIterate","page":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseIterate","text":"RecordPrimalBaseIterate(x)\n\nCreate an RecordAction that records the primal base point, an RecordEntry of o.m.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalBaseChange","page":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseChange","text":"RecordPrimalBaseChange()\n\nCreate an RecordAction that records the primal base point change, an RecordEntryChange of o.m with distance to the last value to store a value.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalChange","page":"Chambolle-Pock","title":"Manopt.RecordPrimalChange","text":"RecordPrimalChange(a)\n\nCreate an RecordAction that records the primal value change, RecordChange, to record the change of o.x.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalIterate","page":"Chambolle-Pock","title":"Manopt.RecordPrimalIterate","text":"RecordDualBaseIterate(x)\n\nCreate an RecordAction that records the dual base point, an RecordIterate of o.x.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.update_prox_parameters!","page":"Chambolle-Pock","title":"Manopt.update_prox_parameters!","text":"update_prox_parameters!(o)\n\nupdate the prox parameters as described in Algorithm 2 of [CP11],\n\nÎ¸_n = frac1sqrt1+2Î³Ï„_n\nÏ„_n+1 = Î¸_nÏ„_n\nÏƒ_n+1 = fracÏƒ_nÎ¸_n\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_residual/#Conjugate-residual-solver-in-a-Tangent-space","page":"Conjugate Residual","title":"Conjugate residual solver in a Tangent space","text":"","category":"section"},{"location":"solvers/conjugate_residual/#State","page":"Conjugate Residual","title":"State","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Objective","page":"Conjugate Residual","title":"Objective","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Additional-stopping-criterion","page":"Conjugate Residual","title":"Additional stopping criterion","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Internal-functions","page":"Conjugate Residual","title":"Internal functions","text":"","category":"section"},{"location":"solvers/conjugate_residual/#Literature","page":"Conjugate Residual","title":"Literature","text":"Z.Â Lai and A.Â Yoshise. Riemannian Interior Point Methods for Constrained Optimization on Manifolds. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 201, 433â€“469 (2024), arXiv:2203.09762.\n\n\n\n","category":"section"},{"location":"solvers/conjugate_residual/#Manopt.conjugate_residual","page":"Conjugate Residual","title":"Manopt.conjugate_residual","text":"conjugate_residual(TpM::TangentSpace, A, b, X=zero_vector(TpM))\nconjugate_residual(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X=zero_vector(TpM))\nconjugate_residual!(TpM::TangentSpace, A, b, X)\nconjugate_residual!(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\n\nCompute the solution of mathcalA(p)X + b(p) = 0_p, where\n\nmathcalA is a linear, symmetric operator on T_pmathcalM\nb is a vector field on the manifold\nX  T_pmathcalM is a tangent vector\n0_p is the zero vector T_pmathcalM.\n\nThis implementation follows Algorithm 3 in [LY24] and is initialised with X^(0) as the zero vector and\n\nthe initial residual r^(0) = -b(p) - mathcalA(p)X^(0)\nthe initial conjugate direction d^(0) = r^(0)\ninitialize Y^(0) = mathcalA(p)X^(0)\n\nperformed the following steps at iteration k=0 until the stopping_criterion is fulfilled.\n\ncompute a step size Î±_k = displaystylefrac r^(k) mathcalA(p)r^(k) _p mathcalA(p)d^(k) mathcalA(p)d^(k) _p\ndo a step X^(k+1) = X^(k) + Î±_kd^(k)\nupdate the residual r^(k+1) = r^(k) + Î±_k Y^(k)\ncompute Z = mathcalA(p)r^(k+1)\nUpdate the conjugate coefficient Î²_k = displaystylefrac r^(k+1) mathcalA(p)r^(k+1) _p r^(k) mathcalA(p)r^(k) _p\nUpdate the conjugate direction d^(k+1) = r^(k+1) + Î²_kd^(k)\nUpdate  Y^(k+1) = -Z + Î²_k Y^(k)\n\nNote that the right hand side of Step 7 is the same as evaluating mathcalAd^(k+1), but avoids the actual evaluation\n\nInput\n\nTpM the TangentSpace as the domain\nA a symmetric linear operator on the tangent space (M, p, X) -> Y\nb a vector field on the tangent space (M, p) -> X\nX the initial tangent vector\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nstopping_criterion::StoppingCriterion=StopAfterIteration(manifold_dimension(M)|StopWhenRelativeResidualLess(c,1e-8): a functor indicating that the stopping criterion is fulfilled ,  where c is ``\\lVert b \\rVert\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_residual/#Manopt.conjugate_residual!","page":"Conjugate Residual","title":"Manopt.conjugate_residual!","text":"conjugate_residual(TpM::TangentSpace, A, b, X=zero_vector(TpM))\nconjugate_residual(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X=zero_vector(TpM))\nconjugate_residual!(TpM::TangentSpace, A, b, X)\nconjugate_residual!(TpM::TangentSpace, slso::SymmetricLinearSystemObjective, X)\n\nCompute the solution of mathcalA(p)X + b(p) = 0_p, where\n\nmathcalA is a linear, symmetric operator on T_pmathcalM\nb is a vector field on the manifold\nX  T_pmathcalM is a tangent vector\n0_p is the zero vector T_pmathcalM.\n\nThis implementation follows Algorithm 3 in [LY24] and is initialised with X^(0) as the zero vector and\n\nthe initial residual r^(0) = -b(p) - mathcalA(p)X^(0)\nthe initial conjugate direction d^(0) = r^(0)\ninitialize Y^(0) = mathcalA(p)X^(0)\n\nperformed the following steps at iteration k=0 until the stopping_criterion is fulfilled.\n\ncompute a step size Î±_k = displaystylefrac r^(k) mathcalA(p)r^(k) _p mathcalA(p)d^(k) mathcalA(p)d^(k) _p\ndo a step X^(k+1) = X^(k) + Î±_kd^(k)\nupdate the residual r^(k+1) = r^(k) + Î±_k Y^(k)\ncompute Z = mathcalA(p)r^(k+1)\nUpdate the conjugate coefficient Î²_k = displaystylefrac r^(k+1) mathcalA(p)r^(k+1) _p r^(k) mathcalA(p)r^(k) _p\nUpdate the conjugate direction d^(k+1) = r^(k+1) + Î²_kd^(k)\nUpdate  Y^(k+1) = -Z + Î²_k Y^(k)\n\nNote that the right hand side of Step 7 is the same as evaluating mathcalAd^(k+1), but avoids the actual evaluation\n\nInput\n\nTpM the TangentSpace as the domain\nA a symmetric linear operator on the tangent space (M, p, X) -> Y\nb a vector field on the tangent space (M, p) -> X\nX the initial tangent vector\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nstopping_criterion::StoppingCriterion=StopAfterIteration(manifold_dimension(M)|StopWhenRelativeResidualLess(c,1e-8): a functor indicating that the stopping criterion is fulfilled ,  where c is ``\\lVert b \\rVert\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_residual/#Manopt.ConjugateResidualState","page":"Conjugate Residual","title":"Manopt.ConjugateResidualState","text":"ConjugateResidualState{T,R,TStop<:StoppingCriterion} <: AbstractManoptSolverState\n\nA state for the conjugate_residual solver.\n\nFields\n\nX::T: the iterate\nr::T: the residual r = -b(p) - mathcalA(p)X\nd::T: the conjugate direction\nAr::T, Ad::T: storages for mathcalA(p)d, mathcalA(p)r\nrAr::R: internal field for storing  r mathcalA(p)r \nÎ±::R: a step length\nÎ²::R: the conjugate coefficient\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\n\nConstructor\n\nConjugateResidualState(TpM::TangentSpace,slso::SymmetricLinearSystemObjective; kwargs...)\n\nInitialise the state with default values.\n\nKeyword arguments\n\nr=-get_gradient(TpM, slso, X)\nd=copy(TpM, r)\nAr=get_hessian(TpM, slso, X, r)\nAd=copy(TpM, Ar)\nÎ±::R=0.0\nÎ²::R=0.0\nstopping_criterion::StoppingCriterion=StopAfterIteration(manifold_dimension(M))|StopWhenGradientNormLess(1e-8): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nSee also\n\nconjugate_residual\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_residual/#Manopt.SymmetricLinearSystemObjective","page":"Conjugate Residual","title":"Manopt.SymmetricLinearSystemObjective","text":"SymmetricLinearSystemObjective{E<:AbstractEvaluationType,TA,T} <: AbstractManifoldObjective{E}\n\nModel the objective\n\nf(X) = frac12 lVert mathcalAX + b rVert_p^2qquad X  T_pmathcalM\n\ndefined on the tangent space T_pmathcalM at p on the manifold mathcalM.\n\nIn other words this is an objective to solve mathcalA = -b(p) for some linear symmetric operator and a vector function. Note the minus on the right hand side, which makes this objective especially tailored for (iteratively) solving Newton-like equations.\n\nFields\n\nA!!: a symmetric, linear operator on the tangent space\nb!!: a gradient function\n\nwhere A!! can work as an allocating operator (M, p, X) -> Y or an in-place one (M, Y, p, X) -> Y, and similarly b!! can either be a function (M, p) -> X or (M, X, p) -> X. The first variants allocate for the result, the second variants work in-place.\n\nConstructor\n\nSymmetricLinearSystemObjective(A, b; evaluation=AllocatingEvaluation())\n\nGenerate the objective specifying whether the two parts work allocating or in-place.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_residual/#Manopt.StopWhenRelativeResidualLess","page":"Conjugate Residual","title":"Manopt.StopWhenRelativeResidualLess","text":"StopWhenRelativeResidualLess <: StoppingCriterion\n\nStop when re relative residual in the conjugate_residual is below a certain threshold, i.e.\n\ndisplaystylefraclVert r^(k) rVertc  Îµ\n\nwhere c = lVert b rVert of the initial vector from the vector field in mathcalA(p)X + b(p) = 0_p, from the conjugate_residual\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nc: the initial norm\nÎµ: the threshold\nnorm_rk: the last computed norm of the residual\n\nConstructor\n\nStopWhenRelativeResidualLess(c, Îµ; norm_r = 2*c*Îµ)\n\nInitialise the stopping criterion.\n\nnote: Note\nThe initial norm of the vector field c = lVert b rVert that is stored internally is updated on initialisation, that is, if this stopping criterion is called with k<=0.\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_residual/#Manopt.get_b","page":"Conjugate Residual","title":"Manopt.get_b","text":"get_b(TpM::TangentSpace, slso::SymmetricLinearSystemObjective)\n\nevaluate the stored value for computing the right hand side b in mathcalA=-b.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/EmbeddingObjectives/#How-to-define-the-cost-in-the-embedding","page":"Define objectives in the embedding","title":"How to define the cost in the embedding","text":"Ronny Bergmann\n\nSpecifying a cost function f  mathcal M  â„ on a manifold is usually the model one starts with. Specifying its gradient operatornamegrad f mathcal M  Tmathcal M, or more precisely operatornamegradf(p)  T_pmathcal M, and eventually a Hessian operatornameHess f  T_pmathcal M  T_pmathcal M are then necessary to perform optimization. Since these might be challenging to compute, especially when manifolds and differential geometry are not the main area of a user,Â easier to use methods might be welcome.\n\nThis tutorial discusses how to specify f in the embedding as tilde f, maybe only locally around the manifold, and use the Euclidean gradient  tilde f and Hessian ^2 tilde f within Manopt.jl.\n\nFor the theoretical background see convert an Euclidean to an Riemannian Gradient, or Section 4.7 of [Bou23] for the gradient part or Section 5.11 as well as [Ngu23] for the background on converting Hessians.\n\nHere we use the Examples 9.40 and 9.49 of [Bou23] and compare the different methods, one can call the solver, depending on which gradient and/or Hessian one provides.\n\nusing Manifolds, Manopt, ManifoldDiff\nusing LinearAlgebra, Random, Colors, Plots\nRandom.seed!(123)\n\nWe consider the cost function on the Grassmann manifold given by\n\nn = 5\nk = 2\nM = Grassmann(5,2)\nA = Symmetric(rand(n,n));\n\nf(M, p) = 1 / 2 * tr(p' * A * p)\n\nNote that this implementation is already also a valid implementation / continuation of f into the (lifted) embedding of the Grassmann manifold. In the implementation we can use f for both the Euclidean tilde f and the Grassmann case f.\n\nIts Euclidean gradient nabla f and Hessian nabla^2f are easy to compute as\n\nâˆ‡f(M, p) = A * p\nâˆ‡Â²f(M,p,X) = A*X\n\nOn the other hand, from the aforementioned Example 9.49 we can also state the Riemannian gradient and Hessian for comparison as\n\ngrad_f(M, p) = A * p - p * (p' * A * p)\nHess_f(M, p, X) = A * X - p * p' * A * X - X * p' * A * p\n\nWe can verify that these are the correct at least numerically by calling the check_gradient\n\ncheck_gradient(M, f, grad_f; plot=true)\n\n(Image: )\n\nand the check_Hessian, which requires a bit more tolerance in its linearity verification\n\ncheck_Hessian(M, f, grad_f, Hess_f; plot=true, error=:error, atol=1e-15)\n\n(Image: )\n\nWhile they look reasonable here and were already derived, for the general case this derivation might be more complicated.\n\nLuckily there exist two functions in ManifoldDiff.jl that are implemented for several manifolds from Manifolds.jl, namely riemannian_gradient(M, p, eG) that converts a Riemannian gradient eG=nabla tilde f(p) into a the Riemannian one operatornamegrad f(p) and riemannian_Hessian(M, p, eG, eH, X) which converts the Euclidean Hessian eH=nabla^2 tilde f(p)X into operatornameHess f(p)X, where we also require the Euclidean gradient eG=nabla tilde f(p).\n\nSo we can define\n\ngrad2_f(M, p) = riemannian_gradient(M, p, âˆ‡f(get_embedding(M), embed(M, p)))\n\nwhere only formally we here call embed(M,p) before passing p to the Euclidean gradient, though here (for the Grassmann manifold with Stiefel representation) the embedding function is the identity.\n\nSimilarly for the Hessian, where in our example the embeddings of both the points and tangent vectors are the identity.\n\nfunction Hess2_f(M, p, X)\n    return riemannian_Hessian(\n        M,\n        p,\n        âˆ‡f(get_embedding(M), embed(M, p)),\n        âˆ‡Â²f(get_embedding(M), embed(M, p), embed(M, p, X)),\n        X\n    )\nend\n\nAnd we can again verify these numerically,\n\ncheck_gradient(M, f, grad2_f; plot=true)\n\n(Image: )\n\nand\n\ncheck_Hessian(M, f, grad2_f, Hess2_f; plot=true, error=:error, atol=1e-14)\n\n(Image: )\n\nwhich yields the same result, but we see that the Euclidean conversion might be a bit less stable.\n\nNow if we want to use these in optimization we would require these two functions to call e.g.\n\np0 = [1.0 0.0; 0.0 1.0; 0.0 0.0; 0.0 0.0; 0.0 0.0]\nr1 = adaptive_regularization_with_cubics(\n    M,\n    f,\n    grad_f,\n    Hess_f,\n    p0;\n    debug=[:Iteration, :Cost, \"\\n\"],\n    return_objective=true,\n    return_state=true,\n)\nq1 = get_solver_result(r1)\nr1\n\nInitial f(x): 0.666814\n# 1     f(x): 0.329582\n# 2     f(x): -0.251913\n# 3     f(x): -0.451908\n# 4     f(x): -0.604753\n# 5     f(x): -0.608791\n# 6     f(x): -0.608797\n# 7     f(x): -0.608797\n\n# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)\nAfter 7 iterations\n\n## Parameters\n* Î·1 | Î·2              : 0.1 | 0.9\n* Î³1 | Î³2              : 0.1 | 2.0\n* Ïƒ (Ïƒmin)             : 0.0004082482904638632 (1.0e-10)\n* Ï (Ï_regularization) : 1.0002163851951777 (1000.0)\n* retraction method    : ManifoldsBase.ExponentialRetraction()\n* sub solver state     :\n    | # Solver state for `Manopt.jl`s Lanczos Iteration\n    | After 6 iterations\n    | \n    | ## Parameters\n    | * Ïƒ                         : 0.0040824829046386315\n    | * # of Lanczos vectors used : 6\n    | \n    | ## Stopping criteria\n    | (a) For the Lanczos Iteration\n    | Stop When _one_ of the following are fulfilled:\n    |   * Max Iteration 6:  reached\n    |   * First order progress with Î¸=0.5:  not reached\n    | Overall: reached\n    | (b) For the Newton sub solver\n    | Max Iteration 200:    not reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 40:   not reached\n  * |grad f| < 1.0e-9: reached\n  * All Lanczos vectors (5) used:   not reached\nOverall: reached\nThis indicates convergence: No\n\n## Debug\n    :Iteration = [ (:Iteration, \"# %-6d\"), (:Cost, \"f(x): %f\"), \"\\n\" ]\n\nbut if you choose to go for the conversions, then, thinking of the embedding and defining two new functions might be tedious. There is a shortcut for these, which performs the change internally, when necessary by specifying objective_type=:Euclidean.\n\nr2 = adaptive_regularization_with_cubics(\n    M,\n    f,\n    âˆ‡f,\n    âˆ‡Â²f,\n    p0;\n    # The one line different to specify our grad/Hess are Eucldiean:\n    objective_type=:Euclidean,\n    debug=[:Iteration, :Cost, \"\\n\"],\n    return_objective=true,\n    return_state=true,\n)\nq2 = get_solver_result(r2)\nr2\n\nInitial f(x): 0.666814\n# 1     f(x): 0.329582\n# 2     f(x): -0.251913\n# 3     f(x): -0.451908\n# 4     f(x): -0.604753\n# 5     f(x): -0.608791\n# 6     f(x): -0.608797\n# 7     f(x): -0.608797\n\n# Solver state for `Manopt.jl`s Adaptive Regularization with Cubics (ARC)\nAfter 7 iterations\n\n## Parameters\n* Î·1 | Î·2              : 0.1 | 0.9\n* Î³1 | Î³2              : 0.1 | 2.0\n* Ïƒ (Ïƒmin)             : 0.0004082482904638632 (1.0e-10)\n* Ï (Ï_regularization) : 1.000409105075989 (1000.0)\n* retraction method    : ManifoldsBase.ExponentialRetraction()\n* sub solver state     :\n    | # Solver state for `Manopt.jl`s Lanczos Iteration\n    | After 6 iterations\n    | \n    | ## Parameters\n    | * Ïƒ                         : 0.0040824829046386315\n    | * # of Lanczos vectors used : 6\n    | \n    | ## Stopping criteria\n    | (a) For the Lanczos Iteration\n    | Stop When _one_ of the following are fulfilled:\n    |   * Max Iteration 6:  reached\n    |   * First order progress with Î¸=0.5:  not reached\n    | Overall: reached\n    | (b) For the Newton sub solver\n    | Max Iteration 200:    not reached\n    | This indicates convergence: No\n\n## Stopping criterion\n\nStop When _one_ of the following are fulfilled:\n  * Max Iteration 40:   not reached\n  * |grad f| < 1.0e-9: reached\n  * All Lanczos vectors (5) used:   not reached\nOverall: reached\nThis indicates convergence: No\n\n## Debug\n    :Iteration = [ (:Iteration, \"# %-6d\"), (:Cost, \"f(x): %f\"), \"\\n\" ]\n\nwhich returns the same result, see\n\ndistance(M, q1, q2)\n\n5.599906634890012e-16\n\nThis conversion also works for the gradients of constraints, and is passed down to sub solvers by default when these are created using the Euclidean objective f, nabla f and nabla^2 f.","category":"section"},{"location":"tutorials/EmbeddingObjectives/#Summary","page":"Define objectives in the embedding","title":"Summary","text":"If you have the Euclidean gradient (or Hessian) available for a solver call, all you need to provide is objective_type=:Euclidean to convert the objective to a Riemannian one.","category":"section"},{"location":"tutorials/EmbeddingObjectives/#Literature","page":"Define objectives in the embedding","title":"Literature","text":"N.Â Boumal. An Introduction to Optimization on Smooth Manifolds. FirstÂ Edition (Cambridge University Press, 2023).\n\n\n\nD.Â Nguyen. Operator-Valued Formulas for Riemannian Gradient and Hessian and Families of Tractable Metrics in Riemannian Optimization. JournalÂ ofÂ OptimizationÂ TheoryÂ andÂ Applications 198, 135â€“164 (2023), arXiv:2009.10159.\n\n\n\n","category":"section"},{"location":"tutorials/EmbeddingObjectives/#Technical-details","page":"Define objectives in the embedding","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:31:04.","category":"section"},{"location":"solvers/alternating_gradient_descent/#solver-alternating-gradient-descent","page":"Alternating Gradient Descent","title":"Alternating gradient descent","text":"","category":"section"},{"location":"solvers/alternating_gradient_descent/#State","page":"Alternating Gradient Descent","title":"State","text":"Additionally, the options share a DirectionUpdateRule, which chooses the current component, so they can be decorated further; The most inner one should always be the following one though.\n\nwhich internally uses","category":"section"},{"location":"solvers/alternating_gradient_descent/#sec-agd-technical-details","page":"Alternating Gradient Descent","title":"Technical details","text":"The alternating_gradient_descent solver requires the following functions of a manifold to be available\n\nThe problem has to be phrased on a ProductManifold, to be able to\n\nalternate between parts of the input.\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nBy default alternating gradient descent uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).","category":"section"},{"location":"solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent","page":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent","text":"alternating_gradient_descent(M::ProductManifold, f, grad_f, p=rand(M))\nalternating_gradient_descent(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\nalternating_gradient_descent!(M::ProductManifold, f, grad_f, p)\nalternating_gradient_descent!(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\n\nperform an alternating gradient descent. This can be done in-place of the start point p\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: a gradient, that can be of two cases\nis a single function returning an ArrayPartition from RecursiveArrayTools.jl or\nis a vector functions each returning a component part of the whole gradient\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Random) or the default :Linear one.\ninner_iterations=5:  how many gradient steps to take in a component before alternating to the next\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000))`: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\norder=[1:n]:         the initial permutation, where n is the number of gradients in gradF.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nOutput\n\nusually the obtained (approximate) minimizer, see get_solver_return for details\n\nnote: Note\nThe input of each of the (component) gradients is still the whole vector X, just that all other then the ith input component are assumed to be fixed and just the ith components gradient is computed / returned.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent!","page":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent!","text":"alternating_gradient_descent(M::ProductManifold, f, grad_f, p=rand(M))\nalternating_gradient_descent(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\nalternating_gradient_descent!(M::ProductManifold, f, grad_f, p)\nalternating_gradient_descent!(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\n\nperform an alternating gradient descent. This can be done in-place of the start point p\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: a gradient, that can be of two cases\nis a single function returning an ArrayPartition from RecursiveArrayTools.jl or\nis a vector functions each returning a component part of the whole gradient\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nevaluation_order=:Linear: whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Random) or the default :Linear one.\ninner_iterations=5:  how many gradient steps to take in a component before alternating to the next\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000))`: a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=ArmijoLinesearch(): a functor inheriting from Stepsize to determine a step size\norder=[1:n]:         the initial permutation, where n is the number of gradients in gradF.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nOutput\n\nusually the obtained (approximate) minimizer, see get_solver_return for details\n\nnote: Note\nThe input of each of the (component) gradients is still the whole vector X, just that all other then the ith input component are assumed to be fixed and just the ith components gradient is computed / returned.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradientDescentState","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradientDescentState","text":"AlternatingGradientDescentState <: AbstractGradientDescentSolverState\n\nStore the fields for an alternating gradient descent algorithm, see also alternating_gradient_descent.\n\nFields\n\ndirection::DirectionUpdateRule\nevaluation_order::Symbol: whether to use a randomly permuted sequence (:FixedRandom), a per cycle newly permuted sequence (:Random) or the default :Linear evaluation order.\ninner_iterations: how many gradient steps to take in a component before alternating to the next\norder: the current permutation\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\np::P: a point on the manifold mathcalM  storing the current iterate\nX::T: a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\nk, Ã¬`:              internal counters for the outer and inner iterations, respectively.\n\nConstructors\n\nAlternatingGradientDescentState(M::AbstractManifold; kwargs...)\n\nKeyword arguments\n\ninner_iterations=5\np::P =rand(M): a point on the manifold mathcalM\norder_type::Symbol=:Linear\norder::Vector{<:Int}=Int[]\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000): a functor indicating that the stopping criterion is fulfilled\nstepsize::Stepsize=default_stepsize(M, AlternatingGradientDescentState): a functor inheriting from Stepsize to determine a step size\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nGenerate the options for point p and where inner_iterations, order_type, order, retraction_method, stopping_criterion, and stepsize` are keyword arguments\n\n\n\n\n\n","category":"type"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradient","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradient","text":"AlternatingGradient(; kwargs...)\nAlternatingGradient(M::AbstractManifold; kwargs...)\n\nSpecify that a gradient based method should only update parts of the gradient in order to do a alternating gradient descent.\n\nKeyword arguments\n\ninitial_gradient::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\n\ninfo: Info\nThis function generates a ManifoldDefaultsFactory for AlternatingGradientRule. For default values, that depend on the manifold, this factory postpones the construction until the manifold from for example a corresponding AbstractManoptSolverState is available.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradientRule","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradientRule","text":"AlternatingGradientRule <: AbstractGradientGroupDirectionRule\n\nCreate a functor (problem, state k) -> (s,X) to evaluate the alternating gradient, that is alternating between the components of the gradient and has an field for partial evaluation of the gradient in-place.\n\nFields\n\nX::T: a tangent vector at the point p on the manifold mathcalM\n\nConstructor\n\nAlternatingGradientRule(M::AbstractManifold; p=rand(M), X=zero_vector(M, p))\n\nInitialize the alternating gradient processor with tangent vector type of X, where both M and p are just help variables.\n\nSee also\n\nalternating_gradient_descent, [AlternatingGradient])@ref)\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#tCG","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint truncated conjugate gradient method","text":"Solve the constraint optimization problem on the tangent space\n\nbeginalign*\noperatorname*argmin_Y    T_pmathcalM m_p(Y) = f(p) +\noperatornamegradf(p) Y_p + frac12 mathcalH_pY Y_p\ntextsuch that  lVert Y rVert_p  Î”\nendalign*\n\non the tangent space T_pmathcal M of a Riemannian manifold mathcal M by using the Steihaug-Toint truncated conjugate-gradient (tCG) method, see [ABG06], Algorithm 2, and [CGT00]. Here mathcal H_p is either the Hessian operatornameHess f(p) or a linear symmetric operator on the tangent space approximating the Hessian.","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Interface","page":"Steihaug-Toint TCG Method","title":"Interface","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#State","page":"Steihaug-Toint TCG Method","title":"State","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Stopping-criteria","page":"Steihaug-Toint TCG Method","title":"Stopping criteria","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Trust-region-model","page":"Steihaug-Toint TCG Method","title":"Trust region model","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#sec-tr-technical-details","page":"Steihaug-Toint TCG Method","title":"Technical details","text":"The trust_regions solver requires the following functions of a manifold to be available\n\nif you do not provide a trust_region_radius=, then injectivity_radius on the manifold M is required.\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nA zero_vector!(M,X,p).\nA copyto!(M, q, p) and copy(M,p) for points.","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Literature","page":"Steihaug-Toint TCG Method","title":"Literature","text":"P.-A.Â Absil, C.Â Baker and K.Â Gallivan. Trust-Region Methods on Riemannian Manifolds. FoundationsÂ ofÂ ComputationalÂ Mathematics 7, 303â€“330 (2006).\n\n\n\nA.Â R.Â Conn, N.Â I.Â Gould and P.Â L.Â Toint. Trust Region Methods (Society for Industrial and Applied Mathematics, 2000).\n\n\n\n","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent","page":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent","text":"truncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p=rand(M), X=rand(M); vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, mho::ManifoldHessianObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, trmo::TrustRegionModelObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\n\nsolve the trust-region subproblem\n\nbeginalign*\noperatornameargmin_Y    T_pmathcalM m_p(Y) = f(p) +\noperatornamegradf(p) Y_p + frac12 mathcalH_pY Y_p\ntextsuch that   lVert Y rVert_p  Î”\nendalign*\n\non a manifold mathcalMnifold))) by using the Steihaug-Toint truncated conjugate-gradient (tCG) method. This can be done inplace of X.\n\nFor a description of the algorithm and theorems offering convergence guarantees, see [ABG06, CGT00].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\nX::T: a tangent vector at the point p on the manifold mathcalM\n\nInstead of the three functions, you either provide a ManifoldHessianObjective mho which is then used to build the trust region model, or a TrustRegionModelObjective trmo directly.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸\nÎº=0.1:                the linear convergence target rate.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(manifold_dimension(base_manifold(Tpm)))|StopWhenResidualIsReducedByFactorOrPower(; Îº=Îº, Î¸=Î¸)|StopWhenTrustRegionIsExceeded()|StopWhenCurvatureIsNegative()|StopWhenModelIncreased(): a functor indicating that the stopping criterion is fulfilled\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntrust_regions\n\n\n\n\n\n","category":"function"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent!","page":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent!","text":"truncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p=rand(M), X=rand(M); vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, mho::ManifoldHessianObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\ntruncated_conjugate_gradient_descent(M, trmo::TrustRegionModelObjective, p=rand(M), X=rand(M; vector_at=p);\n    kwargs...\n)\n\nsolve the trust-region subproblem\n\nbeginalign*\noperatornameargmin_Y    T_pmathcalM m_p(Y) = f(p) +\noperatornamegradf(p) Y_p + frac12 mathcalH_pY Y_p\ntextsuch that   lVert Y rVert_p  Î”\nendalign*\n\non a manifold mathcalMnifold))) by using the Steihaug-Toint truncated conjugate-gradient (tCG) method. This can be done inplace of X.\n\nFor a description of the algorithm and theorems offering convergence guarantees, see [ABG06, CGT00].\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\nHess_f: the (Riemannian) Hessian operatornameHessf T_pmathcalM  T_pmathcalM of f as a function (M, p, X) -> Y or a function (M, Y, p, X) -> Y computing Y in-place\np::P: a point on the manifold mathcalM\nX::T: a tangent vector at the point p on the manifold mathcalM\n\nInstead of the three functions, you either provide a ManifoldHessianObjective mho which is then used to build the trust region model, or a TrustRegionModelObjective trmo directly.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\npreconditioner:       a preconditioner for the Hessian H. This is either an allocating function (M, p, X) -> Y or an in-place function (M, Y, p, X) -> Y, see evaluation, and by default set to the identity.\nÎ¸=1.0:                the superlinear convergence target rate of 1+Î¸\nÎº=0.1:                the linear convergence target rate.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize=false:      indicate whether X is initialised to a random vector or not. This disables preconditioning.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(manifold_dimension(base_manifold(Tpm)))|StopWhenResidualIsReducedByFactorOrPower(; Îº=Îº, Î¸=Î¸)|StopWhenTrustRegionIsExceeded()|StopWhenCurvatureIsNegative()|StopWhenModelIncreased(): a functor indicating that the stopping criterion is fulfilled\ntrust_region_radius=injectivity_radius(M) / 4: the initial trust-region radius\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\nSee also\n\ntrust_regions\n\n\n\n\n\n","category":"function"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.TruncatedConjugateGradientState","page":"Steihaug-Toint TCG Method","title":"Manopt.TruncatedConjugateGradientState","text":"TruncatedConjugateGradientState <: AbstractHessianSolverState\n\ndescribe the Steihaug-Toint truncated conjugate-gradient method, with\n\nFields\n\nLet T denote the type of a tangent vector and R <: Real.\n\nÎ´::T:                     the conjugate gradient search direction\nÎ´HÎ´, YPÎ´, Î´PÎ´, YPÎ´: temporary inner products with HÎ´ and preconditioned inner products.\nHÎ´, HY:                 temporary results of the Hessian applied to Î´ and Y, respectively.\nÎº::R:                     the linear convergence target rate.\nproject!:                 for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nrandomize:          indicate whether X is initialised to a random vector or not\nresidual::T:                 the gradient of the model m(Y)\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nÎ¸::R:                     the superlinear convergence target rate of 1+Î¸\ntrust_region_radius::R:   the trust-region radius\nX::T:                     the gradient operatornamegradf(p)\nY::T:                     current iterate tangent vector\nz::T:                     the preconditioned residual\nz_r::R:                   inner product of the residual and z\n\nConstructor\n\nTruncatedConjugateGradientState(TpM::TangentSpace, Y=rand(TpM); kwargs...)\n\nInitialise the TCG state.\n\nInput\n\nTpM: a TangentSpace\n\nKeyword arguments\n\nÎº=0.1\nproject!::F=copyto!: initialise the numerical stabilisation to just copy the result\nrandomize=false\nÎ¸=1.0\ntrust_region_radius=injectivity_radius(base_manifold(TpM)) / 4\nstopping_criterion::StoppingCriterion=StopAfterIteration(manifold_dimension(base_manifold(Tpm)))|StopWhenResidualIsReducedByFactorOrPower(; Îº=Îº, Î¸=Î¸)|StopWhenTrustRegionIsExceeded()|StopWhenCurvatureIsNegative()|StopWhenModelIncreased(): a functor indicating that the stopping criterion is fulfilled\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenResidualIsReducedByFactorOrPower","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenResidualIsReducedByFactorOrPower","text":"StopWhenResidualIsReducedByFactorOrPower <: StoppingCriterion\n\nA functor for testing if the norm of residual at the current iterate is reduced either by a power of 1+Î¸ or by a factor Îº compared to the norm of the initial residual. The criterion hence reads\n\nlVert r_k rVert_p  lVert r_0 rVert_p^(0) min bigl( Îº lVert r_0 rVert_p^(0)  bigr).\n\nFields\n\nÎº:      the reduction factor\nÎ¸:      part of the reduction power\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\n\nConstructor\n\nStopWhenResidualIsReducedByFactorOrPower(; Îº=0.1, Î¸=1.0)\n\nInitialize the StopWhenResidualIsReducedByFactorOrPower functor to indicate to stop after the norm of the current residual is lesser than either the norm of the initial residual to the power of 1+Î¸ or the norm of the initial residual times Îº.\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenTrustRegionIsExceeded","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenTrustRegionIsExceeded","text":"StopWhenTrustRegionIsExceeded <: StoppingCriterion\n\nA functor for testing if the norm of the next iterate in the Steihaug-Toint truncated conjugate gradient method is larger than the trust-region radius Î¸  lVert Y^(k)^* rVert_p^(k) and to end the algorithm when the trust region has been left.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\ntrr the trust region radius\nYPY the computed norm of Y.\n\nConstructor\n\nStopWhenTrustRegionIsExceeded()\n\ninitialize the StopWhenTrustRegionIsExceeded functor to indicate to stop after the norm of the next iterate is greater than the trust-region radius.\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenCurvatureIsNegative","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenCurvatureIsNegative","text":"StopWhenCurvatureIsNegative <: StoppingCriterion\n\nA functor for testing if the curvature of the model is negative, Î´_k operatornameHess F(p)Î´_k_p  0. In this case, the model is not strictly convex, and the stepsize as computed does not yield a reduction of the model.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nvalue store the value of the inner product.\nreason: stores a reason of stopping if the stopping criterion has been reached, see get_reason.\n\nConstructor\n\nStopWhenCurvatureIsNegative()\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenModelIncreased","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenModelIncreased","text":"StopWhenModelIncreased <: StoppingCriterion\n\nA functor for testing if the curvature of the model value increased.\n\nFields\n\nat_iteration::Int: an integer indicating at which the stopping criterion last indicted to stop, which might also be before the solver started (0). Any negative value indicates that this was not yet the case;\nmodel_valuestre the last model value\ninc_model_value store the model value that increased\n\nConstructor\n\nStopWhenModelIncreased()\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.set_parameter!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualPower}, Any}","page":"Steihaug-Toint TCG Method","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualPower, v)\n\nUpdate the residual Power Î¸  to v.\n\n\n\n\n\n","category":"method"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.set_parameter!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualFactor}, Any}","page":"Steihaug-Toint TCG Method","title":"Manopt.set_parameter!","text":"set_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualFactor, v)\n\nUpdate the residual Factor Îº to v.\n\n\n\n\n\n","category":"method"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.TrustRegionModelObjective","page":"Steihaug-Toint TCG Method","title":"Manopt.TrustRegionModelObjective","text":"TrustRegionModelObjective{O<:AbstractManifoldHessianObjective} <: AbstractManifoldSubObjective{O}\n\nA trust region model of the form\n\n    m(X) = f(p) + operatornamegrad f(p) X_p + frac12 operatornameHess f(p)X X_p\n\nFields\n\nobjective: an AbstractManifoldHessianObjective proving f, its gradient and Hessian\n\nConstructors\n\nTrustRegionModelObjective(objective)\n\nwith either an AbstractManifoldHessianObjective objective or an decorator containing such an objective\n\n\n\n\n\n","category":"type"},{"location":"helpers/test/#Manopt.Test","page":"Test","title":"Manopt.Test","text":"For now those tests mainly consider a few parts from ManoptExamples.jl and a few dummy types.","category":"section"},{"location":"helpers/test/#Manopt.Test","page":"Test","title":"Manopt.Test","text":"Manopt.Test\n\nThe module Manopt.Test provides dummy types and small test problems and examples that can be used throughout testing.\n\nSome of these are simplified variants from problems from ManoptExamples.jl, that are added here to not introduce a circular dependency.\n\nSome of the functionality is only populated when certain packages are loaded, that is\n\nTest.jl\nManifolds.jl\n\n\n\n\n\n","category":"module"},{"location":"helpers/test/#Manopt.Test.mean_task","page":"Test","title":"Manopt.Test.mean_task","text":"f, grad_f = Manopt.Test.mean_task(M, data)\n\nReturns cost and gradient for computing the mean of data d_i on manifold M\n\n```math \\begin{align} f(p) = \\frac{1}{2n} \\sum{i=1}^n dM(p, di)^2 \\operatorname{grad} f(p) = -\\frac{1}{n} \\sum{i=1}^n \\logp(di) \\end{align}\n\n\n\n\n\n","category":"function"},{"location":"helpers/test/#Manopt.Test.Circle_mean_task","page":"Test","title":"Manopt.Test.Circle_mean_task","text":"M, f, grad_f, p0, p_star = Circle_mean_task()\n\nCreate a small mean problem on the circle to test Number-based algorithms Requires Manifolds.jl to be loaded, use Manopt.Test.mean_task(M, data) for the general case\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Levenberg-Marquardt","page":"Levenbergâ€“Marquardt","title":"Levenberg-Marquardt","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/#Options","page":"Levenbergâ€“Marquardt","title":"Options","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/#sec-lm-technical-details","page":"Levenbergâ€“Marquardt","title":"Technical details","text":"The LevenbergMarquardt solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nA copyto!(M, q, p) and copy(M,p) for points.","category":"section"},{"location":"solvers/LevenbergMarquardt/#Internals","page":"Levenbergâ€“Marquardt","title":"Internals","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/#Literature","page":"Levenbergâ€“Marquardt","title":"Literature","text":"S.Â Adachi, T.Â Okuno and A.Â Takeda. Riemannian Levenberg-Marquardt Method with Global and Local Convergence Properties. ArXivÂ Preprint (2022).\n\n\n\nR.Â Peeters. On a Riemannian version of the Levenberg-Marquardt algorithm. Serie Research MemorandaÂ 0011 (VU University Amsterdam, Faculty of Economics, Business Administration and Econometrics, 1993).\n\n\n\n","category":"section"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt","page":"Levenbergâ€“Marquardt","title":"Manopt.LevenbergMarquardt","text":"LevenbergMarquardt(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt(M, vgf, p; kwargs...)\nLevenbergMarquardt(M, nlso, p; kwargs...)\nLevenbergMarquardt!(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, vgf, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, nlso, p, num_components=-1; kwargs...)\n\ncompute the the Riemannian Levenberg-Marquardt algorithm [Pee93, AOT22] to solve\n\noperatorname*argmin_p  mathcalM frac12 sum_i=1^m lvert f_i(p) rvert^2\n\nwhere f mathcalM  â„^m is written with component functions f_i mathcalM  â„, i=1m, and each component function is continuously differentiable.\n\nThe second block of signatures perform the optimization in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalMnifold))nifold)))â„^m. The cost function can be provided in two different ways\nas a single function returning a vector f(p)  â„^m\nas a vector of functions, where each single function returns a scalar f_i(p)  â„\nThe type is determined by the function_type= keyword argument.\njacobian_f:   the Jacobian of f. The Jacobian can be provided in three different ways\nas a single function returning a vector of gradient vectors bigl(operatornamegrad f_i(p)bigr)_i=1^m\nas a vector of functions, where each single function returns a gradient vector operatornamegrad f_i(p), i=1m\nas a single function returning a (coefficient) matrix J  â„^md, where d is the dimension of the manifold.\nThese coefficients are given with respect to an AbstractBasis of the tangent space at p. The type is determined by the jacobian_type= keyword argument.\np::P: a point on the manifold mathcalM\nnum_components: length m of the vector returned by the cost function. By default its value is -1 which means that it is determined automatically by calling f one additional time. This is only possible when evaluation is AllocatingEvaluation, for mutating evaluation this value must be explicitly specified.\n\nYou can also provide the cost and its Jacobian already as aVectorGradientFunction vgf, Alternatively, passing a NonlinearLeastSquaresObjective nlso.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎ·=0.2:                   scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range: 0 < Î· < 1.\nexpect_zero_residual=false: whether or not the algorithm might expect that the value of residual (objective) at minimum is equal to 0.\ndamping_term_min=0.1:      initial (and also minimal) value of the damping term\nÎ²=5.0:                     parameter by which the damping term is multiplied when the current new point is rejected\nfunction_type=FunctionVectorialType: an AbstractVectorialType specifying the type of cost function provided.\ninitial_jacobian_f:      the initial Jacobian of the cost function f. By default this is a matrix of size num_components times the manifold dimension of similar type as p.\ninitial_residual_values: the initial residual vector of the cost function f. By default this is a vector of length num_components of similar type as p.\njacobian_type=FunctionVectorialType: an AbstractVectorialType specifying the type of Jacobian provided.\nlinear_subsolver!:    a function with three arguments sk, JJ, grad_f_c that solves the linear subproblem sk .= JJ \\ grad_f_c, where JJ is (up to numerical issues) a symmetric positive definite matrix. Default value is default_lm_lin_solve!.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt!","page":"Levenbergâ€“Marquardt","title":"Manopt.LevenbergMarquardt!","text":"LevenbergMarquardt(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt(M, vgf, p; kwargs...)\nLevenbergMarquardt(M, nlso, p; kwargs...)\nLevenbergMarquardt!(M, f, jacobian_f, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, vgf, p, num_components=-1; kwargs...)\nLevenbergMarquardt!(M, nlso, p, num_components=-1; kwargs...)\n\ncompute the the Riemannian Levenberg-Marquardt algorithm [Pee93, AOT22] to solve\n\noperatorname*argmin_p  mathcalM frac12 sum_i=1^m lvert f_i(p) rvert^2\n\nwhere f mathcalM  â„^m is written with component functions f_i mathcalM  â„, i=1m, and each component function is continuously differentiable.\n\nThe second block of signatures perform the optimization in-place of p.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalMnifold))nifold)))â„^m. The cost function can be provided in two different ways\nas a single function returning a vector f(p)  â„^m\nas a vector of functions, where each single function returns a scalar f_i(p)  â„\nThe type is determined by the function_type= keyword argument.\njacobian_f:   the Jacobian of f. The Jacobian can be provided in three different ways\nas a single function returning a vector of gradient vectors bigl(operatornamegrad f_i(p)bigr)_i=1^m\nas a vector of functions, where each single function returns a gradient vector operatornamegrad f_i(p), i=1m\nas a single function returning a (coefficient) matrix J  â„^md, where d is the dimension of the manifold.\nThese coefficients are given with respect to an AbstractBasis of the tangent space at p. The type is determined by the jacobian_type= keyword argument.\np::P: a point on the manifold mathcalM\nnum_components: length m of the vector returned by the cost function. By default its value is -1 which means that it is determined automatically by calling f one additional time. This is only possible when evaluation is AllocatingEvaluation, for mutating evaluation this value must be explicitly specified.\n\nYou can also provide the cost and its Jacobian already as aVectorGradientFunction vgf, Alternatively, passing a NonlinearLeastSquaresObjective nlso.\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\nÎ·=0.2:                   scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range: 0 < Î· < 1.\nexpect_zero_residual=false: whether or not the algorithm might expect that the value of residual (objective) at minimum is equal to 0.\ndamping_term_min=0.1:      initial (and also minimal) value of the damping term\nÎ²=5.0:                     parameter by which the damping term is multiplied when the current new point is rejected\nfunction_type=FunctionVectorialType: an AbstractVectorialType specifying the type of cost function provided.\ninitial_jacobian_f:      the initial Jacobian of the cost function f. By default this is a matrix of size num_components times the manifold dimension of similar type as p.\ninitial_residual_values: the initial residual vector of the cost function f. By default this is a vector of length num_components of similar type as p.\njacobian_type=FunctionVectorialType: an AbstractVectorialType specifying the type of Jacobian provided.\nlinear_subsolver!:    a function with three arguments sk, JJ, grad_f_c that solves the linear subproblem sk .= JJ \\ grad_f_c, where JJ is (up to numerical issues) a symmetric positive definite matrix. Default value is default_lm_lin_solve!.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardtState","page":"Levenbergâ€“Marquardt","title":"Manopt.LevenbergMarquardtState","text":"LevenbergMarquardtState{P,T} <: AbstractGradientSolverState\n\nDescribes a Gradient based descent algorithm, with\n\nFields\n\nA default value is given in brackets if a parameter can be left out in initialization.\n\np::P: a point on the manifold mathcalM  storing the current iterate\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nresidual_values:      value of F calculated in the solver setup or the previous iteration\nresidual_values_temp: value of F for the current proposal point\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\njacobian:                 the current Jacobian of F\ngradient:             the current gradient of F\nstep_vector:          the tangent vector at x that is used to move to the next point\nlast_stepsize:        length of step_vector\nÎ·:                    Scaling factor for the sufficient cost decrease threshold required to accept new proposal points. Allowed range: 0 < Î· < 1.\ndamping_term:         current value of the damping term\ndamping_term_min:     initial (and also minimal) value of the damping term\nÎ²:                    parameter by which the damping term is multiplied when the current new point is rejected\nexpect_zero_residual: if true, the algorithm expects that the value of the residual (objective) at minimum is equal to 0.\nlinear_subsolver!:    a function with three arguments sk, JJ, grad_f_cthat solves the linear subproblemsk .= JJ \\ gradfc, whereJJis (up to numerical issues) a symmetric positive definite matrix. Default value is [defaultlmlin_solve!`](@ref).\n\nConstructor\n\nLevenbergMarquardtState(M, initial_residual_values, initial_jacobian; kwargs...)\n\nGenerate the Levenberg-Marquardt solver state.\n\nKeyword arguments\n\nThe following fields are keyword arguments\n\nÎ²=5.0\ndamping_term_min=0.1\nÎ·=0.2,\nexpect_zero_residual=false\ninitial_gradient=zero_vector(M, p)\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstopping_criterion::StoppingCriterion=StopAfterIteration(200)|StopWhenGradientNormLess(1e-12)|StopWhenStepsizeLess(1e-12): a functor indicating that the stopping criterion is fulfilled\n\nSee also\n\ngradient_descent, LevenbergMarquardt\n\n\n\n\n\n","category":"type"},{"location":"solvers/LevenbergMarquardt/#Manopt.default_lm_lin_solve!","page":"Levenbergâ€“Marquardt","title":"Manopt.default_lm_lin_solve!","text":"default_lm_lin_solve!(sk, JJ, grad_f_c)\n\nSolve the system JJ \\ grad_f_c where JJ is (mathematically) a symmetric positive definite matrix and save the result to sk. In case of numerical errors the PosDefException is caught and the default symmetric solver (Symmetric(JJ) \\ grad_f_c) is used.\n\nThe function is intended to be used with LevenbergMarquardt.\n\n\n\n\n\n","category":"function"},{"location":"solvers/exact_penalty_method/#Exact-penalty-method","page":"Exact Penalty Method","title":"Exact penalty method","text":"","category":"section"},{"location":"solvers/exact_penalty_method/#State","page":"Exact Penalty Method","title":"State","text":"","category":"section"},{"location":"solvers/exact_penalty_method/#Helping-functions","page":"Exact Penalty Method","title":"Helping functions","text":"","category":"section"},{"location":"solvers/exact_penalty_method/#sec-dr-technical-details","page":"Exact Penalty Method","title":"Technical details","text":"The exact_penalty_method solver requires the following functions of a manifold to be available\n\nA copyto!(M, q, p) and copy(M,p) for points.\nEverything the subsolver requires, which by default is the quasi_Newton method\nA zero_vector(M,p).\n\nThe stopping criteria involves StopWhenChangeLess and StopWhenGradientNormLess which require\n\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= or inverse_retraction_method_dual= (for mathcal N) does not have to be specified or the distance(M, p, q) for said default inverse retraction.\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.","category":"section"},{"location":"solvers/exact_penalty_method/#Literature","page":"Exact Penalty Method","title":"Literature","text":"C.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\n","category":"section"},{"location":"solvers/exact_penalty_method/#Manopt.exact_penalty_method","page":"Exact Penalty Method","title":"Manopt.exact_penalty_method","text":"exact_penalty_method(M, f, grad_f, p=rand(M); kwargs...)\nexact_penalty_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\nexact_penalty_method!(M, f, grad_f, p; kwargs...)\nexact_penalty_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the exact penalty method (EPM) [LB19] The aim of the EPM is to find a solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. For that a weighted L_1-penalty term for the violation of the constraints is added to the objective\n\nf(x) + Ïbiggl( sum_i=1^m maxbigl0 g_i(x)bigr + sum_j=1^n vert h_j(x)vertbiggr)\n\nwhere Ï0 is the penalty parameter.\n\nSince this is non-smooth, a SmoothingTechnique with parameter u is applied, see the ExactPenaltyCost.\n\nIn every step k of the exact penalty method, the smoothed objective is then minimized over all p mathcalMnifold))nifold))). Then, the accuracy tolerance Ïµ and the smoothing parameter u are updated by setting\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_min is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor, and\n\nu^(k) = max u_min theta_u u^(k-1) \n\nwhere u_min is the lowest value u is allowed to become and Î¸_u  (01) is constant scaling factor.\n\nFinally, the penalty parameter Ï is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  displaystyle max_j  mathcalEi  mathcalI Bigl vert h_j(x^(k)) vert g_i(x^(k))Bigr geq u^(k-1) Bigr) \nÏ^(k-1)  text else\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nif not called with the ConstrainedManifoldObjective cmo\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nFurther keyword arguments\n\nÏµ=1eâ€“3: the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor;\nÏµ_min=1e-6: the lower bound for the accuracy tolerance\nu=1eâ€“1: the smoothing parameter and threshold for violation of the constraints\nu_exponent=1/100: exponent of the u update factor;\nu_min=1e-6: the lower bound for the smoothing parameter and threshold for violation of the constraints\nÏ=1.0: the penalty parameter\nequality_constraints=nothing: the number n of equality constraints. If not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nmin_stepsize=1e-10: the minimal step size\nsmoothing=LogarithmicSumOfExponentials: a SmoothingTechnique to use\nsub_cost=ExactPenaltyCost(problem, Ï, u; smoothing=smoothing): cost to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=ExactPenaltyGrad(problem, Ï, u; smoothing=smoothing): gradient to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-10): a stopping cirterion for the sub solver This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_state::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M,ManifoldGradientObjective(sub_cost, sub_grad; evaluation=evaluation):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_state::Union{AbstractManoptProblem, F} =QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. , where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\"))\nstopping_criterion::StoppingCriterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) ): a functor indicating that the stopping criterion is fulfilled\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/exact_penalty_method/#Manopt.exact_penalty_method!","page":"Exact Penalty Method","title":"Manopt.exact_penalty_method!","text":"exact_penalty_method(M, f, grad_f, p=rand(M); kwargs...)\nexact_penalty_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\nexact_penalty_method!(M, f, grad_f, p; kwargs...)\nexact_penalty_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the exact penalty method (EPM) [LB19] The aim of the EPM is to find a solution of the constrained optimisation task\n\nbeginaligned\noperatorname*argmin_p  mathcalM  f(p)\ntextsubject toquadg_i(p)  0 quad text for  i= 1  m\nquad  h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^n and h_j_j=1^m are twice continuously differentiable functions from M to â„. For that a weighted L_1-penalty term for the violation of the constraints is added to the objective\n\nf(x) + Ïbiggl( sum_i=1^m maxbigl0 g_i(x)bigr + sum_j=1^n vert h_j(x)vertbiggr)\n\nwhere Ï0 is the penalty parameter.\n\nSince this is non-smooth, a SmoothingTechnique with parameter u is applied, see the ExactPenaltyCost.\n\nIn every step k of the exact penalty method, the smoothed objective is then minimized over all p mathcalMnifold))nifold))). Then, the accuracy tolerance Ïµ and the smoothing parameter u are updated by setting\n\nÏµ^(k)=maxÏµ_min Î¸_Ïµ Ïµ^(k-1)\n\nwhere Ïµ_min is the lowest value Ïµ is allowed to become and Î¸_Ïµ  (01) is constant scaling factor, and\n\nu^(k) = max u_min theta_u u^(k-1) \n\nwhere u_min is the lowest value u is allowed to become and Î¸_u  (01) is constant scaling factor.\n\nFinally, the penalty parameter Ï is updated as\n\nÏ^(k) = begincases\nÏ^(k-1)Î¸_Ï   textif  displaystyle max_j  mathcalEi  mathcalI Bigl vert h_j(x^(k)) vert g_i(x^(k))Bigr geq u^(k-1) Bigr) \nÏ^(k-1)  text else\nendcases\n\nwhere Î¸_Ï  (01) is a constant scaling factor.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nif not called with the ConstrainedManifoldObjective cmo\n\ng=nothing: the inequality constraints\nh=nothing: the equality constraints\ngrad_g=nothing: the gradient of the inequality constraints\ngrad_h=nothing: the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be provided. Otherwise the problem is not constrained and a better solver would be for example quasi_Newton.\n\nFurther keyword arguments\n\nÏµ=1eâ€“3: the accuracy tolerance\nÏµ_exponent=1/100: exponent of the Ïµ update factor;\nÏµ_min=1e-6: the lower bound for the accuracy tolerance\nu=1eâ€“1: the smoothing parameter and threshold for violation of the constraints\nu_exponent=1/100: exponent of the u update factor;\nu_min=1e-6: the lower bound for the smoothing parameter and threshold for violation of the constraints\nÏ=1.0: the penalty parameter\nequality_constraints=nothing: the number n of equality constraints. If not provided, a call to the gradient of g is performed to estimate these.\ngradient_range=nothing: specify how both gradients of the constraints are represented\ngradient_equality_range=gradient_range:  specify how gradients of the equality constraints are represented, see VectorGradientFunction.\ngradient_inequality_range=gradient_range:  specify how gradients of the inequality constraints are represented, see VectorGradientFunction.\ninequality_constraints=nothing: the number m of inequality constraints.  If not provided, a call to the gradient of g is performed to estimate these.\nmin_stepsize=1e-10: the minimal step size\nsmoothing=LogarithmicSumOfExponentials: a SmoothingTechnique to use\nsub_cost=ExactPenaltyCost(problem, Ï, u; smoothing=smoothing): cost to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_grad=ExactPenaltyGrad(problem, Ï, u; smoothing=smoothing): gradient to use in the sub solver This is used to define the sub_problem= keyword and has hence no effect, if you set sub_problem directly.\nsub_kwargs = (;): a named tuple of keyword arguments that are passed to decorate_objective! of the sub solvers objective, the decorate_state! of the subsovlers state, and the sub state constructor itself.\nsub_stopping_criterion=StopAfterIteration(200)|StopWhenGradientNormLess(Ïµ)|StopWhenStepsizeLess(1e-10): a stopping cirterion for the sub solver This is used to define the sub_state= keyword and has hence no effect, if you set sub_state directly.\nsub_state::Union{AbstractManoptProblem, F} =DefaultManoptProblem(M,ManifoldGradientObjective(sub_cost, sub_grad; evaluation=evaluation):  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nsub_state::Union{AbstractManoptProblem, F} =QuasiNewtonState:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function. , where QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS is used\"))\nstopping_criterion::StoppingCriterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(Ïµ, Ïµ_min)&StopWhenChangeLess(1e-10) ): a functor indicating that the stopping criterion is fulfilled\n\nFor the ranges of the constraints' gradient, other power manifold tangent space representations, mainly the ArrayPowerRepresentation can be used if the gradients can be computed more efficiently in that representation.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyMethodState","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyMethodState","text":"ExactPenaltyMethodState{P,T} <: AbstractManoptSolverState\n\nDescribes the exact penalty method, with\n\nFields\n\nÏµ: the accuracy tolerance\nÏµ_min: the lower bound for the accuracy tolerance\np::P: a point on the manifold mathcalM  storing the current iterate\nÏ: the penalty parameter\nsub_problem::Union{AbstractManoptProblem, F}:  specify a problem for a solver or a closed form solution function, which can be allocating or in-place.\nsub_state::Union{AbstractManoptProblem, F}:  a state to specify the sub solver to use. For a closed form solution, this indicates the type of function.\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nu: the smoothing parameter and threshold for violation of the constraints\nu_min: the lower bound for the smoothing parameter and threshold for violation of the constraints\nÎ¸_Ïµ: the scaling factor of the tolerance parameter\nÎ¸_Ï: the scaling factor of the penalty parameter\nÎ¸_u: the scaling factor of the smoothing parameter\n\nConstructor\n\nExactPenaltyMethodState(M::AbstractManifold, sub_problem, sub_state; kwargs...)\n\nconstruct the exact penalty state.\n\nExactPenaltyMethodState(M::AbstractManifold, sub_problem;\n    evaluation=AllocatingEvaluation(), kwargs...\n\n)\n\nconstruct the exact penalty state, where sub_problem is a closed form solution with evaluation as type of evaluation.\n\nKeyword arguments\n\nÏµ=1e-3\nÏµ_min=1e-6\nÏµ_exponent=1 / 100: a shortcut for the scaling factor Î¸_Ïµ\nÎ¸_Ïµ=(Ïµ_min / Ïµ)^(Ïµ_exponent)\nu=1e-1\nu_min=1e-6\nu_exponent=1 / 100:  a shortcut for the scaling factor Î¸_u.\nÎ¸_u=(u_min / u)^(u_exponent)\np::P =rand(M): a point on the manifold mathcalM  to specify the initial value\nÏ=1.0\nÎ¸_Ï=0.3\nstopping_criterion::StoppingCriterion=StopAfterIteration(300)|(StopWhenSmallerOrEqual(:Ïµ, Ïµ_min)|StopWhenChangeLess(1e-10) ): a functor indicating that the stopping criterion is fulfilled\n\nSee also\n\nexact_penalty_method\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyCost","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyCost","text":"ExactPenaltyCost{S, Pr, R}\n\nRepresent the cost of the exact penalty method based on a ConstrainedManifoldObjective P and a parameter Ï given by\n\nf(p) + ÏBigl(\n    sum_i=0^m maxset0g_i(p) + sum_j=0^n lvert h_j(p) rvert\nBigr)\n\nwhere an additional parameter u is used as well as a smoothing technique, for example LogarithmicSumOfExponentials or LinearQuadraticHuber to obtain a smooth cost function. This struct is also a functor (M,p) -> v of the cost v.\n\nFields\n\nÏ, u: as described in the mathematical formula, .\nco:     the original cost\n\nConstructor\n\nExactPenaltyCost(co::ConstrainedManifoldObjective, Ï, u; smoothing=LinearQuadraticHuber())\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyGrad","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyGrad","text":"ExactPenaltyGrad{S, CO, R}\n\nRepresent the gradient of the ExactPenaltyCost based on a ConstrainedManifoldObjective co and a parameter Ï and a smoothing technique, which uses an additional parameter u.\n\nThis struct is also a functor in both formats\n\n(M, p) -> X to compute the gradient in allocating fashion.\n(M, X, p) to compute the gradient in in-place fashion.\n\nFields\n\nÏ, u as stated before\nco the nonsmooth objective\n\nConstructor\n\nExactPenaltyGradient(co::ConstrainedManifoldObjective, Ï, u; smoothing=LinearQuadraticHuber())\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.SmoothingTechnique","page":"Exact Penalty Method","title":"Manopt.SmoothingTechnique","text":"abstract type SmoothingTechnique\n\nSpecify a smoothing technique, see for example ExactPenaltyCost and ExactPenaltyGrad.\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber","page":"Exact Penalty Method","title":"Manopt.LinearQuadraticHuber","text":"LinearQuadraticHuber <: SmoothingTechnique\n\nSpecify a smoothing based on maxset0x  mathcalP(xu) for some u, where\n\nmathcalP = begincases   0  text if  x  0    fracx^22u  text if  0  x  u    x-fracu2  text if  x  uendcases\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials","page":"Exact Penalty Method","title":"Manopt.LogarithmicSumOfExponentials","text":"LogarithmicSumOfExponentials <: SmoothingTechnique\n\nSpecify a smoothing based on maxmax  u log(mathrme^fracau+mathrme^fracbu) for some u.\n\n\n\n\n\n","category":"type"},{"location":"plans/#sec-plan","page":"Specify a Solver","title":"Plans for solvers","text":"For any optimisation performed in Manopt.jl information is required about both the optimisation task or â€œproblemâ€ at hand as well as the solver and all its parameters. This together is called a plan in Manopt.jl and it consists of two data structures:\n\nThe Manopt Problem describes all static data of a task, most prominently the manifold and the objective.\nThe Solver State describes all varying data and parameters for the solver that is used. This also means that each solver has its own data structure for the state.\n\nBy splitting these two parts, one problem can be define an then be solved  using different solvers.\n\nStill there might be the need to set certain parameters within any of these structures. For that there is\n\nThe following symbols are used.\n\nSymbol Used in Description\n:Activity DebugWhenActive activity of the debug action stored within\n:Basepoint TangentSpace the point the tangent space is at\n:Cost generic the cost function (within an objective, as pass down)\n:Debug DebugSolverState the stored debugDictionary\n:Gradient generic the gradient function (within an objective, as pass down)\n:Iterate generic the (current) iterate,Â similar to set_iterate!,Â within a state\n:Manifold generic the manifold (within a problem, as pass down)\n:Objective generic the objective (within a problem, as pass down)\n:SubProblem generic the sub problem (within a state, as pass down)\n:SubState generic the sub state (within a state, as pass down)\n:Î» ProximalDCCost, ProximalDCGrad set the proximal parameter within the proximal sub objective elements\n:Population ParticleSwarmState a certain population of points, for example particle_swarms swarm\n:Record RecordSolverState \n:TrustRegionRadius TrustRegionsState the trust region radius, equivalent to :Ïƒ\n:Ï, :u ExactPenaltyCost, ExactPenaltyGrad Parameters within the exact penalty objective\n:Ï, :Î¼, :Î» AugmentedLagrangianCost, AugmentedLagrangianGrad Parameters of the Lagrangian function\n:p, :X LinearizedDCCost, LinearizedDCGrad Parameters within the linearized functional used for the sub problem of the difference of convex algorithm\n\nAny other lower case name or letter as well as single upper case letters access fields of the corresponding first argument. for example :p could be used to access the field s.p of a state. This is often, where the iterate is stored, so the recommended way is to use :Iterate from before.\n\nSince the iterate is often stored in the states fields s.p one could access the iterate often also with :p and similarly the gradient with :X. This is discouraged for both readability as well as to stay more generic, and it is recommended to use :Iterate and :Gradient instead in generic settings.\n\nYou can further activate a â€œTutorialâ€ mode by set_parameter!(:Mode, \"Tutorial\"). Internally, the following convenience function is available.","category":"section"},{"location":"plans/#A-factory-for-providing-manifold-defaults","page":"Specify a Solver","title":"A factory for providing manifold defaults","text":"In several cases a manifold might not yet be known at the time a (keyword) argument should be provided. Therefore, any type with a manifold default can be wrapped into a factory.","category":"section"},{"location":"plans/#Keyword-arguments-and-their-verification","page":"Specify a Solver","title":"Keyword arguments and their verification","text":"Internally Manopt.jl passes keywords for the (high-level) solver functions to several inner functions, e.g. to add debug or caching. Besides the documentation, one can check with the internal function Manopt.accepted_keywords which keywords a solver accepts.\n\nA solver also warns, if a keyword is passed, that is not handled by the solver or any of the inner functions it calls.","category":"section"},{"location":"plans/#Manopt.set_parameter!","page":"Specify a Solver","title":"Manopt.set_parameter!","text":"set_parameter!(f, element::Symbol , args...)\n\nFor any f and a Symbol e, dispatch on its value so by default, to set some args... in f or one of uts sub elements.\n\n\n\n\n\nset_parameter!(element::Symbol, value::Union{String,Bool,<:Number})\n\nSet global Manopt parameters addressed by a symbol element. W This first dispatches on the value of element.\n\nThe parameters are stored to the global settings using Preferences.jl.\n\nPassing a value of \"\" deletes the corresponding entry from the preferences. Whenever the LocalPreferences.toml is modified, this is also issued as an @info.\n\n\n\n\n\nset_parameter!(amo::AbstractManifoldObjective, element::Symbol, args...)\n\nSet a certain args... from the AbstractManifoldObjective amo to value. This function should dispatch onVal(element)`.\n\nCurrently supported\n\n:Cost passes to the get_cost_function\n:Gradient passes to the get_gradient_function\n:SubGradient passes to the get_subgradient_function\n\n\n\n\n\nset_parameter!(ams::AbstractManoptProblem, element::Symbol, field::Symbol , value)\n\nSet a certain field/element from the AbstractManoptProblem ams to value. This function usually dispatches on Val(element). Instead of a single field, also a chain of elements can be provided, allowing to access encapsulated parts of the problem.\n\nMain values for element are :Manifold and :Objective.\n\n\n\n\n\nset_parameter!(ams::DebugSolverState, ::Val{:Debug}, args...)\n\nSet certain values specified by args... into the elements of the debugDictionary\n\n\n\n\n\nset_parameter!(ams::RecordSolverState, ::Val{:Record}, args...)\n\nSet certain values specified by args... into the elements of the recordDictionary\n\n\n\n\n\nset_parameter!(c::StopAfter, :MaxTime, v::Period)\n\nUpdate the time period after which an algorithm shall stop.\n\n\n\n\n\nset_parameter!(c::StopAfterIteration, :;MaxIteration, v::Int)\n\nUpdate the number of iterations after which the algorithm should stop.\n\n\n\n\n\nset_parameter!(c::StopWhenChangeLess, :MinIterateChange, v::Int)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\nset_parameter!(c::StopWhenCostLess, :MinCost, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenEntryChangeLess, :Threshold, v)\n\nUpdate the minimal cost below which the algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenGradientChangeLess, :MinGradientChange, v)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\nset_parameter!(c::StopWhenGradientNormLess, :MinGradNorm, v::Float64)\n\nUpdate the minimal gradient norm when an algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenStepsizeLess, :MinStepsize, v)\n\nUpdate the minimal step size below which the algorithm shall stop\n\n\n\n\n\nset_parameter!(c::StopWhenSubgradientNormLess, :MinSubgradNorm, v::Float64)\n\nUpdate the minimal subgradient norm when an algorithm shall stop\n\n\n\n\n\nset_parameter!(ams::AbstractManoptSolverState, element::Symbol, args...)\n\nSet a certain field or semantic element from the AbstractManoptSolverState ams to value. This function passes to Val(element) and specific setters should dispatch on Val{element}.\n\nBy default, this function just does nothing.\n\n\n\n\n\nset_parameter!(ams::DebugSolverState, ::Val{:SubProblem}, args...)\n\nSet certain values specified by args... to the sub problem.\n\n\n\n\n\nset_parameter!(ams::DebugSolverState, ::Val{:SubState}, args...)\n\nSet certain values specified by args... to the sub state.\n\n\n\n\n\nset_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualPower, v)\n\nUpdate the residual Power Î¸  to v.\n\n\n\n\n\nset_parameter!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualFactor, v)\n\nUpdate the residual Factor Îº to v.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.get_parameter","page":"Specify a Solver","title":"Manopt.get_parameter","text":"get_parameter(f, element::Symbol, args...)\n\nAccess arbitrary parameters from f addressed by a symbol element.\n\nFor any f and a Symbol e dispatch on its value by default, to get some element from f potentially further qualified by args....\n\nThis functions returns nothing if f does not have the property element\n\n\n\n\n\nget_parameter(element::Symbol; default=nothing)\n\nAccess global Manopt parameters addressed by a symbol element. This first dispatches on the value of element.\n\nIf the value is not set, default is returned.\n\nThe parameters are queried from the global settings using Preferences.jl, so they are persistent within your activated Environment, see also set_parameter!.\n\nCurrently used settings\n\n:Mode the mode can be set to \"Tutorial\" to get several hints especially in scenarios, where the optimisation on manifolds is different from the usual â€œexperienceâ€ in (classical, Euclidean) optimization. Any other value has the same effect as not setting it.\n\n:KeywordsErrorMode specify how to handle the case when unknown keywords are passed to a solver. Since solvers often pass their keywords on to internal structures, to e.g. decorate the objective or the state, checking keywords has its own method in Manopt.jl. This parameter specifies how to handle the case where unknown keywords are handled.\n\n\"none\" does not report and the keyword gets just ignored\n\"warn\" issues a warning (default)\n\"error\" throw a ManoptKeywordError\n\nall other symbol values are treated the same as :none.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.status_summary","page":"Specify a Solver","title":"Manopt.status_summary","text":"status_summary(e)\n\nReturn a string reporting about the current status of e, where e is a type from Manopt.\n\nThis method is similar to show but just returns a string. It might also be more verbose in explaining, or hide internal information.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.is_tutorial_mode","page":"Specify a Solver","title":"Manopt.is_tutorial_mode","text":"is_tutorial_mode()\n\nA small internal helper to indicate whether tutorial mode is active.\n\nYou can set the mode by calling set_parameter!(:Mode, \"Tutorial\") or deactivate it by set_parameter!(:Mode, \"\").\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.ManifoldDefaultsFactory","page":"Specify a Solver","title":"Manopt.ManifoldDefaultsFactory","text":"ManifoldDefaultsFactory{M,T,A,K}\n\nA generic factory to postpone the instantiation of certain types from within Manopt.jl, in order to be able to adapt it to defaults from different manifolds and/or postpone the decision on which manifold to use to a later point\n\nFor now this is established for\n\nDirectionUpdateRules\nStepsize\nStoppingCriterion\n\nThis factory stores necessary and optional parameters as well as keyword arguments provided by the user to later produce the type this factory is for.\n\nBesides a manifold as a fallback, the factory can also be used for the (maybe simpler) types from the list of types that do not require the manifold.\n\nFields\n\nM::Union{Nothing,AbstractManifold}:  provide a manifold for defaults\nargs::A:                             arguments (args...) that are passed to the type constructor\nkwargs::K:                           keyword arguments (kwargs...) that are passed to the type constructor\nconstructor_requires_manifold::Bool: indicate whether the type constructor requires the manifold or not\n\nConstructor\n\nManifoldDefaultsFactory(T, args...; kwargs...)\nManifoldDefaultsFactory(T, M, args...; kwargs...)\n\nInput\n\nT a subtype of types listed above that this factory is to produce\nM (optional) a manifold used for the defaults in case no manifold is provided.\nargs... arguments to pass to the constructor of T\nkwargs... keyword arguments to pass (overwrite) when constructing T.\n\nKeyword arguments\n\nrequires_manifold=true: indicate whether the type constructor this factory wraps requires the manifold as first argument or not.\n\nAll other keyword arguments are internally stored to be used in the type constructor\n\nas well as arguments and keyword arguments for the update rule.\n\nsee also\n\n_produce_type\n\n\n\n\n\n","category":"type"},{"location":"plans/#Manopt._produce_type","page":"Specify a Solver","title":"Manopt._produce_type","text":"_produce_type(t::T, M::AbstractManifold)\n_produce_type(t::ManifoldDefaultsFactory{T}, M::AbstractManifold)\n_produce_type(t::ManifoldDefaultsFactory{T}, M::AbstractManifold, p)\n\nUse the ManifoldDefaultsFactory{T} to produce an instance of type T. This acts transparent in the way that if you provide an instance t::T already, this will just be returned.\n\nIf a point p on manifold M is provided, it is passed to the constructor t as a template for allocating points. It is no supposed to be modified by the constructor or stored in the produced object.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.Keywords","page":"Specify a Solver","title":"Manopt.Keywords","text":"Keywords\n\nA small internal struct to represent a set of keywords,\n\nFields\n\naccepted=Set{Symbol}() a Set of symbols of keywords a certain function accepts\ndeprecated=Set{Symbol}() a Set of symbols of keywords a certain function has deprecated\nfrom=nothing the function the keywords are (directly or indirectly) come from or accepted in. to indicate that these are not associated with a certain function, use nothing. to Indicate an empty set, use nothing.\norigins a dictionary that specifies for every keyword the function it is passed to. this usually should point to the function it is directly passed to.\n\nConstructor\n\nKeywords(\n    accepted=Set{Symbol}(), deprecated=Set{Symbol}();\n    from::Type=nothing)\n\nGenerate a Keywords wrapper, where both default to being the empty set. For pretty printing you can provide a type they belong to.\n\n\n\n\n\n","category":"type"},{"location":"plans/#Manopt.accepted_keywords","page":"Specify a Solver","title":"Manopt.accepted_keywords","text":"accepted_keywords(problem)\naccepted_keywords(objective)\naccepted_keywords(solver)\naccepted_keywords(stepsize)\n\nReturn a set of keywords, see Keywords, a certain element of Manopt.jl accepts when constructed.\n\nThis function uses direct_keywords to find keywords a function directly accepts, and calls_with_kwargs to find functions it passes keyword to, where they also might be accepted. In order for nonmutating functions f to work the same as their mutating variants f!, the allocating one, one should set calls_with_kwargs(f) = (f,).\n\nthis also includes keywords that are passed on to internal structures, also specified using calls_with_kwargs.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.ManoptKeywordError","page":"Specify a Solver","title":"Manopt.ManoptKeywordError","text":"ManoptKeywordError <: Exception\n\nAn error to indicate that a certain function received keywords it does not accept.\n\nFields\n\nf the function that received the keywords\nkw::Keywords the keywords that were not accepted\n\nConstructor\n\nManoptKeywordError(f, kw::Keywords)\n\n\n\n\n\n","category":"type"},{"location":"plans/#Manopt.add!","page":"Specify a Solver","title":"Manopt.add!","text":"add!(kw::Keywords, kw2::Keywords)\n\nAppend the Keywords kw2 to kw, i.e. union the accepted and deprecated keywords, as well as their origins, but keep first parameter of kw. Also their origin takes precedence.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.calls_with_kwargs","page":"Specify a Solver","title":"Manopt.calls_with_kwargs","text":"calls_with_kwargs(f)\n\nReturn a tuple of functions f calls and passes its kwargs... to.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.direct_keywords","page":"Specify a Solver","title":"Manopt.direct_keywords","text":"direct_keywords(problem)\ndirect_keywords(objective)\ndirect_keywords(solver)\ndirect_keywords(stepsize)\n\nReturn a set of keywords a function directly would work with.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.keywords_accepted","page":"Specify a Solver","title":"Manopt.keywords_accepted","text":"keywords_accepted(f, mode=:warn, kw::Keywords=accepted_keywords(f); kwargs...)\n\nGiven a function f, Keywords kw it accepts, check if kwargs... are accepted by those keywords and warn if deprecated keywords are passed\n\nFor keywords that are not accepted/processed here, the mode argument provides how to report the result, either :warn or :error on keywords that are not accepted.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/ConstrainedOptimization/#How-to-do-constrained-optimization","page":"Do constrained optimization","title":"How to do constrained optimization","text":"Ronny Bergmann\n\nThis tutorial is a short introduction to using solvers for constraint optimisation in Manopt.jl.","category":"section"},{"location":"tutorials/ConstrainedOptimization/#Introduction","page":"Do constrained optimization","title":"Introduction","text":"A constraint optimisation problem is given by\n\ntagP\nbeginalign*\noperatorname*argmin_pmathcal M  f(p)\ntextsuch that quad g(p) leq 0\nquad h(p) = 0\nendalign*\n\nwhere f  mathcal M  â„ is a cost function, and g  mathcal M  â„^m and h  mathcal M  â„^n are the inequality and equality constraints, respectively. The leq and = in (P) are meant element-wise.\n\nThis can be seen as a balance between moving constraints into the geometry of a manifold mathcal M and keeping some, since they can be handled well in algorithms, see [BH19], [LB19] for details.\n\nusing Distributions, LinearAlgebra, Manifolds, Manopt, Random\nRandom.seed!(42);\n\nIn this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrate the different available forms.\n\nWe consider the problem of a Nonnegative PCA, cf.Â Section 5.1.2 in [LB19]\n\nlet v_0  â„^d, lVert v_0 rVert=1 be given spike signal, that is a signal that is sparse with only s=lfloor Î´d rfloor nonzero entries.\n\nZ = sqrtÏƒ v_0v_0^mathrmT+N\n\nwhere sigma is a signal-to-noise ratio and N is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation 1d on the off-diagonals and 2d on the diagonal\n\nd = 150; # dimension of v0\nÏƒ = 0.1^2; # SNR\nÎ´ = 0.1; sp = Int(floor(Î´ * d)); # Sparsity\nS = sample(1:d, sp; replace=false);\nv0 =  [i âˆˆ S ? 1 / sqrt(sp) : 0.0 for i in 1:d];\nN = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);\nZ = Z = sqrt(Ïƒ) * v0 * transpose(v0) + N;\n\nIn order to recover v_0 we consider the constrained optimisation problem on the sphere mathcal S^d-1 given by\n\nbeginalign*\noperatorname*argmin_pmathcal S^d-1  -p^mathrmTZp^mathrmT\ntextsuch that quad p geq 0\nendalign*\n\nor in the previous notation f(p) = -p^mathrmTZp^mathrmT and g(p) = -p. We first initialize the manifold under consideration\n\nM = Sphere(d - 1)\n\nSphere(149)","category":"section"},{"location":"tutorials/ConstrainedOptimization/#A-first-augmented-Lagrangian-run","page":"Do constrained optimization","title":"A first augmented Lagrangian run","text":"We first defined f and g as usual functions\n\nf(M, p) = -transpose(p) * Z * p;\ng(M, p) = -p;\n\nsince f is a functions defined in the embedding â„^d as well, we obtain its gradient by projection.\n\ngrad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p);\n\nFor the constraints this is a little more involved, since each function g_i=g(p)_i=p_i has to return its own gradient. These are again in the embedding just operatornamegrad g_i(p) = -e_i the i th unit vector. We can project these again onto the tangent space at p:\n\ngrad_g(M, p) = project.(\n    Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]\n);\n\nWe further start in a random point:\n\np0 = rand(M);\n\nLetâ€™s verify a few things for the initial point\n\nf(M, p0)\n\n0.005667399180991248\n\nHow much the function g is positive\n\nmaximum(g(M, p0))\n\n0.17885478285466855\n\nNow as a first method we can just call the Augmented Lagrangian Method with a simple call:\n\n@time v1 = augmented_Lagrangian_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Î”p : %1.5e\"), 20, \"\\n\"],\n    stopping_criterion = StopAfterIteration(300) | (\n        StopWhenSmallerOrEqual(:Ïµ, 1e-5) & StopWhenChangeLess(M, 1e-8)\n    )\n);\n\nInitial f(x): 0.005667 | \n# 20    f(x): -0.123557 | Î”p : 1.00133e+00\n# 40    f(x): -0.123557 | Î”p : 3.77088e-08\n# 60    f(x): -0.123557 | Î”p : 6.22210e-06\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-5).\nAt iteration 69 the algorithm performed a step with a change (7.60659418778478e-11) less than 9.120108393559073e-6.\n  7.522308 seconds (21.46 M allocations: 1.723 GiB, 5.92% gc time, 97.03% compilation time)\n\nNow we have both a lower function value and the point is nearly within the constraints, namely up to numerical inaccuracies\n\nf(M, v1)\n\n-0.12351520332402412\n\nmaximum( g(M, v1) )\n\n2.4732815636354712e-12","category":"section"},{"location":"tutorials/ConstrainedOptimization/#A-faster-augmented-Lagrangian-run","page":"Do constrained optimization","title":"A faster augmented Lagrangian run","text":"Now this is a little slow, so we can modify two things:\n\nGradients should be evaluated in place, so for example\n\ngrad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p);\n\nThe constraints are currently always evaluated all together, since the function grad_g always returns a vector of gradients.  We first change the constraints function into a vector of functions.  We further change the gradient both into a vector of gradient functions operatornamegrad g_ii=1ldotsd, as well as gradients that are computed in place.\n\ng2 = [(M, p) -> -p[i] for i in 1:d];\ngrad_g2! = [\n    (M, X, p) -> project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d\n];\n\nWe obtain\n\n@time v2 = augmented_Lagrangian_method(\n        M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n        debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Î”p : %1.5e\"), 20, \"\\n\"],\n        stopping_criterion = StopAfterIteration(300) | (\n          StopWhenSmallerOrEqual(:Ïµ, 1e-5) & StopWhenChangeLess(M, 1e-8)\n        )\n    );\n\nInitial f(x): 0.005667 | \n# 20    f(x): -0.123557 | Î”p : 1.00133e+00\n# 40    f(x): -0.123557 | Î”p : 3.77088e-08\n# 60    f(x): -0.123557 | Î”p : 6.22210e-06\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-5).\nAt iteration 69 the algorithm performed a step with a change (7.60659418778478e-11) less than 9.120108393559073e-6.\n  2.510404 seconds (5.72 M allocations: 755.547 MiB, 2.54% gc time, 95.24% compilation time)\n\nAs a technical remark: note that (by default) the change to InplaceEvaluations affects both the constrained solver as well as the inner solver of the subproblem in each iteration.\n\nf(M, v2)\n\n-0.12351520332402412\n\nmaximum(g(M, v2))\n\n2.4732815636354712e-12\n\nThese are the very similar to the previous values but the solver took much less time and less memory allocations.","category":"section"},{"location":"tutorials/ConstrainedOptimization/#Exact-penalty-method","page":"Do constrained optimization","title":"Exact penalty method","text":"As a second solver, we have the Exact Penalty Method, which currently is available with two smoothing variants, which make an inner solver for smooth optimization, that is by default again [quasi Newton] possible: LogarithmicSumOfExponentials and LinearQuadraticHuber. We compare both here as well. The first smoothing technique is the default, so we can just call\n\n@time v3 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n);\n\nInitial f(x): 0.005667 | \n# 50    f(x): -0.122792 | Last Change: 0.982159\n# 100   f(x): -0.123555 | Last Change: 0.013515\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 102 the algorithm performed a step with a change (3.024488503740816e-7) less than 1.0e-6.\n  2.971997 seconds (15.69 M allocations: 5.830 GiB, 8.46% gc time, 68.66% compilation time)\n\nWe obtain a similar cost value as for the Augmented Lagrangian Solver from before, but here the constraint is actually fulfilled and not just numerically â€œon the boundaryâ€.\n\nf(M, v3)\n\n-0.12355544268449428\n\nmaximum(g(M, v3))\n\n-3.5897980609997717e-6\n\nThe second smoothing technique is often beneficial, when we have a lot of constraints (in the previously mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time.\n\n@time v4 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!,\n    evaluation=InplaceEvaluation(),\n    smoothing=LinearQuadraticHuber(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n);\n\nInitial f(x): 0.005667 | \n# 50    f(x): -0.123559 | Last Change: 0.008024\n# 100   f(x): -0.123557 | Last Change: 0.000026\nThe value of the variable (Ïµ) is smaller than or equal to its threshold (1.0e-6).\nAt iteration 101 the algorithm performed a step with a change (1.0069976601931904e-8) less than 1.0e-6.\n  2.805204 seconds (9.53 M allocations: 2.601 GiB, 16.86% gc time, 66.65% compilation time)\n\nFor the result we see the same behaviour as for the other smoothing.\n\nf(M, v4)\n\n-0.12355667846517183\n\nmaximum(g(M, v4))\n\n2.6974802260085845e-8","category":"section"},{"location":"tutorials/ConstrainedOptimization/#Comparing-to-the-unconstrained-solver","page":"Do constrained optimization","title":"Comparing to the unconstrained solver","text":"We can compare this to the global optimum on the sphere, which is the unconstrained optimisation problem, where we can just use Quasi Newton.\n\nNote that this is much faster, since every iteration of the algorithm does a quasi-Newton call as well.\n\n@time w1 = quasi_Newton(\n    M, f, grad_f!, p0; evaluation=InplaceEvaluation()\n);\n\n  1.074699 seconds (2.50 M allocations: 144.119 MiB, 1.49% gc time, 98.02% compilation time)\n\nf(M, w1)\n\n-0.13990874034056583\n\nBut for sure here the constraints here are not fulfilled and we have quite positive entries in g(w_1)\n\nmaximum(g(M, w1))\n\n0.1180320073974675","category":"section"},{"location":"tutorials/ConstrainedOptimization/#Technical-details","page":"Do constrained optimization","title":"Technical details","text":"This tutorial is cached. It was last run on the following package versions.\n\nStatus `~/work/Manopt.jl/Manopt.jl/tutorials/Project.toml`\n  [47edcb42] ADTypes v1.21.0\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [5ae59095] Colors v0.13.1\n  [31c24e10] Distributions v0.25.123\n  [26cc04aa] FiniteDifferences v0.12.33\n  [7073ff75] IJulia v1.34.2\n  [8ac3fa9e] LRUCache v1.6.2\n  [af67fdf4] ManifoldDiff v0.4.5\n  [1cead3c2] Manifolds v0.11.12\n  [3362f125] ManifoldsBase v2.3.0\n  [0fc0a36d] Manopt v0.5.32 `.`\n  [91a5bcdd] Plots v1.41.5\n  [731186ca] RecursiveArrayTools v3.47.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\nThis tutorial was last rendered February 11, 2026, 10:29:55.","category":"section"},{"location":"tutorials/ConstrainedOptimization/#Literature","page":"Do constrained optimization","title":"Literature","text":"R.Â Bergmann and R.Â Herzog. Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds. SIAMÂ JournalÂ onÂ Optimization 29, 2423â€“2444 (2019), arXiv:1804.06214.\n\n\n\nC.Â Liu and N.Â Boumal. Simple algorithms for optimization on Riemannian manifolds with constraints. AppliedÂ MathematicsÂ &Â Optimization (2019), arXiv:1091.10000.\n\n\n\n","category":"section"},{"location":"helpers/exports/#sec-exports","page":"Exports","title":"Exports","text":"Exports aim to provide a consistent generation of images of your results. For example if you record the trace your algorithm walks on the Sphere, you can easily export this trace to a rendered image using asymptote_export_S2_signals and render the result with Asymptote. Despite these, you can always record values during your iterations, and export these, for example to csv.","category":"section"},{"location":"helpers/exports/#Asymptote","page":"Exports","title":"Asymptote","text":"The following functions provide exports both in graphics and/or raw data using Asymptote.","category":"section"},{"location":"helpers/exports/#Manopt.asymptote_export_S2_data-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_S2_data","text":"asymptote_export_S2_data(filename)\n\nExport given data as an array of points on the 2-sphere, which might be one-, two- or three-dimensional data with points on the Sphere ð•Š^2.\n\nInput\n\nfilename                a file to store the Asymptote code in.\n\nOptional arguments for the data\n\ndata                    a point representing the 1D,2D, or 3D array of points\nelevation_color_scheme  A ColorScheme for elevation\nscale_axes=(1/3,1/3,1/3): move spheres closer to each other by a factor per direction\n\nOptional arguments for asymptote\n\narrow_head_size=1.8: size of the arrowheads of the vectors (in mm)\ncamera_position  position of the camera scene (default: atop the center of the data in the xy-plane)\ntarget           position the camera points at (default: center of xy-plane within data).\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.asymptote_export_S2_signals-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_S2_signals","text":"asymptote_export_S2_signals(filename; points, curves, tangent_vectors, colors, kwargs...)\n\nExport given points, curves, and tangent_vectors on the sphere ð•Š^2 to Asymptote.\n\nInput\n\nfilename          a file to store the Asymptote code in.\n\nKeywaord arguments for the data\n\ncolors=Dict{Symbol,Array{RGBA{Float64},1}}(): dictionary of color arrays, indexed by symbols :points, :curves and :tvector, where each entry has to provide as least as many colors as the length of the corresponding sets.\ncurves=Array{Array{Float64,1},1}(undef, 0): an Array of Arrays of points on the sphere, where each inner array is interpreted as a curve and is accompanied by an entry within colors.\npoints=Array{Array{Float64,1},1}(undef, 0): an Array of Arrays of points on the sphere where each inner array is interpreted as a set of points and is accompanied by an entry within colors.\ntangent_vectors=Array{Array{Tuple{Float64,Float64},1},1}(undef, 0): an Array of Arrays of tuples, where the first is a points, the second a tangent vector and each set of vectors is accompanied by an entry from within colors.\n\nKeyword arguments for asymptote\n\narrow_head_size=6.0: size of the arrowheads of the tangent vectors\narrow_head_sizes  overrides the previous value to specify a value per tVector` set.\ncamera_position=(1., 1., 0.): position of the camera in the Asymptote scene\nline_width=1.0: size of the lines used to draw the curves.\nline_widths       overrides the previous value to specify a value per curve and tVector` set.\ndot_size=1.0: size of the dots used to draw the points.\ndot_sizes         overrides the previous value to specify a value per point set.\nsize=nothing: a tuple for the image size, otherwise a relative size 4cm is used.\nsphere_color=RGBA{Float64}(0.85, 0.85, 0.85, 0.6): color of the sphere the data is drawn on\nsphere_line_color=RGBA{Float64}(0.75, 0.75, 0.75, 0.6): color of the lines on the sphere\nsphere_line_width=0.5: line width of the lines on the sphere\ntarget=(0.,0.,0.): position the camera points at\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.asymptote_export_SPD-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_SPD","text":"asymptote_export_SPD(filename)\n\nexport given data as a point on a Power(SymmetricPOsitiveDefinnite(3))} manifold of one-, two- or three-dimensional data with points on the manifold of symmetric positive definite matrices.\n\nInput\n\nfilename        a file to store the Asymptote code in.\n\nOptional arguments for the data\n\ndata            a point representing the 1D, 2D, or 3D array of SPD matrices\ncolor_scheme    a ColorScheme for Geometric Anisotropy Index\nscale_axes=(1/3,1/3,1/3): move symmetric positive definite matrices closer to each other by a factor per direction compared to the distance estimated by the maximal eigenvalue of all involved SPD points\n\nOptional arguments for asymptote\n\ncamera_position  position of the camera scene (default: atop the center of the data in the xy-plane)\ntarget           position the camera points at (default: center of xy-plane within data).\n\nBoth values camera_position and target are scaled by scaledAxes*EW, where EW is the maximal eigenvalue in the data.\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.render_asymptote-Tuple{Any}","page":"Exports","title":"Manopt.render_asymptote","text":"render_asymptote(filename; render=4, format=\"png\", ...)\n\nrender an exported asymptote file specified in the filename, which can also be given as a relative or full path\n\nInput\n\nfilename    filename of the exported asy and rendered image\n\nKeyword arguments\n\nthe default values are given in brackets\n\nrender=4: render level of asymptote passed to its -render option.  This can be removed from the command by setting it to nothing.\nformat=\"png\": final rendered format passed to the -f option\nexport_file: (the filename with format as ending) specify the export filename\n\n\n\n\n\n","category":"method"},{"location":"plans/problem/#sec-problem","page":"Problem","title":"A Manopt problem","text":"A problem describes all static data of an optimisation task and has as a super type\n\nUsually, such a problem is determined by the manifold or domain of the optimisation and the objective with all its properties used within an algorithm, see The Objective. For that one can just use\n\nFor the constraint optimisation, there are different possibilities to represent the gradients of the constraints. This can be done with a\n\nConstraintProblem\n\nThe primal dual-based solvers (Chambolle-Pock and the PD Semi-smooth Newton), both need two manifolds as their domains, hence there also exists a\n\nFrom the two ingredients here, you can find more information about\n\nthe ManifoldsBase.AbstractManifold in ManifoldsBase.jl\nthe AbstractManifoldObjective on the page about the objective.","category":"section"},{"location":"plans/problem/#Manopt.AbstractManoptProblem","page":"Problem","title":"Manopt.AbstractManoptProblem","text":"AbstractManoptProblem{M<:AbstractManifold}\n\nDescribe a Riemannian optimization problem with all static (not-changing) properties.\n\nThe most prominent features that should always be stated here are\n\nthe AbstractManifold mathcalMnifold)))\nthe cost function f  mathcalM)  â„\n\nUsually the cost should be within an AbstractManifoldObjective.\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/#Manopt.get_objective","page":"Problem","title":"Manopt.get_objective","text":"get_objective(o::AbstractManifoldObjective, recursive=true)\n\nreturn the (one step) undecorated AbstractManifoldObjective of the (possibly) decorated o. As long as your decorated objective stores the objective within o.objective and the dispatch_objective_decorator is set to Val{true}, the internal state are extracted automatically.\n\nBy default the objective that is stored within a decorated objective is assumed to be at o.objective. Overwrite _get_objective(o, ::Val{true}, recursive) to change this behaviour for your objectiveo` for both the recursive and the direct case.\n\nIf recursive is set to false, only the most outer decorator is taken away instead of all.\n\n\n\n\n\nget_objective(mp::AbstractManoptProblem, recursive=false)\n\nreturn the objective AbstractManifoldObjective stored within an AbstractManoptProblem. If recursive is set to true, it additionally unwraps all decorators of the objective\n\n\n\n\n\nget_objective(amso::AbstractManifoldSubObjective)\n\nReturn the (original) objective stored the sub objective is build on.\n\n\n\n\n\n","category":"function"},{"location":"plans/problem/#Manopt.get_manifold","page":"Problem","title":"Manopt.get_manifold","text":"get_manifold(amp::AbstractManoptProblem)\n\nreturn the manifold stored within an AbstractManoptProblem\n\n\n\n\n\n","category":"function"},{"location":"plans/problem/#Manopt.DefaultManoptProblem","page":"Problem","title":"Manopt.DefaultManoptProblem","text":"DefaultManoptProblem{TM <: AbstractManifold, Objective <: AbstractManifoldObjective}\n\nModel a default manifold problem, that (just) consists of the domain of optimisation, that is an AbstractManifold and an AbstractManifoldObjective\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/#Manopt.TwoManifoldProblem","page":"Problem","title":"Manopt.TwoManifoldProblem","text":"TwoManifoldProblem{\n    MT<:AbstractManifold,NT<:AbstractManifold,O<:AbstractManifoldObjective\n} <: AbstractManoptProblem{MT}\n\nAn abstract type for primal-dual-based problems.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Riemannian-quasi-Newton-methods","page":"Quasi-Newton","title":"Riemannian quasi-Newton methods","text":"","category":"section"},{"location":"solvers/quasi_Newton/#Background","page":"Quasi-Newton","title":"Background","text":"The aim is to minimize a real-valued function on a Riemannian manifold, that is\n\nmin f(p) quad p  mathcalM\n\nRiemannian quasi-Newtonian methods are as generalizations of their Euclidean counterparts Riemannian line search methods. These methods determine a search direction Î·_k  T_p_k mathcalM at the current iterate p_k and a suitable stepsize Î±_k along gamma(Î±) = R_p_k(Î± Î·_k), where R T mathcalM mathcalM is a retraction. The next iterate is obtained by\n\np_k+1 = R_p_k(Î±_k Î·_k)\n\nIn quasi-Newton methods, the search direction is given by\n\nÎ·_k = -mathcalH_k^-1operatornamegradf (p_k) = -mathcalB_k operatornamegrad (p_k)\n\nwhere mathcalH_k  T_p_k mathcalM T_p_k mathcalM is a positive definite self-adjoint operator, which approximates the action of the Hessian operatornameHess f (p_k) and mathcalB_k = mathcalH_k^-1. The idea of quasi-Newton methods is instead of creating a complete new approximation of the Hessian operator operatornameHess f(p_k+1) or its inverse at every iteration, the previous operator mathcalH_k or mathcalB_k is updated by a convenient formula using the obtained information about the curvature of the objective function during the iteration. The resulting operator mathcalH_k+1 or mathcalB_k+1 acts on the tangent space T_p_k+1 mathcalM of the freshly computed iterate p_k+1. In order to get a well-defined method, the following requirements are placed on the new operator mathcalH_k+1 or mathcalB_k+1 that is created by an update. Since the Hessian operatornameHess f(p_k+1) is a self-adjoint operator on the tangent space T_p_k+1 mathcalM, and mathcalH_k+1 approximates it, one requirement is, that mathcalH_k+1 or mathcalB_k+1 is also self-adjoint on T_p_k+1 mathcalM. In order to achieve a steady descent, the next requirement is that Î·_k is a descent direction in each iteration. Hence a further requirement is that mathcalH_k+1 or mathcalB_k+1 is a positive definite operator on T_p_k+1 mathcalM. In order to get information about the curvature of the objective function into the new operator mathcalH_k+1 or mathcalB_k+1, the last requirement is a form of a Riemannian quasi-Newton equation:\n\nmathcalH_k+1 T_p_k rightarrow p_k+1(R_p_k^-1(p_k+1)) = operatornamegrad(p_k+1) - T_p_k rightarrow p_k+1(operatornamegradf(p_k))\n\nor\n\nmathcalB_k+1 operatornamegradf(p_k+1) - T_p_k rightarrow p_k+1(operatornamegradf(p_k)) = T_p_k rightarrow p_k+1(R_p_k^-1(p_k+1))\n\nwhere T_p_k rightarrow p_k+1  T_p_k mathcalM T_p_k+1 mathcalM and the chosen retraction R is the associated retraction of T. Note that, of course, not all updates in all situations meet these conditions in every iteration. For specific quasi-Newton updates, the fulfilment of the Riemannian curvature condition, which requires that\n\ng_p_k+1(s_k y_k)  0\n\nholds, is a requirement for the inheritance of the self-adjointness and positive definiteness of the mathcalH_k or mathcalB_k to the operator mathcalH_k+1 or mathcalB_k+1. Unfortunately, the fulfilment of the Riemannian curvature condition is not given by a step size alpha_k  0 that satisfies the generalized Wolfe conditions. However, to create a positive definite operator mathcalH_k+1 or mathcalB_k+1 in each iteration, the so-called locking condition was introduced in [HGA15], which requires that the isometric vector transport T^S, which is used in the update formula, and its associate retraction R fulfil\n\nT^Sp Î¾_p(Î¾_p) = Î² T^Rp Î¾_p(Î¾_p) quad Î² = fraclVert Î¾_p rVert_plVert T^Rp Î¾_p(Î¾_p) rVert_R_p(Î¾_p)\n\nwhere T^R is the vector transport by differentiated retraction. With the requirement that the isometric vector transport T^S and its associated retraction R satisfies the locking condition and using the tangent vector\n\ny_k = Î²_k^-1 operatornamegradf(p_k+1) - T^Sp_k Î±_k Î·_k(operatornamegradf(p_k))\n\nwhere\n\nÎ²_k = fraclVert Î±_k Î·_k rVert_p_klVert T^Rp_k Î±_k Î·_k(Î±_k Î·_k) rVert_p_k+1\n\nin the update, it can be shown that choosing a stepsize Î±_k  0 that satisfies the Riemannian Wolfe conditions leads to the fulfilment of the Riemannian curvature condition, which in turn implies that the operator generated by the updates is positive definite. In the following the specific operators are denoted in matrix notation and hence use H_k and B_k, respectively.","category":"section"},{"location":"solvers/quasi_Newton/#Direction-updates","page":"Quasi-Newton","title":"Direction updates","text":"In general there are different ways to compute a fixed AbstractQuasiNewtonUpdateRule. In general these are represented by","category":"section"},{"location":"solvers/quasi_Newton/#Hessian-update-rules","page":"Quasi-Newton","title":"Hessian update rules","text":"Using\n\nthe following update formulae for either H_k+1 or B_k+1 are available.","category":"section"},{"location":"solvers/quasi_Newton/#State","page":"Quasi-Newton","title":"State","text":"The quasi Newton algorithm is based on a DefaultManoptProblem.","category":"section"},{"location":"solvers/quasi_Newton/#sec-qn-technical-details","page":"Quasi-Newton","title":"Technical details","text":"The quasi_Newton solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nA vector_transport_to!M, Y, p, X, q); it is recommended to set the default_vector_transport_method to a favourite retraction. If this default is set, a vector_transport_method= or vector_transport_method_dual= (for mathcal N) does not have to be specified.\nBy default quasi Newton uses ArmijoLinesearch which requires max_stepsize(M) to be set and an implementation of inner(M, p, X).\nthe norm as well, to stop when the norm of the gradient is small, but if you implemented inner, the norm is provided already.\nA copyto!(M, q, p) and copy(M,p) for points and similarly copy(M, p, X) for tangent vectors.\nBy default the tangent vector storing the gradient is initialized calling zero_vector(M,p).\n\nMost Hessian approximations further require get_coordinates(M, p, X, b) with respect to the AbstractBasis b provided, which is DefaultOrthonormalBasis by default from the basis= keyword.","category":"section"},{"location":"solvers/quasi_Newton/#Literature","page":"Quasi-Newton","title":"Literature","text":"W.Â Huang, P.-A.Â Absil and K.Â A.Â Gallivan. A Riemannian BFGS method without differentiated retraction for nonconvex optimization problems. SIAMÂ JournalÂ onÂ Optimization 28, 470â€“495 (2018).\n\n\n\nW.Â Huang, K.Â A.Â Gallivan and P.-A.Â Absil. A Broyden class of quasi-Newton methods for Riemannian optimization. SIAMÂ JournalÂ onÂ Optimization 25, 1660â€“1685 (2015).\n\n\n\nJ.Â Nocedal and S.Â J.Â Wright. Numerical Optimization. 2Â Edition (Springer, New York, 2006).\n\n\n\n","category":"section"},{"location":"solvers/quasi_Newton/#Manopt.quasi_Newton","page":"Quasi-Newton","title":"Manopt.quasi_Newton","text":"quasi_Newton(M, f, grad_f, p; kwargs...)\nquasi_Newton!(M, f, grad_f, p; kwargs...)\n\nPerform a quasi Newton iteration to solve\n\noperatorname*argmin_p  mathcalM f(p)\n\nwith start point p. The iterations can be done in-place of p=p^(0). The kth iteration consists of\n\nCompute the search direction Î·^(k) = -mathcalB_k operatornamegradf (p^(k)) or solve mathcalH_k Î·^(k) = -operatornamegradf (p^(k)).\nDetermine a suitable stepsize Î±_k along the curve Î³(Î±) = R_p^(k)(Î± Î·^(k)), usually by using WolfePowellLinesearch.\nCompute p^(k+1) = R_p^(k)(Î±_k Î·^(k)).\nDefine s_k = mathcalT_p^(k) Î±_k Î·^(k)(Î±_k Î·^(k)) and y_k = operatornamegradf(p^(k+1)) - mathcalT_p^(k) Î±_k Î·^(k)(operatornamegradf(p^(k))), where mathcalT denotes a vector transport.\nCompute the new approximate Hessian H_k+1 or its inverse B_k+1.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nbasis=DefaultOrthonormalBasis(): basis to use within each of the the tangent spaces to represent the Hessian (inverse) for the cases where it is stored in full (matrix) form.\ncautious_update=false:  whether or not to use the QuasiNewtonCautiousDirectionUpdate  which wraps the direction_update.\ncautious_function=(x) -> x * 1e-4: a monotone increasing function for the cautious update that is zero at x=0 and strictly increasing at 0\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\ndirection_update=InverseBFGS(): the AbstractQuasiNewtonUpdateRule to use.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second. For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\ninitial_operator= initial_scale*Matrix{Float64}(I, n, n):  initial matrix to use in case the Hessian (inverse) approximation is stored as a full matrix,  that is n=manifold_dimension(M). This matrix is only allocated for the full matrix case.  See also initial_scale.\ninitial_scale=1.0: scale initial s to use in with fracss_ky_k_p_klVert y_krVert_p_k in the computation of the limited memory approach. see also initial_operator\nmemory_size=20: limited memory, number of s_k y_k to store.  Set to a negative value to use a full memory (matrix) representation\nnondescent_direction_behavior=:reinitialize_direction_update: specify how non-descent direction is handled. This can be\n:step_towards_negative_gradient: the direction is replaced with negative gradient, a message is stored.\n:ignore: the verification is not performed, so any computed direction is accepted. No message is stored.\n:reinitialize_direction_update: discards operator state stored in direction update rules.\nany other value performs the verification, keeps the direction but stores a message.\nA stored message can be displayed using DebugMessages.\npreconditioner=nothing specify a preconditioner, either\nthe default nothing does not activate a preconditioning\na function of the form (M, p, X) -> Y or mutating (M, Y, p, X) -> Y depending on the evaluation\na PreconditionedDirection. See also their docs for more details on the preconditioner.\nNote that the preconditioner is applied to the gradient, i.e. the right hand side before solving the linear system.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=WolfePowellLinesearch(retraction_method, vector_transport_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(max(1000, memory_size))|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Manopt.quasi_Newton!","page":"Quasi-Newton","title":"Manopt.quasi_Newton!","text":"quasi_Newton(M, f, grad_f, p; kwargs...)\nquasi_Newton!(M, f, grad_f, p; kwargs...)\n\nPerform a quasi Newton iteration to solve\n\noperatorname*argmin_p  mathcalM f(p)\n\nwith start point p. The iterations can be done in-place of p=p^(0). The kth iteration consists of\n\nCompute the search direction Î·^(k) = -mathcalB_k operatornamegradf (p^(k)) or solve mathcalH_k Î·^(k) = -operatornamegradf (p^(k)).\nDetermine a suitable stepsize Î±_k along the curve Î³(Î±) = R_p^(k)(Î± Î·^(k)), usually by using WolfePowellLinesearch.\nCompute p^(k+1) = R_p^(k)(Î±_k Î·^(k)).\nDefine s_k = mathcalT_p^(k) Î±_k Î·^(k)(Î±_k Î·^(k)) and y_k = operatornamegradf(p^(k+1)) - mathcalT_p^(k) Î±_k Î·^(k)(operatornamegradf(p^(k))), where mathcalT denotes a vector transport.\nCompute the new approximate Hessian H_k+1 or its inverse B_k+1.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\ngrad_f: the (Riemannian) gradient operatornamegradf mathcalM  T_pmathcalM of f as a function (M, p) -> X or a function (M, X, p) -> X computing X in-place\np::P: a point on the manifold mathcalM\n\nKeyword arguments\n\nbasis=DefaultOrthonormalBasis(): basis to use within each of the the tangent spaces to represent the Hessian (inverse) for the cases where it is stored in full (matrix) form.\ncautious_update=false:  whether or not to use the QuasiNewtonCautiousDirectionUpdate  which wraps the direction_update.\ncautious_function=(x) -> x * 1e-4: a monotone increasing function for the cautious update that is zero at x=0 and strictly increasing at 0\ndifferential = nothing: specify a specific function to evaluate the differential. By default, Df(p)X = operatornamegradf(p)X. is used\ndirection_update=InverseBFGS(): the AbstractQuasiNewtonUpdateRule to use.\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second. For example grad_f(M,p) allocates, but grad_f!(M, X, p) computes the result in-place of X.\ninitial_operator= initial_scale*Matrix{Float64}(I, n, n):  initial matrix to use in case the Hessian (inverse) approximation is stored as a full matrix,  that is n=manifold_dimension(M). This matrix is only allocated for the full matrix case.  See also initial_scale.\ninitial_scale=1.0: scale initial s to use in with fracss_ky_k_p_klVert y_krVert_p_k in the computation of the limited memory approach. see also initial_operator\nmemory_size=20: limited memory, number of s_k y_k to store.  Set to a negative value to use a full memory (matrix) representation\nnondescent_direction_behavior=:reinitialize_direction_update: specify how non-descent direction is handled. This can be\n:step_towards_negative_gradient: the direction is replaced with negative gradient, a message is stored.\n:ignore: the verification is not performed, so any computed direction is accepted. No message is stored.\n:reinitialize_direction_update: discards operator state stored in direction update rules.\nany other value performs the verification, keeps the direction but stores a message.\nA stored message can be displayed using DebugMessages.\npreconditioner=nothing specify a preconditioner, either\nthe default nothing does not activate a preconditioning\na function of the form (M, p, X) -> Y or mutating (M, Y, p, X) -> Y depending on the evaluation\na PreconditionedDirection. See also their docs for more details on the preconditioner.\nNote that the preconditioner is applied to the gradient, i.e. the right hand side before solving the linear system.\nproject!=copyto!: for numerical stability it is possible to project onto the tangent space after every iteration. the function has to work inplace of Y, that is (M, Y, p, X) -> Y, where X and Y can be the same memory.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=WolfePowellLinesearch(retraction_method, vector_transport_method): a functor inheriting from Stepsize to determine a step size\nstopping_criterion::StoppingCriterion=StopAfterIteration(max(1000, memory_size))|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonDirectionUpdate","page":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonDirectionUpdate","text":"AbstractQuasiNewtonDirectionUpdate\n\nAn abstract representation of an Quasi Newton Update rule to determine the next direction given current QuasiNewtonState.\n\nAll subtypes should be functors, they should be callable as H(M,x,d) to compute a new direction update.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonMatrixDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonMatrixDirectionUpdate","text":"QuasiNewtonMatrixDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThe QuasiNewtonMatrixDirectionUpdate represent a quasi-Newton update rule, where the operator is stored as a matrix. A distinction is made between the update of the approximation of the Hessian, H_k  H_k+1, and the update of the approximation of the Hessian inverse, B_k  B_k+1. For the first case, the coordinates of the search direction Î·_k with respect to a basis b_i_i=1^n are determined by solving a linear system of equations\n\ntextSolvequadhatÎ·_k = - H_k widehatoperatornamegradf(p_k)\n\nwhere H_k is the matrix representing the operator with respect to the basis b_i_i=1^n and widehatoperatornamegrad f(p_k) represents the coordinates of the gradient of the objective function f in p_k with respect to the basis b_i_i=1^n. If a method is chosen where Hessian inverse is approximated, the coordinates of the search direction Î·_k with respect to a basis b_i_i=1^n are obtained simply by matrix-vector multiplication\n\nhatÎ·_k = - B_k widehatoperatornamegradf(p_k)\n\nwhere B_k is the matrix representing the operator with respect to the basis b_i_i=1^n and widehatoperatornamegrad f(p_k). In the end, the search direction Î·_k is generated from the coordinates hatÎ·_k and the vectors of the basis b_i_i=1^n in both variants. The AbstractQuasiNewtonUpdateRule indicates which quasi-Newton update rule is used. In all of them, the Euclidean update formula is used to generate the matrix H_k+1 and B_k+1, and the basis b_i_i=1^n is transported into the upcoming tangent space T_p_k+1 mathcalM, preferably with an isometric vector transport, or generated there.\n\nProvided functors\n\n(mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction\n(Î·, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction in-place of Î·\n\nFields\n\nbasis:                  an AbstractBasis to use in the tangent spaces\nmatrix:                 the matrix which represents the approximating operator.\ninitial_scale:          when initialising the update, a unit matrix is used as initial approximation, scaled by this factor\nupdate:                 a AbstractQuasiNewtonUpdateRule.\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\n\nConstructor\n\nQuasiNewtonMatrixDirectionUpdate(\n    M::AbstractManifold,\n    update,\n    basis::B=default_basis(M),\n    m=Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M));\n    kwargs...\n)\n\nKeyword arguments\n\ninitial_scale=1.0 â€“ this can also be deactivated by passing nothing.\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\n\nGenerate the Update rule with defaults from a manifold and the names corresponding to the fields.\n\nSee also\n\nQuasiNewtonLimitedMemoryDirectionUpdate, QuasiNewtonCautiousDirectionUpdate, AbstractQuasiNewtonDirectionUpdate,\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","text":"QuasiNewtonLimitedMemoryDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThis AbstractQuasiNewtonDirectionUpdate represents the limited-memory Riemannian BFGS update, where the approximating operator is represented by m stored pairs of tangent vectors widetildes_i_i=k-m^k-1 and widetildey_i_i=k-m^k-1 in the k-th iteration. For the calculation of the search direction X_k, the generalisation of the two-loop recursion is used (see [HGA15]), since it only requires inner products and linear combinations of tangent vectors in T_p_kmathcalM. For that the stored pairs of tangent vectors s_i y_i, the gradient operatornamegrad f(p_k) of the objective function f in p_k and the positive definite self-adjoint operator\n\nmathcalB_k^(0)\n= fracs_k-1y_k-1_p_ky_k-1y_k-1_p_kmathrmId_T_pmathcalM\n\nare used. The two-loop recursion can be understood as that the InverseBFGS update is executed m times in a row on mathcalB^(0)_k using the tangent vectors widehats_iwidehaty_i, and in the same time the resulting operator mathcalB^mathrmLRBFGS_k  is directly applied on operatornamegradf(p_k). When updating there are two cases: if there is still free memory, k  m, the previously stored vector pairs widehats_iwidehaty_i have to be transported into the upcoming tangent space T_p_k+1mathcalM. If there is no free memory, the oldest pair widehats_iwidehaty_i has to be discarded and then all the remaining vector pairs widehats_iwidehaty_i are transported into the tangent space T_p_k+1mathcalM. After that the new values s_k = widehats_k = T^S_p_k Î±_k Î·_k(Î±_k Î·_k) and y_k = widehaty_k are stored at the beginning. This process ensures that new information about the objective function is always included and the old, probably no longer relevant, information is discarded.\n\nProvided functors\n\n(mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction\n(Î·, mp::AbstractManoptproblem, st::QuasiNewtonState) -> Î· to compute the update direction in-place of Î·\n\nFields\n\nmemory_s:                the set of the stored (and transported) search directions times step size widehats_i_i=k-m^k-1.\nmemory_y:                set of the stored gradient differences widehaty_i_i=k-m^k-1.\nÎ¾:                       a variable used in the two-loop recursion.\nÏL                       a variable used in the two-loop recursion.\ninitial_scale:           initial scaling of the Hessian, deactivate (e.g. when using a preconditioner) by passing nothing\nvector_transport_method::AbstractVectorTransportMethod: a vector transport mathcal T_ to use, see the section on vector transports\nmessage:                 a string containing a potential warning that might have appeared\nproject!:                a function to stabilize the update by projecting on the tangent space\n\nConstructor\n\nQuasiNewtonLimitedMemoryDirectionUpdate(\n    M::AbstractManifold,\n    x,\n    update::AbstractQuasiNewtonUpdateRule,\n    memory_size::Int;\n    initial_vector=zero_vector(M,x),\n    initial_scale::Real=1.0\n    project!=copyto!\n)\n\nSee also\n\nInverseBFGS QuasiNewtonCautiousDirectionUpdate AbstractQuasiNewtonDirectionUpdate\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonCautiousDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonCautiousDirectionUpdate","text":"QuasiNewtonCautiousDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThese AbstractQuasiNewtonDirectionUpdates represent any quasi-Newton update rule, which are based on the idea of a so-called cautious update. The search direction is calculated as given in QuasiNewtonMatrixDirectionUpdate or QuasiNewtonLimitedMemoryDirectionUpdate, butut the update  then is only executed if\n\nfracg_x_k+1(y_ks_k)lVert s_k rVert_x_k+1^2  Î¸ lVert operatornamegradf(p_k) rVert_p_k\n\nis satisfied, where Î¸ is a monotone increasing function satisfying Î¸(0) = 0 and Î¸ is strictly increasing at 0. If this is not the case, the corresponding update is skipped, which means that for QuasiNewtonMatrixDirectionUpdate the matrix H_k or B_k is not updated. The basis b_i_i=1^n is nevertheless transported into the upcoming tangent space T_x_k+1 mathcalM), and for QuasiNewtonLimitedMemoryDirectionUpdate neither the oldest vector pair widetildes_km, widetildey_km is discarded nor the newest vector pair widetildes_k widetildey_k is added into storage, but all stored vector pairs setwidetildes_i widetildey_i_i=k-m^k-1 are transported into the tangent space T_x_k+1 mathcalM). If InverseBFGS or InverseBFGS is chosen as update, then the resulting method follows the method of [HAG18], taking into account that the corresponding step size is chosen.\n\nProvided functors\n\n(mp::AbstractManoptProblem, st::QuasiNewtonState) -> Î· to compute the update direction\n(Î·, mp::AbstractManoptProblem, st::QuasiNewtonState) -> Î· to compute the update direction in-place of Î·\n\nFields\n\nupdate: an AbstractQuasiNewtonDirectionUpdate\nÎ¸:      a monotone increasing function satisfying Î¸(0) = 0 and Î¸ is strictly increasing at 0.\n\nConstructor\n\nQuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonMatrixDirectionUpdate; Î¸ = identity)\nQuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonLimitedMemoryDirectionUpdate; Î¸ = identity)\n\nGenerate a cautious update for either a matrix based or a limited memory based update rule.\n\nSee also\n\nQuasiNewtonMatrixDirectionUpdate QuasiNewtonLimitedMemoryDirectionUpdate\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.initialize_update!","page":"Quasi-Newton","title":"Manopt.initialize_update!","text":"initialize_update!(s::AbstractQuasiNewtonDirectionUpdate)\n\nInitialize direction update. By default no change is made.\n\n\n\n\n\ninitialize_update!(d::QuasiNewtonLimitedMemoryDirectionUpdate)\n\nInitialize the limited memory direction update by emptying the memory buffers.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonPreconditioner","page":"Quasi-Newton","title":"Manopt.QuasiNewtonPreconditioner","text":"QuasiNewtonPreconditioner{E<:AbstractEvaluationType, F}\n\nAdd a preconditioning\n\nFields\n\npreconditioner::F: the preconditioner function\n\nConstructors\n\nQuasiNewtonPreconditioner(\n    preconditioner;\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n)\n\nAdd preconditioning to a gradient problem.\n\nInput\n\npreconditioner:   preconditioner function, either as a (M, p, X) -> Y allocating or (M, Y, p, X) -> Y mutating function\n\nKeyword arguments\n\nevaluation::AbstractEvaluationType=AllocatingEvaluation(): specify whether the functions that return an array, for example a point or a tangent vector, work by allocating its result (AllocatingEvaluation) or whether they modify their input argument to return the result therein (InplaceEvaluation). Since usually the first argument is the manifold, the modified argument is the second.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.update_hessian!","page":"Quasi-Newton","title":"Manopt.update_hessian!","text":"update_hessian!(d::AbstractQuasiNewtonDirectionUpdate, amp, st, p_old, k)\n\nupdate the Hessian within the QuasiNewtonState st given a AbstractManoptProblem amp as well as the an AbstractQuasiNewtonDirectionUpdate d and the last iterate p_old. Note that the current (kth) iterate is already stored in get_iterate(st).\n\nSee also AbstractQuasiNewtonUpdateRule and its subtypes for the different rules that are available within d.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonUpdateRule","page":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonUpdateRule","text":"AbstractQuasiNewtonUpdateRule\n\nSpecify a type for the different AbstractQuasiNewtonDirectionUpdates, that is for a QuasiNewtonMatrixDirectionUpdate there are several different updates to the matrix, while the default for QuasiNewtonLimitedMemoryDirectionUpdate the most prominent is InverseBFGS.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.BFGS","page":"Quasi-Newton","title":"Manopt.BFGS","text":"BFGS <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian BFGS update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeH_k^mathrmBFGS the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmBFGS_k+1 = widetildeH^mathrmBFGS_k  + fracy_k y^mathrmT_k s^mathrmT_k y_k - fracwidetildeH^mathrmBFGS_k s_k s^mathrmT_k widetildeH^mathrmBFGS_k  s^mathrmT_k widetildeH^mathrmBFGS_k s_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtext and quad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalMnifold))nifold))nifold)))\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.DFP","page":"Quasi-Newton","title":"Manopt.DFP","text":"DFP <: AbstractQuasiNewtonUpdateRule\n\nindicates in an AbstractQuasiNewtonDirectionUpdate that the Riemannian DFP update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeH_k^mathrmDFP the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmDFP_k+1 = Bigl(\n  mathrmId_T_x_k+1 mathcalM) - fracy_k s^mathrmT_ks^mathrmT_k y_k\nBigr)\nwidetildeH^mathrmDFP_k\nBigl(\n  mathrmId_T_x_k+1 mathcalM) - fracs_k y^mathrmT_ks^mathrmT_k y_k\nBigr) + fracy_k y^mathrmT_ks^mathrmT_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalM)\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.Broyden","page":"Quasi-Newton","title":"Manopt.Broyden","text":"Broyden <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of BFGS and DFP.\n\nDenote by widetildeH_k^mathrmBr the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmBr_k+1\n=   widetildeH^mathrmBr_k - fracwidetildeH^mathrmBr_k s_k s^mathrmT_k widetildeH^mathrmBr_ks^mathrmT_k widetildeH^mathrmBr_k s_k + fracy_k y^mathrmT_ks^mathrmT_k y_k\n    + Ï†_k s^mathrmT_k widetildeH^mathrmBr_k s_k\n    Bigl(\n        fracy_ks^mathrmT_k y_k - fracwidetildeH^mathrmBr_k s_ks^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigr)\n  Bigl(\n        fracy_ks^mathrmT_k y_k - fracwidetildeH^mathrmBr_k s_ks^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigr)^mathrmT\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalM)\n\nrespectively, and Ï†_k is the Broyden factor which is :constant by default but can also be set to :Davidon.\n\nConstructor\n\nBroyden(Ï†, update_rule::Symbol = :constant)\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.SR1","page":"Quasi-Newton","title":"Manopt.SR1","text":"SR1 <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian SR1 update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeH_k^mathrmSR1 the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nH^mathrmSR1_k+1 = widetildeH^mathrmSR1_k\n+ frac(y_k - widetildeH^mathrmSR1_k s_k) (y_k - widetildeH^mathrmSR1_k s_k)^mathrmT(y_k - widetildeH^mathrmSR1_k s_k)^mathrmT s_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalM)\n\nrespectively.\n\nThis method can be stabilized by only performing the update if denominator is larger than rlVert s_k rVert_x_k+1lVert y_k - widetildeH^mathrmSR1_k s_k rVert_x_k+1 for some r0. For more details, see Section 6.2 in [NW06].\n\nConstructor\n\nSR1(r::Float64=-1.0)\n\nGenerate the SR1 update.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseBFGS","page":"Quasi-Newton","title":"Manopt.InverseBFGS","text":"InverseBFGS <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemannian BFGS update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeB_k^mathrmBFGS the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmBFGS_k+1  = Bigl(\n  mathrmId_T_x_k+1 mathcalMnifold))) - fracs_k y^mathrmT_k s^mathrmT_k y_k\nBigr)\nwidetildeB^mathrmBFGS_k\nBigl(\n  mathrmId_T_x_k+1 mathcalM) - fracy_k s^mathrmT_k s^mathrmT_k y_k\nBigr) + fracs_k s^mathrmT_ks^mathrmT_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalM)\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseDFP","page":"Quasi-Newton","title":"Manopt.InverseDFP","text":"InverseDFP <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemannian DFP update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeB_k^mathrmDFP the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmDFP_k+1 = widetildeB^mathrmDFP_k + fracs_k s^mathrmT_ks^mathrmT_k y_k\n  - fracwidetildeB^mathrmDFP_k y_k y^mathrmT_k widetildeB^mathrmDFP_ky^mathrmT_k widetildeB^mathrmDFP_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalM)\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseBroyden","page":"Quasi-Newton","title":"Manopt.InverseBroyden","text":"InverseBroyden <: AbstractQuasiNewtonUpdateRule\n\nIndicates in AbstractQuasiNewtonDirectionUpdate that the Riemannian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of InverseBFGS and InverseDFP.\n\nDenote by widetildeH_k^mathrmBr the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmBr_k+1\n= widetildeB^mathrmBr_k\n   - fracwidetildeB^mathrmBr_k y_k y^mathrmT_k widetildeB^mathrmBr_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n    + fracs_k s^mathrmT_ks^mathrmT_k y_k\n    + Ï†_k y^mathrmT_k widetildeB^mathrmBr_k y_k\n    Bigl(\n        fracs_ks^mathrmT_k y_k\n        - fracwidetildeB^mathrmBr_k y_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n    Bigr)\n    Bigl(\n        fracs_ks^mathrmT_k y_k\n        - fracwidetildeB^mathrmBr_k y_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n     Bigr)^mathrmT\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalM)\n\nrespectively, and Ï†_k is the Broyden factor which is :constant by default but can also be set to :Davidon.\n\nConstructor\n\nInverseBroyden(Ï†, update_rule::Symbol = :constant)\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseSR1","page":"Quasi-Newton","title":"Manopt.InverseSR1","text":"InverseSR1 <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemannian SR1 update is used in the Riemannian quasi-Newton method.\n\nDenote by widetildeB_k^mathrmSR1 the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_p_k(Î±_k Î·_k). Then the update formula reads\n\nB^mathrmSR1_k+1 = widetildeB^mathrmSR1_k\n+ frac(s_k - widetildeB^mathrmSR1_k y_k) (s_k - widetildeB^mathrmSR1_k y_k)^mathrmT(s_k - widetildeB^mathrmSR1_k y_k)^mathrmT y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_p_k Î±_k Î·_k(Î±_k Î·_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_p_k Î±_k Î·_k(operatornamegradf(p_k))  T_x_k+1 mathcalM)\n\nrespectively.\n\nThis method can be stabilized by only performing the update if denominator is larger than rlVert y_k rVert_x_k+1lVert s_k - widetildeH^mathrmSR1_k y_k rVert_x_k+1 for some r0. For more details, see Section 6.2 in [NW06].\n\nConstructor\n\nInverseSR1(r::Float64=-1.0)\n\nGenerate the InverseSR1.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonState","page":"Quasi-Newton","title":"Manopt.QuasiNewtonState","text":"QuasiNewtonState <: AbstractManoptSolverState\n\nThe AbstractManoptSolverState represent any quasi-Newton based method and stores all necessary fields.\n\nFields\n\ndirection_update:              an AbstractQuasiNewtonDirectionUpdate rule.\nÎ·:                             the current update direction\nnondescent_direction_behavior: a Symbol to specify how to handle direction that are not descent ones.\nnondescent_direction_value:    the value from the last inner product from checking for descent directions\np::P: a point on the manifold mathcalM  storing the current iterate\np_old:                         the last iterate\npreconditioner                 an QuasiNewtonPreconditioner\nsk:                            the current step\nyk:                            the current gradient difference\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nstop::StoppingCriterion: a functor indicating that the stopping criterion is fulfilled\nX::T: a tangent vector at the point p on the manifold mathcalM storing the gradient at the current iterate\nX_old:                         the last gradient\n\nConstructor\n\nQuasiNewtonState(M::AbstractManifold, p; kwargs...)\n\nGenerate the Quasi Newton state on the manifold M with start point p.\n\nKeyword arguments\n\ndirection_update=QuasiNewtonLimitedMemoryDirectionUpdate(M, p, InverseBFGS(), memory_size; vector_transport_method=vector_transport_method)\nstopping_criterion::StoppingCriterion=StopAfterIteration(1000)|StopWhenGradientNormLess(1e-6): a functor indicating that the stopping criterion is fulfilled\ninitial_scale=1.0: a relative initial scale. By default deactivated when using a preconditioner.\nmemory_size=20: a shortcut to set the memory in the default direction update\npreconditioner::Union{QuasiNewtonPreconditioner, Nothing} = nothing specify a preconditioner or deactivate by passing nothing.\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\nstepsize::Stepsize=default_stepsize(M,QuasiNewtonState): a functor inheriting from Stepsize to determine a step size\nvector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M, typeof(p)): a vector transport mathcal T_ to use, see the section on vector transports\nX::T =zero_vector(M, p): a tangent vector at the point p on the manifold mathcalM to specify the representation of a tangent vector\n\nSee also\n\nquasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#sec-nelder-meadSolver","page":"Nelderâ€“Mead","title":"Nelder Mead method","text":"","category":"section"},{"location":"solvers/NelderMead/#State","page":"Nelderâ€“Mead","title":"State","text":"","category":"section"},{"location":"solvers/NelderMead/#Simplex","page":"Nelderâ€“Mead","title":"Simplex","text":"","category":"section"},{"location":"solvers/NelderMead/#Additional-stopping-criteria","page":"Nelderâ€“Mead","title":"Additional stopping criteria","text":"","category":"section"},{"location":"solvers/NelderMead/#Technical-details","page":"Nelderâ€“Mead","title":"Technical details","text":"The NelderMead solver requires the following functions of a manifold to be available\n\nA retract!(M, q, p, X); it is recommended to set the default_retraction_method to a favourite retraction. If this default is set, a retraction_method= does not have to be specified.\nAn inverse_retract!(M, X, p, q); it is recommended to set the default_inverse_retraction_method to a favourite retraction. If this default is set, a inverse_retraction_method= does not have to be specified.\nThe distance(M, p, q) when using the default stopping criterion, which includes StopWhenPopulationConcentrated.\nWithin the default initialization rand(M) is used to generate the initial population\nA mean(M, population) has to be available, for example by loading Manifolds.jl and its statistics tools","category":"section"},{"location":"solvers/NelderMead/#Manopt.NelderMead","page":"Nelderâ€“Mead","title":"Manopt.NelderMead","text":"NelderMead(M::AbstractManifold, f, population=NelderMeadSimplex(M))\nNelderMead(M::AbstractManifold, mco::AbstractManifoldCostObjective, population=NelderMeadSimplex(M))\nNelderMead!(M::AbstractManifold, f, population)\nNelderMead!(M::AbstractManifold, mco::AbstractManifoldCostObjective, population)\n\nSolve a Nelder-Mead minimization problem for the cost function f mathcalM  â„ on the manifold M. If the initial NelderMeadSimplex is not provided, a random set of points is chosen. The computation can be performed in-place of the population.\n\nThe algorithm consists of the following steps. Let d denote the dimension of the manifold mathcalM.\n\nOrder the simplex vertices p_i i=1d+1 by increasing cost, such that we have f(p_1)  f(p_2)    f(p_d+1).\nCompute the Riemannian center of mass [Kar77], cf. mean, p_textm  of the simplex vertices p_1p_d+1.\nReflect the point with the worst point at the mean p_textr = operatornameretr_p_textmbigl( - Î±operatornameretr^-1_p_textm (p_d+1) bigr)  If f(p_1)  f(p_textr)  f(p_d) then set p_d+1 = p_textr and go to step 1.\nExpand the simplex if f(p_textr)  f(p_1) by computing the expansion point p_texte = operatornameretr_p_textmbigl( - Î³Î±operatornameretr^-1_p_textm (p_d+1) bigr),  which in this formulation allows to reuse the tangent vector from the inverse retraction from before.  If f(p_texte)  f(p_textr) then set p_d+1 = p_texte otherwise set set p_d+1 = p_textr. Then go to Step 1.\nContract the simplex if f(p_textr)  f(p_d).\nIf f(p_textr)  f(p_d+1) set the step s = -Ï\notherwise set s=Ï.\nCompute the contraction point p_textc = operatornameretr_p_textmbigl(soperatornameretr^-1_p_textm p_d+1 bigr).\nin this case if f(p_textc)  f(p_textr) set p_d+1 = p_textc and go to step 1\nin this case if f(p_textc)  f(p_d+1) set p_d+1 = p_textc and go to step 1\nShrink all points (closer to p_1). For all i=2d+1 set  p_i = operatornameretr_p_1bigl( Ïƒoperatornameretr^-1_p_1 p_i bigr)\n\nFor more details, see The Euclidean variant in the Wikipedia https://en.wikipedia.org/wiki/Nelder-Mead_method or Algorithm 4.1 in http://www.optimization-online.org/DB_FILE/2007/08/1742.pdf.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\npopulation::NelderMeadSimplex=NelderMeadSimplex(M): an initial simplex of d+1 points, where d is the manifold_dimension of M.\n\nKeyword arguments\n\nstopping_criterion::StoppingCriterion=StopAfterIteration(2000)|StopWhenPopulationConcentrated(): a functor indicating that the stopping criterion is fulfilled a StoppingCriterion\nÎ±=1.0: reflection parameter Î±  0:\nÎ³=2.0 expansion parameter Î³:\nÏ=1/2: contraction parameter, 0  Ï  frac12,\nÏƒ=1/2: shrink coefficient, 0  Ïƒ  1\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/NelderMead/#Manopt.NelderMead!","page":"Nelderâ€“Mead","title":"Manopt.NelderMead!","text":"NelderMead(M::AbstractManifold, f, population=NelderMeadSimplex(M))\nNelderMead(M::AbstractManifold, mco::AbstractManifoldCostObjective, population=NelderMeadSimplex(M))\nNelderMead!(M::AbstractManifold, f, population)\nNelderMead!(M::AbstractManifold, mco::AbstractManifoldCostObjective, population)\n\nSolve a Nelder-Mead minimization problem for the cost function f mathcalM  â„ on the manifold M. If the initial NelderMeadSimplex is not provided, a random set of points is chosen. The computation can be performed in-place of the population.\n\nThe algorithm consists of the following steps. Let d denote the dimension of the manifold mathcalM.\n\nOrder the simplex vertices p_i i=1d+1 by increasing cost, such that we have f(p_1)  f(p_2)    f(p_d+1).\nCompute the Riemannian center of mass [Kar77], cf. mean, p_textm  of the simplex vertices p_1p_d+1.\nReflect the point with the worst point at the mean p_textr = operatornameretr_p_textmbigl( - Î±operatornameretr^-1_p_textm (p_d+1) bigr)  If f(p_1)  f(p_textr)  f(p_d) then set p_d+1 = p_textr and go to step 1.\nExpand the simplex if f(p_textr)  f(p_1) by computing the expansion point p_texte = operatornameretr_p_textmbigl( - Î³Î±operatornameretr^-1_p_textm (p_d+1) bigr),  which in this formulation allows to reuse the tangent vector from the inverse retraction from before.  If f(p_texte)  f(p_textr) then set p_d+1 = p_texte otherwise set set p_d+1 = p_textr. Then go to Step 1.\nContract the simplex if f(p_textr)  f(p_d).\nIf f(p_textr)  f(p_d+1) set the step s = -Ï\notherwise set s=Ï.\nCompute the contraction point p_textc = operatornameretr_p_textmbigl(soperatornameretr^-1_p_textm p_d+1 bigr).\nin this case if f(p_textc)  f(p_textr) set p_d+1 = p_textc and go to step 1\nin this case if f(p_textc)  f(p_d+1) set p_d+1 = p_textc and go to step 1\nShrink all points (closer to p_1). For all i=2d+1 set  p_i = operatornameretr_p_1bigl( Ïƒoperatornameretr^-1_p_1 p_i bigr)\n\nFor more details, see The Euclidean variant in the Wikipedia https://en.wikipedia.org/wiki/Nelder-Mead_method or Algorithm 4.1 in http://www.optimization-online.org/DB_FILE/2007/08/1742.pdf.\n\nInput\n\nM::AbstractManifold: a Riemannian manifold mathcalM\nf: a cost function f mathcalM â„ implemented as (M, p) -> v\npopulation::NelderMeadSimplex=NelderMeadSimplex(M): an initial simplex of d+1 points, where d is the manifold_dimension of M.\n\nKeyword arguments\n\nstopping_criterion::StoppingCriterion=StopAfterIteration(2000)|StopWhenPopulationConcentrated(): a functor indicating that the stopping criterion is fulfilled a StoppingCriterion\nÎ±=1.0: reflection parameter Î±  0:\nÎ³=2.0 expansion parameter Î³:\nÏ=1/2: contraction parameter, 0  Ï  frac12,\nÏƒ=1/2: shrink coefficient, 0  Ïƒ  1\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective decorators, respectively.\n\nOutput\n\nThe obtained approximate minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details, especially the return_state= keyword.\n\n\n\n\n\n","category":"function"},{"location":"solvers/NelderMead/#Manopt.NelderMeadState","page":"Nelderâ€“Mead","title":"Manopt.NelderMeadState","text":"NelderMeadState <: AbstractManoptSolverState\n\nDescribes all parameters and the state of a Nelder-Mead heuristic based optimization algorithm.\n\nFields\n\nThe naming of these parameters follows the Wikipedia article of the Euclidean case. The default is given in brackets, the required value range after the description\n\npopulation::NelderMeadSimplex: a population (set) of d+1 points x_i, i=1n+1, where d is the manifold_dimension of M.\nstepsize::Stepsize: a functor inheriting from Stepsize to determine a step size\nÎ±: the reflection parameter Î±  0:\nÎ³ the expansion parameter Î³  0:\nÏ: the contraction parameter, 0  Ï  frac12,\nÏƒ: the shrinkage coefficient, 0  Ïƒ  1\np::P: a point on the manifold mathcalM storing the current best point\ninverse_retraction_method::AbstractInverseRetractionMethod: an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod: a retraction operatornameretr to use, see the section on retractions\n\nConstructors\n\nNelderMeadState(M::AbstractManifold; kwargs...)\n\nConstruct a Nelder-Mead Option with a default population (if not provided) of set of dimension(M)+1 random points stored in NelderMeadSimplex.\n\nKeyword arguments\n\npopulation=NelderMeadSimplex(M)\nstopping_criterion::StoppingCriterion=StopAfterIteration(2000)|StopWhenPopulationConcentrated(): a functor indicating that the stopping criterion is fulfilled a StoppingCriterion\nÎ±=1.0: reflection parameter Î±  0:\nÎ³=2.0 expansion parameter Î³:\nÏ=1/2: contraction parameter, 0  Ï  frac12,\nÏƒ=1/2: shrink coefficient, 0  Ïƒ  1\ninverse_retraction_method::AbstractInverseRetractionMethod=default_inverse_retraction_method(M, typeof(p)): an inverse retraction operatornameretr^-1 to use, see the section on retractions and their inverses\nretraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)): a retraction operatornameretr to use, see the section on retractions\np=copy(M, population.pts[1]): initialise the storage for the best point (iterate)Â¨\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#Manopt.NelderMeadSimplex","page":"Nelderâ€“Mead","title":"Manopt.NelderMeadSimplex","text":"NelderMeadSimplex\n\nA simplex for the Nelder-Mead algorithm.\n\nConstructors\n\nNelderMeadSimplex(M::AbstractManifold)\n\nConstruct a  simplex using d+1 random points from manifold M, where d is the manifold_dimension of M.\n\nNelderMeadSimplex(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis=default_basis(M, typeof(p));\n    a::Real=0.025,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n)\n\nConstruct a simplex from a basis B with one point being p and other points constructed by moving by a in each principal direction defined by basis B of the tangent space at point p using retraction retraction_method. This works similarly to how the initial simplex is constructed in the Euclidean Nelder-Mead algorithm, just in the tangent space at point p.\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#Manopt.StopWhenPopulationConcentrated","page":"Nelderâ€“Mead","title":"Manopt.StopWhenPopulationConcentrated","text":"StopWhenPopulationConcentrated <: StoppingCriterion\n\nA stopping criterion for NelderMead to indicate to stop when both\n\nthe maximal distance of the first to the remaining the cost values and\nthe maximal distance of the first to the remaining the population points\n\ndrops below a certain tolerance tol_f and tol_p, respectively.\n\nConstructor\n\nStopWhenPopulationConcentrated(tol_f::Real=1e-8, tol_x::Real=1e-8)\n\n\n\n\n\n","category":"type"}]
}
