var documenterSearchIndex = {"docs":
[{"location":"notation/#Notation","page":"Notation","title":"Notation","text":"","category":"section"},{"location":"notation/","page":"Notation","title":"Notation","text":"In this package, we follow the notation introduced in Manifolds.jl ‚Äì Notation","category":"page"},{"location":"notation/","page":"Notation","title":"Notation","text":"with the following additional or slightly changed notation","category":"page"},{"location":"notation/","page":"Notation","title":"Notation","text":"Symbol Description Also used Comment\n The Levi-Cevita connection  \noperatornamegradf The Riemannian gradient f due to possible confusion with the connection, we try to avoid f\noperatornameHessf The Riemannian Hessian  ","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#Using-Automatic-Differentiation-in-Manopt.jl","page":"Use Automatic Differentiation","title":"Using Automatic Differentiation in Manopt.jl","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Since Manifolds.jl 0.7, the support of automatic differentiation support has been extended.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"This tutorial explains how to use Euclidean tools to derive a gradient for a real-valued function fcolon mathcal M  ‚Ñù. We will consider two methods: an intrinsic variant and a variant employing the embedding. These gradients can then be used within any gradient based optimization algorithm in Manopt.jl.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"While by default we use FiniteDifferences.jl, you can also use FiniteDiff.jl, ForwardDiff.jl, ReverseDiff.jl, or Zygote.jl.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"In this tutorial we will take a look at a few possibilities to approximate or derive the gradient of a function fmathcal M to ‚Ñù on a Riemannian manifold, without computing it yourself. There are mainly two different philosophies:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Working instrinsically, i.e.¬†staying on the manifold and in the tangent spaces. Here, we will consider approximating the gradient by forward differences.\nWorking in an embedding ‚Äì there we can use all tools from functions on Euclidean spaces ‚Äì finite differences or automatic differenciation ‚Äì and then compute the corresponding Riemannian gradient from there.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We first load all necessary packages","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"using Manopt, Manifolds, Random, LinearAlgebra\nusing FiniteDifferences, ManifoldDiff\nRandom.seed!(42);","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#.-(Intrinsic)-Forward-Differences","page":"Use Automatic Differentiation","title":"1. (Intrinsic) Forward Differences","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"A first idea is to generalize (multivariate) finite differences to Riemannian manifolds. Let X_1ldotsX_d  T_pmathcal M denote an orthonormal basis of the tangent space T_pmathcal M at the point pmathcal M on the Riemannian manifold.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We can generalize the notion of a directional derivative, i.e.¬†for the ‚Äúdirection‚Äù YT_pmathcal M. Let ccolon -ŒµŒµ, Œµ0, be a curve with c(0) = p, dot c(0) = Y, e.g.¬†c(t)= exp_p(tY). We obtain","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"    Df(p)Y = left fracddt right_t=0 f(c(t)) = lim_t to 0 frac1t(f(exp_p(tY))-f(p))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We can approximate Df(p)X by a finite difference scheme for an h0 as","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"DF(p)Y  G_h(Y) = frac1h(f(exp_p(hY))-f(p))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Furthermore the gradient operatornamegradf is the Riesz representer of the differential, ie.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"    Df(p)Y = g_p(operatornamegradf(p) Y)qquad text for all  Y  T_pmathcal M","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"and since it is a tangent vector, we can write it in terms of a basis as","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"    operatornamegradf(p) = sum_i=1^d g_p(operatornamegradf(p)X_i)X_i\n    = sum_i=1^d Df(p)X_iX_i","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"and perform the approximation from above to obtain","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"    operatornamegradf(p)  sum_i=1^d G_h(X_i)X_i","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"for some suitable step size h. This comes at the cost of d+1 function evaluations and d exponential maps.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"This is the first variant we can use. An advantage is that it is intrinsic in the sense that it does not require any embedding of the manifold.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#An-Example:-The-Rayleigh-Quotient","page":"Use Automatic Differentiation","title":"An Example: The Rayleigh Quotient","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"The Rayleigh quotient is concerned with finding eigenvalues (and eigenvectors) of a symmetric matrix Ain ‚Ñù^(n+1)(n+1). The optimization problem reads","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Fcolon ‚Ñù^n+1 to ‚Ñùquad F(mathbf x) = fracmathbf x^mathrmTAmathbf xmathbf x^mathrmTmathbf x","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Minimizing this function yields the smallest eigenvalue lambda_1 as a value and the corresponding minimizer mathbf x^* is a corresponding eigenvector.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Since the length of an eigenvector is irrelevant, there is an ambiguity in the cost function. It can be better phrased on the sphere $ ùïä^n$ of unit vectors in $ R^{n+1}$, i.e.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"operatorname*argmin_p in ùïä^n f(p) = operatorname*argmin_ p in ùïä^n p^mathrmTAp","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We can compute the Riemannian gradient exactly as","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"operatornamegrad f(p) = 2(Ap - pp^mathrmTAp)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"so we can compare it to the approximation by finite differences.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"n = 200\nA = randn(n + 1, n + 1)\nA = Symmetric(A)\nM = Sphere(n);\n\nf1(p) = p' * A'p\ngradf1(p) = 2 * (A * p - p * p' * A * p)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"gradf1 (generic function with 1 method)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Manifolds provides a finite difference scheme in tangent spaces, that you can introduce to use an existing framework (if the wrapper is implemented) form Euclidean space. Here we use FiniteDiff.jl.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"r_backend = ManifoldDiff.TangentDiffBackend(\n    ManifoldDiff.FiniteDifferencesBackend()\n)\ngradf1_FD(p) = ManifoldDiff.gradient(M, f1, p, r_backend)\n\np = zeros(n + 1)\np[1] = 1.0\nX1 = gradf1(p)\nX2 = gradf1_FD(p)\nnorm(M, p, X1 - X2)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"1.016587429282545e-12","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We obtain quite a good approximation of the gradient.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#.-Conversion-of-a-Euclidean-Gradient-in-the-Embedding-to-a-Riemannian-Gradient-of-a-(not-Necessarily-Isometrically)-Embedded-Manifold","page":"Use Automatic Differentiation","title":"2. Conversion of a Euclidean Gradient in the Embedding to a Riemannian Gradient of a (not Necessarily Isometrically) Embedded Manifold","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Let tilde fcolonmathbb R^m to mathbb R be a function on the embedding of an n-dimensional manifold mathcal M subset mathbb R^mand let fcolon mathcal M to mathbb R denote the restriction of tilde f to the manifold mathcal M.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Since we can use the pushforward of the embedding to also embed the tangent space T_pmathcal M, pin mathcal M, we can similarly obtain the differential Df(p)colon T_pmathcal M to mathbb R by restricting the differential Dtilde f(p) to the tangent space.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"If both T_pmathcal M and T_pmathbb R^m have the same inner product, or in other words the manifold is isometrically embedded in mathbb R^m (like for example the sphere mathbb S^nsubsetmathbb R^m+1), then this restriction of the differential directly translates to a projection of the gradient, i.e.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"operatornamegradf(p) = operatornameProj_T_pmathcal M(operatornamegrad tilde f(p))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"More generally we might have to take a change of the metric into account, i.e.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"langle  operatornameProj_T_pmathcal M(operatornamegrad tilde f(p)) X rangle\n= Df(p)X = g_p(operatornamegradf(p) X)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"or in words: we have to change the Riesz representer of the (restricted/projected) differential of f (tilde f) to the one with respect to the Riemannian metric. This is done using change_representer.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#A-Continued-Example","page":"Use Automatic Differentiation","title":"A Continued Example","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We continue with the Rayleigh Quotient from before, now just starting with the defintion of the Euclidean case in the embedding, the function F.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"F(x) = x' * A * x / (x' * x);","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"The cost function is the same by restriction","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"f2(M, p) = F(p);","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"The gradient is now computed combining our gradient scheme with FiniteDifferences.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"function grad_f2_AD(M, p)\n    return Manifolds.gradient(\n        M, F, p, Manifolds.RiemannianProjectionBackend(ManifoldDiff.FiniteDifferencesBackend())\n    )\nend\nX3 = grad_f2_AD(M, p)\nnorm(M, p, X1 - X3)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"1.721066272238026e-12","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#An-Example-for-a-Nonisometrically-Embedded-Manifold","page":"Use Automatic Differentiation","title":"An Example for a Nonisometrically Embedded Manifold","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"on the manifold mathcal P(3) of symmetric positive definite matrices.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"The following function computes (half) the distance squared (with respect to the linear affine metric) on the manifold mathcal P(3) to the identity, i.e.¬†I_3. Denoting the unit matrix we consider the function","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"    G(q)\n    = frac12d^2_mathcal P(3)(qI_3)\n    = lVert operatornameLog(q) rVert_F^2","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"where operatornameLog denotes the matrix logarithm and lVert cdot rVert_F is the Frobenius norm. This can be computed for symmetric positive definite matrices by summing the squares of the logarithms of the eigenvalues of q and dividing by two:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"G(q) = sum(log.(eigvals(Symmetric(q))) .^ 2) / 2","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"G (generic function with 1 method)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We can also interpret this as a function on the space of matrices and apply the Euclidean finite differences machinery; in this way we can easily derive the Euclidean gradient. But when computing the Riemannian gradient, we have to change the representer (see again change_representer) after projecting onto the tangent space T_pmathcal P(n) at p.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Let‚Äôs first define a point and the manifold N=mathcal P(3).","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"rotM(Œ±) = [1.0 0.0 0.0; 0.0 cos(Œ±) sin(Œ±); 0.0 -sin(Œ±) cos(Œ±)]\nq = rotM(œÄ / 6) * [1.0 0.0 0.0; 0.0 2.0 0.0; 0.0 0.0 3.0] * transpose(rotM(œÄ / 6))\nN = SymmetricPositiveDefinite(3)\nis_point(N, q)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"true","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We could first just compute the gradient using FiniteDifferences.jl, but this yields the Euclidean gradient:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"FiniteDifferences.grad(central_fdm(5, 1), G, q)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"([3.240417492806275e-14 -2.3531899864903462e-14 0.0; 0.0 0.3514812167654708 0.017000516835452926; 0.0 0.0 0.36129646973723023],)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Instead, we use the RiemannianProjectedBackend of Manifolds.jl, which in this case internally uses FiniteDifferences.jl to compute a Euclidean gradient but then uses the conversion explained above to derive the Riemannian gradient.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"We define this here again as a function grad_G_FD that could be used in the Manopt.jl framework within a gradient based optimization.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"function grad_G_FD(N, q)\n    return Manifolds.gradient(\n        N, G, q, ManifoldDiff.RiemannianProjectionBackend(ManifoldDiff.FiniteDifferencesBackend())\n    )\nend\nG1 = grad_G_FD(N, q)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"3√ó3 Matrix{Float64}:\n  3.24042e-14  -2.64734e-14  -5.09481e-15\n -2.64734e-14   1.86368       0.826856\n -5.09481e-15   0.826856      2.81845","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Now, we can again compare this to the (known) solution of the gradient, namely the gradient of (half of) the distance squared, i.e.¬†G(q) = frac12d^2_mathcal P(3)(qI_3) is given by operatornamegrad G(q) = -operatornamelog_q I_3, where operatornamelog is the logarithmic map on the manifold.","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"G2 = -log(N, q, Matrix{Float64}(I, 3, 3))","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"3√ó3 Matrix{Float64}:\n -0.0  -0.0       -0.0\n -0.0   1.86368    0.826856\n -0.0   0.826856   2.81845","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"Both terms agree up to 1810^-12:","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"norm(G1 - G2)\nisapprox(M, q, G1, G2; atol=2 * 1e-12)","category":"page"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"true","category":"page"},{"location":"tutorials/AutomaticDifferentiation/#Summary","page":"Use Automatic Differentiation","title":"Summary","text":"","category":"section"},{"location":"tutorials/AutomaticDifferentiation/","page":"Use Automatic Differentiation","title":"Use Automatic Differentiation","text":"This tutorial illustrates how to use tools from Euclidean spaces, finite differences or automatic differentiation, to compute gradients on Riemannian manifolds. The scheme allows to use any differentiation framework within the embedding to derive a Riemannian gradient.","category":"page"},{"location":"solvers/conjugate_gradient_descent/#CGSolver","page":"Conjugate gradient descent","title":"Conjugate Gradient Descent","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"conjugate_gradient_descent\nconjugate_gradient_descent!","category":"page"},{"location":"solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent","page":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent","text":"conjugate_gradient_descent(M, F, gradF, p=rand(M))\nconjugate_gradient_descent(M, gradient_objective, p)\n\nperform a conjugate gradient based descent\n\np_k+1 = operatornameretr_p_k bigl( s_kŒ¥_k bigr)\n\nwhere operatornameretr denotes a retraction on the Manifold M and one can employ different rules to update the descent direction Œ¥_k based on the last direction Œ¥_k-1 and both gradients operatornamegradf(x_k),operatornamegradf(x_k-1). The Stepsize s_k may be determined by a Linesearch.\n\nAlternatively to f and grad_f you can prodive the AbstractManifoldGradientObjective gradient_objective directly.\n\nAvailable update rules are SteepestDirectionUpdateRule, which yields a gradient_descent, ConjugateDescentCoefficient (the default), DaiYuanCoefficient, FletcherReevesCoefficient, HagerZhangCoefficient, HestenesStiefelCoefficient, LiuStoreyCoefficient, and PolakRibiereCoefficient. These can all be combined with a ConjugateGradientBealeRestart rule.\n\nThey all compute Œ≤_k such that this algorithm updates the search direction as\n\ndelta_k=operatornamegradf(p_k) + Œ≤_k delta_k-1\n\nInput\n\nM : a manifold mathcal M\nf : a cost function Fmathcal M‚Ñù to minimize implemented as a function (M,p) -> v\ngrad_f: the gradient operatornamegradFmathcal M  Tmathcal M of F implemented also as (M,x) -> X\np : an initial value xmathcal M\n\nOptional\n\ncoefficient : (ConjugateDescentCoefficient <: DirectionUpdateRule) rule to compute the descent direction update coefficient Œ≤_k, as a functor, i.e. the resulting function maps (amp, cgs, i) -> Œ≤, where amp is an AbstractManoptProblem, cgs are the ConjugateGradientDescentState o and i is the current iterate.\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient works by allocation (default) form gradF(M, x) or InplaceEvaluation in place, i.e. is of the form gradF!(M, X, x).\nretraction_method - (default_retraction_method(M, typeof(p))) a retraction method to use.\nstepsize - (ArmijoLinesearch via default_stepsize) A Stepsize function applied to the search direction. The default is a constant step size 1.\nstopping_criterion : (stopWhenAny( stopAtIteration(200), stopGradientNormLess(10.0^-8))) a function indicating when to stop.\nvector_transport_method ‚Äì (default_vector_transport_method(M, typeof(p))) vector transport method to transport the old descent direction when computing the new descent direction.\n\nIf you provide the ManifoldGradientObjective directly, evaluation is ignored.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#Manopt.conjugate_gradient_descent!","page":"Conjugate gradient descent","title":"Manopt.conjugate_gradient_descent!","text":"conjugate_gradient_descent!(M, F, gradF, x)\nconjugate_gradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform a conjugate gradient based descent in place of x, i.e.\n\np_k+1 = operatornameretr_p_k bigl( s_kdelta_k bigr)\n\nwhere operatornameretr denotes a retraction on the Manifold M\n\nInput\n\nM : a manifold mathcal M\nf : a cost function Fmathcal M‚Ñù to minimize\ngrad_f: the gradient operatornamegradFmathcal M Tmathcal M of F\np : an initial value pmathcal M\n\nAlternatively to f and grad_f you can prodive the AbstractManifoldGradientObjective gradient_objective directly.\n\nfor more details and options, especially the DirectionUpdateRules,  see conjugate_gradient_descent.\n\n\n\n\n\n","category":"function"},{"location":"solvers/conjugate_gradient_descent/#State","page":"Conjugate gradient descent","title":"State","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"ConjugateGradientDescentState","category":"page"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientDescentState","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientDescentState","text":"ConjugateGradientState <: AbstractGradientSolverState\n\nspecify options for a conjugate gradient descent algorithm, that solves a [DefaultManoptProblem].\n\nFields\n\np ‚Äì the current iterate, a point on a manifold\nX ‚Äì the current gradient, also denoted as Œæ or X_k for the gradient in the kth step.\nŒ¥ ‚Äì the current descent direction, i.e. also tangent vector\nŒ≤ ‚Äì the current update coefficient rule, see .\ncoefficient ‚Äì a DirectionUpdateRule function to determine the new Œ≤\nstepsize ‚Äì a Stepsize function\nstop ‚Äì a StoppingCriterion\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a type of retraction\n\nSee also\n\nconjugate_gradient_descent, DefaultManoptProblem, ArmijoLinesearch\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#cg-coeffs","page":"Conjugate gradient descent","title":"Available Coefficients","text":"","category":"section"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"The update rules act as DirectionUpdateRule, which internally always first evaluate the gradient itself.","category":"page"},{"location":"solvers/conjugate_gradient_descent/","page":"Conjugate gradient descent","title":"Conjugate gradient descent","text":"ConjugateGradientBealeRestart\nConjugateDescentCoefficient\nDaiYuanCoefficient\nFletcherReevesCoefficient\nHagerZhangCoefficient\nHestenesStiefelCoefficient\nLiuStoreyCoefficient\nPolakRibiereCoefficient\nSteepestDirectionUpdateRule","category":"page"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateGradientBealeRestart","page":"Conjugate gradient descent","title":"Manopt.ConjugateGradientBealeRestart","text":"ConjugateGradientBealeRestart <: DirectionUpdateRule\n\nAn update rule might require a restart, that is using pure gradient as descent direction, if the last two gradients are nearly orthogonal, cf. [HagerZhang2006], page 12 (in the pdf, 46 in Journal page numbers). This method is named after E. Beale [Beale1972]. This method acts as a decorator to any existing DirectionUpdateRule direction_update.\n\nWhen obtain from the ConjugateGradientDescentStatecgs the last p_kX_k and the current p_k+1X_k+1 iterate and the gradient, respectively.\n\nThen a restart is performed, i.e. Œ≤_k = 0 returned if\n\n    frac X_k+1 P_p_k+1gets p_kX_klVert X_k rVert_p_k  Œæ\n\nwhere P_agets b() denotes a vector transport from the tangent space at a to b, and Œæ is the threshold. The default threshold is chosen as 0.2 as recommended in [Powell1977].\n\nConstructor\n\nConjugateGradientBealeRestart(\n    direction_update::D,\n    threshold=0.2;\n    manifold::AbstractManifold = DefaultManifold(),\n    vector_transport_method::V=default_vector_transport_method(manifold),\n)\n\n[Beale1972]: E.M.L. Beale:, A derivation of conjugate gradients, in: F.A. Lootsma, ed., Numerical methods for nonlinear optimization, Academic Press, London, 1972, pp. 39-43, ISBN 9780124556508.\n\n[HagerZhang2006]: W. W. Hager and H. Zhang, A Survey of Nonlinear Conjugate Gradient Methods Pacific Journal of Optimization 2, 2006, pp. 35-58. url: http://www.yokohamapublishers.jp/online2/pjov2-1.html\n\n[Powell1977]: M.J.D. Powell, Restart Procedures for the Conjugate Gradient Method, Methematical Programming 12, 1977, pp. 241‚Äì254 doi: 10.1007/BF01593790\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.ConjugateDescentCoefficient","page":"Conjugate gradient descent","title":"Manopt.ConjugateDescentCoefficient","text":"ConjugateDescentCoefficient <: DirectionUpdateRule\n\nComputes an update coefficient for the conjugate gradient method, where the ConjugateGradientDescentStatecgds include the last iterates p_kX_k, the current iterates p_k+1X_k+1 of the iterate and the gradient, respectively, and the last update direction delta=delta_k,  based on [Flethcer1987] adapted to manifolds:\n\nŒ≤_k =\nfrac lVert X_k+1 rVert_p_k+1^2 \nlangle -delta_kX_k rangle_p_k\n\nSee also conjugate_gradient_descent\n\nConstructor\n\nConjugateDescentCoefficient(a::StoreStateAction=())\n\nConstruct the conjugate descent coefficient update rule, a new storage is created by default.\n\n[Flethcer1987]: R. Fletcher, Practical Methods of Optimization vol. 1: Unconstrained Optimization John Wiley & Sons, New York, 1987. doi 10.1137/1024028\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.DaiYuanCoefficient","page":"Conjugate gradient descent","title":"Manopt.DaiYuanCoefficient","text":"DaiYuanCoefficient <: DirectionUpdateRule\n\nComputes an update coefficient for the conjugate gradient method, where the ConjugateGradientDescentStatecgds include the last iterates p_kX_k, the current iterates p_k+1X_k+1 of the iterate and the gradient, respectively, and the last update direction delta=delta_k, based on [DaiYuan1999] adapted to manifolds:\n\nLet nu_k = X_k+1 - P_p_k+1gets p_kX_k, where P_agets b() denotes a vector transport from the tangent space at a to b.\n\nThen the coefficient reads\n\nŒ≤_k =\nfrac lVert X_k+1 rVert_p_k+1^2 \nlangle P_p_k+1gets p_kdelta_k nu_k rangle_p_k+1\n\nSee also conjugate_gradient_descent\n\nConstructor\n\nfunction DaiYuanCoefficient(\n    M::AbstractManifold=DefaultManifold(2);\n    t::AbstractVectorTransportMethod=default_vector_transport_method(M)\n)\n\nConstruct the Dai Yuan coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.\n\n[DaiYuan1999]: [Y. H. Dai and Y. Yuan, A nonlinear conjugate gradient method with a strong global convergence property, SIAM J. Optim., 10 (1999), pp. 177‚Äì182. doi: 10.1137/S1052623497318992\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.FletcherReevesCoefficient","page":"Conjugate gradient descent","title":"Manopt.FletcherReevesCoefficient","text":"FletcherReevesCoefficient <: DirectionUpdateRule\n\nComputes an update coefficient for the conjugate gradient method, where the ConjugateGradientDescentStatecgds include the last iterates p_kX_k, the current iterates p_k+1X_k+1 of the iterate and the gradient, respectively, and the last update direction delta=delta_k,  based on [FletcherReeves1964] adapted to manifolds:\n\nŒ≤_k =\nfraclVert X_k+1rVert_p_k+1^2lVert X_krVert_x_k^2\n\nSee also conjugate_gradient_descent\n\nConstructor\n\nFletcherReevesCoefficient(a::StoreStateAction=())\n\nConstruct the Fletcher Reeves coefficient update rule, a new storage is created by default.\n\n[FletcherReeves1964]: R. Fletcher and C. Reeves, Function minimization by conjugate gradients, Comput. J., 7 (1964), pp. 149‚Äì154. doi: 10.1093/comjnl/7.2.149\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HagerZhangCoefficient","page":"Conjugate gradient descent","title":"Manopt.HagerZhangCoefficient","text":"HagerZhangCoefficient <: DirectionUpdateRule\n\nComputes an update coefficient for the conjugate gradient method, where the ConjugateGradientDescentStatecgds include the last iterates p_kX_k, the current iterates p_k+1X_k+1 of the iterate and the gradient, respectively, and the last update direction delta=delta_k, based on [HagerZhang2005] adapted to manifolds: let nu_k = X_k+1 - P_p_k+1gets p_kX_k, where P_agets b() denotes a vector transport from the tangent space at a to b.\n\nŒ≤_k = Bigllanglenu_k -\nfrac 2lVert nu_krVert_p_k+1^2  langle P_p_k+1gets p_kdelta_k nu_k rangle_p_k+1 \nP_p_k+1gets p_kdelta_k\nfracX_k+1 langle P_p_k+1gets p_kdelta_k nu_k rangle_p_k+1 \nBigrrangle_p_k+1\n\nThis method includes a numerical stability proposed by those authors.\n\nSee also conjugate_gradient_descent\n\nConstructor\n\nfunction HagerZhangCoefficient(t::AbstractVectorTransportMethod)\nfunction HagerZhangCoefficient(M::AbstractManifold = DefaultManifold(2))\n\nConstruct the Hager Zhang coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.\n\n[HagerZhang2005]: [W. W. Hager and H. Zhang, A new conjugate gradient method with guaranteed descent and an efficient line search, SIAM J. Optim, (16), pp. 170-192, 2005. doi: 10.1137/030601880\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.HestenesStiefelCoefficient","page":"Conjugate gradient descent","title":"Manopt.HestenesStiefelCoefficient","text":"HestenesStiefelCoefficient <: DirectionUpdateRule\n\nComputes an update coefficient for the conjugate gradient method, where the ConjugateGradientDescentStatecgds include the last iterates p_kX_k, the current iterates p_k+1X_k+1 of the iterate and the gradient, respectively, and the last update direction delta=delta_k,  based on [HeestensStiefel1952] adapted to manifolds as follows:\n\nLet nu_k = X_k+1 - P_p_k+1gets p_kX_k. Then the update reads\n\nŒ≤_k = fraclangle X_k+1 nu_k rangle_p_k+1 \n     langle P_p_k+1gets p_k delta_k nu_krangle_p_k+1 \n\nwhere P_agets b() denotes a vector transport from the tangent space at a to b.\n\nConstructor\n\nfunction HestenesStiefelCoefficient(transport_method::AbstractVectorTransportMethod)\nfunction HestenesStiefelCoefficient(M::AbstractManifold = DefaultManifold(2))\n\nConstruct the Heestens Stiefel coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.\n\nSee also conjugate_gradient_descent\n\n[HeestensStiefel1952]: M.R. Hestenes, E.L. Stiefel, Methods of conjugate gradients for solving linear systems, J. Research Nat. Bur. Standards, 49 (1952), pp. 409‚Äì436. doi: 10.6028/jres.049.044\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.LiuStoreyCoefficient","page":"Conjugate gradient descent","title":"Manopt.LiuStoreyCoefficient","text":"LiuStoreyCoefficient <: DirectionUpdateRule\n\nComputes an update coefficient for the conjugate gradient method, where the ConjugateGradientDescentStatecgds include the last iterates p_kX_k, the current iterates p_k+1X_k+1 of the iterate and the gradient, respectively, and the last update direction delta=delta_k,  based on [LuiStorey1991] adapted to manifolds:\n\nLet nu_k = X_k+1 - P_p_k+1gets p_kX_k, where P_agets b() denotes a vector transport from the tangent space at a to b.\n\nThen the coefficient reads\n\nŒ≤_k = -\nfrac langle X_k+1nu_k rangle_p_k+1 \nlangle delta_kX_k rangle_p_k\n\nSee also conjugate_gradient_descent\n\nConstructor\n\nfunction LiuStoreyCoefficient(t::AbstractVectorTransportMethod)\nfunction LiuStoreyCoefficient(M::AbstractManifold = DefaultManifold(2))\n\nConstruct the Lui Storey coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.\n\n[LuiStorey1991]: Y. Liu and C. Storey, Efficient generalized conjugate gradient algorithms, Part 1: Theory J. Optim. Theory Appl., 69 (1991), pp. 129‚Äì137. doi: 10.1007/BF00940464\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.PolakRibiereCoefficient","page":"Conjugate gradient descent","title":"Manopt.PolakRibiereCoefficient","text":"PolakRibiereCoefficient <: DirectionUpdateRule\n\nComputes an update coefficient for the conjugate gradient method, where the ConjugateGradientDescentStatecgds include the last iterates p_kX_k, the current iterates p_k+1X_k+1 of the iterate and the gradient, respectively, and the last update direction delta=delta_k,  based on [PolakRibiere1969][Polyak1969] adapted to manifolds:\n\nLet nu_k = X_k+1 - P_p_k+1gets p_kX_k, where P_agets b() denotes a vector transport from the tangent space at a to b.\n\nThen the update reads\n\nŒ≤_k =\nfrac langle X_k+1 nu_k rangle_p_k+1 \nlVert X_k rVert_p_k^2 \n\nConstructor\n\nfunction PolakRibiereCoefficient(\n    M::AbstractManifold=DefaultManifold(2);\n    t::AbstractVectorTransportMethod=default_vector_transport_method(M)\n)\n\nConstruct the PolakRibiere coefficient update rule, where the parallel transport is the default vector transport and a new storage is created by default.\n\nSee also conjugate_gradient_descent\n\n[PolakRibiere1969]: E. Polak, G. Ribiere, Note sur la convergence de m√©thodes de directions conjugu√©es ESAIM: Mathematical Modelling and Numerical Analysis - Mod√©lisation Math√©matique et Analyse Num√©rique, Tome 3 (1969) no. R1, p. 35-43, url: http://www.numdam.org/item/?id=M2AN1969__31350\n\n[Polyak1969]: B. T. Polyak, The conjugate gradient method in extreme problems, USSR Comp. Math. Math. Phys., 9 (1969), pp. 94‚Äì112. doi: 10.1016/0041-5553(69)90035-4\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Manopt.SteepestDirectionUpdateRule","page":"Conjugate gradient descent","title":"Manopt.SteepestDirectionUpdateRule","text":"SteepestDirectionUpdateRule <: DirectionUpdateRule\n\nThe simplest rule to update is to have no influence of the last direction and hence return an update Œ≤ = 0 for all ConjugateGradientDescentStatecgds\n\nSee also conjugate_gradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/conjugate_gradient_descent/#Literature","page":"Conjugate gradient descent","title":"Literature","text":"","category":"section"},{"location":"helpers/errorMeasures/#ErrorMeasures","page":"Error Measures","title":"Error Measures","text":"","category":"section"},{"location":"helpers/errorMeasures/","page":"Error Measures","title":"Error Measures","text":"meanSquaredError\nmeanAverageError","category":"page"},{"location":"helpers/errorMeasures/#Manopt.meanSquaredError","page":"Error Measures","title":"Manopt.meanSquaredError","text":"meanSquaredError(M, p, q)\n\nCompute the (mean) squared error between the two points p and q on the (power) manifold M.\n\n\n\n\n\n","category":"function"},{"location":"helpers/errorMeasures/#Manopt.meanAverageError","page":"Error Measures","title":"Manopt.meanAverageError","text":"meanSquaredError(M,x,y)\n\nCompute the (mean) squared error between the two points x and y on the PowerManifold manifold M.\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#GradientDescentSolver","page":"Gradient Descent","title":"Gradient Descent","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"  gradient_descent\n  gradient_descent!","category":"page"},{"location":"solvers/gradient_descent/#Manopt.gradient_descent","page":"Gradient Descent","title":"Manopt.gradient_descent","text":"gradient_descent(M, f, grad_f, p=rand(M); kwargs...)\ngradient_descent(M, gradient_objective, p=rand(M); kwargs...)\n\nperform a gradient descent\n\np_k+1 = operatornameretr_p_kbigl( s_koperatornamegradf(p_k) bigr)\nqquad k=01\n\nwith different choices of the stepsize s_k available (see stepsize option below).\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function f mathcal M‚Ñù to find a minimizer p^* for\ngrad_f ‚Äì the gradient operatornamegradf mathcal M  Tmathcal M of f\nas a function (M, p) -> X or a function (M, X, p) -> X\np ‚Äì an initial value p = p_0  mathcal M\n\nAlternatively to f and grad_f you can prodive the AbstractManifoldGradientObjective gradient_objective directly.\n\nOptional\n\ndirection ‚Äì (IdentityUpdateRule) perform a processing of the direction, e.g.\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient works by allocation (default) form grad_f(M, p) or InplaceEvaluation in place, i.e. is of the form grad_f!(M, X, p).\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction to use\nstepsize ‚Äì (ConstantStepsize(1.)) specify a Stepsize functor.\nstopping_criterion ‚Äì (StopWhenAny(StopAfterIteration(200),StopWhenGradientNormLess(10.0^-8))) a functor inheriting from StoppingCriterion indicating when to stop.\n\nIf you provide the ManifoldGradientObjective directly, evaluation is ignored.\n\nAll other keyword arguments are passed to decorate_state! for state decorators or decorate_objective! for objective, respectively. If you provide the ManifoldGradientObjective directly, these decorations can still be specified\n\nOutput\n\nthe obtained (approximate) minimizer p^*. To obtain the whole final state of the solver, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#Manopt.gradient_descent!","page":"Gradient Descent","title":"Manopt.gradient_descent!","text":"gradient_descent!(M, f, grad_f, p; kwargs...)\ngradient_descent!(M, gradient_objective, p; kwargs...)\n\nperform a gradient_descent\n\np_k+1 = operatornameretr_p_kbigl( s_koperatornamegradf(p_k) bigr)\n\nin place of p with different choices of s_k available.\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function Fmathcal M‚Ñù to minimize\ngrad_f ‚Äì the gradient operatornamegradFmathcal M Tmathcal M of F\np ‚Äì an initial value p  mathcal M\n\nAlternatively to f and grad_f you can prodive the AbstractManifoldGradientObjective gradient_objective directly.\n\nFor more options, especially Stepsizes for s_k, see gradient_descent\n\n\n\n\n\n","category":"function"},{"location":"solvers/gradient_descent/#State","page":"Gradient Descent","title":"State","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"GradientDescentState","category":"page"},{"location":"solvers/gradient_descent/#Manopt.GradientDescentState","page":"Gradient Descent","title":"Manopt.GradientDescentState","text":"GradientDescentState{P,T} <: AbstractGradientSolverState\n\nDescribes a Gradient based descent algorithm, with\n\nFields\n\na default value is given in brackets if a parameter can be left out in initialization.\n\np ‚Äì (rand(M)` the current iterate\nX ‚Äì (zero_vector(M,p)) the current gradient operatornamegradf(p), initialised to zero vector.\nstopping_criterion ‚Äì (StopAfterIteration(100)) a StoppingCriterion\nstepsize ‚Äì (default_stepsize(M, GradientDescentState)) a Stepsize\ndirection - (IdentityUpdateRule) a processor to compute the gradient\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the retraction to use, defaults to the default set for your manifold.\n\nConstructor\n\nGradientDescentState(M, p=rand(M); X=zero_vector(M, p), kwargs...)\n\nGenerate gradient descent options, where X can be used to set the tangent vector to store the gradient in a certain type; it will be initialised accordingly at a later stage. All following fields are keyword arguments.\n\nSee also\n\ngradient_descent\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Direction-Update-Rules","page":"Gradient Descent","title":"Direction Update Rules","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"A field of the options is the direction, a DirectionUpdateRule, which by default IdentityUpdateRule just evaluates the gradient but can be enhanced for example to","category":"page"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"DirectionUpdateRule\nIdentityUpdateRule\nMomentumGradient\nAverageGradient\nNesterov","category":"page"},{"location":"solvers/gradient_descent/#Manopt.DirectionUpdateRule","page":"Gradient Descent","title":"Manopt.DirectionUpdateRule","text":"DirectionUpdateRule\n\nA general functor, that handles direction update rules. It's field(s) is usually only a StoreStateAction by default initialized to the fields required for the specific coefficient, but can also be replaced by a (common, global) individual one that provides these values.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.IdentityUpdateRule","page":"Gradient Descent","title":"Manopt.IdentityUpdateRule","text":"IdentityUpdateRule <: DirectionUpdateRule\n\nThe default gradient direction update is the identity, i.e. it just evaluates the gradient.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.MomentumGradient","page":"Gradient Descent","title":"Manopt.MomentumGradient","text":"MomentumGradient <: DirectionUpdateRule\n\nAppend a momentum to a gradient processor, where the last direction and last iterate are stored and the new is composed as Œ∑_i = m*Œ∑_i-1 - s d_i, where sd_i is the current (inner) direction and Œ∑_i-1 is the vector transported last direction multiplied by momentum m.\n\nFields\n\np_old - (rand(M)) remember the last iterate for parallel transporting the last direction\nmomentum ‚Äì (0.2) factor for momentum\ndirection ‚Äì internal DirectionUpdateRule to determine directions to add the momentum to.\nvector_transport_method ‚Äì default_vector_transport_method(M, typeof(p)) vector transport method to use\nX_old ‚Äì (zero_vector(M,x0)) the last gradient/direction update added as momentum\n\nConstructors\n\nAdd momentum to a gradient problem, where by default just a gradient evaluation is used\n\nMomentumGradient(\n    M::AbstractManifold;\n    p=rand(M),\n    s::DirectionUpdateRule=IdentityUpdateRule();\n    X=zero_vector(p.M, x0), momentum=0.2\n    vector_transport_method=default_vector_transport_method(M, typeof(p)),\n)\n\nInitialize a momentum gradient rule to s. Note that the keyword agruments p and X will be overriden often, so their initialisation is meant to set the to certain types of points or tangent vectors, if you do not use the default types with respect to M.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.AverageGradient","page":"Gradient Descent","title":"Manopt.AverageGradient","text":"AverageGradient <: DirectionUpdateRule\n\nAdd an average of gradients to a gradient processor. A set of previous directions (from the inner processor) and the last iterate are stored, average is taken after vector transporting them to the current iterates tangent space.\n\nFields\n\ngradients ‚Äì (fill(zero_vector(M,x0),n)) the last n gradient/direction updates\nlast_iterate ‚Äì last iterate (needed to transport the gradients)\ndirection ‚Äì internal DirectionUpdateRule to determine directions to apply the averaging to\nvector_transport_method - vector transport method to use\n\nConstructors\n\nAverageGradient(\n    M::AbstractManifold,\n    p::P=rand(M);\n    n::Int=10\n    s::DirectionUpdateRule=IdentityUpdateRule();\n    gradients = fill(zero_vector(p.M, o.x),n),\n    last_iterate = deepcopy(x0),\n    vector_transport_method = default_vector_transport_method(M, typeof(p))\n)\n\nAdd average to a gradient problem, where\n\nn determines the size of averaging\ns is the internal DirectionUpdateRule to determine the gradients to store\ngradients can be prefilled with some history\nlast_iterate stores the last iterate\nvector_transport_method determines how to transport all gradients to the current iterates tangent space before averaging\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.Nesterov","page":"Gradient Descent","title":"Manopt.Nesterov","text":"Nesterov <: DirectionUpdateRule\n\nFields\n\nŒ≥\nŒº the strong convexity coefficient\nv (==v_k, v_0=x_0) an interims point to compute the next gradient evaluation point y_k\nshrinkage (= i -> 0.8) a function to compute the shrinkage Œ≤_k per iterate.\n\nLet's assume f is L-Lipschitz and Œº-strongly convex. Given\n\na step size h_kfrac1L (from the GradientDescentState\na shrinkage parameter Œ≤_k\nand a current iterate x_k\nas well as the interims values Œ≥_k and v_k from the previous iterate.\n\nThis compute a Nesterov type update using the following steps, see [ZhangSra2018]\n\nCopute the positive root, i.e. Œ±_k(01) of Œ±^2 = h_kbigl((1-Œ±_k)Œ≥_k+Œ±_k Œºbigr).\nSet bar Œ≥_k+1 = (1-Œ±_k)Œ≥_k + Œ±_kŒº\ny_k = operatornameretr_x_kBigl(fracŒ±_kŒ≥_kŒ≥_k + Œ±_kŒºoperatornameretr^-1_x_kv_k Bigr)\nx_k+1 = operatornameretr_y_k(-h_k operatornamegradf(y_k))\nv_k+1 = operatornameretr_y_kBigl(frac(1-Œ±_k)Œ≥_kbarŒ≥_koperatornameretr_y_k^-1(v_k) - fracŒ±_kbar Œ≥_k+1operatornamegradf(y_k) Bigr)\nŒ≥_k+1 = frac11+Œ≤_kbar Œ≥_k+1\n\nThen the direction from x_k to x_k+1, i.e. d = operatornameretr^-1_x_kx_k+1 is returned.\n\nConstructor\n\nNesterov(M::AbstractManifold, p::P; Œ≥=0.001, Œº=0.9, schrinkage = k -> 0.8;\n    inverse_retraction_method=LogarithmicInverseRetraction())\n\nInitialize the Nesterov acceleration, where x0 initializes v.\n\n[ZhangSra2018]: H. Zhang, S. Sra: Towards Riemannian Accelerated Gradient Methods, Preprint, 2018, arXiv: 1806.02812\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Debug-Actions","page":"Gradient Descent","title":"Debug Actions","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"DebugGradient\nDebugGradientNorm\nDebugStepsize","category":"page"},{"location":"solvers/gradient_descent/#Manopt.DebugGradient","page":"Gradient Descent","title":"Manopt.DebugGradient","text":"DebugGradient <: DebugAction\n\ndebug for the gradient evaluated at the current iterate\n\nConstructors\n\nDebugGradient(; long=false, prefix= , format= \"$prefix%s\", io=stdout)\n\ndisplay the short (false) or long (true) default text for the gradient, or set the prefix manually. Alternatively the complete format can be set.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.DebugGradientNorm","page":"Gradient Descent","title":"Manopt.DebugGradientNorm","text":"DebugGradientNorm <: DebugAction\n\ndebug for gradient evaluated at the current iterate.\n\nConstructors\n\nDebugGradientNorm([long=false,p=print])\n\ndisplay the short (false) or long (true) default text for the gradient norm.\n\nDebugGradientNorm(prefix[, p=print])\n\ndisplay the a prefix in front of the gradientnorm.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.DebugStepsize","page":"Gradient Descent","title":"Manopt.DebugStepsize","text":"DebugStepsize <: DebugAction\n\ndebug for the current step size.\n\nConstructors\n\nDebugStepsize(;long=false,prefix=\"step size:\", format=\"$prefix%s\", io=stdout)\n\ndisplay the a prefix in front of the step size.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Record-Actions","page":"Gradient Descent","title":"Record Actions","text":"","category":"section"},{"location":"solvers/gradient_descent/","page":"Gradient Descent","title":"Gradient Descent","text":"RecordGradient\nRecordGradientNorm\nRecordStepsize","category":"page"},{"location":"solvers/gradient_descent/#Manopt.RecordGradient","page":"Gradient Descent","title":"Manopt.RecordGradient","text":"RecordGradient <: RecordAction\n\nrecord the gradient evaluated at the current iterate\n\nConstructors\n\nRecordGradient(Œæ)\n\ninitialize the RecordAction to the corresponding type of the tangent vector.\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.RecordGradientNorm","page":"Gradient Descent","title":"Manopt.RecordGradientNorm","text":"RecordGradientNorm <: RecordAction\n\nrecord the norm of the current gradient\n\n\n\n\n\n","category":"type"},{"location":"solvers/gradient_descent/#Manopt.RecordStepsize","page":"Gradient Descent","title":"Manopt.RecordStepsize","text":"RecordStepsize <: RecordAction\n\nrecord the step size\n\n\n\n\n\n","category":"type"},{"location":"solvers/#SolversSection","page":"Introduction","title":"Solvers","text":"","category":"section"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"Solvers can be applied to AbstractManoptProblems with solver specific AbstractManoptSolverState.","category":"page"},{"location":"solvers/#List-of-Algorithms","page":"Introduction","title":"List of Algorithms","text":"","category":"section"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"The following algorithms are currently available","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"Solver Function & State Objective\nAlternating Gradient Descent alternating_gradient_descent AlternatingGradientDescentState f=(f_1ldotsf_n), operatornamegrad f_i\nChambolle-Pock ChambollePock, ChambollePockState (using TwoManifoldProblem) f=F+G(Œõcdot), operatornameprox_œÉ F, operatornameprox_œÑ G^*, Œõ\nConjugate Gradient Descent conjugate_gradient_descent, ConjugateGradientDescentState f, operatornamegrad f\nCyclic Proximal Point cyclic_proximal_point, CyclicProximalPointState f=sum f_i, operatornameprox_lambda f_i\nDifference of Convex Algorithm difference_of_convex_algorithm, DifferenceOfConvexState f=g-h, h, and e.g. g, operatornamegrad g\nDifference of Convex Proximal Point difference_of_convex_proximal_point, DifferenceOfConvexProximalState f=g-h, h, and e.g. g, operatornamegrad g\nDouglas‚ÄìRachford DouglasRachford, DouglasRachfordState f=sum f_i, operatornameprox_lambda f_i\nExact Penalty Method exact_penalty_method, ExactPenaltyMethodState f, operatornamegrad f, g, operatornamegrad g_i, h, operatornamegrad h_j\nFrank-Wolfe algorithm Frank_Wolfe_method, FrankWolfeState sub-problem solver\nGradient Descent gradient_descent, GradientDescentState f, operatornamegrad f\nLevenberg-Marquardt LevenbergMarquardt, LevenbergMarquardtState f = sum_i f_i operatornamegrad f_i (Jacobian)\nNelder-Mead NelderMead, NelderMeadState f\nAugmented Lagrangian Method augmented_Lagrangian_method, AugmentedLagrangianMethodState f, operatornamegrad f, g, operatornamegrad g_i, h, operatornamegrad h_j\nParticle Swarm particle_swarm, ParticleSwarmState f\nPrimal-dual Riemannian semismooth Newton Algorithm primal_dual_semismooth_Newton,  PrimalDualSemismoothNewtonState (using TwoManifoldProblem) f=F+G(Œõcdot), operatornameprox_œÉ F & diff., operatornameprox_œÑ G^* & diff., Œõ\nQuasi-Newton Method quasi_Newton, QuasiNewtonState f, operatornamegrad f\nSteihaug-Toint Truncated Conjugate-Gradient Method truncated_conjugate_gradient_descent, TruncatedConjugateGradientState f, operatornamegrad f, operatornameHess f\nSubgradient Method subgradient_method, SubGradientMethodState f,  f\nStochastic Gradient Descent stochastic_gradient_descent, StochasticGradientDescentState f = sum_i f_i, operatornamegrad f_i\nThe Riemannian Trust-Regions Solver trust_regions, TrustRegionsState f, operatornamegrad f, operatornameHess f","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"Note that the solvers (their AbstractManoptSolverState, to be precise) can also be decorated to enhance your algorithm by general additional properties, see debug output and recording values. This is done using the debug= and record= keywords in the function calls. Similarly, since 0.4 we provide a (simple) caching of the objective function using the cache= keyword in any of the function calls..","category":"page"},{"location":"solvers/#Technical-Details","page":"Introduction","title":"Technical Details","text":"","category":"section"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"The main function a solver calls is","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"solve!(p::AbstractManoptProblem, s::AbstractManoptSolverState)","category":"page"},{"location":"solvers/#Manopt.solve!-Tuple{AbstractManoptProblem, AbstractManoptSolverState}","page":"Introduction","title":"Manopt.solve!","text":"solve!(p::AbstractManoptProblem, s::AbstractManoptSolverState)\n\nrun the solver implemented for the AbstractManoptProblemp and the AbstractManoptSolverStates employing initialize_solver!, step_solver!, as well as the stop_solver! of the solver.\n\n\n\n\n\n","category":"method"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"which is a framework that you in general should not change or redefine. It uses the following methods, which also need to be implemented on your own algorithm, if you want to provide one.","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"initialize_solver!\nstep_solver!\nget_solver_result\nget_solver_return\nstop_solver!(p::AbstractManoptProblem, s::AbstractManoptSolverState, Any)","category":"page"},{"location":"solvers/#Manopt.initialize_solver!","page":"Introduction","title":"Manopt.initialize_solver!","text":"initialize_solver!(ams::AbstractManoptProblem, amp::AbstractManoptSolverState)\n\nInitialize the solver to the optimization AbstractManoptProblem amp by initializing the necessary values in the AbstractManoptSolverState amp.\n\n\n\n\n\ninitialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState)\n\nExtend the initialization of the solver by a hook to run debug that were added to the :Start and :All entries of the debug lists.\n\n\n\n\n\ninitialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState)\n\nExtend the initialization of the solver by a hook to run records that were added to the :Start entry.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.step_solver!","page":"Introduction","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i)\n\nDo one iteration step (the ith) for an AbstractManoptProblemp by modifying the values in the AbstractManoptSolverState ams.\n\n\n\n\n\nstep_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i)\n\nExtend the ith step of the solver by a hook to run debug prints, that were added to the :Step and :All entries of the debug lists.\n\n\n\n\n\nstep_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, i)\n\nExtend the ith step of the solver by a hook to run records, that were added to the :Iteration entry.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.get_solver_result","page":"Introduction","title":"Manopt.get_solver_result","text":"get_solver_result(ams::AbstractManoptSolverState)\nget_solver_result(tos::Tuple{AbstractManifoldObjective,AbstractManoptSolverState})\nget_solver_result(o::AbstractManifoldObjective, s::AbstractManoptSolverState)\n\nReturn the final result after all iterations that is stored within the AbstractManoptSolverState ams, which was modified during the iterations.\n\nFor the case the objective is passed as well, but default, the objective is ignored, and the solver result for the state is called.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.get_solver_return","page":"Introduction","title":"Manopt.get_solver_return","text":"get_solver_return(s::AbstractManoptSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::AbstractManoptSolverState)\n\ndetermine the result value of a call to a solver. By default this returns the same as get_solver_result, i.e. the last iterate or (approximate) minimizer.\n\nget_solver_return(s::ReturnSolverState)\nget_solver_return(o::AbstractManifoldObjective, s::ReturnSolverState)\n\nreturn the internally stored state of the ReturnSolverState instead of the minimizer. This means that when the state are decorated like this, the user still has to call get_solver_result on the internal state separately.\n\nget_solver_return(o::ReturnManifoldObjective, s::AbstractManoptSolverState)\n\nreturn both the objective and the state as a tuple.\n\n\n\n\n\n","category":"function"},{"location":"solvers/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Any}","page":"Introduction","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i)\n\ndepending on the current AbstractManoptProblem amp, the current state of the solver stored in AbstractManoptSolverState ams and the current iterate i this function determines whether to stop the solver, which by default means to call the internal StoppingCriterion. ams.stop\n\n\n\n\n\n","category":"method"},{"location":"solvers/#API-for-solvers","page":"Introduction","title":"API for solvers","text":"","category":"section"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"this is a short overview of the different types of high-level functions are usually available for a solver. Let's assume the solver is called new_solver and requires a cost f and some first order information df as well as a starting point p on M. f and df form the objective together called obj.","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"Then there are basically two different variants to call","category":"page"},{"location":"solvers/#The-easy-to-access-call","page":"Introduction","title":"The easy to access call","text":"","category":"section"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"new_solver(M, f, df, p=rand(M); kwargs...)\nnew_solver!(M, f, df, p; kwargs...)","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"Where the start point should be optional. Keyword arguments include the type of evaluation, decorators like debug= or record= as well as algorithm specific ones. If you provide an immutable point p or the rand(M) point is immutable, like on the Circle() this method should turn the point into a mutable one as well.","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"The third variant works in place of p, so it is mandatory.","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"This first interface would set up the objective and pass all keywords on the the objective based call.","category":"page"},{"location":"solvers/#The-objective-based-call","page":"Introduction","title":"The objective-based call","text":"","category":"section"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"new_solver(M, obj, p=rand(M); kwargs...)\nnew_solver!(M, obj, p; kwargs...)","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"Here the objective would be created beforehand, e.g. to compare different solvers on the same objective, and for the first variant the start point is optional. Keyword arguments include decorators like debug= or record= as well as algorithm specific ones.","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"this variant would generate the problem and the state and check validity of all provided keyword arguments that affect the state. Then it would call the iterate process.","category":"page"},{"location":"solvers/#The-manual-call","page":"Introduction","title":"The manual call","text":"","category":"section"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"If you generate the correctsponding problem and state as the previous step does, you can also use the third (lowest level) and just call","category":"page"},{"location":"solvers/","page":"Introduction","title":"Introduction","text":"solve!(problem, state)","category":"page"},{"location":"functions/gradients/#GradientFunctions","page":"Gradients","title":"Gradients","text":"","category":"section"},{"location":"functions/gradients/","page":"Gradients","title":"Gradients","text":"For a function fmathcal M‚Ñù the Riemannian gradient operatornamegradf(x) at xmathcal M is given by the unique tangent vector fulfilling","category":"page"},{"location":"functions/gradients/","page":"Gradients","title":"Gradients","text":"langle operatornamegradf(x) Œærangle_x = D_xfŒæquad\nforall Œæ  T_xmathcal M","category":"page"},{"location":"functions/gradients/","page":"Gradients","title":"Gradients","text":"where D_xfŒæ denotes the differential of f at x with respect to the tangent direction (vector) Œæ or in other words the directional derivative.","category":"page"},{"location":"functions/gradients/","page":"Gradients","title":"Gradients","text":"This page collects the available gradients.","category":"page"},{"location":"functions/gradients/","page":"Gradients","title":"Gradients","text":"Modules = [Manopt]\nPages   = [\"gradients.jl\"]","category":"page"},{"location":"functions/gradients/#Manopt.forward_logs-Union{Tuple{TPR}, Tuple{TSize}, Tuple{TM}, Tuple{ùîΩ}, Tuple{PowerManifold{ùîΩ, TM, TSize, TPR}, Any}} where {ùîΩ, TM, TSize, TPR}","page":"Gradients","title":"Manopt.forward_logs","text":"Y = forward_logs(M,x)\nforward_logs!(M, Y, x)\n\ncompute the forward logs F (generalizing forward differences) occurring, in the power manifold array, the function\n\nF_i(x) = sum_j  mathcal I_i log_x_i x_jquad i    mathcal G\n\nwhere mathcal G is the set of indices of the PowerManifold manifold M and mathcal I_i denotes the forward neighbors of i. This can also be done in place of Œæ.\n\nInput\n\nM ‚Äì a PowerManifold manifold\nx ‚Äì a point.\n\nOuput\n\nY ‚Äì resulting tangent vector in T_xmathcal M representing the logs, where mathcal N is thw power manifold with the number of dimensions added to size(x). The computation can be done in place of Y.\n\n\n\n\n\n","category":"method"},{"location":"functions/gradients/#Manopt.grad_L2_acceleration_bezier-Union{Tuple{P}, Tuple{AbstractManifold, AbstractVector{P}, AbstractVector{<:Integer}, AbstractVector, Any, AbstractVector{P}}} where P","page":"Gradients","title":"Manopt.grad_L2_acceleration_bezier","text":"grad_L2_acceleration_bezier(\n    M::AbstractManifold,\n    B::AbstractVector{P},\n    degrees::AbstractVector{<:Integer},\n    T::AbstractVector,\n    Œª,\n    d::AbstractVector{P}\n) where {P}\n\ncompute the gradient of the discretized acceleration of a composite B√©zier curve on the Manifold M with respect to its control points B together with a data term that relates the junction points p_i to the data d with a weight Œª compared to the acceleration. The curve is evaluated at the points given in pts (elementwise in 0N), where N is the number of segments of the B√©zier curve. The summands are grad_distance for the data term and grad_acceleration_bezier for the acceleration with interpolation constrains. Here the get_bezier_junctions are included in the optimization, i.e. setting Œª=0 yields the unconstrained acceleration minimization. Note that this is ill-posed, since any B√©zier curve identical to a geodesic is a minimizer.\n\nNote that the Bezi√©r-curve is given in reduces form as a point on a PowerManifold, together with the degrees of the segments and assuming a differentiable curve, the segments can internally be reconstructed.\n\nSee also\n\ngrad_acceleration_bezier, cost_L2_acceleration_bezier, cost_acceleration_bezier.\n\n\n\n\n\n","category":"method"},{"location":"functions/gradients/#Manopt.grad_TV","page":"Gradients","title":"Manopt.grad_TV","text":"X = grad_TV(M, Œª, x[, p=1])\ngrad_TV!(M, X, Œª, x[, p=1])\n\nCompute the (sub)gradient partial F of all forward differences occurring, in the power manifold array, i.e. of the function\n\nF(x) = sum_isum_j  mathcal I_i d^p(x_ix_j)\n\nwhere i runs over all indices of the PowerManifold manifold M and mathcal I_i denotes the forward neighbors of i.\n\nInput\n\nM ‚Äì a PowerManifold manifold\nx ‚Äì a point.\n\nOuput\n\nX ‚Äì resulting tangent vector in T_xmathcal M. The computation can also be done in place.\n\n\n\n\n\n","category":"function"},{"location":"functions/gradients/#Manopt.grad_TV-Union{Tuple{T}, Tuple{AbstractManifold, Tuple{T, T}}, Tuple{AbstractManifold, Tuple{T, T}, Any}} where T","page":"Gradients","title":"Manopt.grad_TV","text":"X = grad_TV(M, (x,y)[, p=1])\ngrad_TV!(M, X, (x,y)[, p=1])\n\ncompute the (sub) gradient of frac1pd^p_mathcal M(xy) with respect to both x and y (in place of X and Y).\n\n\n\n\n\n","category":"method"},{"location":"functions/gradients/#Manopt.grad_TV2","page":"Gradients","title":"Manopt.grad_TV2","text":"grad_TV2(M::PowerManifold, q[, p=1])\n\ncomputes the (sub) gradient of frac1pd_2^p(q_1q_2q_3) with respect to all q_1q_2q_3 occurring along any array dimension in the point q, where M is the corresponding PowerManifold.\n\n\n\n\n\n","category":"function"},{"location":"functions/gradients/#Manopt.grad_TV2-2","page":"Gradients","title":"Manopt.grad_TV2","text":"Y = grad_TV2(M, q[, p=1])\ngrad_TV2!(M, Y, q[, p=1])\n\ncomputes the (sub) gradient of frac1pd_2^p(q_1 q_2 q_3) with respect to all three components of qmathcal M^3, where d_2 denotes the second order absolute difference using the mid point model, i.e. let\n\nmathcal C = bigl c  mathcal M   g(tfrac12q_1q_3) text for some geodesic gbigr\n\ndenote the mid points between q_1 and q_3 on the manifold mathcal M. Then the absolute second order difference is defined as\n\nd_2(q_1q_2q_3) = min_c  mathcal C_q_1q_3 d(c q_2)\n\nWhile the (sub)gradient with respect to q_2 is easy, the other two require the evaluation of an adjoint_Jacobi_field.\n\n\n\n\n\n","category":"function"},{"location":"functions/gradients/#Manopt.grad_acceleration_bezier-Tuple{AbstractManifold, AbstractVector, AbstractVector{<:Integer}, AbstractVector}","page":"Gradients","title":"Manopt.grad_acceleration_bezier","text":"grad_acceleration_bezier(\n    M::AbstractManifold,\n    B::AbstractVector,\n    degrees::AbstractVector{<:Integer}\n    T::AbstractVector\n)\n\ncompute the gradient of the discretized acceleration of a (composite) B√©zier curve c_B(t) on the Manifold M with respect to its control points B given as a point on the PowerManifold assuming C1 conditions and known degrees. The curve is evaluated at the points given in T (elementwise in 0N, where N is the number of segments of the B√©zier curve). The get_bezier_junctions are fixed for this gradient (interpolation constraint). For the unconstrained gradient, see grad_L2_acceleration_bezier and set Œª=0 therein. This gradient is computed using adjoint_Jacobi_fields. For details, see [BergmannGousenbourger2018]. See de_casteljau for more details on the curve.\n\nSee also\n\ncost_acceleration_bezier,  grad_L2_acceleration_bezier, cost_L2_acceleration_bezier.\n\n[BergmannGousenbourger2018]: Bergmann, R. and Gousenbourger, P.-Y.: A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve. Frontiers in Applied Mathematics and Statistics (2018). doi 10.3389/fams.2018.00059, arXiv: 1807.10090\n\n\n\n\n\n","category":"method"},{"location":"functions/gradients/#Manopt.grad_distance","page":"Gradients","title":"Manopt.grad_distance","text":"grad_distance(M,y,x[, p=2])\ngrad_distance!(M,X,y,x[, p=2])\n\ncompute the (sub)gradient of the distance (squared), in place of X.\n\nf(x) = frac1p d^p_mathcal M(xy)\n\nto a fixed point y on the manifold M and p is an integer. The gradient reads\n\n  operatornamegradf(x) = -d_mathcal M^p-2(xy)log_xy\n\nfor pneq 1 or xneq  y. Note that for the remaining case p=1, x=y the function is not differentiable. In this case, the function returns the corresponding zero tangent vector, since this is an element of the subdifferential.\n\nOptional\n\np ‚Äì (2) the exponent of the distance,  i.e. the default is the squared distance\n\n\n\n\n\n","category":"function"},{"location":"functions/gradients/#Manopt.grad_intrinsic_infimal_convolution_TV12-Tuple{AbstractManifold, Vararg{Any, 5}}","page":"Gradients","title":"Manopt.grad_intrinsic_infimal_convolution_TV12","text":"grad_u,‚Å† grad_v = grad_intrinsic_infimal_convolution_TV12(M, f, u, v, Œ±, Œ≤)\n\ncompute (sub)gradient of the intrinsic infimal convolution model using the mid point model of second order differences, see costTV2, i.e. for some f  mathcal M on a PowerManifold manifold mathcal M this function computes the (sub)gradient of\n\nE(uv) =\nfrac12sum_i  mathcal G d_mathcal M(g(frac12v_iw_i)f_i)\n+ alpha\nbigl(\nŒ≤mathrmTV(v) + (1-Œ≤)mathrmTV_2(w)\nbigr)\n\nwhere both total variations refer to the intrinsic ones, grad_TV and grad_TV2, respectively.\n\n\n\n\n\n","category":"method"},{"location":"extensions/#Extensions","page":"Extensions","title":"Extensions","text":"","category":"section"},{"location":"extensions/#LineSearches.jl","page":"Extensions","title":"LineSearches.jl","text":"","category":"section"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"Manopt can be used with line search algorithms implemented in LineSearches.jl. This can be illustrated by the following example of optimizing Rosenbrock function constrained to the unit sphere.","category":"page"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"using Manopt, Manifolds, LineSearches\n\n# define objective function and its gradient\np = [1.0, 100.0]\nfunction rosenbrock(::AbstractManifold, x)\n    val = zero(eltype(x))\n    for i in 1:(length(x) - 1)\n        val += (p[1] - x[i])^2 + p[2] * (x[i + 1] - x[i]^2)^2\n    end\n    return val\nend\nfunction rosenbrock_grad!(M::AbstractManifold, storage, x)\n    storage .= 0.0\n    for i in 1:(length(x) - 1)\n        storage[i] += -2.0 * (p[1] - x[i]) - 4.0 * p[2] * (x[i + 1] - x[i]^2) * x[i]\n        storage[i + 1] += 2.0 * p[2] * (x[i + 1] - x[i]^2)\n    end\n    project!(M, storage, x, storage)\n    return storage\nend\n# define constraint\nn_dims = 5\nM = Manifolds.Sphere(n_dims)\n# set initial point\nx0 = vcat(zeros(n_dims - 1), 1.0)\n# use LineSearches.jl HagerZhang method with Manopt.jl quasiNewton solver\nls_hz = Manopt.LineSearchesStepsize(M, LineSearches.HagerZhang())\nx_opt = quasi_Newton(\n    M,\n    rosenbrock,\n    rosenbrock_grad!,\n    x0;\n    stepsize=ls_hz,\n    evaluation=InplaceEvaluation(),\n    stopping_criterion=StopAfterIteration(1000) | StopWhenGradientNormLess(1e-6),\n    return_state=true,\n)","category":"page"},{"location":"extensions/","page":"Extensions","title":"Extensions","text":"Manopt.LineSearchesStepsize","category":"page"},{"location":"extensions/#Manopt.LineSearchesStepsize","page":"Extensions","title":"Manopt.LineSearchesStepsize","text":"LineSearchesStepsize <: Stepsize\n\nWrapper for line searches available in the LineSearches.jl library.\n\nConstructors\n\nLineSearchesStepsize(\n    M::AbstractManifold,\n    linesearch;\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M),\n    vector_transport_method::AbstractVectorTransportMethod=default_vector_transport_method(M),\n)\nLineSearchesStepsize(\n    linesearch;\n    retraction_method::AbstractRetractionMethod=ExponentialRetraction(),\n    vector_transport_method::AbstractVectorTransportMethod=ParallelTransport(),\n)\n\nWrap linesearch (for example HagerZhang or MoreThuente). The initial step selection from Lineseaches.jl is not yet supported and the value 1.0 is used. The retraction used for determining the line along which the search is performed can be  provided as retraction_method. Gradient vectors are transported between points using vector_transport_method.\n\n\n\n\n\n","category":"type"},{"location":"functions/bezier/#BezierCurves","page":"B√©zier curves","title":"B√©zier curves","text":"","category":"section"},{"location":"functions/bezier/","page":"B√©zier curves","title":"B√©zier curves","text":"Modules = [Manopt]\nPages   = [\"bezier_curves.jl\"]","category":"page"},{"location":"functions/bezier/#Manopt.BezierSegment","page":"B√©zier curves","title":"Manopt.BezierSegment","text":"BezierSegment\n\nA type to capture a Bezier segment. With n points, a Bezi√©r segment of degree n-1 is stored. On the Euclidean manifold, this yields a polynomial of degree n-1.\n\nThis type is mainly used to encapsulate the points within a composite Bezier curve, which consist of an AbstractVector of BezierSegments where each of the points might be a nested array on a PowerManifold already.\n\nNot that this can also be used to represent tangent vectors on the control points of a segment.\n\nSee also: de_casteljau.\n\nConstructor\n\nBezierSegment(pts::AbstractVector)\n\nGiven an abstract vector of pts generate the corresponding B√©zier segment.\n\n\n\n","category":"type"},{"location":"functions/bezier/#Manopt.de_casteljau-Tuple{AbstractManifold, Vararg{Any}}","page":"B√©zier curves","title":"Manopt.de_casteljau","text":"de_casteljau(M::AbstractManifold, b::BezierSegment NTuple{N,P}) -> Function\n\nreturn the B√©zier curve Œ≤(b_0b_n) 01  mathcal M defined by the control points b_0b_nmathcal M, nmathbb N, as a BezierSegment. This function implements de Casteljau's algorithm[Casteljau1959][Casteljau1963] gneralized to manifolds[PopielNoakes2007]: Let Œ≥_ab(t) denote the shortest geodesic connecting abmathcal M. Then the curve is defined by the recursion\n\nbeginaligned\n    Œ≤(tb_0b_1) = gamma_b_0b_1(t)\n    Œ≤(tb_0b_n) = gamma_Œ≤(tb_0b_n-1) Œ≤(tb_1b_n)(t)\nendaligned\n\nand P is the type of a point on the Manifold M.\n\nde_casteljau(M::AbstractManifold, B::AbstractVector{<:BezierSegment}) -> Function\n\nGiven a vector of B√©zier segments, i.e. a vector of control points B=bigl( (b_00b_n_00)(b_0m b_n_mm) bigr), where the different segments might be of different degree(s) n_0n_m. The resulting composite B√©zier curve c_B0m  mathcal M consists of m segments which are B√©zier curves.\n\nc_B(t) =\n    begincases\n        Œ≤(t b_00b_n_00)  text if  t 01\n        Œ≤(t-i b_0ib_n_ii)  text if \n            t(ii+1 quad i1m-1\n    endcases\n\nde_casteljau(M::AbstractManifold, b::BezierSegment, t::Real)\nde_casteljau(M::AbstractManifold, B::AbstractVector{<:BezierSegment}, t::Real)\nde_casteljau(M::AbstractManifold, b::BezierSegment, T::AbstractVector) -> AbstractVector\nde_casteljau(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    T::AbstractVector\n) -> AbstractVector\n\nEvaluate the B√©zier curve at time t or at times t in T.\n\n[Casteljau1959]: de Casteljau, P.: Outillage methodes calcul, Enveloppe Soleau 40.040 (1959), Institute National de la ProprieÃÅteÃÅ Industrielle, Paris.\n\n[Casteljau1963]: de Casteljau, P.: Courbes et surfaces aÃÄ poÃÇles, Microfiche P 4147-1, AndreÃÅ CitroeÃàn Automobile SA, Paris, (1963).\n\n[PopielNoakes2007]: Popiel, T. and Noakes, L.: B√©zier curves and C^2 interpolation in Riemannian manifolds. Journal of Approximation Theory (2007), 148(2), pp. 111‚Äì127.- doi: 10.1016/j.jat.2007.03.002.\n\n\n\n\n\n","category":"method"},{"location":"functions/bezier/#Manopt.get_bezier_degree-Tuple{AbstractManifold, BezierSegment}","page":"B√©zier curves","title":"Manopt.get_bezier_degree","text":"get_bezier_degree(M::AbstractManifold, b::BezierSegment)\n\nreturn the degree of the B√©zier curve represented by the tuple b of control points on the manifold M, i.e. the number of points minus 1.\n\n\n\n\n\n","category":"method"},{"location":"functions/bezier/#Manopt.get_bezier_degrees-Tuple{AbstractManifold, AbstractVector{<:BezierSegment}}","page":"B√©zier curves","title":"Manopt.get_bezier_degrees","text":"get_bezier_degrees(M::AbstractManifold, B::AbstractVector{<:BezierSegment})\n\nreturn the degrees of the components of a composite B√©zier curve represented by tuples in B containing points on the manifold M.\n\n\n\n\n\n","category":"method"},{"location":"functions/bezier/#Manopt.get_bezier_inner_points-Tuple{AbstractManifold, AbstractVector{<:BezierSegment}}","page":"B√©zier curves","title":"Manopt.get_bezier_inner_points","text":"get_bezier_inner_points(M::AbstractManifold, B::AbstractVector{<:BezierSegment} )\nget_bezier_inner_points(M::AbstractManifold, b::BezierSegment)\n\nreturns the inner (i.e. despite start and end) points of the segments of the composite B√©zier curve specified by the control points B. For a single segment b, its inner points are returned\n\n\n\n\n\n","category":"method"},{"location":"functions/bezier/#Manopt.get_bezier_junction_tangent_vectors-Tuple{AbstractManifold, AbstractVector{<:BezierSegment}}","page":"B√©zier curves","title":"Manopt.get_bezier_junction_tangent_vectors","text":"get_bezier_junction_tangent_vectors(M::AbstractManifold, B::AbstractVector{<:BezierSegment})\nget_bezier_junction_tangent_vectors(M::AbstractManifold, b::BezierSegment)\n\nreturns the tangent vectors at start and end points of the composite B√©zier curve pointing from a junction point to the first and last inner control points for each segment of the composite Bezier curve specified by the control points B, either a vector of segments of controlpoints.\n\n\n\n\n\n","category":"method"},{"location":"functions/bezier/#Manopt.get_bezier_junctions","page":"B√©zier curves","title":"Manopt.get_bezier_junctions","text":"get_bezier_junctions(M::AbstractManifold, B::AbstractVector{<:BezierSegment})\nget_bezier_junctions(M::AbstractManifold, b::BezierSegment)\n\nreturns the start and end point(s) of the segments of the composite B√©zier curve specified by the control points B. For just one segment b, its start and end points are returned.\n\n\n\n\n\n","category":"function"},{"location":"functions/bezier/#Manopt.get_bezier_points","page":"B√©zier curves","title":"Manopt.get_bezier_points","text":"get_bezier_points(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    reduce::Symbol=:default\n)\nget_bezier_points(M::AbstractManifold, b::BezierSegment, reduce::Symbol=:default)\n\nreturns the control points of the segments of the composite B√©zier curve specified by the control points B, either a vector of segments of controlpoints or a.\n\nThis method reduces the points depending on the optional reduce symbol\n\n:default ‚Äì no reduction is performed\n:continuous ‚Äì for a continuous function, the junction points are doubled at b_0i=b_n_i-1i-1, so only b_0i is in the vector.\n:differentiable ‚Äì for a differentiable function additionally log_b_0ib_1i = -log_b_n_i-1i-1b_n_i-1-1i-1 holds. hence b_n_i-1-1i-1 is ommited.\n\nIf only one segment is given, all points of b ‚Äì i.e. b.pts is returned.\n\n\n\n\n\n","category":"function"},{"location":"functions/bezier/#Manopt.get_bezier_segments-Union{Tuple{P}, Tuple{AbstractManifold, Vector{P}, Any}, Tuple{AbstractManifold, Vector{P}, Any, Symbol}} where P","page":"B√©zier curves","title":"Manopt.get_bezier_segments","text":"get_bezier_segments(M::AbstractManifold, c::AbstractArray{P}, d[, s::Symbol=:default])\n\nreturns the array of BezierSegments B of a composite B√©zier curve reconstructed from an array c of points on the manifold M and an array of degrees d.\n\nThere are a few (reduced) representations that can get extended; see also get_bezier_points. For ease of the following, let c=(c_1c_k) and d=(d_1d_m), where m denotes the number of components the composite B√©zier curve consists of. Then\n\n:default ‚Äì k = m + sum_i=1^m d_i since each component requires one point more than its degree. The points are then ordered in tuples, i.e.\nB = bigl c_1c_d_1+1 (c_d_1+2c_d_1+d_2+2 c_k-m+1+d_mc_k bigr\n:continuous ‚Äì k = 1+ sum_i=1m d_i, since for a continuous curve start and end point of successive components are the same, so the very first start point and the end points are stored.\nB = bigl c_1c_d_1+1 c_d_1+1c_d_1+d_2+1 c_k-1+d_mb_k) bigr\n:differentiable ‚Äì for a differentiable function additionally to the last explanation, also the second point of any segment was not stored except for the first segment. Hence k = 2 - m + sum_i=1m d_i and at a junction point b_n with its given prior point c_n-1, i.e. this is the last inner point of a segment, the first inner point in the next segment the junction is computed as b = exp_c_n(-log_c_n c_n-1) such that the assumed differentiability holds\n\n\n\n\n\n","category":"method"},{"location":"functions/bezier/#Literature","page":"B√©zier curves","title":"Literature","text":"","category":"section"},{"location":"solvers/subgradient/#SubgradientSolver","page":"Subgradient method","title":"Subgradient Method","text":"","category":"section"},{"location":"solvers/subgradient/","page":"Subgradient method","title":"Subgradient method","text":"subgradient_method\nsubgradient_method!","category":"page"},{"location":"solvers/subgradient/#Manopt.subgradient_method","page":"Subgradient method","title":"Manopt.subgradient_method","text":"subgradient_method(M, f, ‚àÇf, p; kwargs...)\nsubgradient_method(M; sgo, p; kwargs...)\n\nperform a subgradient method p_k+1 = mathrmretr(p_k s_kf(p_k)),\n\nwhere mathrmretr is a retraction, s_k is a step size, usually the ConstantStepsize but also be specified. Though the subgradient might be set valued, the argument ‚àÇf should always return one element from the subgradient, but not necessarily deterministic.\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function fmathcal M‚Ñù to minimize\n‚àÇf‚Äì the (sub)gradient partial f mathcal M Tmathcal M of F restricted to always only returning one value/element from the subgradient. This function can be passed as an allocation function (M, p) -> X or a mutating function (M, X, p) -> X, see evaluation.\np ‚Äì an initial value p_0=p  mathcal M\n\nalternatively to f and ‚àÇf a ManifoldSubgradientObjective sgo can be provided.\n\nOptional\n\nevaluation ‚Äì (AllocatingEvaluation) specify whether the subgradient works by  allocation (default) form ‚àÇF(M, y) or InplaceEvaluation in place, i.e. is  of the form ‚àÇF!(M, X, x).\nstepsize ‚Äì (ConstantStepsize(M)) specify a Stepsize\nretraction ‚Äì (default_retraction_method(M, typeof(p))) a retraction to use.\nstopping_criterion ‚Äì (StopAfterIteration(5000)) a functor, seeStoppingCriterion, indicating when to stop.\n\nand the ones that are passed to decorate_state! for decorators.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/subgradient/#Manopt.subgradient_method!","page":"Subgradient method","title":"Manopt.subgradient_method!","text":"subgradient_method!(M, f, ‚àÇf, p)\nsubgradient_method!(M, sgo, p)\n\nperform a subgradient method p_k+1 = mathrmretr(p_k s_kf(p_k)),\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function fmathcal M‚Ñù to minimize\n‚àÇf‚Äì the (sub)gradient partial f mathcal M Tmathcal M of F restricted to always only returning one value/element from the subgradient. This function can be passed as an allocation function (M, p) -> X or a mutating function (M, X, p) -> X, see evaluation.\np ‚Äì an initial value p_0=p  mathcal M\n\nalternatively to f and ‚àÇf a ManifoldSubgradientObjective sgo can be provided.\n\nfor more details and all optional parameters, see subgradient_method.\n\n\n\n\n\n","category":"function"},{"location":"solvers/subgradient/#State","page":"Subgradient method","title":"State","text":"","category":"section"},{"location":"solvers/subgradient/","page":"Subgradient method","title":"Subgradient method","text":"SubGradientMethodState","category":"page"},{"location":"solvers/subgradient/#Manopt.SubGradientMethodState","page":"Subgradient method","title":"Manopt.SubGradientMethodState","text":"SubGradientMethodState <: AbstractManoptSolverState\n\nstories option values for a subgradient_method solver\n\nFields\n\nretraction_method ‚Äì the retration to use within\nstepsize ‚Äì (ConstantStepsize(M)) a Stepsize\nstop ‚Äì (StopAfterIteration(5000))a [StoppingCriterion`](@ref)\np ‚Äì (initial or current) value the algorithm is at\np_star ‚Äì optimal value (initialized to a copy of p.)\nX (zero_vector(M, p)) the current element from the possible subgradients at  p that was last evaluated.\n\nConstructor\n\nSubGradientMethodState(M::AbstractManifold, p; kwargs...)\n\nwith keywords for all fields above besides p_star which obtains the same type as p. You can use e.g. X= to specify the type of tangent vector to use\n\n\n\n\n\n","category":"type"},{"location":"solvers/subgradient/","page":"Subgradient method","title":"Subgradient method","text":"For DebugActions and RecordActions to record (sub)gradient, its norm and the step sizes, see the steepest Descent actions.","category":"page"},{"location":"functions/#Functions","page":"Introduction","title":"Functions","text":"","category":"section"},{"location":"functions/","page":"Introduction","title":"Introduction","text":"There are several functions required within optimization, most prominently costFunctions and gradients. This package includes several cost functions and corresponding gradients, but also corresponding proximal maps for variational methods manifold-valued data. Most of these functions require the evaluation of Differentials or their adjointss.","category":"page"},{"location":"functions/differentials/#DifferentialFunctions","page":"Differentials","title":"Differentials","text":"","category":"section"},{"location":"functions/differentials/","page":"Differentials","title":"Differentials","text":"Modules = [Manopt]\nPages   = [\"functions/differentials.jl\"]","category":"page"},{"location":"functions/differentials/#Manopt.differential_bezier_control-Tuple{AbstractManifold, AbstractVector{<:BezierSegment}, AbstractVector, AbstractVector{<:BezierSegment}}","page":"Differentials","title":"Manopt.differential_bezier_control","text":"differential_bezier_control(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    T::AbstractVector\n    Œû::AbstractVector{<:BezierSegment}\n)\ndifferential_bezier_control!(\n    M::AbstractManifold,\n    Œò::AbstractVector{<:BezierSegment}\n    B::AbstractVector{<:BezierSegment},\n    T::AbstractVector\n    Œû::AbstractVector{<:BezierSegment}\n)\n\nevaluate the differential of the composite B√©zier curve with respect to its control points B and tangent vectors Œû in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at the points in T, which are elementwise in 0N, and each depending the corresponding segment(s). Here, N is the length of B. For the mutating variant the result is computed in Œò.\n\nSee de_casteljau for more details on the curve and [BergmannGousenbourger2018].\n\n[BergmannGousenbourger2018]: Bergmann, R. and Gousenbourger, P.-Y.: A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve. Frontiers in Applied Mathematics and Statistics, 2018. doi: 10.3389/fams.2018.00059, arXiv: 1807.10090\n\n\n\n\n\n","category":"method"},{"location":"functions/differentials/#Manopt.differential_bezier_control-Tuple{AbstractManifold, AbstractVector{<:BezierSegment}, Any, AbstractVector{<:BezierSegment}}","page":"Differentials","title":"Manopt.differential_bezier_control","text":"differential_bezier_control(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X::AbstractVector{<:BezierSegment}\n)\ndifferential_bezier_control!(\n    M::AbstractManifold,\n    Y::AbstractVector{<:BezierSegment}\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X::AbstractVector{<:BezierSegment}\n)\n\nevaluate the differential of the composite B√©zier curve with respect to its control points B and tangent vectors Œû in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at t0N, which depends only on the corresponding segment. Here, N is the length of B. The computation can be done in place of Y.\n\nSee de_casteljau for more details on the curve.\n\n\n\n\n\n","category":"method"},{"location":"functions/differentials/#Manopt.differential_bezier_control-Tuple{AbstractManifold, BezierSegment, AbstractVector, BezierSegment}","page":"Differentials","title":"Manopt.differential_bezier_control","text":"differential_bezier_control(\n    M::AbstractManifold,\n    b::BezierSegment,\n    T::AbstractVector,\n    X::BezierSegment,\n)\ndifferential_bezier_control!(\n    M::AbstractManifold,\n    Y,\n    b::BezierSegment,\n    T::AbstractVector,\n    X::BezierSegment,\n)\n\nevaluate the differential of the B√©zier curve with respect to its control points b and tangent vectors X in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at the points T, elementwise in t01. The computation can be done in place of Y.\n\nSee de_casteljau for more details on the curve.\n\n\n\n\n\n","category":"method"},{"location":"functions/differentials/#Manopt.differential_bezier_control-Tuple{AbstractManifold, BezierSegment, Any, BezierSegment}","page":"Differentials","title":"Manopt.differential_bezier_control","text":"differential_bezier_control(M::AbstractManifold, b::BezierSegment, t::Float, X::BezierSegment)\ndifferential_bezier_control!(\n    M::AbstractManifold,\n    Y,\n    b::BezierSegment,\n    t,\n    X::BezierSegment\n)\n\nevaluate the differential of the B√©zier curve with respect to its control points b and tangent vectors X given in the tangent spaces of the control points. The result is the ‚Äúchange‚Äù of the curve at t01. The computation can be done in place of Y.\n\nSee de_casteljau for more details on the curve.\n\n\n\n\n\n","category":"method"},{"location":"functions/differentials/#Manopt.differential_forward_logs-Tuple{PowerManifold, Any, Any}","page":"Differentials","title":"Manopt.differential_forward_logs","text":"Y = differential_forward_logs(M, p, X)\ndifferential_forward_logs!(M, Y, p, X)\n\ncompute the differential of forward_logs F on the PowerManifold manifold M at p and direction X , in the power manifold array, the differential of the function\n\nF_i(x) = sum_j  mathcal I_i log_p_i p_j quad i  mathcal G\n\nwhere mathcal G is the set of indices of the PowerManifold manifold M and mathcal I_i denotes the forward neighbors of i.\n\nInput\n\nM     ‚Äì a PowerManifold manifold\np     ‚Äì a point.\nX     ‚Äì a tangent vector.\n\nOuput\n\nY ‚Äì resulting tangent vector in T_xmathcal N representing the differentials of the   logs, where mathcal N is the power manifold with the number of dimensions added   to size(x). The computation can also be done in place.\n\n\n\n\n\n","category":"method"},{"location":"solvers/augmented_Lagrangian_method/#AugmentedLagrangianSolver","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/augmented_Lagrangian_method/","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"  augmented_Lagrangian_method\n  augmented_Lagrangian_method!","category":"page"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method","page":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method","text":"augmented_Lagrangian_method(M, f, grad_f, p=rand(M); kwargs...)\naugmented_Lagrangian_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\n\nperform the augmented Lagrangian method (ALM)[LiuBoumal2020]. The aim of the ALM is to find the solution of the constrained optimisation task\n\nbeginaligned\nmin_p mathcalM f(p)\ntextsubject to  g_i(p)leq 0 quad text for  i= 1  m\nquad h_j(p)=0 quad text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^m and h_j_j=1^p are twice continuously differentiable functions from M to ‚Ñù. In every step k of the algorithm, the AugmentedLagrangianCost mathcalL_œÅ^(k-1)(p Œº^(k-1) Œª^(k-1)) is minimized on mathcalM, where Œº^(k-1) in mathbb R^n and Œª^(k-1) in mathbb R^m are the current iterates of the Lagrange multipliers and œÅ^(k-1) is the current penalty parameter.\n\nThe Lagrange multipliers are then updated by\n\nŒª_j^(k) =operatornameclip_Œª_minŒª_max (Œª_j^(k-1) + œÅ^(k-1) h_j(p^(k))) textfor all j=1p\n\nand\n\nŒº_i^(k) =operatornameclip_0Œº_max (Œº_i^(k-1) + œÅ^(k-1) g_i(p^(k))) text for all  i=1m\n\nwhere Œª_min leq Œª_max and Œº_max are the multiplier boundaries.\n\nNext, we update the accuracy tolerance œµ by setting\n\nœµ^(k)=maxœµ_min Œ∏_œµ œµ^(k-1)\n\nwhere œµ_min is the lowest value œµ is allowed to become and Œ∏_œµ  (01) is constant scaling factor.\n\nLast, we update the penalty parameter œÅ. For this, we define\n\nœÉ^(k)=max_j=1p i=1m h_j(p^(k)) max_i=1mg_i(p^(k)) -fracŒº_i^(k-1)œÅ^(k-1)  \n\nThen, we update œÅ according to\n\nœÅ^(k) = begincases\nœÅ^(k-1)Œ∏_œÅ   textif  œÉ^(k)leq Œ∏_œÅ œÉ^(k-1) \nœÅ^(k-1)  textelse\nendcases\n\nwhere Œ∏_œÅ in (01) is a constant scaling factor.\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function Fmathcal M‚Ñù to minimize\ngrad_f ‚Äì the gradient of the cost function\n\nOptional (if not called with the ConstrainedManifoldObjective cmo)\n\ng ‚Äì (nothing) the inequality constraints\nh ‚Äì (nothing) the equality constraints\ngrad_g ‚Äì (nothing) the gradient of the inequality constraints\ngrad_h ‚Äì (nothing) the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be proviede. Otherwise the problem is not constrained and you can also call e.g. quasi_Newton\n\nOptional\n\nœµ ‚Äì (1e-3) the accuracy tolerance\nœµ_min ‚Äì (1e-6) the lower bound for the accuracy tolerance\nœµ_exponent ‚Äì (1/100) exponent of the œµ update factor;  also 1/number of iterations until maximal accuracy is needed to end algorithm naturally\nŒ∏_œµ ‚Äì ((œµ_min / œµ)^(œµ_exponent)) the scaling factor of the exactness\nŒº ‚Äì (ones(size(h(M,x),1))) the Lagrange multiplier with respect to the inequality constraints\nŒº_max ‚Äì (20.0) an upper bound for the Lagrange multiplier belonging to the inequality constraints\nŒª ‚Äì (ones(size(h(M,x),1))) the Lagrange multiplier with respect to the equality constraints\nŒª_max ‚Äì (20.0) an upper bound for the Lagrange multiplier belonging to the equality constraints\nŒª_min ‚Äì (- Œª_max) a lower bound for the Lagrange multiplier belonging to the equality constraints\nœÑ ‚Äì (0.8) factor for the improvement of the evaluation of the penalty parameter\nœÅ ‚Äì (1.0) the penalty parameter\nŒ∏_œÅ ‚Äì (0.3) the scaling factor of the penalty parameter\nsub_cost ‚Äì (AugmentedLagrangianCost(problem, œÅ, Œº, Œª)) use augmented Lagranian, expecially with the same numbers œÅ,Œº as in the options for the sub problem\nsub_grad ‚Äì (AugmentedLagrangianGrad(problem, œÅ, Œº, Œª)) use augmented Lagranian gradient, expecially with the same numbers œÅ,Œº as in the options for the sub problem\nsub_kwargs ‚Äì keyword arguments to decorate the sub options, e.g. with debug.\nsub_stopping_criterion ‚Äì (StopAfterIteration(200) |StopWhenGradientNormLess(œµ) |StopWhenStepsizeLess(1e-8)) specify a stopping criterion for the subsolver.\nsub_problem ‚Äì (DefaultManoptProblem(M,ConstrainedManifoldObjective(subcost, subgrad; evaluation=evaluation))) problem for the subsolver\nsub_state ‚Äì (QuasiNewtonState) using QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS and sub_stopping_criterion as a stopping criterion. See also sub_kwargs.\nstopping_criterion ‚Äì (StopAfterIteration(300) | (StopWhenSmallerOrEqual(œµ, œµ_min) & StopWhenChangeLess(1e-10))) a functor inheriting from StoppingCriterion indicating when to stop.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n[LiuBoumal2020]: C. Liu, N. Boumal, Simple Algorithms for Optimization on Riemannian Manifolds with Constraints, In: Applied Mathematics & Optimization, vol 82, 949‚Äì981 (2020), doi 10.1007/s00245-019-09564-3, arXiv: 1901.10000 Matlab source: https://github.com/losangle/Optimization-on-manifolds-with-extra-constraints\n\n\n\n\n\n","category":"function"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.augmented_Lagrangian_method!","page":"Augmented Lagrangian Method","title":"Manopt.augmented_Lagrangian_method!","text":"augmented_Lagrangian_method!(M, f, grad_f p=rand(M); kwargs...)\n\nperform the augmented Lagrangian method (ALM) in-place of p.\n\nFor all options, see augmented_Lagrangian_method.\n\n\n\n\n\n","category":"function"},{"location":"solvers/augmented_Lagrangian_method/#State","page":"Augmented Lagrangian Method","title":"State","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"AugmentedLagrangianMethodState","category":"page"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianMethodState","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianMethodState","text":"AugmentedLagrangianMethodState{P,T} <: AbstractManoptSolverState\n\nDescribes the augmented Lagrangian method, with\n\nFields\n\na default value is given in brackets if a parameter can be left out in initialization.\n\np ‚Äì a point on a manifold as starting point and current iterate\nsub_problem ‚Äì an AbstractManoptProblem problem for the subsolver\nsub_state ‚Äì an AbstractManoptSolverState for the subsolver\nœµ ‚Äì (1e‚Äì3) the accuracy tolerance\nœµ_min ‚Äì (1e-6) the lower bound for the accuracy tolerance\nŒª ‚Äì (ones(len(get_equality_constraints(p,x))) the Lagrange multiplier with respect to the equality constraints\nŒª_max ‚Äì (20.0) an upper bound for the Lagrange multiplier belonging to the equality constraints\nŒª_min ‚Äì (- Œª_max) a lower bound for the Lagrange multiplier belonging to the equality constraints\nŒº ‚Äì (ones(len(get_inequality_constraints(p,x))) the Lagrange multiplier with respect to the inequality constraints\nŒº_max ‚Äì (20.0) an upper bound for the Lagrange multiplier belonging to the inequality constraints\nœÅ ‚Äì (1.0) the penalty parameter\nœÑ ‚Äì (0.8) factor for the improvement of the evaluation of the penalty parameter\nŒ∏_œÅ ‚Äì (0.3) the scaling factor of the penalty parameter\nŒ∏_œµ ‚Äì ((œµ_min/œµ)^(œµ_exponent)) the scaling factor of the accuracy tolerance\npenalty ‚Äì evaluation of the current penalty term, initialized to Inf.\nstopping_criterion ‚Äì ((StopAfterIteration(300) | (StopWhenSmallerOrEqual(œµ, œµ_min) &StopWhenChangeLess(1e-10))) a functor inheriting from StoppingCriterion indicating when to stop.\n\nConstructor\n\nAugmentedLagrangianMethodState(M::AbstractManifold, co::ConstrainedManifoldObjective, p; kwargs...)\n\nconstruct an augmented Lagrangian method options with the fields and defaults as above, where the manifold M and the ConstrainedManifoldObjective co are used for defaults in the keyword arguments.\n\nSee also\n\naugmented_Lagrangian_method\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Helping-Functions","page":"Augmented Lagrangian Method","title":"Helping Functions","text":"","category":"section"},{"location":"solvers/augmented_Lagrangian_method/","page":"Augmented Lagrangian Method","title":"Augmented Lagrangian Method","text":"AugmentedLagrangianCost\nAugmentedLagrangianGrad","category":"page"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianCost","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianCost","text":"AugmentedLagrangianCost{CO,R,T}\n\nStores the parameters œÅ  mathbb R, Œº  mathbb R^m, Œª  mathbb R^n of the augmented Lagrangian associated to the ConstrainedManifoldObjective co.\n\nThis struct is also a functor (M,p) -> v that can be used as a cost function within a solver, based on the internal ConstrainedManifoldObjective we can compute\n\nmathcal L_rho(p Œº Œª)\n= f(x) + fracœÅ2 biggl(\n    sum_j=1^n Bigl( h_j(p) + fracŒª_jœÅ Bigr)^2\n    +\n    sum_i=1^m maxBigl 0 fracŒº_iœÅ + g_i(p) Bigr^2\nBigr)\n\nFields\n\nco::CO, œÅ::R, Œº::T, Œª::T as mentioned above\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Manopt.AugmentedLagrangianGrad","page":"Augmented Lagrangian Method","title":"Manopt.AugmentedLagrangianGrad","text":"AugmentedLagrangianGrad{CO,R,T}\n\nStores the parameters œÅ  mathbb R, Œº  mathbb R^m, Œª  mathbb R^n of the augmented Lagrangian associated to the ConstrainedManifoldObjective co.\n\nThis struct is also a functor in both formats\n\n(M, p) -> X to compute the gradient in allocating fashion.\n(M, X, p) to compute the gradient in in-place fashion.\n\nbased on the internal ConstrainedManifoldObjective and computes the gradient operatornamegrad mathcal L_œÅ(p Œº Œª), see also AugmentedLagrangianCost.\n\n\n\n\n\n","category":"type"},{"location":"solvers/augmented_Lagrangian_method/#Literature","page":"Augmented Lagrangian Method","title":"Literature","text":"","category":"section"},{"location":"plans/record/#RecordSection","page":"Recording values","title":"Record values","text":"","category":"section"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"CurrentModule = Manopt","category":"page"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"To record values during the iterations of a solver run, there are in general two possibilities. On the one hand, the high-level interfaces provide a record= keyword, that accepts several different inputs. For more details see How to record.","category":"page"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"For example recording the gradient from the GradientDescentState is automatically available, as explained in the gradient_descent solver.","category":"page"},{"location":"plans/record/#RecordSolverState","page":"Recording values","title":"Record Solver States","text":"","category":"section"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"Modules = [Manopt]\nPages = [\"plans/record.jl\"]\nOrder = [:type, :function]\nPrivate = true","category":"page"},{"location":"plans/record/#Manopt.RecordAction","page":"Recording values","title":"Manopt.RecordAction","text":"RecordAction\n\nA RecordAction is a small functor to record values. The usual call is given by (amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i) -> s that performs the record, where i is the current iteration.\n\nBy convention i<=0 is interpreted as \"For Initialization only\", i.e. only initialize internal values, but not trigger any record, the same holds for i=typemin(Inf) which is used to indicate stop, i.e. that the record is called from within stop_solver! which returns true afterwards.\n\nFields (assumed by subtypes to exist)\n\nrecorded_values an Array of the recorded values.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordChange","page":"Recording values","title":"Manopt.RecordChange","text":"RecordChange <: RecordAction\n\ndebug for the amount of change of the iterate (stored in o.x of the AbstractManoptSolverState) during the last iteration.\n\nAdditional Fields\n\nstorage a StoreStateAction to store (at least) o.x to use this as the last value (to compute the change\ninverse_retraction_method - (default_inverse_retraction_method(manifold, p)) the inverse retraction to be used for approximating distance.\n\nConstructor\n\nRecordChange(M=DefaultManifold();)\n\nwith the above fields as keywords. For the DefaultManifold only the field storage is used. Providing the actual manifold moves the default storage to the efficient point storage.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordCost","page":"Recording values","title":"Manopt.RecordCost","text":"RecordCost <: RecordAction\n\nRecord the current cost function value, see get_cost.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEntry","page":"Recording values","title":"Manopt.RecordEntry","text":"RecordEntry{T} <: RecordAction\n\nrecord a certain fields entry of type {T} during the iterates\n\nFields\n\nrecorded_values ‚Äì the recorded Iterates\nfield ‚Äì Symbol the entry can be accessed with within AbstractManoptSolverState\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEntryChange","page":"Recording values","title":"Manopt.RecordEntryChange","text":"RecordEntryChange{T} <: RecordAction\n\nrecord a certain entries change during iterates\n\nAdditional Fields\n\nrecorded_values ‚Äì the recorded Iterates\nfield ‚Äì Symbol the field can be accessed with within AbstractManoptSolverState\ndistance ‚Äì function (p,o,x1,x2) to compute the change/distance between two values of the entry\nstorage ‚Äì a StoreStateAction to store (at least) getproperty(o, d.field)\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordEvery","page":"Recording values","title":"Manopt.RecordEvery","text":"RecordEvery <: RecordAction\n\nrecord only every ith iteration. Otherwise (optionally, but activated by default) just update internal tracking values.\n\nThis method does not perform any record itself but relies on it's childrens methods\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordGroup","page":"Recording values","title":"Manopt.RecordGroup","text":"RecordGroup <: RecordAction\n\ngroup a set of RecordActions into one action, where the internal RecordActions act independently, but the results can be collected in a grouped fashion, i.e. tuples per calls of this group. The enries can be later addressed either by index or semantic Symbols\n\nConstructors\n\nRecordGroup(g::Array{<:RecordAction, 1})\n\nconstruct a group consisting of an Array of RecordActions g,\n\nRecordGroup(g, symbols)\n\nExamples\n\nr = RecordGroup([RecordIteration(), RecordCost()])\n\nA RecordGroup to record the current iteration and the cost. The cost can then be accessed using get_record(r,2) or r[2].\n\nr = RecordGroup([RecordIteration(), RecordCost()], Dict(:Cost => 2))\n\nA RecordGroup to record the current iteration and the cost, wich can then be accesed using get_record(:Cost) or r[:Cost].\n\nr = RecordGroup([RecordIteration(), :Cost => RecordCost()])\n\nA RecordGroup identical to the previous constructor, just a little easier to use.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordIterate","page":"Recording values","title":"Manopt.RecordIterate","text":"RecordIterate <: RecordAction\n\nrecord the iterate\n\nConstructors\n\nRecordIterate(x0)\n\ninitialize the iterate record array to the type of x0, e.g. your initial data.\n\nRecordIterate(P)\n\ninitialize the iterate record array to the data type T.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordIteration","page":"Recording values","title":"Manopt.RecordIteration","text":"RecordIteration <: RecordAction\n\nrecord the current iteration\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordSolverState","page":"Recording values","title":"Manopt.RecordSolverState","text":"RecordSolverState <: AbstractManoptSolverState\n\nappend to any AbstractManoptSolverState the decorator with record functionality, Internally a Dictionary is kept that stores a RecordAction for several concurrent modes using a Symbol as reference. The default mode is :Iteration, which is used to store information that is recorded during the iterations. RecordActions might be added to :Start or :Stop to record values at the beginning or for the stopping time point, respectively\n\nThe original options can still be accessed using the get_state function.\n\nFields\n\noptions ‚Äì the options that are extended by debug information\nrecordDictionary ‚Äì a Dict{Symbol,RecordAction} to keep track of all different recorded values\n\nConstructors\n\nRecordSolverState(o,dR)\n\nconstruct record decorated AbstractManoptSolverState, where dR can be\n\na RecordAction, then it is stored within the dictionary at :Iteration\nan Array of RecordActions, then it is stored as a recordDictionary(@ref) within the dictionary at :All.\na Dict{Symbol,RecordAction}.\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Manopt.RecordTime","page":"Recording values","title":"Manopt.RecordTime","text":"RecordTime <: RecordAction\n\nrecord the time elapsed during the current iteration.\n\nThe three possible modes are\n\n:cumulative record times without resetting the timer\n:iterative record times with resetting the timer\n:total record a time only at the end of an algorithm (see stop_solver!)\n\nThe default is :cumulative, and any non-listed symbol default to using this mode.\n\nConstructor\n\nRecordTime(; mode::Symbol=:cumulative)\n\n\n\n\n\n","category":"type"},{"location":"plans/record/#Base.getindex-Tuple{RecordGroup, Vararg{Any}}","page":"Recording values","title":"Base.getindex","text":"getindex(r::RecordGroup, s::Symbol)\nr[s]\ngetindex(r::RecordGroup, sT::NTuple{N,Symbol})\nr[sT]\ngetindex(r::RecordGroup, i)\nr[i]\n\nreturn an array of recorded values with respect to the s, the symbols from the tuple sT or the index i. See get_record for details.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Base.getindex-Tuple{RecordSolverState, Symbol}","page":"Recording values","title":"Base.getindex","text":"get_index(rs::RecordSolverState, s::Symbol)\nro[s]\n\nGet the recorded values for reording type s, see get_record for details.\n\nget_index(rs::RecordSolverState, s::Symbol, i...)\nro[s, i...]\n\nAcces the recording type of type s and call its RecordAction with [i...].\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordActionFactory-Tuple{AbstractManoptSolverState, RecordAction}","page":"Recording values","title":"Manopt.RecordActionFactory","text":"RecordActionFactory(s)\n\ncreate a RecordAction where\n\na RecordAction is passed through\na [Symbol] creates RecordEntry of that symbol, with the exceptions of\n:Change - to recorde the change of the iterates in o.x`\n:Iterate - to record the iterate\n:Iteration - to record the current iteration numner\n:Cost - to record the current cost function value\n:Time - to record the total time taken after every iteration\n:IterativeTime ‚Äì to record the times taken for each iteration.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.RecordFactory-Tuple{AbstractManoptSolverState, Vector}","page":"Recording values","title":"Manopt.RecordFactory","text":"RecordFactory(s::AbstractManoptSolverState, a)\n\ngiven an array of Symbols and RecordActions and Ints\n\nThe symbol :Cost creates a RecordCost\nThe symbol :iteration creates a RecordIteration\nThe symbol :Change creates a RecordChange\nany other symbol creates a RecordEntry of the corresponding field in AbstractManoptSolverState\nany RecordAction is directly included\nan semantic pair :symbol => RecordAction is directly included\nan Integer k introduces that record is only performed every kth iteration\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record","page":"Recording values","title":"Manopt.get_record","text":"get_record(s::AbstractManoptSolverState, [,symbol=:Iteration])\nget_record(s::RecordSolverState, [,symbol=:Iteration])\n\nreturn the recorded values from within the RecordSolverState s that where recorded with respect to the Symbol symbol as an Array. The default refers to any recordings during an :Iteration.\n\nWhen called with arbitrary AbstractManoptSolverState, this method looks for the RecordSolverState decorator and calls get_record on the decorator.\n\n\n\n\n\n","category":"function"},{"location":"plans/record/#Manopt.get_record-Tuple{RecordAction, Any}","page":"Recording values","title":"Manopt.get_record","text":"get_record(r::RecordAction)\n\nreturn the recorded values stored within a RecordAction r.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record-Tuple{RecordGroup}","page":"Recording values","title":"Manopt.get_record","text":"get_record(r::RecordGroup)\n\nreturn an array of tuples, where each tuple is a recorded set, e.g. per iteration / record call.\n\nget_record(r::RecordGruop, i::Int)\n\nreturn an array of values corresponding to the ith entry in this record group\n\nget_record(r::RecordGruop, s::Symbol)\n\nreturn an array of recorded values with respect to the s, see RecordGroup.\n\nget_record(r::RecordGroup, s1::Symbol, s2::Symbol,...)\n\nreturn an array of tuples, where each tuple is a recorded set corresponding to the symbols s1, s2,... per iteration / record call.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.get_record_action","page":"Recording values","title":"Manopt.get_record_action","text":"get_record_action(s::AbstractManoptSolverState, s::Symbol)\n\nreturn the action contained in the (first) RecordSolverState decorator within the AbstractManoptSolverState o.\n\n\n\n\n\n","category":"function"},{"location":"plans/record/#Manopt.get_record_state-Tuple{AbstractManoptSolverState}","page":"Recording values","title":"Manopt.get_record_state","text":"get_record_state(s::AbstractManoptSolverState)\n\nreturn the RecordSolverState among the decorators from the AbstractManoptSolverState o\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.has_record-Tuple{RecordSolverState}","page":"Recording values","title":"Manopt.has_record","text":"has_record(s::AbstractManoptSolverState)\n\ncheck whether the AbstractManoptSolverStates are decorated with RecordSolverState\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.record_or_reset!-Tuple{RecordAction, Any, Int64}","page":"Recording values","title":"Manopt.record_or_reset!","text":"record_or_reset!(r,v,i)\n\neither record (i>0 and not Inf) the value v within the RecordAction r or reset (i<0) the internal storage, where v has to match the internal value type of the corresponding Recordaction.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"see recording values for details on the decorated solver.","category":"page"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"Further specific RecordActions can be found when specific types of AbstractManoptSolverState define them on their corresponding site.","category":"page"},{"location":"plans/record/#Technical-Details:-The-Record-Solver","page":"Recording values","title":"Technical Details: The Record Solver","text":"","category":"section"},{"location":"plans/record/","page":"Recording values","title":"Recording values","text":"initialize_solver!(amp::AbstractManoptProblem, rss::RecordSolverState)\nstep_solver!(p::AbstractManoptProblem, s::RecordSolverState, i)\nstop_solver!(p::AbstractManoptProblem, s::RecordSolverState, i)","category":"page"},{"location":"plans/record/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, RecordSolverState}","page":"Recording values","title":"Manopt.initialize_solver!","text":"initialize_solver!(ams::AbstractManoptProblem, rss::RecordSolverState)\n\nExtend the initialization of the solver by a hook to run records that were added to the :Start entry.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.step_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","page":"Recording values","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, i)\n\nExtend the ith step of the solver by a hook to run records, that were added to the :Iteration entry.\n\n\n\n\n\n","category":"method"},{"location":"plans/record/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, RecordSolverState, Any}","page":"Recording values","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, rss::RecordSolverState, i)\n\nExtend the check, whether to stop the solver by a hook to run records, that were added to the :Stop entry.\n\n\n\n\n\n","category":"method"},{"location":"solvers/trust_regions/#trust_regions","page":"Trust-Regions Solver","title":"The Riemannian Trust-Regions Solver","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"The aim is to solve an optimization problem on a manifold","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"operatorname*min_x    mathcalM F(x)","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"by using the Riemannian trust-regions solver. It is number one choice for smooth optimization. This trust-region method uses the Steihaug-Toint truncated conjugate-gradient method truncated_conjugate_gradient_descent to solve the inner minimization problem called the trust-regions subproblem. This inner solver can be preconditioned by providing a preconditioner (symmetric and positive deÔ¨Ånite, an approximation of the inverse of the Hessian of F). If no Hessian of the cost function F is provided, a standard approximation of the Hessian based on the gradient operatornamegradF with ApproxHessianFiniteDifference will be computed.","category":"page"},{"location":"solvers/trust_regions/#Initialization","page":"Trust-Regions Solver","title":"Initialization","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"Initialize x_0 = x with an initial point x on the manifold. It can be given by the caller or set randomly. Set the initial trust-region radius Delta =frac18 barDelta where barDelta is the maximum radius the trust-region can have. Usually one uses the root of the manifold's dimension operatornamedim(mathcalM). For accepting the next iterate and evaluating the new trust-region radius, one needs an accept/reject threshold rho    0frac14), which is rho = 01 on default. Set k=0.","category":"page"},{"location":"solvers/trust_regions/#Iteration","page":"Trust-Regions Solver","title":"Iteration","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"Repeat until a convergence criterion is reached","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"Set Œ∑ as a random tangent vector if using randomized approach. Else  set Œ∑ as the zero vector in the tangential space T_x_kmathcalM.\nSet Œ∑^* as the solution of the trust-region subproblem, computed by  the tcg-method with Œ∑ as initial vector.\nIf using randomized approach, compare Œ∑^* with the Cauchy point  Œ∑_c^* = -tau_c fracDeltalVert operatornameGradF (x_k) rVert_x_k operatornameGradF (x_k) by the model function m_x_k(). If the  model decrease is larger by using the Cauchy point, set  Œ∑^* = Œ∑_c^*.\nSet x^* = operatornameretr_x_k(Œ∑^*).\nSet rho = fracF(x_k)-F(x^*)m_x_k(Œ∑)-m_x_k(Œ∑^*), where  m_x_k() describes the quadratic model function.\nUpdate the trust-region radius:Delta = begincasesfrac14 Delta text if  rho  frac14  textor  m_x_k(Œ∑)-m_x_k(Œ∑^*) leq 0  textor   rho = pm   fty  operatornamemin(2 Delta barDelta) text if  rho  frac34  textand the tcg-method stopped because of negative curvature or exceeding the trust-regionDelta   textotherwiseendcases\nIf m_x_k(Œ∑)-m_x_k(Œ∑^*) geq 0 and rho  rho set  x_k = x^*.\nSet k = k+1.","category":"page"},{"location":"solvers/trust_regions/#Result","page":"Trust-Regions Solver","title":"Result","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"The result is given by the last computed x_k.","category":"page"},{"location":"solvers/trust_regions/#Remarks","page":"Trust-Regions Solver","title":"Remarks","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To the initialization: a random point on the manifold.","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To step number 1: using a randomized approach means using a random tangent vector as initial vector for the approximate solve of the trust-regions subproblem. If this is the case, keep in mind that the vector must be in the trust-region radius. This is achieved by multiplying Œ∑ by sqrt(4,eps(Float64)) as long as its norm is greater than the current trust-region radius Delta. For not using randomized approach, one can get the zero tangent vector.","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To step number 2: obtain Œ∑^* by (approximately) solving the trust-regions subproblem","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"operatorname*argmin_Œ∑    T_x_kmathcalM m_x_k(Œ∑) = F(x_k) +\nlangle operatornamegradF(x_k) Œ∑ rangle_x_k + frac12 langle\noperatornameHessF(Œ∑)_ x_k Œ∑ rangle_x_k","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"textst  langle Œ∑ Œ∑ rangle_x_k leq Delta^2","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"with the Steihaug-Toint truncated conjugate-gradient (tcg) method. The problem as well as the solution method is described in the truncated_conjugate_gradient_descent. In this inner solver, the stopping criterion  StopWhenResidualIsReducedByFactorOrPower so that superlinear or at least linear convergence in the trust-region method can be achieved.","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To step number 3: if using a random tangent vector as an initial vector, compare the result of the tcg-method with the Cauchy point. Convergence proofs assume that one achieves at least (a fraction of) the reduction of the Cauchy point. The idea is to go in the direction of the gradient to an optimal point. This can be on the edge, but also before. The parameter tau_c for the optimal length is defined by","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"tau_c = begincases 1  langle operatornameGradF (x_k) \noperatornameHessF (Œ∑_k)_ x_krangle_x_k leq 0  \noperatornamemin(fracoperatornamenorm(operatornameGradF (x_k))^3\nDelta langle operatornameGradF (x_k) \noperatornameHessF (Œ∑_k)_ x_krangle_x_k 1)   textotherwise\nendcases","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To check the model decrease one compares","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"m_x_k(Œ∑_c^*) = F(x_k) + langle Œ∑_c^*\noperatornameGradF (x_k)rangle_x_k + frac12langle Œ∑_c^*\noperatornameHessF (Œ∑_c^*)_ x_krangle_x_k","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"with","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"m_x_k(Œ∑^*) = F(x_k) + langle Œ∑^*\noperatornameGradF (x_k)rangle_x_k + frac12langle Œ∑^*\noperatornameHessF (Œ∑^*)_ x_krangle_x_k","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"If m_x_k(Œ∑_c^*)  m_x_k(Œ∑^*) then m_x_k(Œ∑_c^*) is the better choice.","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To step number 4: operatornameretr_x_k() denotes the retraction, a mapping operatornameretr_x_kT_x_kmathcalM rightarrow mathcalM which approximates the exponential map. In some cases it is cheaper to use this instead of the exponential.","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To step number 6: one knows that the truncated_conjugate_gradient_descent algorithm stopped for these reasons when the stopping criteria StopWhenCurvatureIsNegative, StopWhenTrustRegionIsExceeded are activated.","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"To step number 7: the last step is to decide if the new point x^* is accepted.","category":"page"},{"location":"solvers/trust_regions/#Interface","page":"Trust-Regions Solver","title":"Interface","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"trust_regions\ntrust_regions!","category":"page"},{"location":"solvers/trust_regions/#Manopt.trust_regions","page":"Trust-Regions Solver","title":"Manopt.trust_regions","text":"trust_regions(M, f, grad_f, hess_f, p)\ntrust_regions(M, f, grad_f, p)\n\nrun the Riemannian trust-regions solver for optimization on manifolds to minmize f.\n\nFor the case that no hessian is provided, the Hessian is computed using finite difference, see ApproxHessianFiniteDifference. For solving the the inner trust-region subproblem of finding an update-vector, see truncated_conjugate_gradient_descent.\n\nP.-A. Absil, C.G. Baker, K.A. Gallivan,   Trust-region methods on Riemannian manifolds, FoCM, 2007.   doi: 10.1007/s10208-005-0179-9\nA. R. Conn, N. I. M. Gould, P. L. Toint, Trust-region methods, SIAM,   MPS, 2000. doi: 10.1137/1.9780898719857\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function F  mathcal M  ‚Ñù to minimize\ngrad_f- the gradient operatornamegradF  mathcal M  T mathcal M of F\nHess_f ‚Äì (optional), the hessian operatornameHessF(x) T_xmathcal M  T_xmathcal M, X  operatornameHessF(x)X = _Œæoperatornamegradf(x)\np ‚Äì an initial value x    mathcal M\n\nOptional\n\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient and hessian work by  allocation (default) or InplaceEvaluation in place\nmax_trust_region_radius ‚Äì the maximum trust-region radius\npreconditioner ‚Äì a preconditioner (a symmetric, positive definite operator that should approximate the inverse of the Hessian)\nrandomize ‚Äì set to true if the trust-region solve is to be initiated with a random tangent vector. If set to true, no preconditioner will be used. This option is set to true in some scenarios to escape saddle points, but is otherwise seldom activated.\nproject! : (copyto!) specify a projection operation for tangent vectors within the TCG   for numerical stability. A function (M, Y, p, X) -> ... working in place of Y.   per default, no projection is perfomed, set it to project! to activate projection.\nretraction ‚Äì (default_retraction_method(M, typeof(p))) approximation of the exponential map\nstopping_criterion ‚Äì (StopWhenAny(StopAfterIteration(1000), StopWhenGradientNormLess(10^(-6))) a functor inheriting from StoppingCriterion indicating when to stop.\ntrust_region_radius - the initial trust-region radius\nœÅ_prime ‚Äì Accept/reject threshold: if œÅ (the performance ratio for the iterate) is at least œÅ', the outer iteration is accepted. Otherwise, it is rejected. In case it is rejected, the trust-region radius will have been decreased. To ensure this, œÅ' >= 0 must be strictly smaller than 1/4. If œÅ_prime is negative, the algorithm is not guaranteed to produce monotonically decreasing cost values. It is strongly recommended to set œÅ' > 0, to aid convergence.\nœÅ_regularization ‚Äì Close to convergence, evaluating the performance ratio œÅ is numerically challenging. Meanwhile, close to convergence, the quadratic model should be a good fit and the steps should be accepted. Regularization lets œÅ go to 1 as the model decrease and the actual decrease go to zero. Set this option to zero to disable regularization (not recommended). When this is not zero, it may happen that the iterates produced are not monotonically improving the cost when very close to convergence. This is because the corrected cost improvement could change sign if it is negative but very small.\nŒ∏ ‚Äì (1.0) 1+Œ∏ is the superlinear convergence target rate of the tCG-method   truncated_conjugate_gradient_descent, which computes an   approximate solution for the trust-region subproblem. The tCG-method aborts   if the residual is less than or equal to the initial residual to the power of 1+Œ∏.\nŒ∫ ‚Äì (0.1) the linear convergence target rate of the tCG-method   truncated_conjugate_gradient_descent, which computes an   approximate solution for the trust-region subproblem. The method aborts if the   residual is less than or equal to Œ∫ times the initial residual.\nreduction_threshold ‚Äì (0.1) Trust-region reduction threshold: if œÅ (the performance ratio for   the iterate) is less than this bound, the trust-region radius and thus the trust-regions   decreases.\naugmentation_threshold ‚Äì (0.75) Trust-region augmentation threshold: if œÅ (the performance ratio for   the iterate) is greater than this and further conditions apply, the trust-region radius and thus the trust-regions increases.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\nsee also\n\ntruncated_conjugate_gradient_descent\n\n\n\n\n\n","category":"function"},{"location":"solvers/trust_regions/#Manopt.trust_regions!","page":"Trust-Regions Solver","title":"Manopt.trust_regions!","text":"trust_regions!(M, f, grad_f, Hess_f, p; kwargs...)\ntrust_regions!(M, f, grad_f, p; kwargs...)\n\nevaluate the Riemannian trust-regions solver for optimization on manifolds in place of p.\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function F mathcal M  ‚Ñù to minimize\ngrad_f- the gradient operatornamegradF mathcal M  T mathcal M of F\nHess_f ‚Äì (optional) the hessian H( mathcal M x Œæ) of F\nx ‚Äì an initial value x    mathcal M\n\nFor the case that no hessian is provided, the Hessian is computed using finite difference, see ApproxHessianFiniteDifference.\n\nfor more details and all options, see trust_regions\n\n\n\n\n\n","category":"function"},{"location":"solvers/trust_regions/#State","page":"Trust-Regions Solver","title":"State","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"TrustRegionsState","category":"page"},{"location":"solvers/trust_regions/#Manopt.TrustRegionsState","page":"Trust-Regions Solver","title":"Manopt.TrustRegionsState","text":"TrustRegionsState <: AbstractHessianSolverState\n\ndescribe the trust-regions solver, with\n\nFields\n\nwhere all but p are keyword arguments in the constructor\n\np : the current iterate\nstop : (`StopAfterIteration(1000) | StopWhenGradientNormLess(1e-6))\nmax_trust_region_radius : (sqrt(manifold_dimension(M))) the maximum trust-region radius\nproject! : (copyto!) specify a projection operation for tangent vectors   for numerical stability. A function (M, Y, p, X) -> ... working in place of Y.   per default, no projection is perfomed, set it to project! to activate projection.\nrandomize : (false) indicates if the trust-region solve is to be initiated with a       random tangent vector. If set to true, no preconditioner will be       used. This option is set to true in some scenarios to escape saddle       points, but is otherwise seldom activated.\nœÅ_prime : (0.1) a lower bound of the performance ratio for the iterate that       decides if the iteration will be accepted or not. If not, the       trust-region radius will have been decreased. To ensure this,       œÅ'>= 0 must be strictly smaller than 1/4. If œÅ' is negative,       the algorithm is not guaranteed to produce monotonically decreasing       cost values. It is strongly recommended to set œÅ' > 0, to aid       convergence.\nœÅ_regularization : (10000.0) Close to convergence, evaluating the performance ratio œÅ       is numerically challenging. Meanwhile, close to convergence, the       quadratic model should be a good fit and the steps should be       accepted. Regularization lets œÅ go to 1 as the model decrease and       the actual decrease go to zero. Set this option to zero to disable       regularization (not recommended). When this is not zero, it may happen       that the iterates produced are not monotonically improving the cost       when very close to convergence. This is because the corrected cost       improvement could change sign if it is negative but very small.\ntrust_region_radius : the (initial) trust-region radius\n\nConstructor\n\nTrustRegionsState(M,\n    p=rand(M),\n    X=zero_vector(M,p),\n    sub_state=TruncatedConjugateGradientState(M, p, X),\n\n)\n\nconstruct a trust-regions Option with all other fields from above being keyword arguments\n\nSee also\n\ntrust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Approximation-of-the-Hessian","page":"Trust-Regions Solver","title":"Approximation of the Hessian","text":"","category":"section"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"We currently provide a few different methods to approximate the Hessian.","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"ApproxHessianFiniteDifference\nApproxHessianSymmetricRankOne\nApproxHessianBFGS","category":"page"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianFiniteDifference","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianFiniteDifference","text":"ApproxHessianFiniteDifference{E, P, T, G, RTR,, VTR, R <: Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by a finite difference of gradient evaluation.\n\nGiven a point p and a direction X and the gradient operatornamegradF mathcal M to Tmathcal M of a function F the Hessian is approximated as follows: Let c be a stepsize, X T_pmathcal M a tangent vector and q = operatornameretr_p(fracclVert X rVert_pX) be a step in direction X of length c following a retraction Then we approximate the Hessian by the finite difference of the gradients, where mathcal T_cdotgetscdot is a vector transport.\n\noperatornameHessF(p)X\n \nfraclVert X rVert_pcBigl( mathcal T_pgets qbigr(operatornamegradF(q)bigl) - operatornamegradF(p)Bigl)\n\nFields\n\ngradient!! the gradient function (either allocating or mutating, see evaluation parameter)\nstep_length a step length for the finite difference\nretraction_method - a retraction to use\nvector_transport_method a vector transport to use\n\nInternal temporary fields\n\ngrad_tmp a temporary storage for the gradient at the current p\ngrad_dir_tmp a temporary storage for the gradient at the current p_dir\np_dir::P a temporary storage to the forward direction (i.e. q above)\n\nConstructor\n\nApproximateFiniteDifference(M, p, grad_f; kwargs...)\n\nKeyword arguments\n\nevaluation (AllocatingEvaluation) whether the gradient is given as an allocation function or an in-place (InplaceEvaluation).\nsteplength (2^-14) step length c to approximate the gradient evaluations\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction(M, p, X) to use in the approximation.\nvector_transport_method - (default_vector_transport_method(M, typeof(p))) a vector transport to use\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianSymmetricRankOne","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianSymmetricRankOne","text":"ApproxHessianSymmetricRankOne{E, P, G, T, B<:AbstractBasis{‚Ñù}, VTR, R<:Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by the symmetric rank one update.\n\nFields\n\ngradient!! the gradient function (either allocating or mutating, see evaluation parameter).\nŒΩ a small real number to ensure that the denominator in the update does not become too small and thus the method does not break down.\nvector_transport_method a vector transport to use.\n\nInternal temporary fields\n\np_tmp a temporary storage the current point p.\ngrad_tmp a temporary storage for the gradient at the current p.\nmatrix a temporary storage for the matrix representation of the approximating operator.\nbasis a temporary storage for an orthonormal basis at the current p.\n\nConstructor\n\nApproxHessianSymmetricRankOne(M, p, gradF; kwargs...)\n\nKeyword arguments\n\ninitial_operator (Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M))) the matrix representation of the initial approximating operator.\nbasis (DefaultOrthonormalBasis()) an orthonormal basis in the tangent space of the initial iterate p.\nnu (-1)\nevaluation (AllocatingEvaluation) whether the gradient is given as an allocation function or an in-place (InplaceEvaluation).\nvector_transport_method (ParallelTransport()) vector transport mathcal T_cdotgetscdot to use.\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/#Manopt.ApproxHessianBFGS","page":"Trust-Regions Solver","title":"Manopt.ApproxHessianBFGS","text":"ApproxHessianBFGS{E, P, G, T, B<:AbstractBasis{‚Ñù}, VTR, R<:Real} <: AbstractApproxHessian\n\nA functor to approximate the Hessian by the BFGS update.\n\nFields\n\ngradient!! the gradient function (either allocating or mutating, see evaluation parameter).\nscale\nvector_transport_method a vector transport to use.\n\nInternal temporary fields\n\np_tmp a temporary storage the current point p.\ngrad_tmp a temporary storage for the gradient at the current p.\nmatrix a temporary storage for the matrix representation of the approximating operator.\nbasis a temporary storage for an orthonormal basis at the current p.\n\nConstructor\n\nApproxHessianBFGS(M, p, gradF; kwargs...)\n\nKeyword arguments\n\ninitial_operator (Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M))) the matrix representation of the initial approximating operator.\nbasis (DefaultOrthonormalBasis()) an orthonormal basis in the tangent space of the initial iterate p.\nnu (-1)\nevaluation (AllocatingEvaluation) whether the gradient is given as an allocation function or an in-place (InplaceEvaluation).\nvector_transport_method (ParallelTransport()) vector transport mathcal T_cdotgetscdot to use.\n\n\n\n\n\n","category":"type"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"as well as their (non-exported) common supertype","category":"page"},{"location":"solvers/trust_regions/","page":"Trust-Regions Solver","title":"Trust-Regions Solver","text":"Manopt.AbstractApproxHessian","category":"page"},{"location":"solvers/trust_regions/#Manopt.AbstractApproxHessian","page":"Trust-Regions Solver","title":"Manopt.AbstractApproxHessian","text":"AbstractApproxHessian <: Function\n\nAn abstract supertypes for approximate hessian functions, declares them also to be functions.\n\n\n\n\n\n","category":"type"},{"location":"list/#Table-of-Contents,-Types-and-Functions","page":"Function Index","title":"Table of Contents, Types and Functions","text":"","category":"section"},{"location":"list/","page":"Function Index","title":"Function Index","text":"This page lists all pages of this documentations, all available types and functions.","category":"page"},{"location":"list/#Complete-List-of-Contents","page":"Function Index","title":"Complete List of Contents","text":"","category":"section"},{"location":"list/","page":"Function Index","title":"Function Index","text":"Depth = 3","category":"page"},{"location":"list/#Available-Types","page":"Function Index","title":"Available Types","text":"","category":"section"},{"location":"list/","page":"Function Index","title":"Function Index","text":"Modules = [Manopt]\nOrder   = [:type]","category":"page"},{"location":"list/#Solver-Functions","page":"Function Index","title":"Solver Functions","text":"","category":"section"},{"location":"list/","page":"Function Index","title":"Function Index","text":"Modules = [Manopt]\nPages = [\"plans/index.md\", \"solvers/index.md\"]","category":"page"},{"location":"list/#Functions","page":"Function Index","title":"Functions","text":"","category":"section"},{"location":"list/","page":"Function Index","title":"Function Index","text":"Modules = [Manopt]\nPages = [\"functions/adjointDifferentials.md\", \"functions/costs.md\", \"functions/differentials.md\", \"functions/gradients.md\", \"functions/jacobiFields.md\", \"functions/proximalMaps.md\"]","category":"page"},{"location":"plans/debug/#DebugSection","page":"Debug Output","title":"Debug Output","text":"","category":"section"},{"location":"plans/debug/","page":"Debug Output","title":"Debug Output","text":"CurrentModule = Manopt","category":"page"},{"location":"plans/debug/","page":"Debug Output","title":"Debug Output","text":"Debug output can easily be added to any solver run. On the high level interfaces, like gradient_descent, you can just use the debug= keyword.","category":"page"},{"location":"plans/debug/","page":"Debug Output","title":"Debug Output","text":"Modules = [Manopt]\nPages = [\"plans/debug.jl\"]\nOrder = [:type, :function]\nPrivate = true","category":"page"},{"location":"plans/debug/#Manopt.DebugAction","page":"Debug Output","title":"Manopt.DebugAction","text":"DebugAction\n\nA DebugAction is a small functor to print/issue debug output. The usual call is given by (amp::AbstractManoptProblem, ams::AbstractManoptSolverState, i) -> s, where i is the current iterate.\n\nBy convention i=0 is interpreted as \"For Initialization only\", i.e. only debug info that prints initialization reacts, i<0 triggers updates of variables internally but does not trigger any output. Finally typemin(Int) is used to indicate a call from stop_solver! that returns true afterwards.\n\nFields (assumed by subtypes to exist)\n\nprint method to perform the actual print. Can for example be set to a file export,\n\nor to @info. The default is the print function on the default Base.stdout.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugChange","page":"Debug Output","title":"Manopt.DebugChange","text":"DebugChange(M=DefaultManifold())\n\ndebug for the amount of change of the iterate (stored in get_iterate(o) of the AbstractManoptSolverState) during the last iteration. See DebugEntryChange for the general case\n\nKeyword Parameters\n\nstorage ‚Äì (StoreStateAction( [:Gradient] )) ‚Äì (eventually shared) the storage of the previous action\nprefix ‚Äì (\"Last Change:\") prefix of the debug output (ignored if you set format)\nio ‚Äì (stdout) default steream to print the debug to.\nformat - ( \"$prefix %f\") format to print the output using an sprintf format.\ninverse_retraction_method - (default_inverse_retraction_method(M)) the inverse retraction to be used for approximating distance.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugCost","page":"Debug Output","title":"Manopt.DebugCost","text":"DebugCost <: DebugAction\n\nprint the current cost function value, see get_cost.\n\nConstructors\n\nDebugCost()\n\nParameters\n\nformat - (\"$prefix %f\") format to print the output using sprintf and a prefix (see long).\nio ‚Äì (stdout) default steream to print the debug to.\nlong - (false) short form to set the format to F(x): (default) or current cost: and the cost\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugDivider","page":"Debug Output","title":"Manopt.DebugDivider","text":"DebugDivider <: DebugAction\n\nprint a small divider (default \" | \").\n\nConstructor\n\nDebugDivider(div,print)\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEntry","page":"Debug Output","title":"Manopt.DebugEntry","text":"DebugEntry <: DebugAction\n\nprint a certain fields entry of type {T} during the iterates, where a format can be specified how to print the entry.\n\nAddidtional Fields\n\nfield ‚Äì Symbol the entry can be accessed with within AbstractManoptSolverState\n\nConstructor\n\nDebugEntry(f[, prefix=\"$f:\", format = \"$prefix %s\", io=stdout])\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEntryChange","page":"Debug Output","title":"Manopt.DebugEntryChange","text":"DebugEntryChange{T} <: DebugAction\n\nprint a certain entries change during iterates\n\nAdditional Fields\n\nprint ‚Äì (print) function to print the result\nprefix ‚Äì (\"Change of :Iterate\") prefix to the print out\nformat ‚Äì (\"$prefix %e\") format to print (uses the `prefix by default and scientific notation)\nfield ‚Äì Symbol the field can be accessed with within AbstractManoptSolverState\ndistance ‚Äì function (p,o,x1,x2) to compute the change/distance between two values of the entry\nstorage ‚Äì a StoreStateAction to store the previous value of :f\n\nConstructors\n\nDebugEntryChange(f,d)\n\nKeyword arguments\n\nio (stdout) an IOStream\nprefix (\"Change of $f\")\nstorage (StoreStateAction((f,))) a StoreStateAction\ninitial_value an initial value for the change of o.field.\nformat ‚Äì (\"$prefix %e\") format to print the change\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugEvery","page":"Debug Output","title":"Manopt.DebugEvery","text":"DebugEvery <: DebugAction\n\nevaluate and print debug only every ith iteration. Otherwise no print is performed. Whether internal variables are updates is determined by always_update.\n\nThis method does not perform any print itself but relies on it's childrens print.\n\nConstructor\n\nDebugEvery(d::DebugAction, every=1, always_update=true)\n\nInitialise the DebugEvery.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugGradientChange","page":"Debug Output","title":"Manopt.DebugGradientChange","text":"DebugGradientChange()\n\ndebug for the amount of change of the gradient (stored in get_gradient(o) of the AbstractManoptSolverState o) during the last iteration. See DebugEntryChange for the general case\n\nKeyword Parameters\n\nstorage ‚Äì (StoreStateAction( (:Gradient,) )) ‚Äì (eventually shared) the storage of the previous action\nprefix ‚Äì (\"Last Change:\") prefix of the debug output (ignored if you set format)\nio ‚Äì (stdout) default steream to print the debug to.\nformat - ( \"$prefix %f\") format to print the output using an sprintf format.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugGroup","page":"Debug Output","title":"Manopt.DebugGroup","text":"DebugGroup <: DebugAction\n\ngroup a set of DebugActions into one action, where the internal prints are removed by default and the resulting strings are concatenated\n\nConstructor\n\nDebugGroup(g)\n\nconstruct a group consisting of an Array of DebugActions g, that are evaluated en bloque; the method does not perform any print itself, but relies on the internal prints. It still concatenates the result and returns the complete string\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIterate","page":"Debug Output","title":"Manopt.DebugIterate","text":"DebugIterate <: DebugAction\n\ndebug for the current iterate (stored in get_iterate(o)).\n\nConstructor\n\nDebugIterate()\n\nParameters\n\nio ‚Äì (stdout) default steream to print the debug to.\nlong::Bool whether to print x: or current iterate\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugIteration","page":"Debug Output","title":"Manopt.DebugIteration","text":"DebugIteration <: DebugAction\n\nConstructor\n\nDebugIteration()\n\nKeyword parameters\n\nformat - (\"# %-6d\") format to print the output using an sprintf format.\nio ‚Äì (stdout) default steream to print the debug to.\n\ndebug for the current iteration (prefixed with # by )\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugMessages","page":"Debug Output","title":"Manopt.DebugMessages","text":"DebugMessages <: DebugAction\n\nAn AbstractManoptSolverState or one of its substeps like a Stepsize might generate warnings throughout their compuations. This debug can be used to :print them display them as :info or :warnings or even :error, depending on the message type.\n\nConstructor\n\nDebugMessages(mode=:Info; io::IO=stdout)\n\nInitialize the messages debug to a certain mode. Available modes are\n\n:Error ‚Äì issue the messages as an error and hence stop at any issue occuring\n:Info ‚Äì issue the messages as an @info\n:Print ‚Äì print messages to the steam io.\n:Warning ‚Äì issue the messages as a warning\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugSolverState","page":"Debug Output","title":"Manopt.DebugSolverState","text":"DebugSolverState <: AbstractManoptSolverState\n\nThe debug options append to any options a debug functionality, i.e. they act as a decorator pattern. Internally a Dictionary is kept that stores a DebugAction for several occasions using a Symbol as reference. The default occasion is :All and for example solvers join this field with :Start, :Step and :Stop at the beginning, every iteration or the end of the algorithm, respectively\n\nThe original options can still be accessed using the get_state function.\n\nFields (defaults in brackets)\n\noptions ‚Äì the options that are extended by debug information\ndebugDictionary ‚Äì a Dict{Symbol,DebugAction} to keep track of Debug for different actions\n\nConstructors\n\nDebugSolverState(o,dA)\n\nconstruct debug decorated options, where dD can be\n\na DebugAction, then it is stored within the dictionary at :All\nan Array of DebugActions, then it is stored as a debugDictionary within :All.\na Dict{Symbol,DebugAction}.\nan Array of Symbols, String and an Int for the DebugFactory\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugStoppingCriterion","page":"Debug Output","title":"Manopt.DebugStoppingCriterion","text":"DebugStoppingCriterion <: DebugAction\n\nprint the Reason provided by the stopping criterion. Usually this should be empty, unless the algorithm stops.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugTime","page":"Debug Output","title":"Manopt.DebugTime","text":"DebugTime()\n\nMeasure time and print the intervals. Using start=true you can start the timer on construction, for example to measure the runtime of an algorithm overall (adding)\n\nThe measured time is rounded using the given time_accuracy and printed after canonicalization.\n\nKeyword Parameters\n\nprefix ‚Äì (\"Last Change:\") prefix of the debug output (ignored if you set format)\nio ‚Äì (stdout) default steream to print the debug to.\nformat - ( \"$prefix %s\") format to print the output using an sprintf format, where %s is the canonicalized time`.\nmode ‚Äì (:cumulative) whether to display the total time or reset on every call using :iterative.\nstart ‚Äì (false) indicate whether to start the timer on creation or not. Otherwise it might only be started on firsr call.\ntime_accuracy ‚Äì (Millisecond(1)) round the time to this period before printing the canonicalized time\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfCostIncreases","page":"Debug Output","title":"Manopt.DebugWarnIfCostIncreases","text":"DebugWarnIfCostIncreases <: DebugAction\n\nprint a warning if the cost increases.\n\nNote that this provides an additional warning for gradient descent with its default constant step size.\n\nConstructor\n\nDebugWarnIfCostIncreases(warn=:Once; tol=1e-13)\n\nInitialize the warning to warning level (:Once) and introduce a tolerance for the test of 1e-13.\n\nThe warn level can be set to :Once to only warn the first time the cost increases, to :Always to report an increase every time it happens, and it can be set to :No to deactivate the warning, then this DebugAction is inactive. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfCostNotFinite","page":"Debug Output","title":"Manopt.DebugWarnIfCostNotFinite","text":"DebugWarnIfCostNotFinite <: DebugAction\n\nA debug to see when a field (value or array within the AbstractManoptSolverState is or contains values that are not finite, for example Inf or Nan.\n\nConstructor\n\nDebugWarnIfCostNotFinite(field::Symbol, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugWarnIfFieldNotFinite","page":"Debug Output","title":"Manopt.DebugWarnIfFieldNotFinite","text":"DebugWarnIfFieldNotFinite <: DebugAction\n\nA debug to see when a field from the options is not finite, for example Inf or Nan\n\nConstructor\n\nDebugWarnIfFieldNotFinite(field::Symbol, warn=:Once)\n\nInitialize the warning to warn :Once.\n\nThis can be set to :Once to only warn the first time the cost is Nan. It can also be set to :No to deactivate the warning, but this makes this Action also useless. All other symbols are handled as if they were :Always:\n\nExample\n\nDebugWaranIfFieldNotFinite(:Gradient)\n\nCreates a [DebugAction] to track whether the gradient does not get Nan or Inf.\n\n\n\n\n\n","category":"type"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{String}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(s)\n\ncreate a DebugAction where\n\na Stringyields the correspoinding divider\na DebugAction is passed through\na [Symbol] creates DebugEntry of that symbol, with the exceptions of :Change, :Iterate, :Iteration, and :Cost.\na Tuple{Symbol,String} creates a DebugEntry of that symbol where the String specifies the format.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{Symbol}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(s::Symbol)\n\nConvert certain Symbols in the debug=[ ... ] vector to DebugActions Currently the following ones are done. Note that the Shortcut symbols should all start with a capital letter.\n\n:Cost creates a DebugCost\n:Change creates a DebugChange\n:GradientChange creates a DebugGradientChange\n:GradientNorm creates a DebugGradientNorm\n:Iterate creates a DebugIterate\n:Iteration creates a DebugIteration\n:IterativeTime creates a DebugTime(:Iterative)\n:Stepsize creates a DebugStepsize\n:WarnCost creates a DebugWarnIfCostNotFinite\n:WarnGradient creates a DebugWarnIfFieldNotFinite for the ::Gradient.\n:Time creates a DebugTime\n:WarningMessagescreates a DebugMessages(:Warning)\n:InfoMessagescreates a DebugMessages(:Info)\n:ErrorMessagescreates a DebugMessages(:Error)\n:Messagescreates a DebugMessages() (i.e. the same as :InfoMessages)\n\nany other symbol creates a DebugEntry(s) to print the entry (o.:s) from the options.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugActionFactory-Tuple{Tuple{Symbol, String}}","page":"Debug Output","title":"Manopt.DebugActionFactory","text":"DebugActionFactory(t::Tuple{Symbol,String)\n\nConvert certain Symbols in the debug=[ ... ] vector to DebugActions Currently the following ones are done, where the string in t[2] is passed as the format the corresponding debug. Note that the Shortcut symbols t[1] should all start with a capital letter.\n\n:Cost creates a DebugCost\n:Change creates a DebugChange\n:GradientChange creates a DebugGradientChange\n:Iterate creates a DebugIterate\n:Iteration creates a DebugIteration\n:Stepsize creates a DebugStepsize\n:Time creates a DebugTime\n:IterativeTime creates a DebugTime(:Iterative)\n\nany other symbol creates a DebugEntry(s) to print the entry (o.:s) from the options.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.DebugFactory-Tuple{Vector}","page":"Debug Output","title":"Manopt.DebugFactory","text":"DebugFactory(a)\n\ngiven an array of Symbols, Strings DebugActions and Ints\n\nThe symbol :Stop creates an entry of to display the stopping criterion at the end (:Stop => DebugStoppingCriterion()), for further symbols see DebugActionFactory\nTuples of a symbol and a string can be used to also specify a format, see DebugActionFactory\nany string creates a DebugDivider\nany DebugAction is directly included\nan Integer kintroduces that debug is only printed every kth iteration\n\nReturn value\n\nThis function returns a dictionary with an entry :All containing one general DebugAction, possibly a DebugGroup of entries. It might contain an entry :Start, :Step, :Stop with an action (each) to specify what to do at the start, after a step or at the end of an Algorithm, respectively. On all three occastions the :All action is exectued. Note that only the :Stop entry is actually filled when specifying the :Stop symbol.\n\nExample\n\nThe array\n\n[:Iterate, \" | \", :Cost, :Stop, 10]\n\nAdds a group to :All of three actions (DebugIteration, DebugDivider with \" | \" to display, DebugCost) as a DebugGroup inside an DebugEvery to only be executed every 10th iteration. It also adds the DebugStoppingCriterion to the :Stop entry of the dictionary.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.reset!-Tuple{DebugTime}","page":"Debug Output","title":"Manopt.reset!","text":"reset!(d::DebugTime)\n\nreset the internal time of a DebugTime, that is start from now again.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.stop!-Tuple{DebugTime}","page":"Debug Output","title":"Manopt.stop!","text":"stop!(d::DebugTime)\n\nstop the reset the internal time of a DebugTime, that is set the time to 0 (undefined)\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Technical-Details:-The-Debug-Solver","page":"Debug Output","title":"Technical Details: The Debug Solver","text":"","category":"section"},{"location":"plans/debug/","page":"Debug Output","title":"Debug Output","text":"The decorator to print debug during the iterations can be activated by decorating the state of a solver and implementing your own DebugActions. For example printing a gradient from the GradientDescentState is automatically available, as explained in the gradient_descent solver.","category":"page"},{"location":"plans/debug/","page":"Debug Output","title":"Debug Output","text":"initialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState)\nstep_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i)\nstop_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i::Int)","category":"page"},{"location":"plans/debug/#Manopt.initialize_solver!-Tuple{AbstractManoptProblem, DebugSolverState}","page":"Debug Output","title":"Manopt.initialize_solver!","text":"initialize_solver!(amp::AbstractManoptProblem, dss::DebugSolverState)\n\nExtend the initialization of the solver by a hook to run debug that were added to the :Start and :All entries of the debug lists.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.step_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Any}","page":"Debug Output","title":"Manopt.step_solver!","text":"step_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i)\n\nExtend the ith step of the solver by a hook to run debug prints, that were added to the :Step and :All entries of the debug lists.\n\n\n\n\n\n","category":"method"},{"location":"plans/debug/#Manopt.stop_solver!-Tuple{AbstractManoptProblem, DebugSolverState, Int64}","page":"Debug Output","title":"Manopt.stop_solver!","text":"stop_solver!(amp::AbstractManoptProblem, dss::DebugSolverState, i)\n\nExtend the check, whether to stop the solver by a hook to run debug, that were added to the :Stop and :All entries of the debug lists.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Stepsize","page":"Stepsize","title":"Stepsize and Linesearch","text":"","category":"section"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"CurrentModule = Manopt","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Most iterative algorithms determine a direction along which the algorithm will proceed and determine a step size to find the next iterate. How advanced the step size computation can be implemented depends (among others) on the properties the corresponding problem provides.","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Within Manopt.jl, the step size determination is implemented as a functor which is a subtype of [Stepsize](@refbased on","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Stepsize","category":"page"},{"location":"plans/stepsize/#Manopt.Stepsize","page":"Stepsize","title":"Manopt.Stepsize","text":"Stepsize\n\nAn abstract type for the functors representing step sizes, i.e. they are callable structures. The naming scheme is TypeOfStepSize, e.g. ConstantStepsize.\n\nEvery Stepsize has to provide a constructor and its function has to have the interface (p,o,i) where a AbstractManoptProblem as well as AbstractManoptSolverState and the current number of iterations are the arguments and returns a number, namely the stepsize to use.\n\nSee also\n\nLinesearch\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Usually, a constructor should take the manifold M as its first argument, for consistency, to allow general step size functors to be set up based on default values that might depend on the manifold currently under consideration.","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Currently, the following step sizes are available","category":"page"},{"location":"plans/stepsize/","page":"Stepsize","title":"Stepsize","text":"Modules = [Manopt]\nPages = [\"plans/stepsize.jl\"]\nOrder = [:type,:function]\nFilter = t -> t != Stepsize","category":"page"},{"location":"plans/stepsize/#Manopt.ArmijoLinesearch","page":"Stepsize","title":"Manopt.ArmijoLinesearch","text":"ArmijoLinesearch <: Linesearch\n\nA functor representing Armijo line search including the last runs state, i.e. a last step size.\n\nFields\n\ninitial_stepsize    ‚Äì (1.0) and initial step size\nretraction_method   ‚Äì (default_retraction_method(M)) the rectraction to use\ncontraction_factor  ‚Äì (0.95) exponent for line search reduction\nsufficient_decrease ‚Äì (0.1) gain within Armijo's rule\nlast_stepsize       ‚Äì (initialstepsize) the last step size we start the search with\ninitial_guess       - ((p,s,i,l) -> l)  based on a AbstractManoptProblem p, AbstractManoptSolverState s and a current iterate i and a last step size l, this returns an initial guess. The default uses the last obtained stepsize\n\nFurthermore the following fields act as safeguards\n\nstop_when_stepsize_less    - (0.0`) smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds - ([max_stepsize](@ref)(M, p)`) ‚Äì largest stepsize when to stop.\nstop_increasing_at_step   - (^100`) last step to increase the stepsize (phase 1),\nstop_decreasing_at_step   - (1000) last step size to decrese the stepsize (phase 2),\n\nPass :Messages to a debug= to see @infos when these happen.\n\nConstructor\n\nArmijoLinesearch(M=DefaultManifold())\n\nwith the Fields above as keyword arguments and the retraction is set to the default retraction on M.\n\nThe constructors return the functor to perform Armijo line search, where two interfaces are available:\n\nbased on a tuple (amp, ams, i) of a AbstractManoptProblem amp, AbstractManoptSolverState ams and a current iterate i.\nwith (M, x, F, gradFx[,Œ∑=-gradFx]) -> s where Manifold M, a current point x a function F, that maps from the manifold to the reals, its gradient (a tangent vector) gradFx=operatornamegradF(x) at  x and an optional search direction tangent vector Œ∑=-gradFx are the arguments.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.ConstantStepsize","page":"Stepsize","title":"Manopt.ConstantStepsize","text":"ConstantStepsize <: Stepsize\n\nA functor that always returns a fixed step size.\n\nFields\n\nlength ‚Äì constant value for the step size.\n\nConstructors\n\nConstantStepsize(s::Real)\n\ninitialize the stepsize to a constant s.\n\nConstantStepsize(M::AbstractManifold=DefaultManifold(2); stepsize=injectivity_radius(M)/2)\n\ninitialize the stepsize to a constant stepsize, which by default is half the injectivity radius, unless the radius is infinity, then the default step size is 1.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.DecreasingStepsize","page":"Stepsize","title":"Manopt.DecreasingStepsize","text":"DecreasingStepsize()\n\nA functor that represents several decreasing step sizes\n\nFields\n\nlength ‚Äì (1) the initial step size l.\nfactor ‚Äì (1) a value f to multiply the initial step size with every iteration\nsubtrahend ‚Äì (0) a value a that is subtracted every iteration\nexponent ‚Äì (1) a value e the current iteration numbers eth exponential is taken of\nshift ‚Äì (0) shift the denominator iterator i by s`.\n\nIn total the complete formulae reads for the ith iterate as\n\ns_i = frac(l - i a)f^i(i+s)^e\n\nand hence the default simplifies to just s_i = fracli\n\nConstructor\n\nDecreasingStepsize(l=1,f=1,a=0,e=1,s=0)\n\nAlternatively one can also use the following keyword.\n\nDecreasingStepsize(\n    M::AbstractManifold=DefaultManifold(3);\n    length=injectivity_radius(M)/2, multiplier=1.0, subtrahend=0.0, exponent=1.0, shift=0)\n\ninitialiszes all fields above, where none of them is mandatory and the length is set to half and to 1 if the injectivity radius is infinite.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.Linesearch","page":"Stepsize","title":"Manopt.Linesearch","text":"Linesearch <: Stepsize\n\nAn abstract functor to represent line search type step size deteminations, see Stepsize for details. One example is the ArmijoLinesearch functor.\n\nCompared to simple step sizes, the linesearch functors provide an interface of the form (p,o,i,Œ∑) -> s with an additional (but optional) fourth parameter to provide a search direction; this should default to something reasonable, e.g. the negative gradient.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.NonmonotoneLinesearch","page":"Stepsize","title":"Manopt.NonmonotoneLinesearch","text":"NonmonotoneLinesearch <: Linesearch\n\nA functor representing a nonmonotone line search using the Barzilai-Borwein step size[Iannazzo2018]. Together with a gradient descent algorithm this line search represents the Riemannian Barzilai-Borwein with nonmonotone line-search (RBBNMLS) algorithm. We shifted the order of the algorithm steps from the paper by Iannazzo and Porcelli so that in each iteration we first find\n\ny_k = operatornamegradF(x_k) - operatornameT_x_k-1  x_k(operatornamegradF(x_k-1))\n\nand\n\ns_k = - Œ±_k-1 * operatornameT_x_k-1  x_k(operatornamegradF(x_k-1))\n\nwhere Œ±_k-1 is the step size computed in the last iteration and operatornameT is a vector transport. We then find the Barzilai‚ÄìBorwein step size\n\nŒ±_k^textBB = begincases\nmin(Œ±_textmax max(Œ±_textmin œÑ_k))   textif  s_k y_k_x_k  0\nŒ±_textmax  textelse\nendcases\n\nwhere\n\nœÑ_k = fracs_k s_k_x_ks_k y_k_x_k\n\nif the direct strategy is chosen,\n\nœÑ_k = fracs_k y_k_x_ky_k y_k_x_k\n\nin case of the inverse strategy and an alternation between the two in case of the alternating strategy. Then we find the smallest h = 0 1 2  such that\n\nF(operatornameretr_x_k(- œÉ^h Œ±_k^textBB operatornamegradF(x_k)))\nleq\nmax_1  j  min(k+1m) F(x_k+1-j) - Œ≥ œÉ^h Œ±_k^textBB operatornamegradF(x_k) operatornamegradF(x_k)_x_k\n\nwhere œÉ is a step length reduction factor  (01), m is the number of iterations after which the function value has to be lower than the current one and Œ≥ is the sufficient decrease parameter (01). We can then find the new stepsize by\n\nŒ±_k = œÉ^h Œ±_k^textBB\n\n[Iannazzo2018]: B. Iannazzo, M. Porcelli, The Riemannian Barzilai‚ÄìBorwein Method with Nonmonotone Line Search and the Matrix Geometric Mean Computation, In: IMA Journal of Numerical Analysis. Volume 38, Issue 1, January 2018, Pages 495‚Äì517, doi 10.1093/imanum/drx015\n\nFields\n\ninitial_stepsize ‚Äì (1.0) the step size we start the search with\nmemory_size ‚Äì (10) number of iterations after which the cost value needs to be lower than the current one\nbb_min_stepsize ‚Äì (1e-3) lower bound for the Barzilai-Borwein step size greater than zero\nbb_max_stepsize ‚Äì (1e3) upper bound for the Barzilai-Borwein step size greater than min_stepsize\nretraction_method ‚Äì (ExponentialRetraction()) the rectraction to use\nstrategy ‚Äì (direct) defines if the new step size is computed using the direct, indirect or alternating strategy\nstorage ‚Äì (for :Iterate and :Gradient) a StoreStateAction\nstepsize_reduction ‚Äì (0.5) step size reduction factor contained in the interval (0,1)\nsufficient_decrease ‚Äì (1e-4) sufficient decrease parameter contained in the interval (0,1)\nvector_transport_method ‚Äì (ParallelTransport()) the vector transport method to use\n\nFurthermore the following fields act as safeguards\n\nstop_when_stepsize_less    - (0.0`) smallest stepsize when to stop (the last one before is taken)\nstop_when_stepsize_exceeds - ([max_stepsize](@ref)(M, p)`) ‚Äì largest stepsize when to stop.\nstop_increasing_at_step   - (^100`) last step to increase the stepsize (phase 1),\nstop_decreasing_at_step   - (1000) last step size to decrese the stepsize (phase 2),\n\nPass :Messages to a debug= to see @infos when these happen.\n\nConstructor\n\nNonmonotoneLinesearch()\n\nwith the Fields above in their order as optional arguments (deprecated).\n\nNonmonotoneLinesearch(M)\n\nwith the Fields above in their order as keyword arguments and where the retraction and vector transport are set to the default ones on M, repsectively.\n\nThe constructors return the functor to perform nonmonotone line search.\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.WolfePowellBinaryLinesearch","page":"Stepsize","title":"Manopt.WolfePowellBinaryLinesearch","text":"WolfePowellBinaryLinesearch <: Linesearch\n\nA Linesearch method that determines a step size t fulfilling the Wolfe conditions\n\nbased on a binary chop. Let Œ∑ be a search direction and c1c_20 be two constants. Then with\n\nA(t) = f(x_+)  c1 t operatornamegradf(x) Œ∑_x\nquadtextandquad\nW(t) = operatornamegradf(x_+) textV_x_+gets xŒ∑_x_+  c_2 Œ∑ operatornamegradf(x)_x\n\nwhere x_+ = operatornameretr_x(tŒ∑) is the current trial point, and textV is a vector transport, we perform the following Algorithm similar to Algorithm 7 from [Huang2014]\n\nset Œ±=0, Œ≤= and t=1.\nWhile either A(t) does not hold or W(t) does not hold do steps 3-5.\nIf A(t) fails, set Œ≤=t.\nIf A(t) holds but W(t) fails, set Œ±=t.\nIf Œ≤ set t=fracŒ±+Œ≤2, otherwise set t=2Œ±.\n\nConstructors\n\nThere exist two constructors, where, when prodivind the manifold M as a first (optional) parameter, its default retraction and vector transport are the default. In this case the retraction and the vector transport are also keyword arguments for ease of use. The other constructor is kept for backward compatibility.\n\nWolfePowellLinesearch(\n    M=DefaultManifold(),\n    c1::Float64=10^(-4),\n    c2::Float64=0.999;\n    retraction_method = default_retraction_method(M),\n    vector_transport_method = default_vector_transport(M),\n    linesearch_stopsize = 0.0\n)\n\n[Huang2014]: Huang, W.: Optimization algorithms on Riemannian manifolds with applications, Dissertation, Flordia State University, 2014. pdf\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.WolfePowellLinesearch","page":"Stepsize","title":"Manopt.WolfePowellLinesearch","text":"WolfePowellLinesearch <: Linesearch\n\nDo a backtracking linesearch to find a step size Œ± that fulfils the Wolfe conditions along a search direction Œ∑ starting from x, i.e.\n\nfbigl( operatornameretr_x(Œ±Œ∑) bigr)  f(x_k) + c_1 Œ±_k operatornamegradf(x) Œ∑_x\nquadtextandquad\nfracmathrmdmathrmdt fbigr(operatornameretr_x(tŒ∑)bigr)\nBigvert_t=Œ±\n c_2 fracmathrmdmathrmdt fbigl(operatornameretr_x(tŒ∑)bigr)Bigvert_t=0\n\nConstructors\n\nThere exist two constructors, where, when prodivind the manifold M as a first (optional) parameter, its default retraction and vector transport are the default. In this case the retraction and the vector transport are also keyword arguments for ease of use. The other constructor is kept for backward compatibility. Note that the linesearch_stopsize to stop for too small stepsizes is only available in the new signature including M.\n\nWolfePowellLinesearch(\n    M,\n    c1::Float64=10^(-4),\n    c2::Float64=0.999;\n    retraction_method = default_retraction_method(M),\n    vector_transport_method = default_vector_transport(M),\n    linesearch_stopsize = 0.0\n)\n\n\n\n\n\n","category":"type"},{"location":"plans/stepsize/#Manopt.default_stepsize-Tuple{AbstractManifold, Type{<:AbstractManoptSolverState}}","page":"Stepsize","title":"Manopt.default_stepsize","text":"default_stepsize(M::AbstractManifold, ams::AbstractManoptSolverState)\n\nReturns the default Stepsize functor used when running the solver specified by the AbstractManoptSolverState ams running with an objective on the AbstractManifold M.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.get_stepsize-Tuple{AbstractManoptProblem, AbstractManoptSolverState, Vararg{Any}}","page":"Stepsize","title":"Manopt.get_stepsize","text":"get_stepsize(amp::AbstractManoptProblem, ams::AbstractManoptSolverState, vars...)\n\nreturn the stepsize stored within AbstractManoptSolverState ams when solving the AbstractManoptProblem amp. This method also works for decorated options and the Stepsize function within the options, by default stored in o.stepsize.\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.linesearch_backtrack-Union{Tuple{T}, Tuple{TF}, Tuple{AbstractManifold, TF, Any, T, Any, Any, Any}, Tuple{AbstractManifold, TF, Any, T, Any, Any, Any, AbstractRetractionMethod}, Tuple{AbstractManifold, TF, Any, T, Any, Any, Any, AbstractRetractionMethod, T}, Tuple{AbstractManifold, TF, Any, T, Any, Any, Any, AbstractRetractionMethod, T, Any}} where {TF, T}","page":"Stepsize","title":"Manopt.linesearch_backtrack","text":"(s, msg) = linesearch_backtrack(\n    M, F, x, gradFx, s, decrease, contract, retr, Œ∑ = -gradFx, f0 = F(x);\n    stop_when_stepsize_less=0.0,\n    stop_when_stepsize_exceeds=max_stepsize(M, p),\n    stop_increasing_at_step = 100,\n    stop_decreasing_at_step = 1000,\n)\n\nperform a linesearch for\n\na manifold M\na cost function f,\nan iterate p\nthe gradient operatornamegradF(x)\nan initial stepsize s usually called Œ≥\na sufficient decrease\na contraction factor œÉ\na retraction, which defaults to the default_retraction_method(M)\na search direction Œ∑ = -operatornamegradF(x)\nan offset, f_0 = F(x)\n\nAnd use the 4 keywords to limit the maximal increase and decrease steps as well as a maximal stepsize (especially on non-Hadamard manifolds) and a minimal one.\n\nReturn value\n\nA stepsize s and a message msg (in case any of the 4 criteria hit)\n\n\n\n\n\n","category":"method"},{"location":"plans/stepsize/#Manopt.max_stepsize-Tuple{AbstractManifold, Any}","page":"Stepsize","title":"Manopt.max_stepsize","text":"max_stepsize(M::AbstractManifold, p)\nmax_stepsize(M::AbstractManifold)\n\nGet the maximum stepsize (at point p) on manifold M. It should be used to limit the distance an algorithm is trying to move in a single step.\n\n\n\n\n\n","category":"method"},{"location":"tutorials/Optimize!/#Get-Started:-Optimize!","page":"Get started: Optimize!","title":"Get Started: Optimize!","text":"","category":"section"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"In this tutorial, we will both introduce the basics of optimisation on manifolds as well as how to use Manopt.jl to perform optimisation on manifolds in Julia.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"For more theoretical background, see e.g. (do Carmo, 1992) for an introduction to Riemannian manifolds and (Absil, Mahony and Sepulchre, 2008) or (Boumal, 2022) to read more about optimisation thereon.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Let mathcal M denote a Riemannian manifold and let fcolon mathcal M  ‚Ñù be a cost function. We aim to compute a point p^* where f is minimal or in other words p^* is a minimizer of f.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"We also write this as","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"    operatorname*argmin_p  mathcal M f(p)","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"and would like to find p^* numerically. As an example we take the generalisation of the (arithemtic) mean. In the Euclidean case withdinmathbb N, that is for nin mathbb N data points y_1ldotsy_n in mathbb R^d the mean","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"  sum_i=1^n y_i","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"can not be directly generalised to data q_1ldotsq_n, since on a manifold we do not have an addition. But the mean can also be charcterised as","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"  operatorname*argmin_xinmathbb R^d frac12nsum_i=1^n lVert x - y_irVert^2","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"and using the Riemannian distance d_mathcal M, this can be written on Riemannian manifolds. We obtain the Riemannian Center of Mass (Karcher, 1977)","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"  operatorname*argmin_pinmathbb R^d\n  frac12n sum_i=1^n d_mathcal M^2(p q_i)","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Fortunately the gradient can be computed and is","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"  operatorname*argmin_pinmathbb R^d frac1n sum_i=1^n -log_p q_i","category":"page"},{"location":"tutorials/Optimize!/#Loading-the-necessary-packages","page":"Get started: Optimize!","title":"Loading the necessary packages","text":"","category":"section"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Let‚Äôs assume you have already installed both Manotp and Manifolds in Julia (using e.g.¬†using Pkg; Pkg.add([\"Manopt\", \"Manifolds\"])). Then we can get started by loading both packages ‚Äì and Random for persistency in this tutorial.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"using Manopt, Manifolds, Random, LinearAlgebra\nRandom.seed!(42);","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Now assume we are on the Sphere mathcal M = mathbb S^2 and we generate some random points ‚Äúaround‚Äù some initial point p","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"n = 100\nœÉ = œÄ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n];","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Now we can define the cost function f and its (Riemannian) gradient operatornamegrad f for the Riemannian center of mass:","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)));","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"and just call gradient_descent. For a first start, we do not have to provide more than the manifold, the cost, the gradient, and a startig point, which we just set to the first data point","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"m1 = gradient_descent(M, f, grad_f, data[1])","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"3-element Vector{Float64}:\n 0.6868392794868674\n 0.006531600674932074\n 0.7267799820761327","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"In order to get more details, we further add the debug= keyword argument, which act as a decorator pattern.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"This way we can easily specify a certain debug to be printed. The goal is to get an output of the form","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"# i | Last Change: [...] | F(x): [...] |","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"but where we also want to fix the display format for the change and the cost numbers (the [...]) to have a certain format. Furthermore, the reason why the solver stopped should be printed at the end","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"These can easily be specified using either a Symbol ‚Äì using the default format for numbers ‚Äì or a tuple of a symbol and a format-string in the debug= keyword that is avaiable for every solver. We can also ‚Äì¬†for illustration reasons ‚Äì¬†just look at the first 6 steps by setting a stopping_criterion=","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"m2 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Œîp|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop],\n    stopping_criterion = StopAfterIteration(6)\n  )","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Initial  F(x): 0.32487988924 | \n# 1     |Œîp|: 1.063609017 | F(x): 0.25232524046 | \n# 2     |Œîp|: 0.809858671 | F(x): 0.20966960102 | \n# 3     |Œîp|: 0.616665145 | F(x): 0.18546505598 | \n# 4     |Œîp|: 0.470841764 | F(x): 0.17121604104 | \n# 5     |Œîp|: 0.359345690 | F(x): 0.16300825911 | \n# 6     |Œîp|: 0.274597420 | F(x): 0.15818548927 | \nThe algorithm reached its maximal number of iterations (6).\n\n3-element Vector{Float64}:\n  0.7533872481682505\n -0.06053107055583637\n  0.6547851890466334","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"See here for the list of available symbols.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"!!! info \\\"Technical Detail\\\"     The debug= keyword is actually a list of DebugActions added to every iteration, allowing you to write your own ones even. Additionally, :Stop is an action added to the end of the solver to display the reason why the solver stopped.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"The default stopping criterion for gradient_descent is, to either stopwhen the gradient is small (<1e-9) or a max number of iterations is reached (as a fallback. Combining stopping-criteria can be done by | or &. We further pass a number 25 to debug= to only an output every 25th iteration:","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"m3 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Œîp|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 25],\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |¬†StopAfterIteration(400),\n)","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Initial  F(x): 0.32487988924 | \n# 25    |Œîp|: 0.459715605 | F(x): 0.15145076374 | \n# 50    |Œîp|: 0.000551270 | F(x): 0.15145051509 | \nThe algorithm reached approximately critical point after 73 iterations; the gradient norm (9.988871119384563e-16) is less than 1.0e-14.\n\n3-element Vector{Float64}:\n 0.6868392794788668\n 0.006531600680779286\n 0.7267799820836411","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"We can finally use another way to determine the stepsize, for example a little more expensive ArmijoLineSeach than the default stepsize rule used on the Sphere.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"m4 = gradient_descent(M, f, grad_f, data[1];\n    debug=[:Iteration,(:Change, \"|Œîp|: %1.9f |\"),\n        (:Cost, \" F(x): %1.11f | \"), \"\\n\", :Stop, 2],\n      stepsize = ArmijoLinesearch(M; contraction_factor=0.999, sufficient_decrease=0.5),\n    stopping_criterion = StopWhenGradientNormLess(1e-14) |¬†StopAfterIteration(400),\n)","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Initial  F(x): 0.32487988924 | \n# 2     |Œîp|: 0.001318138 | F(x): 0.15145051509 | \n# 4     |Œîp|: 0.000000004 | F(x): 0.15145051509 | \n# 6     |Œîp|: 0.000000000 | F(x): 0.15145051509 | \nThe algorithm reached approximately critical point after 7 iterations; the gradient norm (5.073696618059386e-15) is less than 1.0e-14.\n\n3-element Vector{Float64}:\n 0.6868392794788669\n 0.006531600680779358\n 0.7267799820836413","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Then we reach approximately the same point as in the previous run, but in far less steps","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"[f(M, m3)-f(M,m4), distance(M, m3, m4)]","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"2-element Vector{Float64}:\n 1.6653345369377348e-16\n 1.727269835930624e-16","category":"page"},{"location":"tutorials/Optimize!/#Example-2:-Computing-the-median-of-symmetric-positive-definite-matrices.","page":"Get started: Optimize!","title":"Example 2: Computing the median of symmetric positive definite matrices.","text":"","category":"section"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"For the second example let‚Äôs consider the manifold of 3  3 symmetric positive definite matrices and again 100 random points","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"N = SymmetricPositiveDefinite(3)\nm = 100\nœÉ = 0.005\nq = Matrix{Float64}(I, 3, 3)\ndata2 = [exp(N, q, œÉ * rand(N; vector_at=q)) for i in 1:m];","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Instead of the mean, let‚Äôs consider a non-smooth optimisation task: The median can be generalized to Manifolds as the minimiser of the sum of distances, see e.g. (Baƒç√°k, 2014). We define","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"g(N, q) = sum(1 / (2 * m) * distance.(Ref(N), Ref(q), data2))","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"g (generic function with 1 method)","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Since the function is non-smooth, we can not use a gradient-based approach. But since for every summand the proximal map is available, we can use the cyclic proximal point algorithm (CPPA). We hence define the vector of proximal maps as","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"proxes_g = Function[(N, Œª, q) -> prox_distance(N, Œª / m, di, q, 1) for di in data2];","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Besides also looking at a some debug prints, we can also easily record these values. Similarly to debug=, record= also accepts Symbols, see list here, to indicate things to record. We further set return_state to true to obtain not just the (approximate) minimizer.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"s = cyclic_proximal_point(N, g, proxes_g, data2[1];\n  debug=[:Iteration,\" | \",:Change,\" | \",(:Cost, \"F(x): %1.12f\"),\"\\n\", 1000, :Stop,\n        ],\n        record=[:Iteration, :Change, :Cost, :Iterate],\n        return_state=true,\n    );","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Initial  |  | F(x): 0.005875512856\n# 1000   | Last Change: 0.003704 | F(x): 0.003239019699\n# 2000   | Last Change: 0.000015 | F(x): 0.003238996105\n# 3000   | Last Change: 0.000005 | F(x): 0.003238991748\n# 4000   | Last Change: 0.000002 | F(x): 0.003238990225\n# 5000   | Last Change: 0.000001 | F(x): 0.003238989520\nThe algorithm reached its maximal number of iterations (5000).","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"!!! note \\\"Technical Detail\\\"     The recording is realised by RecordActions that are (also) executed at every iteration. These can also be individually implemented and added to the record= array instead of symbols.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"\nFirst, the computed median can be accessed as\n\n::: {.cell execution_count=14}","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"{.julia .cell-code} median = getsolverresult(s)","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"3√ó3 Matrix{Float64}:\n 1.0          2.12236e-5   0.000398721\n 2.12236e-5   1.00044      0.000141798\n 0.000398721  0.000141798  1.00041","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":":::","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"but we can also look at the recorded values. For simplicity (of output), lets just look at the recorded values at iteration 42","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"get_record(s)[42]","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"(42, 1.0569455860769079e-5, 0.003252547739370045, [0.9998583866917449 0.0002098880312604301 0.0002895445818451581; 0.00020988803126037459 1.0000931572564762 0.0002084371501681892; 0.00028954458184524134 0.0002084371501681892 1.000070920743257])","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"But we can also access whole serieses and see that the cost does not decrease that fast; actually, the CPPA might converge relatively slow. For that we can for example access the :Cost that was recorded every :Iterate as well as the (maybe a little boring) :Iteration-number in a semilogplot.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"x = get_record(s, :Iteration, :Iteration)\ny = get_record(s, :Iteration, :Cost)\nusing Plots\nplot(x,y,xaxis=:log, label=\"CPPA Cost\")","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"(Image: )","category":"page"},{"location":"tutorials/Optimize!/#Literature","page":"Get started: Optimize!","title":"Literature","text":"","category":"section"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Absil, P.-A., Mahony, R. and Sepulchre, R. (2008) Optimization algorithms on matrix manifolds. Princeton University Press. Available at: https://doi.org/10.1515/9781400830244.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Baƒç√°k, M. (2014) ‚ÄúComputing medians and means in Hadamard spaces,‚Äù SIAM Journal on Optimization, 24(3), pp. 1542‚Äì1566. Available at: https://doi.org/10.1137/140953393.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Boumal, N. (2022) An introduction to optimization on smooth manifolds. Available at: https://www.nicolasboumal.net/book.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"do Carmo, M.P. (1992) Riemannian geometry. Birkh√§user Boston, Inc., Boston, MA (Mathematics: Theory & applications), p. xiv+300. Available at: https://doi.org/10.1007/978-1-4757-2201-7.","category":"page"},{"location":"tutorials/Optimize!/","page":"Get started: Optimize!","title":"Get started: Optimize!","text":"Karcher, H. (1977) ‚ÄúRiemannian center of mass and mollifier smoothing,‚Äù Communications on Pure and Applied Mathematics, 30(5), pp. 509‚Äì541. Available at: https://doi.org/10.1002/cpa.3160300502.","category":"page"},{"location":"#Welcome-to-Manopt.jl","page":"Home","title":"Welcome to Manopt.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Manopt","category":"page"},{"location":"","page":"Home","title":"Home","text":"Manopt.Manopt","category":"page"},{"location":"#Manopt.Manopt","page":"Home","title":"Manopt.Manopt","text":"üèîÔ∏è Manopt.jl ‚Äì Optimization on Manifolds in Julia.\n\nüìö Documentation: manoptjl.org\nüì¶ Repository: github.com/JuliaManifolds/Manopt.jl\nüí¨ Discussions: github.com/JuliaManifolds/Manopt.jl/discussions\nüéØ Issues: github.com/JuliaManifolds/Manopt.jl/issues\n\n\n\n\n\n","category":"module"},{"location":"","page":"Home","title":"Home","text":"For a function fmathcal M  ‚Ñù defined on a Riemannian manifold mathcal M we aim to solve","category":"page"},{"location":"","page":"Home","title":"Home","text":"operatorname*argmin_p  mathcal M f(p)","category":"page"},{"location":"","page":"Home","title":"Home","text":"or in other words: find the point x on the manifold, where f reaches its minimal function value.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Manopt.jl provides a framework for optimization on manifolds as well as a Library of optimization algorithms in Julia. It belongs to the ‚ÄúManopt family‚Äù, which includes Manopt (Matlab) and pymanopt.org (Python).","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you want to delve right into Manopt.jl check out the Get started: Optimize! tutorial.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Manopt.jl makes it easy to use an algorithm for your favourite manifold as well as a manifold for your favourite algorithm. It already provides many manifolds and algorithms, which can easily be enhanced, for example to record certain data or debug output throughout iterations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you use Manopt.jlin your work, please cite the following","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{Bergmann2022,\n    Author    = {Ronny Bergmann},\n    Doi       = {10.21105/joss.03866},\n    Journal   = {Journal of Open Source Software},\n    Number    = {70},\n    Pages     = {3866},\n    Publisher = {The Open Journal},\n    Title     = {Manopt.jl: Optimization on Manifolds in {J}ulia},\n    Volume    = {7},\n    Year      = {2022},\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"To refer to a certain version or the source code in general we recommend to cite for example","category":"page"},{"location":"","page":"Home","title":"Home","text":"@software{manoptjl-zenodo-mostrecent,\n    Author = {Ronny Bergmann},\n    Copyright = {MIT License},\n    Doi = {10.5281/zenodo.4290905},\n    Publisher = {Zenodo},\n    Title = {Manopt.jl},\n    Year = {2022},\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"for the most recent version or a corresponding version specific DOI, see the list of all versions. Note that both citations are in BibLaTeX format.","category":"page"},{"location":"#Main-Features","page":"Home","title":"Main Features","text":"","category":"section"},{"location":"#Optimization-Algorithms-(Solvers)","page":"Home","title":"Optimization Algorithms (Solvers)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For every optimization algorithm, a solver is implemented based on a AbstractManoptProblem that describes the problem to solve and its AbstractManoptSolverState that set up the solver, store interims values. Together they form a plan.","category":"page"},{"location":"#Manifolds","page":"Home","title":"Manifolds","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This project is build upon ManifoldsBase.jl, a generic interface to implement manifolds. Certain functions are extended for specific manifolds from Manifolds.jl, but all other manifolds from that package can be used here, too.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The notation in the documentation aims to follow the same notation from these packages.","category":"page"},{"location":"#Functions-on-Manifolds","page":"Home","title":"Functions on Manifolds","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Several functions are available, implemented on an arbitrary manifold, cost functions, differentials and their adjoints, and gradients as well as proximal maps.","category":"page"},{"location":"#Visualization","page":"Home","title":"Visualization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To visualize and interpret results, Manopt.jl aims to provide both easy plot functions as well as exports. Furthermore a system to get debug during the iterations of an algorithms as well as record capabilities, i.e. to record a specified tuple of values per iteration, most prominently RecordCost and RecordIterate. Take a look at the Get Started: Optimize! tutorial on how to easily activate this.","category":"page"},{"location":"#Literature","page":"Home","title":"Literature","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you want to get started with manifolds, one book is [do Carmo, 1992], and if you want do directly dive into optimization on manifolds, my favorites references are [Absil, Mahony, Sepulchre, 2008] and [Boumal 2023], which are both available online for free","category":"page"},{"location":"","page":"Home","title":"Home","text":"<ul>\n<li id=\"AbsilMahonySepulchre2008\">\n    [<a>Absil, Mahony, Sepulchre, 2008</a>]\n    P.-A. Absil, R. Mahony and R. Sepulchre,\n    <emph>Optimization Algorithms on Matrix Manifolds</emph>,\n    Princeton University Press, 2008,\n    doi: <a href=\"https://doi.org/10.1515/9781400830244\">10.1515/9781400830244</a>,\n    <a href=\"http://press.princeton.edu/chapters/absil/\">open access</a>.\n</li>\n<li id=\"Boumal2023\">\n    [<a>Boumal, 2022</a>]\n    N. Boumal,\n    <emph>An introduction to optimization on smooth manifolds</emph>,\n    to appear with Cambridge University Press, 2023,\n    <a href=\"https://www.nicolasboumal.net/book/index.html\">open access</a>.\n</li>\n<li id=\"doCarmo1992\">\n    [<a>doCarmo, 1992</a>]\n    M. P. do Carmo,\n    <emph>Riemannian Geometry</emph>,\n    Birkh√§user Boston, 1992,\n    ISBN: 0-8176-3490-8.\n</li>\n</ul>","category":"page"},{"location":"tutorials/StochasticGradientDescent/#How-to-Run-Stochastic-Gradient-Descent","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"","category":"section"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"This tutorial illustrates how to use the stochastic_gradient_descent solver and different DirectionUpdateRules in order to introduce the average or momentum variant, see Stochastic Gradient Descent.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"Computationally, we look at a very simple but large scale problem, the Riemannian Center of Mass or Fr√©chet mean: for given points p_i mathcal M, i=1N this optimization problem reads","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"operatorname*argmin_xmathcal M frac12sum_i=1^N\n  operatornamed^2_mathcal M(xp_i)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"which of course can be (and is) solved by a gradient descent, see the introductionary tutorial or Statistics in Manifolds.jl. If N is very large, evaluating the complete gradient might be quite expensive. A remedy is to evaluate only one of the terms at a time and choose a random order for these.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"We first initialize the packages","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"using Manifolds, Manopt, Random, BenchmarkTools\nRandom.seed!(42);","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"We next generate a (little) large(r) data set","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"n = 5000\nœÉ = œÄ / 12\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n];","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"Note that due to the construction of the points as zero mean tangent vectors, the mean should be very close to our initial point p.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"In order to use the stochastic gradient, we now need a function that returns the vector of gradients. There are two ways to define it in Manopt.jl: either as a single function that returns a vector, or as a vector of functions.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"The first variant is of course easier to define, but the second is more efficient when only evaluating one of the gradients.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"For the mean, the gradient is","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"operatornamegradf(p) = sum_i=1^N operatornamegradf_i(x) quad textwhere operatornamegradf_i(x) = -log_x p_i","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"which we define in Manopt.jl in two different ways: either as one function returning all gradients as a vector (see gradF), or ‚Äì maybe more fitting for a large scale problem, as a vector of small gradient functions (see gradf)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"F(M, p) = 1 / (2 * n) * sum(map(q -> distance(M, p, q)^2, data))\ngradF(M, p) = [grad_distance(M, p, q) for q in data]\ngradf = [(M, p) -> grad_distance(M, q, p) for q in data];\np0 = 1 / sqrt(3) * [1.0, 1.0, 1.0]","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"3-element Vector{Float64}:\n 0.5773502691896258\n 0.5773502691896258\n 0.5773502691896258","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"The calls are only slightly different, but notice that accessing the 2nd gradient element requires evaluating all logs in the first function, while we only call one of the functions in the second array of functions. So while you can use both gradF and gradf in the following call, the second one is (much) faster:","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"p_opt1 = stochastic_gradient_descent(M, gradF, p)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"3-element Vector{Float64}:\n  0.14325784688909826\n -1.0958972513835996\n -0.1203504171470485","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"@benchmark stochastic_gradient_descent($M, $gradF, $p0)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"BenchmarkTools.Trial: 1 sample with 1 evaluation.\n Single result which took 12.703 s (6.34% GC) to evaluate,\n with a memory estimate of 7.83 GiB, over 100158838 allocations.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"p_opt2 = stochastic_gradient_descent(M, gradf, p0)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"3-element Vector{Float64}:\n  0.3720618759999458\n -0.11462522239619974\n  0.9211031531907936","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"@benchmark stochastic_gradient_descent($M, $gradf, $p0)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"BenchmarkTools.Trial: 570 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  7.266 ms ‚Ä¶ 16.274 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 36.39%\n Time  (median):     8.115 ms              ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   8.753 ms ¬±  1.775 ms  ‚îä GC (mean ¬± œÉ):  5.12% ¬± 11.08%\n\n   ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ                                    ‚ñÅ       \n  ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñá‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÑ ‚ñà\n  7.27 ms      Histogram: log(frequency) by time     14.7 ms <\n\n Memory estimate: 3.43 MiB, allocs estimate: 50029.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"This result is reasonably close. But we can improve it by using a DirectionUpdateRule, namely:","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"On the one hand MomentumGradient, which requires both the manifold and the initial value, in order to keep track of the iterate and parallel transport the last direction to the current iterate. The necessary vector_transport_method keyword is set to a suitable default on every manifold, see default_vector_transport_method. We get ‚Äú‚Äú‚Äù","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"p_opt3 = stochastic_gradient_descent(\n    M, gradf, p0; direction=MomentumGradient(M, p0; direction=StochasticGradient(M))\n)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"3-element Vector{Float64}:\n -0.7117638264711592\n  0.28597137443326925\n -0.6415704391038297","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"MG = MomentumGradient(M, p0; direction=StochasticGradient(M));\n@benchmark stochastic_gradient_descent($M, $gradf, $p0; direction=$MG)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"BenchmarkTools.Trial: 131 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  33.736 ms ‚Ä¶ 49.839 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 16.38%\n Time  (median):     36.761 ms              ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   38.424 ms ¬±  3.888 ms  ‚îä GC (mean ¬± œÉ):  4.98% ¬±  7.45%\n\n     ‚ñÅ‚ñÇ ‚ñÇ‚ñà‚ñà ‚ñá‚ñÑ ‚ñÅ               ‚ñÅ                               \n  ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÅ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ ‚ñÉ\n  33.7 ms         Histogram: frequency by time        49.5 ms <\n\n Memory estimate: 11.36 MiB, allocs estimate: 249515.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"And on the other hand the AverageGradient computes an average of the last n gradients, i.e.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"p_opt4 = stochastic_gradient_descent(\n    M, gradf, p0; direction=AverageGradient(M, p0; n=10, direction=StochasticGradient(M))\n)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"3-element Vector{Float64}:\n  0.5890747108042973\n -0.09496704200328851\n  0.8024788134424362","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"AG = AverageGradient(M, p0; n=10, direction=StochasticGradient(M));\n@benchmark stochastic_gradient_descent($M, $gradf, $p0; direction=$AG)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"BenchmarkTools.Trial: 61 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  73.206 ms ‚Ä¶ 94.060 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 8.09%\n Time  (median):     83.284 ms              ‚îä GC (median):    8.05%\n Time  (mean ¬± œÉ):   82.854 ms ¬±  3.828 ms  ‚îä GC (mean ¬± œÉ):  6.41% ¬± 3.49%\n\n                          ‚ñÇ   ‚ñÇ   ‚ñÇ‚ñà ‚ñÖ‚ñÇ                        \n  ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñà‚ñà‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÖ ‚ñÅ\n  73.2 ms         Histogram: frequency by time        91.8 ms <\n\n Memory estimate: 34.25 MiB, allocs estimate: 569515.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"Note that the default StoppingCriterion is a fixed number of iterations which helps the comparison here.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"For both update rules we have to internally specify that we are still in the stochastic setting, since both rules can also be used with the IdentityUpdateRule within gradient_descent.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"For this not-that-large-scale example we can of course also use a gradient descent with ArmijoLinesearch,","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"fullGradF(M, p) = sum(grad_distance(M, q, p) for q in data)\np_opt5 = gradient_descent(M, F, fullGradF, p0; stepsize=ArmijoLinesearch(M))","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"3-element Vector{Float64}:\n  0.6923385117411869\n -0.025289924143011427\n  0.7211295340622513","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"but it will be a little slower usually","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"AL = ArmijoLinesearch(M);\n@benchmark gradient_descent($M, $F, $fullGradF, $p0; stepsize=$AL)","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"BenchmarkTools.Trial: 5 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  1.114 s ‚Ä¶  1.138 s  ‚îä GC (min ‚Ä¶ max): 8.05% ‚Ä¶ 7.94%\n Time  (median):     1.121 s             ‚îä GC (median):    7.99%\n Time  (mean ¬± œÉ):   1.123 s ¬± 8.973 ms  ‚îä GC (mean ¬± œÉ):  7.97% ¬± 0.05%\n\n  ‚ñà         ‚ñà     ‚ñà  ‚ñà                                   ‚ñà  \n  ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà ‚ñÅ\n  1.11 s        Histogram: frequency by time        1.14 s <\n\n Memory estimate: 703.16 MiB, allocs estimate: 9021017.","category":"page"},{"location":"tutorials/StochasticGradientDescent/","page":"How to Run Stochastic Gradient Descent","title":"How to Run Stochastic Gradient Descent","text":"Note that all 5 runs are very close to each other, here we check the distance to the first","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"EditURL = \"https://github.com/JuliaManifolds/Manopt.jl/blob/master/CONTRIBUTING.md\"","category":"page"},{"location":"contributing/#Contributing-to-Manopt.jl","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"First, thanks for taking the time to contribute. Any contribution is appreciated and welcome.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"The following is a set of guidelines to Manopt.jl.","category":"page"},{"location":"contributing/#Table-of-Contents","page":"Contributing to Manopt.jl","title":"Table of Contents","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Contributing to Manopt.jl     - Table of Contents\nI just have a question\nHow can I file an issue?\nHow can I contribute?\nAdd a missing method\nProvide a new algorithm\nProvide a new example\nCode style","category":"page"},{"location":"contributing/#I-just-have-a-question","page":"Contributing to Manopt.jl","title":"I just have a question","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"The developer can most easily be reached in the Julia Slack channel #manifolds. You can apply for the Julia Slack workspace here if you haven't joined yet. You can also ask your question on discourse.julialang.org.","category":"page"},{"location":"contributing/#How-can-I-file-an-issue?","page":"Contributing to Manopt.jl","title":"How can I file an issue?","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"If you found a bug or want to propose a feature, we track our issues within the GitHub repository.","category":"page"},{"location":"contributing/#How-can-I-contribute?","page":"Contributing to Manopt.jl","title":"How can I contribute?","text":"","category":"section"},{"location":"contributing/#Add-a-missing-method","page":"Contributing to Manopt.jl","title":"Add a missing method","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"There is still a lot of methods for within the optimization framework of  Manopt.jl, may it be functions, gradients, differentials, proximal maps, step size rules or stopping criteria. If you notice a method missing and can contribute an implementation, please do so! Even providing a single new method is a good contribution.","category":"page"},{"location":"contributing/#Provide-a-new-algorithm","page":"Contributing to Manopt.jl","title":"Provide a new algorithm","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"A main contribution you can provide is another algorithm that is not yet included in the package. An algorithm is always based on a concrete type of a AbstractManoptProblem storing the main information of the task and a concrete type of an AbstractManoptSolverState storing all information that needs to be known to the solver in general. The actual algorithm is split into an initialization phase, see initialize_solver!, and the implementation of the ith step of the solver itself, see  before the iterative procedure, see step_solver!. For these two functions, it would be great if a new algorithm uses functions from the ManifoldsBase.jl interface as generically as possible. For example, if possible use retract!(M,q,p,X) in favor of exp!(M,q,p,X) to perform a step starting in p in direction X (in place of q), since the exponential map might be too expensive to evaluate or might not be available on a certain manifold. See Retractions and inverse retractions for more details. Further, if possible, prefer retract!(M,q,p,X) in favor of retract(M,p,X), since a computation in place of a suitable variable q reduces memory allocations.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Usually, the methods implemented in Manopt.jl also have a high-level interface, that is easier to call, creates the necessary problem and options structure and calls the solver.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"The two technical functions initialize_solver! and step_solver! should be documented with technical details, while the high level interface should usually provide a general description and some literature references to the algorithm at hand.","category":"page"},{"location":"contributing/#Provide-a-new-example","page":"Contributing to Manopt.jl","title":"Provide a new example","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"Example problems are available at ManoptExamples.jl, where also their reproducible Quarto-Markdown files are stored.","category":"page"},{"location":"contributing/#Code-style","page":"Contributing to Manopt.jl","title":"Code style","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"We try to follow the documentation guidelines from the Julia documentation as well as Blue Style. We run JuliaFormatter.jl on the repo in the way set in the .JuliaFormatter.toml file, which enforces a number of conventions consistent with the Blue Style.","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"We also follow a few internal conventions:","category":"page"},{"location":"contributing/","page":"Contributing to Manopt.jl","title":"Contributing to Manopt.jl","text":"It is preferred that the AbstractManoptProblem's struct contains information about the general structure of the problem.\nAny implemented function should be accompanied by its mathematical formulae if a closed form exists.\nAbstractManoptProblem and option structures are stored within the plan/ folder and sorted by properties of the problem and/or solver at hand.\nWithin the source code of one algorithm, the high level interface should be first, then the initialization, then the step.\nOtherwise an alphabetical order is preferable.\nThe above implies that the mutating variant of a function follows the non-mutating variant.\nThere should be no dangling = signs.\nAlways add a newline between things of different types (struct/method/const).\nAlways add a newline between methods for different functions (including mutating/nonmutating variants).\nPrefer to have no newline between methods for the same function; when reasonable, merge the docstrings.\nAll import/using/include should be in the main module file.","category":"page"},{"location":"helpers/checks/#Checks","page":"Checks","title":"Checks","text":"","category":"section"},{"location":"helpers/checks/","page":"Checks","title":"Checks","text":"If you have computed a gradient or differential and you are not sure whether it is correct.","category":"page"},{"location":"helpers/checks/","page":"Checks","title":"Checks","text":"Modules = [Manopt]\nPages   = [\"checks.jl\"]","category":"page"},{"location":"helpers/checks/#Manopt.check_Hessian","page":"Checks","title":"Manopt.check_Hessian","text":"check_Hessian(M, f, grad_f, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M, vector_at=p); kwargs...)\n\nCheck numerivcally whether the Hessian {operatorname{Hess} f(M,p, X) of f(M,p) is correct.\n\nFor this we require either a second-order retraction or a critical point p of f.\n\ngiven that we know  that is whether\n\nf(operatornameretr_p(tX)) = f(p) + toperatornamegrad f(p) X + fract^22operatornameHessf(p)X X + mathcal O(t^3)\n\nor in other words, that the error between the function f and its second order Taylor behaves in error mathcal O(t^3), which indicates that the Hessian is correct, cf. also Section 6.8 [Boumal2022].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot will be generated.\n\nKeyword arguments\n\ncheck_grad       ‚Äì (true) check whether operatornamegrad f(p) in T_pmathcal M.\ncheck_linearity  ‚Äì (true) check whether the Hessian is linear, see is_Hessian_linear using a, b, X, and Y\ncheck_symmetry   ‚Äì (true) check whether the Hessian is symmetric, see is_Hessian_symmetric\ncheck_vector     ‚Äì (false) check whether operatornameHess f(p)X in T_pmathcal M using is_vector.\nmode             - (:Default) specify the mode, by default we assume to have a second order retraction given by retraction_method= you can also this method if you already have a cirtical point p. Set to :CritalPoint to use gradient_descent to find a critical point. Note: This requires (and evaluates) new tangent vectors X and Y\natol, rtol      ‚Äì (same defaults as isapprox) tolerances that are passed down to all checks\na, b            ‚Äì two real values to check linearity of the Hessian (if check_linearity=true)\nN                 - (101) number of points to check within the log_range default range 10^-810^0\nexactness_tol     - (1e-12) if all errors are below this tolerance, the check is considered to be exact\nio                ‚Äì (nothing) provide an IO to print the check result to\ngradient          - (grad_f(M, p)) instead of the gradient function you can also provide the gradient at p directly\nHessian           - (Hess_f(M, p, X)) instead of the Hessian function you can provide the result of operatornameHess f(p)X directly. Note that evaluations of the Hessian might still be necessary for checking linearity and symmetry and/or when using :CriticalPoint mode.\nlimits            - ((1e-8,1)) specify the limits in the log_range\nlog_range         - (range(limits[1], limits[2]; length=N)) specify the range of points (in log scale) to sample the Hessian line\nN                 - (101) number of points to check within the log_range default range 10^-810^0\nplot              - (false) whether to plot the resulting check (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method - (default_retraction_method(M, typeof(p))) retraction method to use for the check\nslope_tol         ‚Äì (0.1) tolerance for the slope (global) of the approximation\nthrow_error       - (false) throw an error message if the Hessian is wrong\nwindow ‚Äì (nothing) specify window sizes within the log_range that are used for the slope estimation. the default is, to use all window sizes 2:N.\n\nThe kwargs... are also passed down to the check_vector call, such that tolerances can easily be set.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.check_differential","page":"Checks","title":"Manopt.check_differential","text":"check_differential(M, F, dF, p=rand(M), X=rand(M; vector_at=p); kwargs...)\n\nCheck numerivcally whether the differential dF(M,p,X) of F(M,p) is correct.\n\nThis implements the method described in Section 4.8 [Boumal2022].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot will be generated,\n\nKeyword arguments\n\nexactness_tol - (1e-12) if all errors are below this tolerance, the check is considered to be exact\nio ‚Äì (nothing) provide an IO to print the check result to\nlimits ((1e-8,1)) specify the limits in the log_range\nlog_range (range(limits[1], limits[2]; length=N)) - specify the range of points (in log scale) to sample the differential line\nN (101) ‚Äì number of points to check within the log_range default range 10^-810^0\nname (\"differential\") ‚Äì name to display in the check (e.g. if checking differential)\nplot- (false) whether to plot the resulting check (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method - (default_retraction_method(M, typeof(p))) retraction method to use for the check\nslope_tol ‚Äì (0.1) tolerance for the slope (global) of the approximation\nthrow_error - (false) throw an error message if the differential is wrong\nwindow ‚Äì (nothing) specify window sizes within the log_range that are used for the slope estimation. the default is, to use all window sizes 2:N.\n\n[Boumal2022]: Boumal, N.: An Introduction to Optimization on Smooth Manifolds, book in preparation, 2022. url: http://www.nicolasboumal.net/book.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.check_gradient","page":"Checks","title":"Manopt.check_gradient","text":"check_gradient(M, F, gradF, p=rand(M), X=rand(M; vector_at=p); kwargs...)\n\nCheck numerivcally whether the gradient gradF(M,p) of F(M,p) is correct, that is whether\n\nf(operatornameretr_p(tX)) = f(p) + toperatornamegrad f(p) X + mathcal O(t^2)\n\nor in other words, that the error between the function f and its first order Taylor behaves in error mathcal O(t^2), which indicates that the gradient is correct, cf. also Section 4.8 [Boumal2022].\n\nNote that if the errors are below the given tolerance and the method is exact, no plot will be generated.\n\nKeyword arguments\n\ncheck_vector      ‚Äì (true) check whether operatornamegrad f(p) in T_pmathcal M using is_vector.\nexactness_tol     - (1e-12) if all errors are below this tolerance, the check is considered to be exact\nio                ‚Äì (nothing) provide an IO to print the check result to\ngradient          - (grad_f(M, p)) instead of the gradient function you can also provide the gradient at p directly\nlimits            - ((1e-8,1)) specify the limits in the log_range\nlog_range         - (range(limits[1], limits[2]; length=N)) - specify the range of points (in log scale) to sample the gradient line\nN                 - (101) ‚Äì number of points to check within the log_range default range 10^-810^0\nplot              - (false) whether to plot the resulting check (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nretraction_method - (default_retraction_method(M, typeof(p))) retraction method to use for the check\nslope_tol         ‚Äì (0.1) tolerance for the slope (global) of the approximation\natol, rtol      ‚Äì (same defaults as isapprox) tolerances that are passed down to is_vector if check_vector is set to true\nthrow_error       - (false) throw an error message if the gradient is wrong\nwindow ‚Äì (nothing) specify window sizes within the log_range that are used for the slope estimation. the default is, to use all window sizes 2:N.\n\nThe kwargs... are also passed down to the check_vector call, such that tolerances can easily be set.\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.find_best_slope_window","page":"Checks","title":"Manopt.find_best_slope_window","text":"(a,b,i,j) = find_best_slope_window(X,Y,window=nothing; slope=2.0, slope_tol=0.1)\n\nCheck data X,Y for the largest contiguous interval (window) with a regression line fitting ‚Äúbest‚Äù. Among all intervals with a slope within slope_tol to slope the longest one is taken. If no such interval exists, the one with the slope closest to slope is taken.\n\nIf the window is set to nothing (default), all window sizes 2,...,length(X) are checked. You can also specify a window size or an array of window sizes.\n\nFor each window size , all its translates in the data are checked. For all these (shifted) windows the regression line is computed (i.e. a,b in a + t*b) and the best line is computed.\n\nFrom the best line the following data is returned\n\na, b specifying the regression line a + t*b\ni, j determining the window, i.e the regression line stems from data X[i], ..., X[j]\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.is_Hessian_linear","page":"Checks","title":"Manopt.is_Hessian_linear","text":"is_Hessian_linear(M, Hess_f, p,\n    X=rand(M; vector_at=p), Y=rand(M; vector_at=p), a=randn(), b=randn();\n    throw_error=false, io=nothing, kwargs...\n)\n\nCheck whether the Hessian function Hess_f fulfills linearity, i.e. that\n\noperatornameHess f(p)aX + bY = boperatornameHess f(p)X\n + boperatornameHess f(p)Y\n\nwhich is checked using isapprox and the kwargs... are passed to this function.\n\nOptional Arguments\n\nthrow_error       - (false) throw an error message if the Hessian is wrong\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.is_Hessian_symmetric","page":"Checks","title":"Manopt.is_Hessian_symmetric","text":"is_Hessian_symmetric(M, Hess_f, p=rand(M), X=rand(M; vector_at=p), Y=rand(M; vector_at=p);\nthrow_error=false, io=nothing, atol::Real=0, rtol::Real=atol>0 ? 0 : ‚àöeps\n\n)\n\nCheck whether the Hessian function Hess_f fulfills symmetry, i.e. that\n\noperatornameHess f(p)X Y = X operatornameHess f(p)Y\n\nwhich is checked using isapprox and the kwargs... are passed to this function.\n\nOptional Arguments\n\natol, rtol - with the same defaults as the usual isapprox\nthrow_error - (false) throw an error message if the Hessian is wrong\n\n\n\n\n\n","category":"function"},{"location":"helpers/checks/#Manopt.plot_slope-Tuple{Any, Any}","page":"Checks","title":"Manopt.plot_slope","text":"plot_slope(x, y; slope=2, line_base=0, a=0, b=2.0, i=1,j=length(x))\n\nPlot the result from the error check functions, e.g. check_gradient, check_differential, check_Hessian on data x,y with two comparison lines\n\nline_base + tslope  as the global slope the plot should have\na + b*t on the interval [x[i], x[j]] for some (best fitting) comparison slope\n\n\n\n\n\n","category":"method"},{"location":"helpers/checks/#Manopt.prepare_check_result-Tuple{Any, Any, Any}","page":"Checks","title":"Manopt.prepare_check_result","text":"prepare_check_result(log_range, errors, slope)\n\nGiven a range of values log_range, where we computed errors, check whether this yields a slope of slope in log-scale\n\nNote that if the errors are below the given tolerance and the method is exact, no plot will be generated,\n\nKeyword arguments\n\nexactness_tol - (1e3*eps(eltype(errors))) is all errors are below this tolerance, the check is considered to be exact\nio ‚Äì (nothing) provide an IO to print the check result to\nname (\"differntial\") ‚Äì name to display in the check (e.g. if checking gradient)\nplot- (false) whether to plot the resulting check (if Plots.jl is loaded). The plot is in log-log-scale. This is returned and can then also be saved.\nslope_tol ‚Äì (0.1) tolerance for the slope (global) of the approximation\nthrow_error - (false) throw an error message if the gradient or Hessian is wrong\n\n\n\n\n\n","category":"method"},{"location":"helpers/checks/#Internal-methods","page":"Checks","title":"Internal methods","text":"","category":"section"},{"location":"helpers/checks/","page":"Checks","title":"Checks","text":"Modules = [Manopt]\nPages   = [\"check_plots.jl\"]\nPrivate = true","category":"page"},{"location":"solvers/difference_of_convex/#DifferenceOfConvexSolvers","page":"Difference of Convex","title":"Difference of Convex","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/difference_of_convex/#DCASolver","page":"Difference of Convex","title":"Difference of Convex Algorithm","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"difference_of_convex_algorithm\ndifference_of_convex_algorithm!","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm","page":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm","text":"difference_of_convex_algorithm(M, f, g, ‚àÇh, p=rand(M); kwargs...)\ndifference_of_convex_algorithm(M, mdco, p; kwargs...)\n\nCompute the difference of convex algorithm[FerreiraSantosSouza2021] to minimize\n\n    operatorname*argmin_pmathcal M  g(p) - h(p)\n\nwhere you need to provide f(p) = g(p) - h(p), g and the subdifferential h of h.\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01ldots\n\nTake X^(k)   h(p^(k))\nSet the next iterate to the solution of the subproblem\n\n  p^(k+1) in operatorname*argmin_qin mathcal M g(q) - X^(k) log_p^(k)q\n\nuntil the stopping_criterion is fulfilled.\n\nOptional parameters\n\nevaluation          ‚Äì (AllocatingEvaluation) specify whether the gradient works by allocation (default) form grad_f(M, p) or InplaceEvaluation form grad_f!(M, X, x)\ngradient            ‚Äì (nothing) specify operatornamegrad f, for debug / analysis or enhancing stopping_criterion=\ngrad_g              ‚Äì (nothing) specify the gradient of g. If specified, a subsolver is automatically set up.\ninitial_vector      - (zero_vector(M, p)) initialise the inner tangent vecor to store the subgradient result.\nstopping_criterion  ‚Äì (StopAfterIteration(200) |StopWhenChangeLess(1e-8)) a StoppingCriterion for the algorithm ‚Äì includes a StopWhenGradientNormLess(1e-8), when a gradient is provided.\n\nif you specify the ManifoldDifferenceOfConvexObjective mdco, additionally\n\ng                   - (nothing) speficy the function g If specified, a subsolver is automatically set up.\n\nWhile there are several parameters for a sub solver, the easiest is to provide the function grad_g=, such that together with the mandatory function g a default cost and gradient can be generated and passed to a default subsolver. Hence the easiest example call looks like\n\ndifference_of_convex_algorithm(M, f, g, grad_h, p; grad_g=grad_g)\n\nOptional parameters for the sub problem\n\nsub_cost              - (LinearizedDCCost(g, p, initial_vector)) a cost to be used within the default sub_problem Use this if you have a more efficient version than the default that is built using g from above.\nsub_grad              - (LinearizedDCGrad(grad_g, p, initial_vector; evaluation=evaluation) gradient to be used within the default sub_problem. This is generated by default when grad_g is provided. You can specify your own by overwriting this keyword.\nsub_hess              ‚Äì (a fininte difference approximation by default) specify a Hessian  of the subproblem, which the default solver, see sub_state needs\nsub_kwargs            - ([]) pass keyword arguments to the sub_state, in form of a Dict(:kwname=>value), unless you set the sub_state directly.\nsub_objective         - (a gradient or hessian objetive based on the last 3 keywords) provide the objective used within sub_problem (if that is not specified by the user)\nsub_problem           - (DefaultManoptProblem(M, sub_objective) specify a manopt problem for the sub-solver runs. You can also provide a function for a closed form solution. Then evaluation= is taken into account for the form of this function.\nsub_state             - (TrustRegionsState by default, requires sub_hessian to be provided; decorated with sub_kwargs). Choose the solver by specifying a solver state to solve the sub_problem if the sub_problem if a function (i.e. a closed form solution), this is set to evaluation and can be changed to the evalution type of the closed form solution accordingly.\nsub_stopping_criterion - (StopAfterIteration(300) |StopWhenStepsizeLess(1e-9) |StopWhenGradientNormLess(1e-9)) a stopping crierion used withing the default sub_state=\nsub_stepsize           - (ArmijoLinesearch(M)) specify a step size used within the sub_state\n\n...all others are passed on to decorate the inner DifferenceOfConvexState.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n[FerreiraSantosSouza2021]: Ferreira, O. P., Santos, E. M., Souza, J. C. O.: The difference of convex algorithm on Riemannian manifolds, 2021, arXiv: 2112.05250.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_algorithm!","page":"Difference of Convex","title":"Manopt.difference_of_convex_algorithm!","text":"difference_of_convex_algorithm!(M, f, g, ‚àÇh, p; kwargs...)\ndifference_of_convex_algorithm!(M, mdco, p; kwargs...)\n\nRun the difference of convex algorithm and perform the steps in place of p. See difference_of_convex_algorithm for more details.\n\nif you specify the ManifoldDifferenceOfConvexObjective mdco, the g is a keyword argument.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#DCPPASolver","page":"Difference of Convex","title":"Difference of Convex Proximal Point","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"difference_of_convex_proximal_point\ndifference_of_convex_proximal_point!","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point","page":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point","text":"difference_of_convex_proximal_point(M, grad_h, p=rand(M); kwargs...)\ndifference_of_convex_proximal_point(M, mdcpo, p=rand(M); kwargs...)\n\nCompute the difference of convex proximal point algorithm [SouzaOliveira2015] to minimize\n\n    operatorname*argmin_pmathcal M g(p) - h(p)\n\nwhere you have to provide the (sub) gradient h of h and either\n\nthe proximal map operatornameprox_lambda g of g as a function prox_g(M, Œª, p) or  prox_g(M, q, Œª, p)\nthe functions g and grad_g to compute the proximal map using a sub solver\nyour own sub-solver, see optional keywods below\n\nThis algorithm performs the following steps given a start point p= p^(0). Then repeat for k=01ldots\n\nX^(k)   operatornamegrad h(p^(k))\nq^(k) = operatornameretr_p^(k)(Œª_kX^(k))\nr^(k) = operatornameprox_Œª_kg(q^(k))\nX^(k) = operatornameretr^-1_p^(k)(r^(k))\nCompute a stepsize s_k and\nset p^(k+1) = operatornameretr_p^(k)(s_kX^(k)).\n\nuntil the stopping_criterion is fulfilled. See [AlmeidaNetoOliveiraSouza2020] for more details on the modified variant, where we slightly changed step 4-6, sine here we get the classical proximal point method for DC functions for s_k = 1 and we can employ linesearches similar to other solvers.\n\nOptional parameters\n\nŒª                         ‚Äì ( i -> 1/2 ) a function returning the sequence of prox parameters Œªi\nevaluation                ‚Äì (AllocatingEvaluation) specify whether the gradient works by allocation (default) form gradF(M, x) or InplaceEvaluation in place, i.e. is of the form gradF!(M, X, x).\ncost                      - (nothing) provide the cost f, e.g. for debug reasonscost to be used within the default sub_problem. Use this if you have a more efficient version than using g from above.\ngradient                  ‚Äì (nothing) specify operatornamegrad f, for debug / analysis  or enhancing the stopping_criterion\nprox_g                    - (nothing) specify a proximal map for the sub problem or both of the following\ng                         ‚Äì (nothing) specify the function g.\ngrad_g                    ‚Äì (nothing) specify the gradient of g. If both gand grad_g are specified, a subsolver is automatically set up.\ninverse_retraction_method - (default_inverse_retraction_method(M)) an inverse retraction method to use (see step 4).\nretraction_method         ‚Äì (default_retraction_method(M)) a retraction to use (see step 2)\nstepsize                  ‚Äì (ConstantStepsize(M)) specify a Stepsize to run the modified algorithm (experimental.) functor.\nstopping_criterion (StopAfterIteration(200) |StopWhenChangeLess(1e-8)) a StoppingCriterion for the algorithm ‚Äì includes a StopWhenGradientNormLess(1e-8), when a gradient is provided.\n\nWhile there are several parameters for a sub solver, the easiest is to provide the function g and grad_g, such that together with the mandatory function g a default cost and gradient can be generated and passed to a default subsolver. Hence the easiest example call looks like\n\ndifference_of_convex_proximal_point(M, grad_h, p0; g=g, grad_g=grad_g)\n\nOptional parameters for the sub problem\n\nsub_cost               ‚Äì (ProximalDCCost(g, copy(M, p), Œª(1))) cost to be used within the default sub_problem that is initialized as soon as g is provided.\nsub_grad               ‚Äì (ProximalDCGrad(grad_g, copy(M, p), Œª(1); evaluation=evaluation) gradient to be used within the default sub_problem, that is initialized as soon as grad_g is provided. This is generated by default when grad_g is provided. You can specify your own by overwriting this keyword.\nsub_hess               ‚Äì (a fininte difference approximation by default) specify a Hessian of the subproblem, which the default solver, see sub_state needs\nsub_kwargs             ‚Äì ([]) pass keyword arguments to the sub_state, in form of a Dict(:kwname=>value), unless you set the sub_state directly.\nsub_objective          ‚Äì (a gradient or hessian objetive based on the last 3 keywords) provide the objective used within sub_problem (if that is not specified by the user)\nsub_problem            ‚Äì (DefaultManoptProblem(M, sub_objective) specify a manopt problem for the sub-solver runs. You can also provide a function for a closed form solution. Then evaluation= is taken into account for the form of this function.\nsub_state              ‚Äì (TrustRegionsState ‚Äì requires the sub_hessian to be provided,  decorated withsubkwargs) choose the solver by specifying a solver state to solve thesubproblem`\nsub_stopping_criterion - (StopAfterIteration(300) |StopWhenStepsizeLess(1e-9) |StopWhenGradientNormLess(1e-9)) a stopping crierion used withing the default sub_state=\n\n...all others are passed on to decorate the inner DifferenceOfConvexProximalState.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n[SouzaOliveira2015]: de Oliveira Souza, J. C., Oliveira, P. R.: A proximal point algorithm for {DC} fuctions on Hadamard manifolds, Journal of Global Optimization (64), 4, 2015, pp. 797‚Äì810, doi: 10.1007/s10898-015-0282-7.\n\n[AlmeidaNetoOliveiraSouza2020]: Almeida, Y. T., de Cruz Neto, J. X. Oliveira, P. R., de Oliveira Souza, J. C.: A modified proximal point method for DC functions on Hadamard manifolds, Computational Optimization and Applications (76), 2020, pp. 649‚Äì673. doi: 10.1007/s10589-020-00173-3\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt.difference_of_convex_proximal_point!","page":"Difference of Convex","title":"Manopt.difference_of_convex_proximal_point!","text":"difference_of_convex_proximal_point!(M, grad_h, p; cost=nothing, kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, p; cost=nothing, kwargs...)\ndifference_of_convex_proximal_point!(M, mdcpo, prox_g, p; cost=nothing, kwargs...)\n\nCompute the difference of convex algorithm to minimize\n\n    operatorname*argmin_pmathcal M g(p) - h(p)\n\nwhere you have to provide the proximal map of g and the gradient of h.\n\nThe compuation is done inplace of p.\n\nFor all further details, especially the keyword arguments, see difference_of_convex_proximal_point.\n\n\n\n\n\n","category":"function"},{"location":"solvers/difference_of_convex/#Manopt-Solver-States","page":"Difference of Convex","title":"Manopt Solver States","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"DifferenceOfConvexState\nDifferenceOfConvexProximalState","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.DifferenceOfConvexState","page":"Difference of Convex","title":"Manopt.DifferenceOfConvexState","text":"DifferenceOfConvexState{Pr,St,P,T,SC<:StoppingCriterion} <:\n           AbstractManoptSolverState\n\nA struct to store the current state of the [difference_of_convex_algorithm])(@ref). It comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\np ‚Äì the current iterate, i.e. a point on the manifold\nX ‚Äì the current subgradient, i.e. a tangent vector to p.\nsub_problem ‚Äì problem for the subsolver\nsub_state ‚Äì state of the subproblem\nstop ‚Äì a functor inheriting from StoppingCriterion indicating when to stop.\n\nFor the sub task, we need a method to solve\n\n    operatorname*argmin_qmathcal M g(p) - X log_p q\n\nbesides a problem and options, one can also provide a function and an AbstractEvaluationType, respectively, to indicate a closed form solution for the sub task.\n\nConstructors\n\nDifferenceOfConvexState(M, p, sub_problem, sub_state; kwargs...)\nDifferenceOfConvexState(M, p, sub_solver; evaluation=InplaceEvaluation(), kwargs...)\n\nGenerate the state either using a solver from Manopt, given by an AbstractManoptProblem sub_problem and an AbstractManoptSolverState sub_state, or a closed form solution sub_solver for the sub-problem, where by default its AbstractEvaluationType evaluation is in-place, i.e. the function is of the form (M, p, X) -> q or (M, q, p, X) -> q, such that the current iterate p and the subgradient X of h can be passed to that function and the result if q.\n\nFurther keyword Arguments\n\ninitial_vector=zero_vector (zero_vectoir(M,p)) how to initialize the inner gradient tangent vector\nstopping_criterion ‚Äì StopAfterIteration(200) a stopping criterion\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.DifferenceOfConvexProximalState","page":"Difference of Convex","title":"Manopt.DifferenceOfConvexProximalState","text":"DifferenceOfConvexProximalState{Type} <: Options\n\nA struct to store the current state of the algorithm as well as the form. It comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\ninverse_retraction_method ‚Äì (default_inverse_retraction_method(M)) an inverse retraction method to use within Frank Wolfe.\nretraction_method ‚Äì (default_retraction_method(M)) a type of retraction\np, q, r  ‚Äì the current iterate, the gradient step and the prox, respetively their type is set by intializing p\nstepsize ‚Äì (ConstantStepsize(1.0)) a Stepsize function to run the modified algorithm (experimental)\nstop ‚Äì (StopWhenChangeLess(1e-8)) a StoppingCriterion\nX, Y ‚Äì (zero_vector(M,p)) the current gradient and descent direction, respectively their common type is set by the keyword X\n\nConstructor\n\nDifferenceOfConvexProximalState(M, p; kwargs...)\n\nKeyword arguments\n\nX, retraction_method, inverse_retraction_method, stepsize for the fields above\nstoppping_criterion for the StoppingCriterion\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#The-difference-of-convex-objective","page":"Difference of Convex","title":"The difference of convex objective","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"ManifoldDifferenceOfConvexObjective","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexObjective","page":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexObjective","text":"ManifoldDifferenceOfConvexObjective{E} <: AbstractManifoldCostObjective{E}\n\nSpecify an objetive for a difference_of_convex_algorithm.\n\nThe objective f mathcal M to ‚Ñù is given as\n\n    f(p) = g(p) - h(p)\n\nwhere both g and h are convex, lsc. and proper. Furthermore we assume that the subdifferential h of h is given.\n\nFields\n\ncost ‚Äì an implementation of f(p) = g(p)-h(p) as a function f(M,p).\n‚àÇh!! ‚Äì a deterministic version of h mathcal M  Tmathcal M, i.e. calling ‚àÇh(M, p) returns a subgradient of h at p and if there is more than one, it returns a deterministic choice.\n\nNote that the subdifferential might be given in two possible signatures\n\n‚àÇh(M,p) which does an AllocatingEvaluation\n‚àÇh!(M, X, p) which does an InplaceEvaluation in place of X.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"as well as for the corresponding sub problem","category":"page"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"LinearizedDCCost\nLinearizedDCGrad","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.LinearizedDCCost","page":"Difference of Convex","title":"Manopt.LinearizedDCCost","text":"LinearizedDCCost\n\nA functor (M,q) ‚Üí ‚Ñù to represent the inner problem of a ManifoldDifferenceOfConvexObjective, i.e. a cost function of the form\n\n    F_p_kX_k(p) = g(p) - X_k log_p_kp\n\nfor a point p_k and a tangent vector X_k at p_k (e.g. outer iterates) that are stored within this functor as well.\n\nFields\n\ng a function\npk a point on a manifold\nXk a tangent vector at pk\n\nBoth interims values can be set using set_manopt_parameter!(::LinearizedDCCost, ::Val{:p}, p) and set_manopt_parameter!(::LinearizedDCCost, ::Val{:X}, X), respectively.\n\nConstructor\n\nLinearizedDCCost(g, p, X)\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.LinearizedDCGrad","page":"Difference of Convex","title":"Manopt.LinearizedDCGrad","text":"LinearizedDCGrad\n\nA functor (M,X,p) ‚Üí ‚Ñù to represent the gradient of the inner problem of a ManifoldDifferenceOfConvexObjective, i.e. for a cost function of the form\n\n    F_p_kX_k(p) = g(p) - X_k log_p_kp\n\nits gradient is given by using F=F_1(F_2(p)), where F_1(X) = X_kX and F_2(p) = log_p_kp and the chain rule as well as the adjoint differential of the logarithmic map with respect to its argument for D^*F_2(p)\n\n    operatornamegrad F(q) = operatornamegrad f(q) - DF_2^*(q)X\n\nfor a point pk and a tangent vector Xk at pk (the outer iterates) that are stored within this functor as well\n\nFields\n\ngrad_g!! the gradient of g (see also LinearizedDCCost)\npk a point on a manifold\nXk a tangent vector at pk\n\nBoth interims values can be set using set_manopt_parameter!(::LinearizedDCGrad, ::Val{:p}, p) and set_manopt_parameter!(::LinearizedDCGrad, ::Val{:X}, X), respectively.\n\nConstructor\n\nLinearizedDCGrad(grad_g, p, X; evaluation=AllocatingEvaluation())\n\nWhere you specify whether grad_g is AllocatingEvaluation or InplaceEvaluation, while this function still provides both signatures.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"ManifoldDifferenceOfConvexProximalObjective","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.ManifoldDifferenceOfConvexProximalObjective","page":"Difference of Convex","title":"Manopt.ManifoldDifferenceOfConvexProximalObjective","text":"ManifoldDifferenceOfConvexProximalObjective{E} <: Problem\n\nSpecify an objective difference_of_convex_proximal_point algorithm. The problem is of the form\n\n    operatorname*argmin_pin mathcal M g(p) - h(p)\n\nwhere both g and h are convex, lsc. and proper.\n\nFields\n\ncost ‚Äì (nothing) implementation of f(p) = g(p)-h(p) (optional)\ngradient - the gradient of the cost\ngrad_h!! ‚Äì a function operatornamegradh mathcal M  Tmathcal M,\n\nNote that both the gradients miht be given in two possible signatures as allocating or Inplace.\n\nConstructor\n\nManifoldDifferenceOfConvexProximalObjective(gradh; cost=norhting, gradient=nothing)\n\nan note that neither cost nor gradient are required for the algorithm, just for eventual debug or stopping criteria.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"as well as for the corresponding sub problems","category":"page"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"ProximalDCCost\nProximalDCGrad","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.ProximalDCCost","page":"Difference of Convex","title":"Manopt.ProximalDCCost","text":"ProximalDCCost\n\nA functor (M, p) ‚Üí ‚Ñù to represent the inner cost function of a ManifoldDifferenceOfConvexProximalObjective, i.e. the cost function of the proximal map of g.\n\n    F_p_k(p) = frac12Œªd_mathcal M(p_kp)^2 + g(p)\n\nfor a point pk and a proximal parameter Œª.\n\nFields\n\ng  - a function\npk - a point on a manifold\nŒª  - the prox parameter\n\nBoth interims values can be set using set_manopt_parameter!(::ProximalDCCost, ::Val{:p}, p) and set_manopt_parameter!(::ProximalDCCost, ::Val{:Œª}, Œª), respectively.\n\nConstructor\n\nProximalDCCost(g, p, Œª)\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Manopt.ProximalDCGrad","page":"Difference of Convex","title":"Manopt.ProximalDCGrad","text":"ProximalDCGrad\n\nA functor (M,X,p) ‚Üí ‚Ñù to represent the gradient of the inner cost function of a ManifoldDifferenceOfConvexProximalObjective, i.e. the gradient function of the proximal map cost function of g, i.e. of\n\n    F_p_k(p) = frac12Œªd_mathcal M(p_kp)^2 + g(p)\n\nwhich reads\n\n    operatornamegrad F_p_k(p) = operatornamegrad g(p) - frac1Œªlog_p p_k\n\nfor a point pk and a proximal parameter Œª.\n\nFields\n\ngrad_g  - a gradient function\npk - a point on a manifold\nŒª  - the prox parameter\n\nBoth interims values can be set using set_manopt_parameter!(::ProximalDCGrad, ::Val{:p}, p) and set_manopt_parameter!(::ProximalDCGrad, ::Val{:Œª}, Œª), respectively.\n\nConstructor\n\nProximalDCGrad(grad_g, pk, Œª; evaluation=AllocatingEvaluation())\n\nWhere you specify whether grad_g is AllocatingEvaluation or InplaceEvaluation, while this function still always provides both signatures.\n\n\n\n\n\n","category":"type"},{"location":"solvers/difference_of_convex/#Further-helper-functions","page":"Difference of Convex","title":"Further helper functions","text":"","category":"section"},{"location":"solvers/difference_of_convex/","page":"Difference of Convex","title":"Difference of Convex","text":"get_subtrahend_gradient","category":"page"},{"location":"solvers/difference_of_convex/#Manopt.get_subtrahend_gradient","page":"Difference of Convex","title":"Manopt.get_subtrahend_gradient","text":"X = get_subtrahend_gradient(amp, q)\nget_subtrahend_gradient!(amp, X, q)\n\nEvaluate the (sub)gradient of the subtrahend h from within a ManifoldDifferenceOfConvexObjective amp at the point q (in place of X).\n\nThe evaluation is done in place of X for the !-variant. The T=AllocatingEvaluation problem might still allocate memory within. When the non-mutating variant is called with a T=InplaceEvaluation memory for the result is allocated.\n\n\n\n\n\nX = get_subtrahend_gradient(M::AbstractManifold, dcpo::ManifoldDifferenceOfConvexProximalObjective, p)\nget_subtrahend_gradient!(M::AbstractManifold, X, dcpo::ManifoldDifferenceOfConvexProximalObjective, p)\n\nEvaluate the gradient of the subtrahend h from within a ManifoldDifferenceOfConvexProximalObjectivePat the pointp` (in place of X).\n\n\n\n\n\n","category":"function"},{"location":"solvers/primal_dual_semismooth_Newton/#PDRSSNSolver","page":"Primal-dual Riemannian semismooth Newton","title":"The Primal-dual Riemannian semismooth Newton Algorithm","text":"","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The Primal-dual Riemannian semismooth Newton Algorithm is a second-order method derived from the ChambollePock.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The aim is to solve an optimization problem on a manifold with a cost function of the form","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"F(p) + G(Œõ(p))","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"where Fmathcal M  overline‚Ñù, Gmathcal N  overline‚Ñù, and Œõmathcal M mathcal N. If the manifolds mathcal M or mathcal N are not Hadamard, it has to be considered locally, i.e. on geodesically convex sets mathcal C subset mathcal M and mathcal D subsetmathcal N such that Œõ(mathcal C) subset mathcal D.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The algorithm comes down to applying the Riemannian semismooth Newton method to the rewritten primal-dual optimality conditions, i.e., we define the vector field X mathcalM times mathcalT_n^* mathcalN rightarrow mathcalT mathcalM times mathcalT_n^* mathcalN as","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Xleft(p xi_nright)=left(beginarrayc\n-log _p operatornameprox_sigma Fleft(exp _pleft(mathcalP_p leftarrow mleft(-sigmaleft(D_m Lambdaright)^*leftmathcalP_Lambda(m) leftarrow n xi_nrightright)^sharpright)right) \nxi_n-operatornameprox_tau G_n^*left(xi_n+tauleft(mathcalP_n leftarrow Lambda(m) D_m Lambdaleftlog _m prightright)^flatright)\nendarrayright)","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"and solve for X(pŒæ_n)=0.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Given base points mmathcal C, n=Œõ(m)mathcal D, initial primal and dual values p^(0) mathcal C, Œæ_n^(0)  mathcal T_n^*mathcal N, and primal and dual step sizes sigma, tau.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"The algorithms performs the steps k=1 (until a StoppingCriterion is reached)","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Choose any element\nV^(k)  _C X(p^(k)Œæ_n^(k))\nof the Clarke generalized covariant derivative\nSolve\nV^(k) (d_p^(k) d_n^(k)) = - X(p^(k)Œæ_n^(k))\nin the vector space mathcalT_p^(k) mathcalM times mathcalT_n^* mathcalN\nUpdate\np^(k+1) = exp_p^(k)(d_p^(k))\nand\nŒæ_n^(k+1) = Œæ_n^(k) + d_n^(k)","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Furthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction and a vector transport.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"Finally you can also update the base points m and n during the iterations. This introduces a few additional vector transports. The same holds for the case that Œõ(m^(k))neq n^(k) at some point. All these cases are covered in the algorithm.","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"primal_dual_semismooth_Newton\nprimal_dual_semismooth_Newton!","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton","text":"primal_dual_semismooth_Newton(M, N, cost, p, X, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_dual_G, linearized_operator, adjoint_linearized_operator)\n\nPerform the Primal-Dual Riemannian Semismooth Newton algorithm.\n\nGiven a cost function mathcal Ecolonmathcal M to overline‚Ñù of the form\n\nmathcal E(p) = F(p) + G( Œõ(p) )\n\nwhere Fcolonmathcal M to overline‚Ñù, Gcolonmathcal N to overline‚Ñù, and Lambdacolonmathcal M to mathcal N. The remaining input parameters are\n\np, X primal and dual start points xinmathcal M and xiin T_nmathcal N\nm,n base points on mathcal M and mathcal N, respectively.\nlinearized_forward_operator the linearization DŒõ() of the operator Œõ().\nadjoint_linearized_operator the adjoint DŒõ^* of the linearized operator DŒõ(m)colon T_mmathcal M to T_Œõ(m)mathcal N\nprox_F, prox_G_Dual the proximal maps of F and G^ast_n\ndiff_prox_F, diff_prox_dual_G the (Clarke Generalized) differentials of the proximal maps of F and G^ast_n\n\nFor more details on the algorithm, see[DiepeveenLellmann2021].\n\nOptional Parameters\n\nprimal_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the primal prox\nŒõ (missing) the exact operator, that is required if Œõ(m)=n does not hold;\n\nmissing indicates, that the forward operator is exact.\n\ndual_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the dual prox\nreg_param ‚Äì (1e-5) regularisation parameter for the Newton matrix\n\nNote that this changes the arguments the forward_operator will be called.\n\nstopping_criterion ‚Äì (stopAtIteration(50)) a StoppingCriterion\nupdate_primal_base ‚Äì (missing) function to update m (identity by default/missing)\nupdate_dual_base ‚Äì (missing) function to update n (identity by default/missing)\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the rectraction to use\ninverse_retraction_method - (default_inverse_retraction_method(M, typeof(p))) an inverse retraction to use.\nvector_transport_method - (default_vector_transport_method(M, typeof(p))) a vector transport to use\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n[DiepeveenLellmann2021]: W. Diepeveen, J. Lellmann: An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising, SIAM Journal on Imaging Sciences, 2021. doi: 10.1137/21M1398513\n\n\n\n\n\n","category":"function"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.primal_dual_semismooth_Newton!","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.primal_dual_semismooth_Newton!","text":"primal_dual_semismooth_Newton(M, N, cost, x0, Œæ0, m, n, prox_F, diff_prox_F, prox_G_dual, diff_prox_G_dual, linearized_forward_operator, adjoint_linearized_operator)\n\nPerform the Riemannian Primal-dual Riemannian semismooth Newton algorithm in place of x, Œæ, and potentially m, n if they are not fixed. See primal_dual_semismooth_Newton for details and optional parameters.\n\n\n\n\n\n","category":"function"},{"location":"solvers/primal_dual_semismooth_Newton/#State","page":"Primal-dual Riemannian semismooth Newton","title":"State","text":"","category":"section"},{"location":"solvers/primal_dual_semismooth_Newton/","page":"Primal-dual Riemannian semismooth Newton","title":"Primal-dual Riemannian semismooth Newton","text":"PrimalDualSemismoothNewtonState","category":"page"},{"location":"solvers/primal_dual_semismooth_Newton/#Manopt.PrimalDualSemismoothNewtonState","page":"Primal-dual Riemannian semismooth Newton","title":"Manopt.PrimalDualSemismoothNewtonState","text":"PrimalDualSemismoothNewtonState <: AbstractPrimalDualSolverState\n\nm - base point on $ \\mathcal M $\nn - base point on $ \\mathcal N $\nx - an initial point on x^(0) in mathcal M (and its previous iterate)\nŒæ - an initial tangent vector xi^(0)in T_n^*mathcal N (and its previous iterate)\nprimal_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the primal prox\ndual_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the dual prox\nreg_param ‚Äì (1e-5) regularisation parameter for the Newton matrix\nstop - a StoppingCriterion\nupdate_primal_base (( amp, ams, i) -> o.m) function to update the primal base\nupdate_dual_base ((amp, ams, i) -> o.n) function to update the dual base\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the rectraction to use\ninverse_retraction_method - (default_inverse_retraction_method(M, typeof(p))) an inverse retraction to use.\nvector_transport_method - (default_vector_transport_method(M, typeof(p))) a vector transport to use\n\nwhere for the update functions a AbstractManoptProblem amp, AbstractManoptSolverState ams and the current iterate i are the arguments. If you activate these to be different from the default identity, you have to provide p.Œõ for the algorithm to work (which might be missing).\n\nConstructor\n\nPrimalDualSemismoothNewtonState(M::AbstractManifold,\n    m::P, n::Q, x::P, Œæ::T, primal_stepsize::Float64, dual_stepsize::Float64, reg_param::Float64;\n    stopping_criterion::StoppingCriterion = StopAfterIteration(50),\n    update_primal_base::Union{Function,Missing} = missing,\n    update_dual_base::Union{Function,Missing} = missing,\n    retraction_method = default_retraction_method(M, typeof(p)),\n    inverse_retraction_method = default_inverse_retraction_method(M, typeof(p)),\n    vector_transport_method = default_vector_transport_method(M, typeof(p)),\n)\n\n\n\n\n\n","category":"type"},{"location":"solvers/DouglasRachford/#DRSolver","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford Algorithm","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"The (Parallel) Douglas‚ÄìRachford ((P)DR) Algorithm was generalized to Hadamard manifolds in [Bergmann, Persch, Steidl, 2016].","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"The aim is to minimize the sum","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"F(x) = f(x) + g(x)","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"on a manifold, where the two summands have proximal maps operatornameprox_Œª f operatornameprox_Œª g that are easy to evaluate (maybe in closed form, or not too costly to approximate). Further, define the reflection operator at the proximal map as","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"operatornamerefl_Œª f(x) = exp_operatornameprox_Œª f(x) bigl( -log_operatornameprox_Œª f(x) x bigr)","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":".","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"Let alpha_k   01 with sum_k  mathbb N alpha_k(1-alpha_k) =   fty and Œª  0 which might depend on iteration k as well) be given.","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"Then the (P)DRA algorithm for initial data x_0  mathcal H as","category":"page"},{"location":"solvers/DouglasRachford/#Initialization","page":"Douglas‚ÄìRachford","title":"Initialization","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"Initialize t_0 = x_0 and k=0","category":"page"},{"location":"solvers/DouglasRachford/#Iteration","page":"Douglas‚ÄìRachford","title":"Iteration","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"Repeat until a convergence criterion is reached","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"Compute s_k = operatornamerefl_Œª foperatornamerefl_Œª g(t_k)\nWithin that operation, store x_k+1 = operatornameprox_Œª g(t_k) which is the prox the inner reflection reflects at.\nCompute t_k+1 = g(alpha_k t_k s_k)\nSet k = k+1","category":"page"},{"location":"solvers/DouglasRachford/#Result","page":"Douglas‚ÄìRachford","title":"Result","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"The result is given by the last computed x_K.","category":"page"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"For the parallel version, the first proximal map is a vectorial version where in each component one prox is applied to the corresponding copy of t_k and the second proximal map corresponds to the indicator function of the set, where all copies are equal (in mathcal H^n, where n is the number of copies), leading to the second prox being the Riemannian mean.","category":"page"},{"location":"solvers/DouglasRachford/#Interface","page":"Douglas‚ÄìRachford","title":"Interface","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"  DouglasRachford\n  DouglasRachford!","category":"page"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachford","page":"Douglas‚ÄìRachford","title":"Manopt.DouglasRachford","text":"DouglasRachford(M, f, proxes_f, p)\nDouglasRachford(M, mpo, p)\n\nCompute the Douglas-Rachford algorithm on the manifold mathcal M, initial data p and the (two) proximal maps proxMaps.\n\nFor k2 proximal maps, the problem is reformulated using the parallel Douglas Rachford: A vectorial proximal map on the power manifold mathcal M^k is introduced as the first proximal map and the second proximal map of the is set to the mean (Riemannian Center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, i.e. component wise in a vector.\n\nIf you provide a ManifoldProximalMapObjective mpo instead, the proximal maps are kept unchanged.\n\nInput\n\nM ‚Äì a Riemannian Manifold mathcal M\nF ‚Äì a cost function consisting of a sum of cost functions\nproxes_f ‚Äì functions of the form (M, Œª, p)->... performing a proximal maps, where ‚Å†Œª denotes the proximal parameter, for each of the summands of F. These can also be given in the InplaceEvaluation variants (M, q, Œª p) -> ... computing in place of q.\np ‚Äì initial data p  mathcal M\n\nOptional values\n\nevaluation ‚Äì (AllocatingEvaluation) specify whether the proximal maps work by allocation (default) form prox(M, Œª, x) or InplaceEvaluation in place, i.e. is of the form prox!(M, y, Œª, x).\nŒª ‚Äì ((iter) -> 1.0) function to provide the value for the proximal parameter during the calls\nŒ± ‚Äì ((iter) -> 0.9) relaxation of the step from old to new iterate, i.e. t_k+1 = g(Œ±_k t_k s_k), where s_k is the result of the double reflection involved in the DR algorithm\nR ‚Äì (reflect) method employed in the iteration to perform the reflection of x at the prox p.\nstopping_criterion ‚Äì (StopWhenAny(StopAfterIteration(200),StopWhenChangeLess(10.0^-5))) a StoppingCriterion.\nparallel ‚Äì (false) clarify that we are doing a parallel DR, i.e. on a PowerManifold manifold with two proxes. This can be used to trigger parallel Douglas‚ÄìRachford if you enter with two proxes. Keep in mind, that a parallel Douglas‚ÄìRachford implicitly works on a PowerManifold manifold and its first argument is the result then (assuming all are equal after the second prox.\n\nand the ones that are passed to decorate_state! for decorators.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachford!","page":"Douglas‚ÄìRachford","title":"Manopt.DouglasRachford!","text":" DouglasRachford!(M, f, proxes_f, p)\n DouglasRachford!(M, mpo, p)\n\nCompute the Douglas-Rachford algorithm on the manifold mathcal M, initial data p in mathcal M and the (two) proximal maps proxes_f in place of p.\n\nFor k2 proximal maps, the problem is reformulated using the parallel Douglas Rachford: A vectorial proximal map on the power manifold mathcal M^k is introduced as the first proximal map and the second proximal map of the is set to the mean (Riemannian Center of mass). This hence also boils down to two proximal maps, though each evaluates proximal maps in parallel, i.e. component wise in a vector.\n\nnote: Note\nWhile creating the new staring point p' on the power manifold, a copy of p Is created, so that the (by k>2 implicitly generated) parallel Douglas Rachford does not work in-place for now.\n\nIf you provide a ManifoldProximalMapObjective mpo instead, the proximal maps are kept unchanged.\n\nInput\n\nM ‚Äì a Riemannian Manifold mathcal M\nf ‚Äì a cost function consisting of a sum of cost functions\nproxes_f ‚Äì functions of the form (M, Œª, p)->q or (M, q, Œª, p)->q performing a proximal map, where ‚Å†Œª denotes the proximal parameter, for each of the summands of f.\np ‚Äì initial point p  mathcal M\n\nFor more options, see DouglasRachford.\n\n\n\n\n\n","category":"function"},{"location":"solvers/DouglasRachford/#State","page":"Douglas‚ÄìRachford","title":"State","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"DouglasRachfordState","category":"page"},{"location":"solvers/DouglasRachford/#Manopt.DouglasRachfordState","page":"Douglas‚ÄìRachford","title":"Manopt.DouglasRachfordState","text":"DouglasRachfordState <: AbstractManoptSolverState\n\nStore all options required for the DouglasRachford algorithm,\n\nFields\n\np - the current iterate (result) For the parallel Douglas-Rachford, this is not a value from the PowerManifold manifold but the mean.\ns ‚Äì the last result of the double reflection at the proxes relaxed by Œ±.\nŒª ‚Äì function to provide the value for the proximal parameter during the calls\nŒ± ‚Äì relaxation of the step from old to new iterate, i.e. x^(k+1) = g(Œ±(k) x^(k) t^(k)), where t^(k) is the result of the double reflection involved in the DR algorithm\nR ‚Äì method employed in the iteration to perform the reflection of x at the prox p.\nstop ‚Äì a StoppingCriterion\nparallel ‚Äì indicate whether we are running a parallel Douglas-Rachford or not.\n\nConstructor\n\nDouglasRachfordState(M, p; kwargs...)\n\nGenerate the options for a Manifold M and an initial point p, where the following keyword arguments can be used\n\nŒª ‚Äì ((iter)->1.0) function to provide the value for the proximal parameter during the calls\nŒ± ‚Äì ((iter)->0.9) relaxation of the step from old to new iterate, i.e. x^(k+1) = g(Œ±(k) x^(k) t^(k)), where t^(k) is the result of the double reflection involved in the DR algorithm\nR ‚Äì (reflect) method employed in the iteration to perform the reflection of x at the prox p.\nstopping_criterion ‚Äì (StopAfterIteration(300)) a StoppingCriterion\nparallel ‚Äì (false) indicate whether we are running a parallel Douglas-Rachford or not.\n\n\n\n\n\n","category":"type"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"For specific DebugActions and RecordActions see also Cyclic Proximal Point.","category":"page"},{"location":"solvers/DouglasRachford/#Literature","page":"Douglas‚ÄìRachford","title":"Literature","text":"","category":"section"},{"location":"solvers/DouglasRachford/","page":"Douglas‚ÄìRachford","title":"Douglas‚ÄìRachford","text":"<ul>\n<li id=\"BergmannPerschSteidl2016\">[<a>Bergmann, Persch, Steidl, 2016</a>]\n  Bergmann, R; Persch, J.; Steidl, G.: <emph>A Parallel Douglas‚ÄìRachford\n  Algorithm for Minimizing ROF-like Functionals on Images with Values in\n  Symmetric Hadamard Manifolds.</emph>\n  SIAM Journal on Imaging Sciences, Volume 9, Number 3, pp. 901‚Äì937, 2016.\n  doi: <a href=\"https://doi.org/10.1137/15M1052858\">10.1137/15M1052858</a>,\n  arXiv: <a href=\"https://arxiv.org/abs/1512.02814\">1512.02814</a>.\n</li>\n</ul>","category":"page"},{"location":"tutorials/CountAndCache/#How-to-Count-and-Cache-Function-Calls","page":"Count and use a Cache","title":"How to Count and Cache Function Calls","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"In this tutorial, we want to investigate the caching and counting (i.e.¬†statistics) features of Manopt.jl. We will reuse the optimization tasks from the introductory tutorial Get Started: Optimize!.","category":"page"},{"location":"tutorials/CountAndCache/#Introduction","page":"Count and use a Cache","title":"Introduction","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"There are surely many ways to keep track for example of how often the cost function is called, for example with a functor, as we used in an example in How to Record Data","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"mutable struct MyCost{I<:Integer}\n    count::I\nend\nMyCost() = MyCost{Int64}(0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    # [ .. Actual implementation of the cost here ]\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"This still leaves a bit of work to the user, especially for tracking more than just the number of cost function evaluations.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"When a function like the objective or gradient is expensive to compute, it may make sense to cache its results. Manopt.jl tries to minimize the number of repeated calls but sometimes they are necessary and harmless when the function is cheap to compute. Caching of expensive function calls can for example be added using Memoize.jl by the user. The approach in the solvers of Manopt.jl aims to simplify adding both these capabilities on the level of calling a solver.","category":"page"},{"location":"tutorials/CountAndCache/#Technical-Background","page":"Count and use a Cache","title":"Technical Background","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"The two ingredients for a solver in Manopt.jl are the AbstractManoptProblem and the AbstractManoptSolverState, where the former consists of the domain, that is the manifold and AbstractManifoldObjective.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"Both recording and debug capabilities are implemented in a decorator pattern to the solver state. They can be easily added using the record= and debug= in any solver call. This pattern was recently extended, such that also the objective can be decorated. This is how both caching and counting are implemented, as decorators of the AbstractManifoldObjective and hence for example changing/extending the behaviour of a call to get_cost.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"Let‚Äôs finish off the technical background by loading the necessary packages. Besides Manopt.jl and Manifolds.jl we also need LRUCaches.jl which are (since Julia 1.9) a weak dependency and provide the least recently used strategy for our caches.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"using Manopt, Manifolds, Random, LRUCache, LinearAlgebra","category":"page"},{"location":"tutorials/CountAndCache/#Counting","page":"Count and use a Cache","title":"Counting","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"We first define our task, the Riemannian Center of Mass from the Get Started: Optimize! tutorial.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"n = 100\nœÉ = œÄ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\nRandom.seed!(42)\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)));","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"to now count how often the cost and the gradient are called, we use the count= keyword argument that works in any solver to specify the elements of the objective whose calls we want to count calls to. A full list is available in the documentation of the AbstractManifoldObjective. To also see the result, we have to set return_objective=true. This returns (objective, p) instead of just the solver result p. We can further also set return_state=true to get even more information about the solver run.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"gradient_descent(M, f, grad_f, data[1]; count=[:Cost, :Gradient], return_objective=true, return_state=true)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 68 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Statistics on function calls\n  * :Gradient :  205\n  * :Cost     :  282\non a ManifoldGradientObjective{AllocatingEvaluation}","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"And we see that statistics are shown in the end.","category":"page"},{"location":"tutorials/CountAndCache/#Caching","page":"Count and use a Cache","title":"Caching","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"To now also cache these calls, we can use the cache= keyword argument. Since now both the cache and the count ‚Äúextend‚Äù the functionality of the objective, the order is important: On the high-level interface, the count is treated first, which means that only actual function calls and not cache look-ups are counted. With the proper initialisation, you can use any caches here that support the get!(function, cache, key)! update. All parts of the objective that can currently be cached are listed at ManifoldCachedObjective. The solver call has a keyword cache that takes a tuple(c, vs, n) of three arguments, where c is a symbol for the type of cache, vs is a vector of symbols, which calls to cache and n is the size of the cache. If the last element is not provided, a suitable default (currentlyn=10) is used.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"Here we want to use c=:LRU caches for vs=[Cost, :Gradient] with a size of n=25.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"r = gradient_descent(M, f, grad_f, data[1];\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true, return_state=true)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 68 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Statistics on function calls\n  * :Gradient :  68\n  * :Cost     :  154\non a ManifoldGradientObjective{AllocatingEvaluation}","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"Since the default setup with ArmijoLinesearch needs the gradient and the cost, and similarly the stopping criterion might (independently) evaluate the gradient, the caching is quite helpful here.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"And of course also for this advanced return value of the solver, we can still access the result as usual:","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"get_solver_result(r)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"3-element Vector{Float64}:\n 0.6868392794868674\n 0.006531600674932074\n 0.7267799820761327","category":"page"},{"location":"tutorials/CountAndCache/#Advanced-Caching-Examples","page":"Count and use a Cache","title":"Advanced Caching Examples","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"There are more options other than caching single calls to specific parts of the objective. For example you may want to cache intermediate results of computing the cost and share that with the gradient computation. We will present three solutions to this:","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"An easy approach from within Manopt.jl: The ManifoldCostGradientObjective\nA shared storage approach using a functor\nA shared (internal) cache approach also using a functor","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"For that we switch to another example: The Rayleigh quotient. We aim to maximize the Rayleigh quotient displaystylefracx^mathrmTAxx^mathrmTx, for some Ainmathbb R^m+1times m+1 and xinmathbb R^m+1 but since we consider this on the sphere and Manopt.jl (as many other optimization toolboxes) minimizes, we consider","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"g(p) = -p^mathrmTApqquad pinmathbb S^m","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"The Euclidean gradient (that is in $ R^{m+1}$) is actually just nabla g(p) = -2Ap, the Riemannian gradient the projection of nabla g(p) onto the tangent space T_pmathbb S^m.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"m = 25\nRandom.seed!(42)\nA = randn(m + 1, m + 1)\nA = Symmetric(A)\np_star = eigvecs(A)[:, end] # minimizer (or similarly -p)\nf_star = -eigvals(A)[end] # cost (note that we get - the largest Eigenvalue)\n\nN = Sphere(m);\n\ng(M, p) = -p' * A*p\n‚àág(p) = -2 * A * p\ngrad_g(M,p) = project(M, p, ‚àág(p))\ngrad_g!(M,X, p) = project!(M, X, p, ‚àág(p))","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"grad_g! (generic function with 1 method)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"But since both the cost and the gradient require the computation of the matrix-vector product Ap, it might be beneficial to only compute this once.","category":"page"},{"location":"tutorials/CountAndCache/#The-[ManifoldCostGradientObjective](@ref)-approach","page":"Count and use a Cache","title":"The ManifoldCostGradientObjective approach","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"The ManifoldCostGradientObjective uses a combined function to compute both the gradient and the cost at the same time. We define the inplace variant as","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"function g_grad_g!(M::AbstractManifold, X, p)\n    X .= -A*p\n    c = p'*X\n    X .*= 2\n    project!(M, X, p, X)\n    return (c, X)\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"g_grad_g! (generic function with 1 method)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"where we only compute the matrix-vector product once. The small disadvantage might be, that we always compute both, the gradient and the cost. Luckily, the cache we used before, takes this into account and caches both results, such that we indeed end up computing A*p only once when asking to a cost and a gradient.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"Let‚Äôs compare both methods","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"p0 = [(1/5 .* ones(5))..., zeros(m-4)...];\n@time s1 = gradient_descent(N, g, grad_g!, p0;\n    stopping_criterion =¬†StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"  1.573594 seconds (1.52 M allocations: 124.086 MiB, 3.99% gc time, 99.20% compilation time)\n\n## Statistics on function calls\n  * :Gradient :  602\n  * :Cost     :  1449\non a ManifoldGradientObjective{InplaceEvaluation}\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"versus","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"obj = ManifoldCostGradientObjective(g_grad_g!; evaluation=InplaceEvaluation())\n@time s2 = gradient_descent(N, obj, p0;\n    stopping_criterion=StopWhenGradientNormLess(1e-5),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"  0.914073 seconds (741.80 k allocations: 58.287 MiB, 3.24% gc time, 94.80% compilation time)\n\n## Statistics on function calls\n  * :Gradient :  1448\n  * :Cost     :  1448\non a ManifoldCostGradientObjective{InplaceEvaluation}\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"first of all both yield the same result","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"p1 = get_solver_result(s1)\np2 = get_solver_result(s2)\n[distance(N, p1, p2), g(N, p1), g(N, p2), f_star]","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"4-element Vector{Float64}:\n  0.0\n -7.8032957637779\n -7.8032957637779\n -7.803295763793949","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"and we can see that the combined number of evaluations is once 2051, once just the number of cost evaluations 1449. Note that the involved additional 847 gradient evaluations are merely a multiplication with 2. On the other hand, the additional caching of the gradient in these cases might be less beneficial. It is beneficial, when the gradient and the cost are very often required together.","category":"page"},{"location":"tutorials/CountAndCache/#A-shared-storage-approach-using-a-functor","page":"Count and use a Cache","title":"A shared storage approach using a functor","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"An alternative to the previous approach is the usage of a functor that introduces a ‚Äúshared storage‚Äù of the result of computing A*p. We additionally have to store p though, since we have to check that we are still evaluating the cost and/or gradient at the same point at which the cached A*p was computed. We again consider the (more efficient) inplace variant. This can be done as follows","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"struct StorageG{T,M}\n    A::M\n    Ap::T\n    p::T\nend\nfunction (g::StorageG)(::Val{:Cost}, M::AbstractManifold, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    return -g.p'*g.Ap\nend\nfunction (g::StorageG)(::Val{:Gradient}, M::AbstractManifold, X, p)\n    if !(p==g.p) #We are at a new point -> Update\n        g.Ap .= g.A*p\n        g.p .= p\n    end\n    X .= -2 .* g.Ap\n    project!(M, X, p, X)\n    return X\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"Here we use the first parameter to distinguish both functions. For the mutating case the signatures are different regardless of the additional argument but for the allocating case, the signatures of the cost and the gradient function are the same.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"#Define the new functor\nstorage_g = StorageG(A, zero(p0), zero(p0))\n# and cost and gradient that use this functor as\ng3(M,p) = storage_g(Val(:Cost), M, p)\ngrad_g3!(M, X, p) = storage_g(Val(:Gradient), M, X, p)\n@time s3 = gradient_descent(N, g3, grad_g3!, p0;\n    stopping_criterion =¬†StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 2),\n    return_objective=true#, return_state=true\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"  0.534735 seconds (302.51 k allocations: 21.855 MiB, 98.48% compilation time)\n\n## Statistics on function calls\n  * :Gradient :  602\n  * :Cost     :  1449\non a ManifoldGradientObjective{InplaceEvaluation}\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"This of course still yields the same result","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"p3 = get_solver_result(s3)\ng(N, p3) - f_star","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"1.6049384043981263e-11","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"And while we again have a split off the cost and gradient evaluations, we can observe that the allocations are less than half of the previous approach.","category":"page"},{"location":"tutorials/CountAndCache/#A-local-cache-approach","page":"Count and use a Cache","title":"A local cache approach","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"This variant is very similar to the previous one, but uses a whole cache instead of just one place to store A*p. This makes the code a bit nicer, and it is possible to store more than just the last p either cost or gradient was called with.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"struct CacheG{C,M}\n    A::M\n    cache::C\nend\nfunction (g::CacheG)(::Val{:Cost}, M, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    return -p'*Ap\nend\nfunction (g::CacheG)(::Val{:Gradient}, M, X, p)\n    Ap = get!(g.cache, copy(M,p)) do\n        g.A*p\n    end\n    X .= -2 .* Ap\n    project!(M, X, p, X)\n    return X\nend","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"However, the resulting solver run is not always faster, since the whole cache instead of storing just Ap and p is a bit more costly. Then the tradeoff is, whether this pays off.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"#Define the new functor\ncache_g = CacheG(A, LRU{typeof(p0),typeof(p0)}(; maxsize=25))\n# and cost and gradient that use this functor as\ng4(M,p) = cache_g(Val(:Cost), M, p)\ngrad_g4!(M, X, p) = cache_g(Val(:Gradient), M, X, p)\n@time s4 = gradient_descent(N, g4, grad_g4!, p0;\n    stopping_criterion =¬†StopWhenGradientNormLess(1e-5),\n    evaluation=InplaceEvaluation(),\n    count=[:Cost, :Gradient],\n    cache=(:LRU, [:Cost, :Gradient], 25),\n    return_objective=true,\n)","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"  0.548084 seconds (290.98 k allocations: 21.476 MiB, 97.96% compilation time)\n\n## Statistics on function calls\n  * :Gradient :  602\n  * :Cost     :  1449\non a ManifoldGradientObjective{InplaceEvaluation}\n\nTo access the solver result, call `get_solver_result` on this variable.","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"and for safety let‚Äôs check that we are reasonably close","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"p4 = get_solver_result(s4)\ng(N, p4) - f_star","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"1.6049384043981263e-11","category":"page"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"For this example, or maybe even gradient_descent in general it seems, this additional (second, inner) cache does not improve the result further, it is about the same effort both time and allocation-wise.","category":"page"},{"location":"tutorials/CountAndCache/#Summary","page":"Count and use a Cache","title":"Summary","text":"","category":"section"},{"location":"tutorials/CountAndCache/","page":"Count and use a Cache","title":"Count and use a Cache","text":"While the second approach of ManifoldCostGradientObjective is very easy to implement, both the storage and the (local) cache approach are more efficient. All three are an improvement over the first implementation without sharing interms results. The results with storage or cache have further advantage of being more flexible, i.e.¬†the stored information could also be reused in a third function, for example when also computing the Hessian.","category":"page"},{"location":"tutorials/InplaceGradient/#Speedup-using-Inplace-Evaluation","page":"Speedup using Inplace computations","title":"Speedup using Inplace Evaluation","text":"","category":"section"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"When it comes to time critital operations, a main ingredient in Julia is given by mutating functions, i.e.¬†those that compute in place without additional memory allocations. In the following, we illustrate how to do this with Manopt.jl.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"Let‚Äôs start with the same function as in Get Started: Optimize! and compute the mean of some points, only that here we use the sphere mathbb S^30 and n=800 points.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"From the aforementioned example.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"We first load all necessary packages.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"using Manopt, Manifolds, Random, BenchmarkTools\nRandom.seed!(42);","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"And setup our data","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"Random.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nœÉ = œÄ / 8\np = zeros(Float64, m + 1)\np[2] = 1.0\ndata = [exp(M, p, œÉ * rand(M; vector_at=p)) for i in 1:n];","category":"page"},{"location":"tutorials/InplaceGradient/#Classical-Definition","page":"Speedup using Inplace computations","title":"Classical Definition","text":"","category":"section"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"The variant from the previous tutorial defines a cost f(x) and its gradient operatornamegradf(p) ‚Äú‚Äú‚Äù","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)))","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"grad_f (generic function with 1 method)","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"We further set the stopping criterion to be a little more strict. Then we obtain","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"sc = StopWhenGradientNormLess(3e-10)\np0 = zeros(Float64, m + 1); p0[1] = 1/sqrt(2); p0[2] = 1/sqrt(2)\nm1 = gradient_descent(M, f, grad_f, p0; stopping_criterion=sc);","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"We can also benchmark this as","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"@benchmark gradient_descent($M, $f, $grad_f, $p0; stopping_criterion=$sc)","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"BenchmarkTools.Trial: 102 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  47.810 ms ‚Ä¶  53.557 ms  ‚îä GC (min ‚Ä¶ max): 5.09% ‚Ä¶ 6.53%\n Time  (median):     48.820 ms               ‚îä GC (median):    5.34%\n Time  (mean ¬± œÉ):   49.060 ms ¬± 818.642 Œºs  ‚îä GC (mean ¬± œÉ):  5.77% ¬± 0.64%\n\n            ‚ñÖ‚ñÖ‚ñà      ‚ñÉ‚ñÉ                                         \n  ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ ‚ñÉ\n  47.8 ms         Histogram: frequency by time         52.4 ms <\n\n Memory estimate: 194.10 MiB, allocs estimate: 655347.","category":"page"},{"location":"tutorials/InplaceGradient/#In-place-Computation-of-the-Gradient","page":"Speedup using Inplace computations","title":"In-place Computation of the Gradient","text":"","category":"section"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"We can reduce the memory allocations by implementing the gradient to be evaluated in-place. We do this by using a functor. The motivation is twofold: on one hand, we want to avoid variables from the global scope, for example the manifold M or the data, being used within the function. Considering to do the same for more complicated cost functions might also be worth pursuing.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"Here, we store the data (as reference) and one introduce temporary memory in order to avoid reallocation of memory per grad_distance computation. We get","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"struct GradF!{TD,TTMP}\n    data::TD\n    tmp::TTMP\nend\nfunction (grad_f!::GradF!)(M, X, p)\n    fill!(X, 0)\n    for di in grad_f!.data\n        grad_distance!(M, grad_f!.tmp, di, p)\n        X .+= grad_f!.tmp\n    end\n    X ./= length(grad_f!.data)\n    return X\nend","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"For the actual call to the solver, we first have to generate an instance of GradF! and tell the solver, that the gradient is provided in an InplaceEvaluation. We can further also use gradient_descent! to even work inplace of the initial point we pass.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"grad_f2! = GradF!(data, similar(data[1]))\nm2 = deepcopy(p0)\ngradient_descent!(\n    M, f, grad_f2!, m2; evaluation=InplaceEvaluation(), stopping_criterion=sc\n);","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"We can again benchmark this","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"@benchmark gradient_descent!(\n    $M, $f, $grad_f2!, m2; evaluation=$(InplaceEvaluation()), stopping_criterion=$sc\n) setup = (m2 = deepcopy($p0))","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"BenchmarkTools.Trial: 179 samples with 1 evaluation.\n Range (min ‚Ä¶ max):  27.027 ms ‚Ä¶  31.367 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 11.00%\n Time  (median):     27.712 ms               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   27.939 ms ¬± 779.920 Œºs  ‚îä GC (mean ¬± œÉ):  0.84% ¬±  2.56%\n\n         ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñá                                                \n  ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñá ‚ñÖ\n  27 ms         Histogram: log(frequency) by time      30.7 ms <\n\n Memory estimate: 3.76 MiB, allocs estimate: 5949.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"which is faster by about a factor of 2 compared to the first solver-call. Note that the results m1 and m2 are of course the same.","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"distance(M, m1, m2)","category":"page"},{"location":"tutorials/InplaceGradient/","page":"Speedup using Inplace computations","title":"Speedup using Inplace computations","text":"2.0004809792350595e-10","category":"page"},{"location":"plans/state/#SolverStateSection","page":"Solver State","title":"The Solver State","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"CurrentModule = Manopt","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"Given an AbstractManoptProblem, that is a certain optimisation task, the state specifies the solver to use. It contains the parameters of a solver and all fields necessary during the algorithm, e.g. the current iterate, a StoppingCriterion or a Stepsize.","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"AbstractManoptSolverState\nget_state\nManopt.get_count","category":"page"},{"location":"plans/state/#Manopt.AbstractManoptSolverState","page":"Solver State","title":"Manopt.AbstractManoptSolverState","text":"AbstractManoptSolverState\n\nA general super type for all solver states.\n\nFields\n\nThe following fields are assumed to be default. If you use different ones, provide the access functions accordingly\n\np a point on a manifold with the current iterate\nstop a StoppingCriterion.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.get_state","page":"Solver State","title":"Manopt.get_state","text":"get_state(s::AbstractManoptSolverState)\n\nreturn the undecorated AbstractManoptSolverState of the (possibly) decorated s. As long as your decorated state store the state within s.state and the dispatch_state_decorator is set to Val{true}, the internal state are extracted.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_count","page":"Solver State","title":"Manopt.get_count","text":"get_count(ams::AbstractManoptSolverState, ::Symbol)\n\nObtain the count for a certain countable size, e.g. the :Iterations. This function returns 0 if there was nothing to count\n\nAvailable symbols from within the solver state\n\n:Iterations is passed on to the stop field to obtain the iterataion at which the solver stopped.\n\n\n\n\n\nget_count(co::ManifoldCountObjective, s::Symbol, mode::Symbol=:None)\n\nGet the number of counts for a certain symbel s.\n\nDepending on the mode different results appear if the symbol does not exist in the dictionary\n\n:None ‚Äì (default) silent mode, returns -1 for non-existing entries\n:warn ‚Äì issues a warning if a field does not exist\n:error ‚Äì issues an error if a field does not exist\n\n\n\n\n\n","category":"function"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"Since every subtype of an AbstractManoptSolverState directly relate to a solver, the concrete states are documented together with the corresponding solvers. This page documents the general functionality available for every state.","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A first example is to access, i.e. obtain or set, the current iterate. This might be useful to continue investigation at the current iterate, or to set up a solver for a next experiment, respectively.","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"get_iterate\nset_iterate!\nget_gradient(::AbstractManifoldGradientObjective)\nset_gradient!","category":"page"},{"location":"plans/state/#Manopt.get_iterate","page":"Solver State","title":"Manopt.get_iterate","text":"get_iterate(O::AbstractManoptSolverState)\n\nreturn the (last stored) iterate within AbstractManoptSolverStates`. By default also undecorates the state beforehand.\n\n\n\n\n\nget_iterate(agst::AbstractGradientSolverState)\n\nreturn the iterate stored within gradient options. THe default resturns agst.p.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.set_iterate!","page":"Solver State","title":"Manopt.set_iterate!","text":"set_iterate!(s::AbstractManoptSolverState, M::AbstractManifold, p)\n\nset the iterate within an AbstractManoptSolverState to some (start) value p.\n\n\n\n\n\nset_iterate!(agst::AbstractGradientSolverState, M, p)\n\nset the (current) iterate stored within an AbstractGradientSolverState to p. The default function modifies s.p.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.get_gradient-Tuple{AbstractManifoldGradientObjective}","page":"Solver State","title":"Manopt.get_gradient","text":"get_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, k)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, Y, p, k)\n\nEvaluate one of the summands gradients operatornamegradf_k, k1n, at x (in place of Y).\n\nIf you use a single function for the stochastic gradient, that works inplace, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\nget_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, X, p)\n\nEvaluate the complete gradient operatornamegrad f = displaystylesum_i=1^n operatornamegrad f_i(p) at p (in place of X).\n\nIf you use a single function for the stochastic gradient, that works inplace, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\n","category":"method"},{"location":"plans/state/#Manopt.set_gradient!","page":"Solver State","title":"Manopt.set_gradient!","text":"set_gradient!(s::AbstractManoptSolverState, M::AbstractManifold, p, X)\n\nset the gradient within an (possibly decorated) AbstractManoptSolverState to some (start) value X in the tangent space at p.\n\n\n\n\n\nset_gradient!(agst::AbstractGradientSolverState, M, p, X)\n\nset the (current) gradient stored within an AbstractGradientSolverState to X. The default function modifies s.X.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"An internal function working on the state and elements within a state is used to pass messages from (sub) activties of a state to the corresponding DebugMessages","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"get_message","category":"page"},{"location":"plans/state/#Manopt.get_message","page":"Solver State","title":"Manopt.get_message","text":"get_message(du::AbstractManoptSolverState)\n\nget a message (String) from e.g. performing a step computation. This should return any message a sub-step might have issued\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Decorators-for-AbstractManoptSolverState","page":"Solver State","title":"Decorators for AbstractManoptSolverState","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A solver state can be decorated using the following trait and function to initialize","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"dispatch_state_decorator\nis_state_decorator\ndecorate_state!","category":"page"},{"location":"plans/state/#Manopt.dispatch_state_decorator","page":"Solver State","title":"Manopt.dispatch_state_decorator","text":"dispatch_state_decorator(s::AbstractManoptSolverState)\n\nIndicate internally, whether an AbstractManoptSolverState s to be of decorating type, i.e. it stores (encapsulates) a state in itself, by default in the field s.state.\n\nDecorators indicate this by returning Val{true} for further dispatch.\n\nThe default is Val{false}, i.e. by default an state is not decorated.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.is_state_decorator","page":"Solver State","title":"Manopt.is_state_decorator","text":"is_state_decorator(s::AbstractManoptSolverState)\n\nIndicate, whether AbstractManoptSolverState s are of decorator type.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.decorate_state!","page":"Solver State","title":"Manopt.decorate_state!","text":"decorate_state!(s::AbstractManoptSolverState)\n\ndecorate the AbstractManoptSolverStates with specific decorators.\n\nOptional Arguments\n\noptional arguments provide necessary details on the decorators. A specific one is used to activate certain decorators.\n\ndebug ‚Äì (Array{Union{Symbol,DebugAction,String,Int},1}()) a set of symbols representing DebugActions, Strings used as dividers and a subsampling integer. These are passed as a DebugGroup within :All to the DebugSolverState decorator dictionary. Only excention is :Stop that is passed to :Stop.\nrecord ‚Äì (Array{Union{Symbol,RecordAction,Int},1}()) specify recordings by using Symbols or RecordActions directly. The integer can again be used for only recording every ith iteration.\nreturn_state - (false) indicate whether to wrap the options in a ReturnSolverState, indicating that the solver should return options and not (only) the minimizer.\n\nother keywords are ignored.\n\nSee also\n\nDebugSolverState, RecordSolverState, ReturnSolverState\n\n\n\n\n\n","category":"function"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A simple example is the","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"ReturnSolverState","category":"page"},{"location":"plans/state/#Manopt.ReturnSolverState","page":"Solver State","title":"Manopt.ReturnSolverState","text":"ReturnSolverState{O<:AbstractManoptSolverState} <: AbstractManoptSolverState\n\nThis internal type is used to indicate that the contained AbstractManoptSolverState state should be returned at the end of a solver instead of the usual minimizer.\n\nSee also\n\nget_solver_result\n\n\n\n\n\n","category":"type"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"as well as DebugSolverState and RecordSolverState.","category":"page"},{"location":"plans/state/#State-Actions","page":"Solver State","title":"State Actions","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"A state action is a struct for callback functions that can be attached within for example the just mentioned debug decorator or the record decorator.","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"AbstractStateAction","category":"page"},{"location":"plans/state/#Manopt.AbstractStateAction","page":"Solver State","title":"Manopt.AbstractStateAction","text":"AbstractStateAction\n\na common Type for AbstractStateActions that might be triggered in decoraters, for example within the DebugSolverState or within the RecordSolverState.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"Several state decorators or actions might store intermediate values like the (last) iterate to compute some change or the last gradient. In order to minimise the storage of these, there is a generic StoreStateAction that acts as generic common storage that can be shared among different actions.","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"StoreStateAction\nget_storage\nhas_storage\nupdate_storage!\nPointStorageKey\nVectorStorageKey","category":"page"},{"location":"plans/state/#Manopt.StoreStateAction","page":"Solver State","title":"Manopt.StoreStateAction","text":"StoreStateAction <: AbstractStateAction\n\ninternal storage for AbstractStateActions to store a tuple of fields from an AbstractManoptSolverStates\n\nThis functor posesses the usual interface of functions called during an iteration, i.e. acts on (p,o,i), where p is a AbstractManoptProblem, o is an AbstractManoptSolverState and i is the current iteration.\n\nFields\n\nvalues ‚Äì a dictionary to store interims values based on certain Symbols\nkeys ‚Äì a Vector of Symbols to refer to fields of AbstractManoptSolverState\npoint_values ‚Äì a NamedTuple of mutable values of points on a manifold to be stored in StoreStateAction. Manifold is later determined by AbstractManoptProblem passed to update_storage!.\npoint_init ‚Äì a NamedTuple of boolean values indicating whether a point in point_values with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector keys.\nvector_values ‚Äì a NamedTuple of mutable values of tangent vectors on a manifold to be stored in StoreStateAction. Manifold is later determined by AbstractManoptProblem passed to update_storage!. It is not specified at which point the vectors are tangent but for storage it should not matter.\nvector_init ‚Äì a NamedTuple of boolean values indicating whether a tangent vector in vector_values with matching key has been already initialized to a value. When it is false, it corresponds to a general value not being stored for the key present in the vector keys.\nonce ‚Äì whether to update the internal values only once per iteration\nlastStored ‚Äì last iterate, where this AbstractStateAction was called (to determine once)\n\nTo handle the general storage, use get_storage and has_storage with keys as Symbols. For the point storage use PointStorageKey. For tangent vector storage use VectorStorageKey. Point and tangent storage have been optimized to be more efficient.\n\nConstructiors\n\nStoreStateAction(s::Vector{Symbol})\n\nThis is equivalent as providing s to the keyword store_fields, just that here, no manifold is necessay for the construciton.\n\nStoreStateAction(M)\n\nKeyword arguments\n\nstore_fields (Symbol[])\nstore_points (Symbol[])\nstore_vectors (Symbol[])\n\nas vectors of symbols each referring to fields of the state (lower case symbols) or semantic ones (upper case).\n\np_init (rand(M))\nX_init (zero_vector(M, p_init))\n\nare used to initialize the point and vector storages, change these if you use other types (than the default) for your points/vectors on M.\n\nonce (true) whether to update internal storage only once per iteration or on every update call\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.get_storage","page":"Solver State","title":"Manopt.get_storage","text":"get_storage(a::AbstractStateAction, key::Symbol)\n\nReturn the internal value of the AbstractStateAction a at the Symbol key.\n\n\n\n\n\nget_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key}\n\nReturn the internal value of the AbstractStateAction a at the Symbol key that represents a point.\n\n\n\n\n\nget_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key}\n\nReturn the internal value of the AbstractStateAction a at the Symbol key that represents a vector vector.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.has_storage","page":"Solver State","title":"Manopt.has_storage","text":"has_storage(a::AbstractStateAction, key::Symbol)\n\nReturn whether the AbstractStateAction a has a value stored at the Symbol key.\n\n\n\n\n\nhas_storage(a::AbstractStateAction, ::PointStorageKey{key}) where {key}\n\nReturn whether the AbstractStateAction a has a point value stored at the Symbol key.\n\n\n\n\n\nhas_storage(a::AbstractStateAction, ::VectorStorageKey{key}) where {key}\n\nReturn whether the AbstractStateAction a has a point value stored at the Symbol key.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.update_storage!","page":"Solver State","title":"Manopt.update_storage!","text":"update_storage!(a::AbstractStateAction, amp::AbstractManoptProblem, s::AbstractManoptSolverState)\n\nUpdate the AbstractStateAction a internal values to the ones given on the AbstractManoptSolverState s. Optimized using the information from amp\n\n\n\n\n\nupdate_storage!(a::AbstractStateAction, d::Dict{Symbol,<:Any})\n\nUpdate the AbstractStateAction a internal values to the ones given in the dictionary d. The values are merged, where the values from d are preferred.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt.PointStorageKey","page":"Solver State","title":"Manopt.PointStorageKey","text":"struct PointStorageKey{key} end\n\nRefer to point storage of StoreStateAction in get_storage and has_storage functions\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.VectorStorageKey","page":"Solver State","title":"Manopt.VectorStorageKey","text":"struct VectorStorageKey{key} end\n\nRefer to tangent storage of StoreStateAction in get_storage and has_storage functions\n\n\n\n\n\n","category":"type"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"as well as two internal functions","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"_storage_copy_vector\n_storage_copy_point","category":"page"},{"location":"plans/state/#Manopt._storage_copy_vector","page":"Solver State","title":"Manopt._storage_copy_vector","text":"_storage_copy_vector(M::AbstractManifold, X)\n\nMake a copy of tangent vector X from manifold M for storage in StoreStateAction.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Manopt._storage_copy_point","page":"Solver State","title":"Manopt._storage_copy_point","text":"_storage_copy_point(M::AbstractManifold, p)\n\nMake a copy of point p from manifold M for storage in StoreStateAction.\n\n\n\n\n\n","category":"function"},{"location":"plans/state/#Abstract-States","page":"Solver State","title":"Abstract States","text":"","category":"section"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"In a few cases it is useful to have a hierarchy of types. These are","category":"page"},{"location":"plans/state/","page":"Solver State","title":"Solver State","text":"AbstractSubProblemSolverState\nAbstractGradientSolverState\nAbstractHessianSolverState\nAbstractPrimalDualSolverState","category":"page"},{"location":"plans/state/#Manopt.AbstractSubProblemSolverState","page":"Solver State","title":"Manopt.AbstractSubProblemSolverState","text":"AbstractSubProblemSolverState <: AbstractManoptSolverState\n\nAn abstract type for problems that involve a subsolver\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractGradientSolverState","page":"Solver State","title":"Manopt.AbstractGradientSolverState","text":"AbstractGradientSolverState <: AbstractManoptSolverState\n\nA generic AbstractManoptSolverState type for gradient based options data.\n\nIt assumes that\n\nthe iterate is stored in the field p\nthe gradient at p is stored in X.\n\nsee also\n\nGradientDescentState, StochasticGradientDescentState, SubGradientMethodState, QuasiNewtonState.\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractHessianSolverState","page":"Solver State","title":"Manopt.AbstractHessianSolverState","text":"AbstractHessianSolverState <: AbstractGradientSolverState\n\nAn AbstractManoptSolverState type to represent algorithms that employ the Hessian. These options are assumed to have a field (gradient) to store the current gradient operatornamegradf(x)\n\n\n\n\n\n","category":"type"},{"location":"plans/state/#Manopt.AbstractPrimalDualSolverState","page":"Solver State","title":"Manopt.AbstractPrimalDualSolverState","text":"AbstractPrimalDualSolverState\n\nA general type for all primal dual based options to be used within primal dual based algorithms\n\n\n\n\n\n","category":"type"},{"location":"about/#About","page":"About","title":"About","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"Manopt.jl inherited its name from Manopt, a Matlab toolbox for optimization on manifolds. This Julia package was started and is currently maintained by Ronny Bergmann.","category":"page"},{"location":"about/","page":"About","title":"About","text":"The following people contributed","category":"page"},{"location":"about/","page":"About","title":"About","text":"Constantin Ahlmann-Eltze implemented the gradient and differential check functions\nRen√©e Dornig implemented the particle swarm, the Riemannian Augmented Lagrangian Method, the Exact Penalty Method, as well as the NonmonotoneLinesearch\nWillem Diepeveen implemented the primal-dual Riemannian semismooth Newton solver.\nEven Stephansen Kjems√•s contributed to the implementation of the Frank Wolfe Method\nTom-Christian Riemer Riemer implemented the trust regions and quasi Newton solvers.\nManuel Weiss implemented most of the conjugate gradient update rules","category":"page"},{"location":"about/","page":"About","title":"About","text":"...as well as various contributors providing small extensions, finding small bugs and mistakes and fixing them by opening PRs.","category":"page"},{"location":"about/","page":"About","title":"About","text":"If you want to contribute a manifold or algorithm or have any questions, visit the GitHub repository to clone/fork the repository or open an issue.","category":"page"},{"location":"about/#Further-Packages-and-Links","page":"About","title":"Further Packages & Links","text":"","category":"section"},{"location":"about/","page":"About","title":"About","text":"Manopt.jl belongs to the Manopt family:","category":"page"},{"location":"about/","page":"About","title":"About","text":"manopt.org ‚Äì The Matlab version of Manopt, see also their :octocat: GitHub repository\npymanopt.org ‚Äì The Python version of Manopt ‚Äì providing also several AD backends, see also their :octocat: GitHub repository","category":"page"},{"location":"about/","page":"About","title":"About","text":"but there are also more packages providing tools on manifolds:","category":"page"},{"location":"about/","page":"About","title":"About","text":"Jax Geometry (Python/Jax) for differential geometry and stochastic dynamics with deep learning\nGeomstats (Python with several backends) focusing on statistics and machine learning :octocat: GitHub repository\nGeoopt (Python & PyTorch) ‚Äì Riemannian ADAM & SGD. :octocat: GitHub repository\nMcTorch (Python & PyToch) ‚Äì Riemannian SGD, Adagrad, ASA & CG.\nROPTLIB (C++) a Riemannian OPTimization LIBrary :octocat: GitHub repository\nTF Riemopt (Python & TensorFlow) Riemannian optimization using TensorFlow","category":"page"},{"location":"tutorials/GeodesicRegression/#How-to-perform-Geodesic-Regression","page":"Do Geodesic Regression","title":"How to perform Geodesic Regression","text":"","category":"section"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Geodesic regression generalizes linear regression to Riemannian manifolds. Let‚Äôs first phrase it informally as follows:","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"For given data points d_1ldotsd_n on a Riemannian manifold mathcal M, find the geodesic that ‚Äúbest explains‚Äù the data.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"The meaning of ‚Äúbest explain‚Äù has still to be clarified. We distinguish two cases: time labelled data and unlabelled data","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"    using Manopt, ManifoldDiff, Manifolds, Random, Colors\n    using LinearAlgebra: svd\n    Random.seed!(42);","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"We use the following data, where we want to highlight one of the points.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"n = 7\nœÉ = œÄ / 8\nS = Sphere(2)\nbase = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndir = [-0.75, 0.5, 0.75]\ndata_orig = [exp(S, base, dir, t) for t in range(-0.5, 0.5; length=n)]\n# add noise to the points on the geodesic\ndata = map(p -> exp(S, p, rand(S; vector_at=p, œÉ=œÉ)), data_orig)\nhighlighted = 4;","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"(Image: The given data)","category":"page"},{"location":"tutorials/GeodesicRegression/#Time-Labeled-Data","page":"Do Geodesic Regression","title":"Time Labeled Data","text":"","category":"section"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"If for each data item d_i we are also given a time point t_iinmathbb R, which are pairwise different, then we can use the least squares error to state the objetive function as (Fletcher, 2013)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"F(pX) = frac12sum_i=1^n d_mathcal M^2(Œ≥_pX(t_i) d_i)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"where d_mathcal M is the Riemannian distance and Œ≥_pX is the geodesic with Œ≥(0) = p and dotgamma(0) = X.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"For the real-valued case mathcal M = mathbb R^m the solution (p^* X^*) is given in closed form as follows: with d^* = frac1ndisplaystylesum_i=1^nd_i and t^* = frac1ndisplaystylesum_i=1^n t_i we get","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":" X^* = fracsum_i=1^n (d_i-d^*)(t-t^*)sum_i=1^n (t_i-t^*)^2\nquadtext and quad\np^* = d^* - t^*X^*","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"and hence the linear regression result is the line Œ≥_p^*X^*(t) = p^* + tX^*.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"On a Riemannian manifold we can phrase this as an optimization problem on the tangent bundle, i.e.¬†the disjoint union of all tangent spaces, as","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"operatorname*argmin_(pX) in mathrmTmathcal M F(pX)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Due to linearity, the gradient of F(pX) is the sum of the single gradients of","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":" frac12d_mathcal M^2bigl(Œ≥_pX(t_i)d_ibigr)\n = frac12d_mathcal M^2bigl(exp_p(t_iX)d_ibigr)\n quad i1ldotsn","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"which can be computed using a chain rule of the squared distance and the exponential map, see for example (Bergmann and Gousenbourger, 2018) for details or Equations (7) and (8) of (Fletcher, 2013): ‚Äú‚Äú‚Äù","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"M = TangentBundle(S)\nstruct RegressionCost{T,S}\n    data::T\n    times::S\nend\nRegressionCost(data::T, times::S) where {T,S} = RegressionCost{T,S}(data, times)\nfunction (a::RegressionCost)(M, x)\n    pts = [geodesic(M.manifold, x[M, :point], x[M, :vector], ti) for ti in a.times]\n    return 1 / 2 * sum(distance.(Ref(M.manifold), pts, a.data) .^ 2)\nend\nstruct RegressionGradient!{T,S}\n    data::T\n    times::S\nend\nfunction RegressionGradient!(data::T, times::S) where {T,S}\n    return RegressionGradient!{T,S}(data, times)\nend\nfunction (a::RegressionGradient!)(M, Y, x)\n    pts = [geodesic(M.manifold, x[M, :point], x[M, :vector], ti) for ti in a.times]\n    gradients = grad_distance.(Ref(M.manifold), a.data, pts)\n    Y[M, :point] .= sum(\n        ManifoldDiff.adjoint_differential_exp_basepoint.(\n            Ref(M.manifold),\n            Ref(x[M, :point]),\n            [ti * x[M, :vector] for ti in a.times],\n            gradients,\n        ),\n    )\n    Y[M, :vector] .= sum(\n        ManifoldDiff.adjoint_differential_exp_argument.(\n            Ref(M.manifold),\n            Ref(x[M, :point]),\n            [ti * x[M, :vector] for ti in a.times],\n            gradients,\n        ),\n    )\n    return Y\nend","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"For the Euclidean case, the result is given by the first principal component of a principal component analysis, see PCR, i.e.¬†with p^* = frac1ndisplaystylesum_i=1^n d_i the direction X^* is obtained by defining the zero mean data matrix","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"D = bigl(d_1-p^* ldots d_n-p^*bigr) in mathbb R^mn","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"and taking X^* as an eigenvector to the largest eigenvalue of D^mathrmTD.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"We can do something similar, when considering the tangent space at the (Riemannian) mean of the data and then do a PCA on the coordinate coefficients with respect to a basis.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"m = mean(S, data)\nA = hcat(\n    map(x -> get_coordinates(S, m, log(S, m, x), DefaultOrthonormalBasis()), data)...\n)\npca1 = get_vector(S, m, svd(A).U[:, 1], DefaultOrthonormalBasis())\nx0 = ArrayPartition(m, pca1)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"([0.6998621681746481, -0.013681674945026638, 0.7141468737791822], [0.5931302057517893, -0.5459465115717783, -0.5917254139611094])","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"The optimal ‚Äútime labels‚Äù are then just the projections t_i = d_iX^*, i=1ldotsn.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"t = map(d -> inner(S, m, pca1, log(S, m, d)), data)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"7-element Vector{Float64}:\n  1.0763904949888323\n  0.4594060193318443\n -0.5030195874833682\n  0.02135686940521725\n -0.6158692507563633\n -0.24431652575028764\n -0.2259012492666664","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"And we can call the gradient descent. Note that since gradF! works in place of Y, we have to set the evalutation type accordingly.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"y = gradient_descent(\n    M,\n    RegressionCost(data, t),\n    RegressionGradient!(data, t),\n    x0;\n    evaluation=InplaceEvaluation(),\n    stepsize=ArmijoLinesearch(\n        M;\n        initial_stepsize=1.0,\n        contraction_factor=0.990,\n        sufficient_decrease=0.05,\n        stop_when_stepsize_less=1e-9,\n    ),\n    stopping_criterion=StopAfterIteration(200) |\n                        StopWhenGradientNormLess(1e-8) |\n                        StopWhenStepsizeLess(1e-9),\n    debug=[:Iteration, \" | \", :Cost, \"\\n\", :Stop, 50],\n)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Initial  | F(x): 0.142862\n# 50     | F(x): 0.141113\n# 100    | F(x): 0.141113\n# 150    | F(x): 0.141113\n# 200    | F(x): 0.141113\nThe algorithm reached its maximal number of iterations (200).\n\n([0.7119768725361988, 0.009463059143003981, 0.7021391482357537], [0.590008151835008, -0.5543272518659472, -0.5908038715512287])","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"For the result, we can generate and plot all involved geodesics","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"dense_t = range(-0.5, 0.5; length=100)\ngeo = geodesic(S, y[M, :point], y[M, :vector], dense_t)\ninit_geo = geodesic(S, x0[M, :point], x0[M, :vector], dense_t)\ngeo_pts = geodesic(S, y[M, :point], y[M, :vector], t)\ngeo_conn_highlighted = shortest_geodesic(\n    S, data[highlighted], geo_pts[highlighted], 0.5 .+ dense_t\n);","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"(Image: Result of Geodesic Regression)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"In this image, together with the blue data points, you see the geodesic of the initialization in black (evaluated on -frac12frac12), the final point on the tangent bundle in orange, as well as the resulting regression geodesic in teal, (on the same interval as the start) as well as small teal points indicating the time points on the geodesic corresponding to the data. Additionally, a thin blue line indicates the geodesic between a data point and its corresponding data point on the geodesic. While this would be the closest point in Euclidean space and hence the two directions (along the geodesic vs.¬†to the data point) orthogonal, here we have","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"inner(\n    S,\n    geo_pts[highlighted],\n    log(S, geo_pts[highlighted], geo_pts[highlighted + 1]),\n    log(S, geo_pts[highlighted], data[highlighted]),\n)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"0.002487393068917863","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"But we also started with one of the best scenarios, i.e.¬†equally spaced points on a geodesic obstructed by noise.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"This gets worse if you start with less evenly distributed data","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"data2 = [exp(S, base, dir, t) for t in [-0.5, -0.49, -0.48, 0.1, 0.48, 0.49, 0.5]]\ndata2 = map(p -> exp(S, p, rand(S; vector_at=p, œÉ=œÉ / 2)), data2)\nm2 = mean(S, data2)\nA2 = hcat(\n    map(x -> get_coordinates(S, m, log(S, m, x), DefaultOrthonormalBasis()), data2)...\n)\npca2 = get_vector(S, m, svd(A2).U[:, 1], DefaultOrthonormalBasis())\nx1 = ArrayPartition(m, pca2)\nt2 = map(d -> inner(S, m2, pca2, log(S, m2, d)), data2)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"7-element Vector{Float64}:\n  0.8226008307680276\n  0.470952643700004\n  0.7974195537403082\n  0.01533949241264346\n -0.6546705405852389\n -0.8913273825362389\n -0.5775954445730889","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"then we run again","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"y2 = gradient_descent(\n    M,\n    RegressionCost(data2, t2),\n    RegressionGradient!(data2, t2),\n    x1;\n    evaluation=InplaceEvaluation(),\n    stepsize=ArmijoLinesearch(\n        M;\n        initial_stepsize=1.0,\n        contraction_factor=0.990,\n        sufficient_decrease=0.05,\n        stop_when_stepsize_less=1e-9,\n    ),\n    stopping_criterion=StopAfterIteration(200) |\n                        StopWhenGradientNormLess(1e-8) |\n                        StopWhenStepsizeLess(1e-9),\n    debug=[:Iteration, \" | \", :Cost, \"\\n\", :Stop, 3],\n);","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Initial  | F(x): 0.089844\n# 3      | F(x): 0.085364\n# 6      | F(x): 0.085364\n# 9      | F(x): 0.085364\n# 12     | F(x): 0.085364\n# 15     | F(x): 0.085364\n# 18     | F(x): 0.085364\n# 21     | F(x): 0.085364\n# 24     | F(x): 0.085364\n# 27     | F(x): 0.085364\n# 30     | F(x): 0.085364\n# 33     | F(x): 0.085364\n# 36     | F(x): 0.085364\n# 39     | F(x): 0.085364\n# 42     | F(x): 0.085364\n# 45     | F(x): 0.085364\n# 48     | F(x): 0.085364\n# 51     | F(x): 0.085364\n# 54     | F(x): 0.085364\n# 57     | F(x): 0.085364\n# 60     | F(x): 0.085364\n# 63     | F(x): 0.085364\n# 66     | F(x): 0.085364\n# 69     | F(x): 0.085364\n# 72     | F(x): 0.085364\n# 75     | F(x): 0.085364\n# 78     | F(x): 0.085364\n# 81     | F(x): 0.085364\n# 84     | F(x): 0.085364\n# 87     | F(x): 0.085364\n# 90     | F(x): 0.085364\n# 93     | F(x): 0.085364\n# 96     | F(x): 0.085364\n# 99     | F(x): 0.085364\n# 102    | F(x): 0.085364\n# 105    | F(x): 0.085364\n# 108    | F(x): 0.085364\n# 111    | F(x): 0.085364\n# 114    | F(x): 0.085364\n# 117    | F(x): 0.085364\n# 120    | F(x): 0.085364\n# 123    | F(x): 0.085364\n# 126    | F(x): 0.085364\n# 129    | F(x): 0.085364\n# 132    | F(x): 0.085364\n# 135    | F(x): 0.085364\n# 138    | F(x): 0.085364\n# 141    | F(x): 0.085364\n# 144    | F(x): 0.085364\n# 147    | F(x): 0.085364\n# 150    | F(x): 0.085364\n# 153    | F(x): 0.085364\n# 156    | F(x): 0.085364\n# 159    | F(x): 0.085364\n# 162    | F(x): 0.085364\n# 165    | F(x): 0.085364\n# 168    | F(x): 0.085364\n# 171    | F(x): 0.085364\n# 174    | F(x): 0.085364\n# 177    | F(x): 0.085364\n# 180    | F(x): 0.085364\n# 183    | F(x): 0.085364\n# 186    | F(x): 0.085364\n# 189    | F(x): 0.085364\n# 192    | F(x): 0.085364\n# 195    | F(x): 0.085364\n# 198    | F(x): 0.085364\nThe algorithm reached its maximal number of iterations (200).","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"For plotting we again generate all data","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"geo2 = geodesic(S, y2[M, :point], y2[M, :vector], dense_t)\ninit_geo2 = geodesic(S, x1[M, :point], x1[M, :vector], dense_t)\ngeo_pts2 = geodesic(S, y2[M, :point], y2[M, :vector], t2)\ngeo_conn_highlighted2 = shortest_geodesic(\n    S, data2[highlighted], geo_pts2[highlighted], 0.5 .+ dense_t\n);","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"(Image: A second result with different time points)","category":"page"},{"location":"tutorials/GeodesicRegression/#Unlabeled-Data","page":"Do Geodesic Regression","title":"Unlabeled Data","text":"","category":"section"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"If we are not given time points t_i, then the optimization problem extends ‚Äì informally speaking ‚Äì to also finding the ‚Äúbest fitting‚Äù (in the sense of smallest error). To formalize, the objective function here reads","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"F(p X t) = frac12sum_i=1^n d_mathcal M^2(Œ≥_pX(t_i) d_i)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"where t = (t_1ldotst_n) in mathbb R^n is now an additional parameter of the objective function. We write F_1(p X) to refer to the function on the tangent bundle for fixed values of t (as the one in the last part) and F_2(t) for the function F(p X t) as a function in t with fixed values (p X).","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"For the Euclidean case, there is no neccessity to optimize with respect to t, as we saw above for the initialization of the fixed time points.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"On a Riemannian manifold this can be stated as a problem on the product manifold mathcal N = mathrmTmathcal M times mathbb R^n, i.e.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"N = M √ó Euclidean(length(t2))","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"ProductManifold with 2 submanifolds:\n TangentBundle(Sphere(2, ‚Ñù))\n Euclidean(7; field = ‚Ñù)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"  operatorname*argmin_bigl((pX)tbigr)inmathcal N F(p X t)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"In this tutorial we present an approach to solve this using an alternating gradient descent scheme. To be precise, we define the cost funcion now on the product manifold","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"struct RegressionCost2{T}\n    data::T\nend\nRegressionCost2(data::T) where {T} = RegressionCost2{T}(data)\nfunction (a::RegressionCost2)(N, x)\n    TM = N[1]\n    pts = [\n        geodesic(TM.manifold, x[N, 1][TM, :point], x[N, 1][TM, :vector], ti) for\n        ti in x[N, 2]\n    ]\n    return 1 / 2 * sum(distance.(Ref(TM.manifold), pts, a.data) .^ 2)\nend","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"The gradient in two parts, namely (a) the same gradient as before w.r.t. (pX)  Tmathcal M, just now with a fixed t in mind for the second component of the product manifold mathcal N","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"struct RegressionGradient2a!{T}\n    data::T\nend\nRegressionGradient2a!(data::T) where {T} = RegressionGradient2a!{T}(data)\nfunction (a::RegressionGradient2a!)(N, Y, x)\n    TM = N[1]\n    p = x[N, 1]\n    pts = [geodesic(TM.manifold, p[TM, :point], p[TM, :vector], ti) for ti in x[N, 2]]\n    gradients = Manopt.grad_distance.(Ref(TM.manifold), a.data, pts)\n    Y[TM, :point] .= sum(\n        ManifoldDiff.adjoint_differential_exp_basepoint.(\n            Ref(TM.manifold),\n            Ref(p[TM, :point]),\n            [ti * p[TM, :vector] for ti in x[N, 2]],\n            gradients,\n        ),\n    )\n    Y[TM, :vector] .= sum(\n        ManifoldDiff.adjoint_differential_exp_argument.(\n            Ref(TM.manifold),\n            Ref(p[TM, :point]),\n            [ti * p[TM, :vector] for ti in x[N, 2]],\n            gradients,\n        ),\n    )\n    return Y\nend","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Finally, we addionally look for a fixed point x=(pX)  mathrmTmathcal M at the gradient with respect to tmathbb R^n, i.e.¬†the second component, which is given by","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"  (operatornamegradF_2(t))_i\n  = - dot Œ≥_pX(t_i) log_Œ≥_pX(t_i)d_i_Œ≥_pX(t_i) i = 1 ldots n","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"struct RegressionGradient2b!{T}\n    data::T\nend\nRegressionGradient2b!(data::T) where {T} = RegressionGradient2b!{T}(data)\nfunction (a::RegressionGradient2b!)(N, Y, x)\n    TM = N[1]\n    p = x[N, 1]\n    pts = [geodesic(TM.manifold, p[TM, :point], p[TM, :vector], ti) for ti in x[N, 2]]\n    logs = log.(Ref(TM.manifold), pts, a.data)\n    pt = map(\n        d -> vector_transport_to(TM.manifold, p[TM, :point], p[TM, :vector], d), pts\n    )\n    Y .= -inner.(Ref(TM.manifold), pts, logs, pt)\n    return Y\nend","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"We can reuse the computed initial values from before, just that now we are on a product manifold","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"x2 = ArrayPartition(x1, t2)\nF3 = RegressionCost2(data2)\ngradF3_vector = [RegressionGradient2a!(data2), RegressionGradient2b!(data2)];","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"and we run the algorithm","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"y3 = alternating_gradient_descent(\n    N,\n    F3,\n    gradF3_vector,\n    x2;\n    evaluation=InplaceEvaluation(),\n    debug=[:Iteration, \" | \", :Cost, \"\\n\", :Stop, 50],\n    stepsize=ArmijoLinesearch(\n        M;\n        contraction_factor=0.999,\n        sufficient_decrease=0.066,\n        stop_when_stepsize_less=1e-11,\n        retraction_method=ProductRetraction(SasakiRetraction(2), ExponentialRetraction()),\n    ),\n    inner_iterations=1,\n)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Initial  | F(x): 0.089844\n# 50     | F(x): 0.091097\n# 100    | F(x): 0.091097\nThe algorithm reached its maximal number of iterations (100).\n\n(ArrayPartition{Float64, Tuple{Vector{Float64}, Vector{Float64}}}(([0.750222090700214, 0.031464227399200885, 0.6604368380243274], [0.6636489079535082, -0.3497538263293046, -0.737208025444054])), [0.7965909273713889, 0.43402264218923514, 0.755822122896529, 0.001059348203453764, -0.6421135044471217, -0.8635572995105818, -0.5546338813212247])","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"which we render can collect into an image creating the geodesics again","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"geo3 = geodesic(S, y3[N, 1][M, :point], y3[N, 1][M, :vector], dense_t)\ninit_geo3 = geodesic(S, x1[M, :point], x1[M, :vector], dense_t)\ngeo_pts3 = geodesic(S, y3[N, 1][M, :point], y3[N, 1][M, :vector], y3[N, 2])\nt3 = y3[N, 2]\ngeo_conns = shortest_geodesic.(Ref(S), data2, geo_pts3, Ref(0.5 .+ 4*dense_t));","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"which yields","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"(Image: The third result)","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Note that the geodesics from the data to the regression geodesic meet at a nearly orthogonal angle.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Acknowledgement. Parts of this tutorial are based on the bachelor thesis of Jeremias Arf.","category":"page"},{"location":"tutorials/GeodesicRegression/#Literature","page":"Do Geodesic Regression","title":"Literature","text":"","category":"section"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Bergmann, R. and Gousenbourger, P.-Y. (2018) ‚ÄúA variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve,‚Äù Frontiers in Applied Mathematics and Statistics, 4. Available at: https://doi.org/10.3389/fams.2018.00059.","category":"page"},{"location":"tutorials/GeodesicRegression/","page":"Do Geodesic Regression","title":"Do Geodesic Regression","text":"Fletcher, P.T. (2013) ‚ÄúGeodesic regression and the theory of least squares on Riemannian manifolds,‚Äù International Journal of Computer Vision, 105(2), pp. 171‚Äì185. Available at: https://doi.org/10.1007/s11263-012-0591-y.","category":"page"},{"location":"solvers/FrankWolfe/#FrankWolfe","page":"Frank-Wolfe","title":"Frank Wolfe Method","text":"","category":"section"},{"location":"solvers/FrankWolfe/","page":"Frank-Wolfe","title":"Frank-Wolfe","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/FrankWolfe/","page":"Frank-Wolfe","title":"Frank-Wolfe","text":"Frank_Wolfe_method\nFrank_Wolfe_method!","category":"page"},{"location":"solvers/FrankWolfe/#Manopt.Frank_Wolfe_method","page":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method","text":"Frank_Wolfe_method(M, f, grad_f, p)\nFrank_Wolfe_method(M, gradient_objective, p; kwargs...)\n\nPerform the Frank-Wolfe algorithm to compute for mathcal C subset mathcal M\n\n    operatorname*argmin_pmathcal C f(p)\n\nWhere the main step is a constrained optimisation is within the algorithm, that is the sub problem (Oracle)\n\n    q_k = operatornameargmin_q in C operatornamegrad F(p_k) log_p_kq\n\nfor every iterate p_k together with a stepsize s_k1, by default s_k = frac2k+2.\n\nThe next iterate is then given by p_k+1 = Œ≥_p_kq_k(s_k), where by default Œ≥ is the shortest geodesic between the two points but can also be changed to use a retraction and its inverse.\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function f mathcal M‚Ñù to find a minimizer p^* for\ngrad_f ‚Äì the gradient operatornamegradf mathcal M  Tmathcal M of f\nas a function (M, p) -> X or a function (M, X, p) -> X\np ‚Äì an initial value p  mathcal C, note that it really has to be a feasible point\n\nAlternatively to f and grad_f you can prodive the AbstractManifoldGradientObjective gradient_objective directly.\n\nKeyword Arguments\n\nevaluation (AllocatingEvaluation) whether grad_F is an inplace or allocating (default) funtion\ninitial_vector ‚Äì (zero_vectoir(M,p)) how to initialize the inner gradient tangent vector\nstopping_criterion ‚Äì (StopAfterIteration(500) |StopWhenGradientNormLess(1.0e-6)) a stopping criterion\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a type of retraction\nstepsize (DecreasingStepsize(; length=2.0, shift=2) a Stepsize to use; but it has to be always less than 1. The default is the one proposed by Frank & Wolfe: s_k = frac2k+2.\n\nAll other keyword arguments are passed to decorate_state! for decorators or decorate_objective!, respectively. If you provide the ManifoldGradientObjective directly, these decorations can still be specified\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/FrankWolfe/#Manopt.Frank_Wolfe_method!","page":"Frank-Wolfe","title":"Manopt.Frank_Wolfe_method!","text":"Frank_Wolfe_method!(M, f, grad_f, p; kwargs...)\nFrank_Wolfe_method!(M, gradient_objective, p; kwargs...)\n\nPeform the Frank Wolfe method in place of p.\n\nFor all options and keyword arguments, see Frank_Wolfe_method.\n\n\n\n\n\n","category":"function"},{"location":"solvers/FrankWolfe/#State","page":"Frank-Wolfe","title":"State","text":"","category":"section"},{"location":"solvers/FrankWolfe/","page":"Frank-Wolfe","title":"Frank-Wolfe","text":"FrankWolfeState","category":"page"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeState","page":"Frank-Wolfe","title":"Manopt.FrankWolfeState","text":"FrankWolfeState <: AbstractManoptSolverState\n\nA struct to store the current state of the Frank_Wolfe_method\n\nIt comes in two forms, depending on the realisation of the subproblem.\n\nFields\n\np ‚Äì the current iterate, i.e. a point on the manifold\nX ‚Äì the current gradient operatornamegrad F(p), i.e. a tangent vector to p.\ninverse_retraction_method ‚Äì (default_inverse_retraction_method(M, typeof(p))) an inverse retraction method to use within Frank Wolfe.\nsub_problem ‚Äì an AbstractManoptProblem problem for the subsolver\nsub_state ‚Äì an AbstractManoptSolverState for the subsolver\nstop ‚Äì (StopAfterIteration(200) |StopWhenGradientNormLess(1.0e-6)) a StoppingCriterion\nstepsize - (DecreasingStepsize(; length=2.0, shift=2)) s_k which by default is set to s_k = frac2k+2.\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction to use within Frank-Wolfe\n\nFor the subtask, we need a method to solve\n\n    operatorname*argmin_qmathcal M X log_p qqquad text where X=operatornamegrad f(p)\n\nConstructor\n\nFrankWolfeState(M, p, X, sub_problem, sub_task)\n\nwhere the remaining fields from above are keyword arguments with their defaults already given in brackets.\n\n\n\n\n\n","category":"type"},{"location":"solvers/FrankWolfe/#Helpers","page":"Frank-Wolfe","title":"Helpers","text":"","category":"section"},{"location":"solvers/FrankWolfe/","page":"Frank-Wolfe","title":"Frank-Wolfe","text":"For the inner sub-problem you can easily create the corresponding cost and gradient using","category":"page"},{"location":"solvers/FrankWolfe/","page":"Frank-Wolfe","title":"Frank-Wolfe","text":"FrankWolfeCost\nFrankWolfeGradient","category":"page"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeCost","page":"Frank-Wolfe","title":"Manopt.FrankWolfeCost","text":"FrankWolfeCost{P,T}\n\nA structure to represent the oracle sub problem in the Frank_Wolfe_method. The cost function reads\n\nF(q) = X log_p q\n\nThe values pand X are stored within this functor and hsould be references to the iterate and gradient from within FrankWolfeState.\n\n\n\n\n\n","category":"type"},{"location":"solvers/FrankWolfe/#Manopt.FrankWolfeGradient","page":"Frank-Wolfe","title":"Manopt.FrankWolfeGradient","text":"FrankWolfeGradient{P,T}\n\nA structure to represent the gradeint of the oracle sub problem in the Frank_Wolfe_method, that is for a given point p and a tangent vector X we have\n\nF(q) = X log_p q\n\nIts gradient can be computed easily using adjoint_differential_log_argument.\n\nThe values pand X are stored within this functor and hsould be references to the iterate and gradient from within FrankWolfeState.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/ImplementASolver/#How-to-implementing-your-own-solver","page":"Implement a Solver","title":"How to implementing your own solver","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"When you have used a few solvers from Manopt.jl for example like in the opening tutorial Get Started: Optimize! you might come to the idea of implementing a solver yourself.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"After a short introduction of the algorithm we will implement, this tutorial first discusses the structural details, i.e.¬†what a solver consists of and ‚Äúworks with‚Äù. Afterwards, we will show how to implement the algorithm. Finally, we will discuss how to make the algorithm both nice for the user as well as initialized in a way, that it can benefit from features already available in Manopt.jl.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"note: Note\nIf you have implemented your own solver, we would be very happy to have that within Manopt.jl as well, so maybe consider opening a Pull Request","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"using Manopt, Manifolds, Random","category":"page"},{"location":"tutorials/ImplementASolver/#Our-Guiding-Example:-A-random-walk-Minimization","page":"Implement a Solver","title":"Our Guiding Example: A random walk Minimization","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Since most serious algorithms should be implemented in Manopt.jl themselves directly, we will implement a solver that randomly walks on the manifold and keeps track of the lowest point visited. As for algorithms in Manopt.jl we aim to implement this generically for any manifold that is implemented using ManifoldsBase.jl.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"The Random Walk Minimization","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Given:","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"a manifold mathcal M\na starting point p=p^(0)\na cost function f mathcal M tomathbb R.\na parameter sigma  0.\na retraction operatornameretr_p(X) that maps Xin T_pmathcal M to the manifold.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We can run the following steps of the algorithm","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"set k=0\nset our best point q = p^(0)\nRepeat until a stopping criterion is fulfilled\nChoose a random tangent vector X^(k) in T_p^(k)mathcal M of length lVert X^(k) rVert = sigma\n‚ÄúWalk‚Äù along this direction, i.e.¬†p^(k+1) = operatornameretr_p^(k)(X^(k))\nIf f(p^(k+1))  f(q) set q = p^{(k+1)}$ as our new best visited point\nReturn q as the resulting best point we visited","category":"page"},{"location":"tutorials/ImplementASolver/#Preliminaries-‚Äì-Elements-a-Solver-works-on","page":"Implement a Solver","title":"Preliminaries ‚Äì Elements a Solver works on","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"There are two main ingredients a solver needs: a problem to work on and the state of a solver, which ‚Äúidentifies‚Äù the solver and stores intermediate results.","category":"page"},{"location":"tutorials/ImplementASolver/#The-‚ÄúTask‚Äù-‚Äì-An-AbstractManoptProblem","page":"Implement a Solver","title":"The ‚ÄúTask‚Äù ‚Äì¬†An AbstractManoptProblem","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"A problem in Manopt.jl usually consists of a manifold (an AbstractManifold) and an AbstractManifoldObjective describing the function we have and its features. In our case the objective is (just) a ManifoldCostObjective that stores cost function f(M,p) = .... More generally, it might for example store a gradient function or the Hessian or any other information we have about our task.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"This is something independent of the solver itself, since it only identifies the problem we want to solve independent of how we want to solve it ‚Äì¬†or in other words, this type contains all information that is static and independent of the specific solver at hand.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Usually the problems variable is called mp.","category":"page"},{"location":"tutorials/ImplementASolver/#The-Solver-‚Äì-An-AbstractManoptSolverState","page":"Implement a Solver","title":"The Solver ‚Äì An AbstractManoptSolverState","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Everything that is needed by a solver during the iterations, all its parameters, interims values that are needed beyond just one iteration, is stored in a subtype of the AbstractManoptSolverState. This identifies the solver uniquely.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"In our case we want to store five things","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"the current iterate p=p^(k)\nthe best visited point q\nthe variable sigma  0\nthe retraction operatornameretr to use (cf.¬†retractions and inverse retractions)\na criterion, when to stop, i.e.¬†a StoppingCriterion","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We can defined this as","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"mutable struct RandomWalkState{\n    P,\n    R<:AbstractRetractionMethod,\n    S<:StoppingCriterion,\n} <: AbstractManoptSolverState\n  p::P\n  q::P\n  œÉ::Float64\n  retraction_method::R\n  stop::S\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"The stopping criterion is usually stored in the state‚Äôs stop field. If you have a reason to do otherwise, you have one more function to implement (see next section). For ease of use, we can provide a constructor, that for example chooses a good default for the retraction based on a given manifold.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"function RandomWalkState(M::AbstractManifold, p::P=rand(M);\n    œÉ = 0.1,\n    retraction_method::R=default_retraction_method(M),\n    stopping_criterion::S=StopAfterIteration(200)\n) where {P, R<:AbstractRetractionMethod, S<:StoppingCriterion}\n    return RandomWalkState{P,R,S}(p, copy(M, p), œÉ, retraction_method, stopping_criterion)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Parametrising the state avoid that we have abstract typed fields. The keyword arguments for the retraction and stopping criterion are the ones usually used in Manopt.jl and provide an easy way to construct this state now.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"States usually have a shortened name as their variable, we will use rws for our state here.","category":"page"},{"location":"tutorials/ImplementASolver/#Implementing-the-Your-solver","page":"Implement a Solver","title":"Implementing the Your solver","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"There is basically only two methods we need to implement for our solver","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"initialize_solver!(mp, rws) which initialises the solver before the first iteration\nstep_solver!(mp, rws, i) which implements the ith iteration, where i is given to you as the third parameter\nget_iterate(rws) which accesses the iterate from other places in the solver\nget_solver_result(rws) returning the solvers final (best) point we reached. By default this would return the last iterate rws.p (or more precisely calls get_iterate), but since we randomly walk and remember our best point in q, this has to return rws.q.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"The first two functions are in-place functions, that is they modify our solver state rws. You implement these by multiple dispatch on the types after importing said functions from Manopt:","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"import Manopt: initialize_solver!, step_solver!, get_iterate, get_solver_result","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"The state above has two fields where we use the common names used in Manopt.jl, that is the StoppingCriterion is usually in stop and the iterate in p. If your choice is different, you need to reimplement","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"stop_solver!(mp, rws, i) to determine whether or not to stop after the ith iteration.\nget_iterate(rws) to access the current iterate","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We recommend to follow the general scheme with the stop field. If you have specific criteria when to stop, consider implementing your own stoping criterion instead.","category":"page"},{"location":"tutorials/ImplementASolver/#Initialization-and-Iterate-Access","page":"Implement a Solver","title":"Initialization & Iterate Access","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"For our solver, there is not so much to initialize, just to be safe we should copy over the initial value in p we start with, to q. We do not have to care about remembering the iterate, that is done by Manopt.jl. For the iterate access we just have to pass p.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"function initialize_solver!(mp::AbstractManoptProblem, rws::RandomWalkState)\n    copyto!(M, rws.q, rws.p) # Set p^{(0)} = q\n    return rws\nend\nget_iterate(rws::RandomWalkState) = rws.p\nget_solver_result(rws::RandomWalkState) = rws.q","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"and similarly we implement the step. Here we make use of the fact that the problem (and also the objective in fact) have access functions for their elements, the one we need is get_cost.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"function step_solver!(mp::AbstractManoptProblem, rws::RandomWalkState, i)\n    M = get_manifold(mp) # for ease of use get the manifold from the problem\n    X = rand(M; vector_at=p)     # generate a direction\n    X .*= rws.œÉ/norm(M, p, X)\n    # Walk\n    retract!(M, rws.p, rws.p, X, rws.retraction_method)\n    # is the new point better? Then store it\n    if get_cost(mp, rws.p) < get_cost(mp, rws.q)\n        copyto!(M, rws.p, rws.q)\n    end\n    return rws\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Performance wise we could improve the number of allocations by making X also a field of our rws but let‚Äôs keep it simple here. We could also store the cost of q in the state, but we will see how to easily also enable this solver to allow for caching. In practice, however, it is preferable to cache intermediate values like cost of q in the state when it can be easily achieved. This way we do not have to deal with overheads of an external cache.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Now we can just run the solver already! We take the same example as for the other tutorials","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We first define our task, the Riemannian Center of Mass from the Get Started: Optimize! tutorial.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Random.seed!(23)\nn = 100\nœÉ = œÄ / 8\nM = Sphere(2)\np = 1 / sqrt(2) * [1.0, 0.0, 1.0]\ndata = [exp(M, p,  œÉ * rand(M; vector_at=p)) for i in 1:n];\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We can now generate the problem with its objective and the state","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"mp = DefaultManoptProblem(M, ManifoldCostObjective(f))\ns = RandomWalkState(M; œÉ = 0.2)\n\nsolve!(mp, s)\nget_solver_result(s)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"3-element Vector{Float64}:\n -0.2412674850987521\n  0.8608618657176527\n -0.44800317943876844","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"The function solve! works also in place of s, but the last line illustrates how to access the result in general; we could also just look at s.p, but the function get_iterate is also used in several other places.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We could for example easily set up a second solver to work from a specified starting point with a different œÉ like","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"s2 = RandomWalkState(M, [1.0, 0.0, 0.0];  œÉ = 0.1)\nsolve!(mp, s2)\nget_solver_result(s2)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"3-element Vector{Float64}:\n 1.0\n 0.0\n 0.0","category":"page"},{"location":"tutorials/ImplementASolver/#Ease-of-Use-I:-The-high-level-interface(s)","page":"Implement a Solver","title":"Ease of Use I: The high level interface(s)","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Manopt.jl offers a few additional features for solvers in their high level interfaces, for example debug= for debug, record= keywords for debug and recording within solver states or count= and cache keywords for the objective.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We can introduce these here as well with just a few lines of code. There are usually two steps. We further need three internal function from Manopt.jl","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"using Manopt: get_solver_return, indicates_convergence, status_summary","category":"page"},{"location":"tutorials/ImplementASolver/#A-high-level-interface-using-the-objective","page":"Implement a Solver","title":"A high level interface using the objective","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"This could be considered as an interims step to the high-level interface: If we already have the objective ‚Äì¬†in our case a ManifoldCostObjective at hand, the high level interface consists of the steps","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"possibly decorate the objective\ngenerate the problem\ngenerate and possiblz generate the state\ncall the solver\ndetermine the return value","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We illustrate the step with an in-place variant here. A variant that keeps the given start point unchanged would just add a copy(M, p) upfront. Manopt.jl provides both variants.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"function random_walk_algorithm!(\n    M::AbstractManifold,\n    mgo::ManifoldCostObjective,\n    p;\n    œÉ = 0.1,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n    stopping_criterion::StoppingCriterion=StopAfterIteration(200),\n    kwargs...,\n)\n    dmgo = decorate_objective!(M, mgo; kwargs...)\n    dmp = DefaultManoptProblem(M, dmgo)\n    s = RandomWalkState(M, [1.0, 0.0, 0.0];\n        œÉ=0.1,\n        retraction_method=retraction_method, stopping_criterion=stopping_criterion,\n    )\n    ds = decorate_state!(s; kwargs...)\n    solve!(dmp, ds)\n    return get_solver_return(get_objective(dmp), ds)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"random_walk_algorithm! (generic function with 1 method)","category":"page"},{"location":"tutorials/ImplementASolver/#The-high-level-interface","page":"Implement a Solver","title":"The high level interface","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Starting from the last section, the usual call a user would prefer is just passing a manifold M the cost f and maybe a start point p.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"function random_walk_algorithm!(M::AbstractManifold, f, p=rand(M); kwargs...)\n    mgo = ManifoldCostObjective(f)\n    return random_walk_algorithm!(M, mgo, p; kwargs...)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"random_walk_algorithm! (generic function with 3 methods)","category":"page"},{"location":"tutorials/ImplementASolver/#Ease-of-Use-II:-The-State-Summary","page":"Implement a Solver","title":"Ease of Use II: The State Summary","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"For the case that you set return_state=true the solver should return a summary of the run. When a show method is provided, users can easily read such summary in a terminal. It should reflect its main parameters, if they are not too verbose and provide information about the reason it stopped and whether this indicates convergence.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Here it would for example look like","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"import Base: show\nfunction show(io::IO, rws::RandomWalkState)\n    i = get_count(rws, :Iterations)\n    Iter = (i > 0) ? \"After $i iterations\\n\" : \"\"\n    Conv = indicates_convergence(rws.stop) ? \"Yes\" : \"No\"\n    s = \"\"\"\n    # Solver state for `Manopt.jl`s Tutorial Random Walk\n    $Iter\n    ## Parameters\n    * retraction method: $(rws.retraction_method)\n    * œÉ                : $(rws.œÉ)\n\n    ## Stopping Criterion\n    $(status_summary(rws.stop))\n    This indicates convergence: $Conv\"\"\"\n    return print(io, s)\nend","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"show (generic function with 657 methods)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"Now the algorithm can be easily called and provides ‚Äì if wanted ‚Äì all features of a Manopt.jl algorithm. For example to see the summary, we could now just call","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"q = random_walk_algorithm!(M, f; return_state=true)","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"# Solver state for `Manopt.jl`s Tutorial Random Walk\nAfter 200 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n* œÉ                : 0.1\n\n## Stopping Criterion\nMax Iteration 200:  reached\nThis indicates convergence: No","category":"page"},{"location":"tutorials/ImplementASolver/#Conclusion-and-Beyond","page":"Implement a Solver","title":"Conclusion & Beyond","text":"","category":"section"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"We saw in this tutorial how to implement a simple cost-based algorithm, to illustrate how optimization algorithms are covered in Manopt.jl.","category":"page"},{"location":"tutorials/ImplementASolver/","page":"Implement a Solver","title":"Implement a Solver","text":"One feature we did not cover is that most algorithms allow for inplace and allocation functions, as soon as they work on more than just the cost, e.g.¬†gradients, proximal maps or Hessians. This is usually a keyword argument of the objective and hence also part of the high-level interfaces.","category":"page"},{"location":"functions/manifold/#Specific-manifold-functions","page":"Specific Manifold Functions","title":"Specific manifold functions","text":"","category":"section"},{"location":"functions/manifold/","page":"Specific Manifold Functions","title":"Specific Manifold Functions","text":"This small section extends the functions available from ManifoldsBase.jl and Manifolds.jl, especially a few random generators, that are simpler than the available functions.","category":"page"},{"location":"functions/manifold/","page":"Specific Manifold Functions","title":"Specific Manifold Functions","text":"Modules = [Manopt]\nPages   = [\"manifold_functions.jl\"]","category":"page"},{"location":"functions/manifold/#Manopt.reflect-Tuple{AbstractManifold, Any, Any}","page":"Specific Manifold Functions","title":"Manopt.reflect","text":"reflect(M, p, x)\nreflect!(M, q, p, x)\n\nReflect the point x from the manifold M at point p, i.e.\n\n    operatornamerefl_p(x) = exp_p(-log_p x)\n\nwhere exp and log denote the exponential and logarithmic map on M. This can also be done in place of q.\n\n\n\n\n\n","category":"method"},{"location":"functions/manifold/#Manopt.reflect-Tuple{AbstractManifold, Function, Any}","page":"Specific Manifold Functions","title":"Manopt.reflect","text":"reflect(M, f, x)\nreflect!(M, q, f, x)\n\nreflect the point x from the manifold M at the point f(x) of the function f mathcal M  mathcal M, i.e.,\n\n    operatornamerefl_f(x) = operatornamerefl_f(x)(x)\n\nCompute the result in q.\n\nsee also reflect(M,p,x).\n\n\n\n\n\n","category":"method"},{"location":"solvers/particle_swarm/#ParticleSwarmSolver","page":"Particle Swarm Optimization","title":"Particle Swarm Optimization","text":"","category":"section"},{"location":"solvers/particle_swarm/","page":"Particle Swarm Optimization","title":"Particle Swarm Optimization","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/particle_swarm/","page":"Particle Swarm Optimization","title":"Particle Swarm Optimization","text":"  particle_swarm\n  particle_swarm!","category":"page"},{"location":"solvers/particle_swarm/#Manopt.particle_swarm","page":"Particle Swarm Optimization","title":"Manopt.particle_swarm","text":"patricle_swarm(M, f; kwargs...)\npatricle_swarm(M, f, swarm; kwargs...)\npatricle_swarm(M, mco::AbstractManifoldCostObjective; kwargs..)\npatricle_swarm(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\n\nperform the particle swarm optimization algorithm (PSO), starting with an initial swarm[Borckmans2010]. If no swarm is provided, swarm_size many random points are used. Note that since this method does not work in-place ‚Äì these points are duplicated internally.\n\nThe aim of PSO is to find the particle position g on the Manifold M that solves\n\nmin_x mathcalM F(x)\n\nTo this end, a swarm of particles is moved around the Manifold M in the following manner. For every particle k we compute the new particle velocities v_k^(i) in every step i of the algorithm by\n\nv_k^(i) = œâ  operatornameT_x_k^(i)gets x_k^(i-1)v_k^(i-1) + c   r_1  operatornameretr_x_k^(i)^-1(p_k^(i)) + s   r_2 operatornameretr_x_k^(i)^-1(g)\n\nwhere x_k^(i) is the current particle position, œâ denotes the inertia, c and s are a cognitive and a social weight, respectively, r_j, j=12 are random factors which are computed new for each particle and step, operatornameretr^-1 denotes an inverse retraction on the Manifold M, and operatornameT is a vector transport.\n\nThen the position of the particle is updated as\n\nx_k^(i+1) = operatornameretr_x_k^(i)(v_k^(i))\n\nwhere operatornameretr denotes a retraction on the Manifold M. At the end of each step for every particle, we set\n\np_k^(i+1) = begincases\nx_k^(i+1)   textif  F(x_k^(i+1))F(p_k^(i))\np_k^(i)  textelse\nendcases\n\n\nand\n\ng_k^(i+1) =begincases\np_k^(i+1)   textif  F(p_k^(i+1))F(g_k^(i))\ng_k^(i)  textelse\nendcases\n\ni.e. p_k^(i) is the best known position for the particle k and g^(i) is the global best known position ever visited up to step i.\n\n[Borckmans2010]: P. B. Borckmans, M. Ishteva, P.-A. Absil, A Modified Particle Swarm Optimization Algorithm for the Best Low Multilinear Rank Approximation of Higher-Order Tensors, In: Dorigo M. et al. (eds) Swarm Intelligence. ANTS 2010. Lecture Notes in Computer Science, vol 6234. Springer, Berlin, Heidelberg, doi 10.1007/978-3-642-15461-4_2\n\nInput\n\nM     ‚Äì a manifold mathcal M\nf     ‚Äì a cost function Fmathcal M‚Ñù to minimize\nswarm ‚Äì ([rand(M) for _ in 1:swarm_size]) ‚Äì an initial swarm of points.\n\nInstead of a cost function f you can also provide an AbstractManifoldCostObjective mco.\n\nOptional\n\ncognitive_weight          ‚Äì (1.4) a cognitive weight factor\ninertia                   ‚Äì (0.65) the inertia of the patricles\ninverse_retraction_method - (default_inverse_retraction_method(M, eltype(x))) an inverse_retraction(M,x,y) to use.\nswarm_size                - (100) number of random initial positions of x0\nretraction_method         ‚Äì (default_retraction_method(M, eltype(x))) a retraction(M,x,Œæ) to use.\nsocial_weight             ‚Äì (1.4) a social weight factor\nstopping_criterion        ‚Äì (StopWhenAny(StopAfterIteration(500), StopWhenChangeLess(10^{-4}))) a functor inheriting from StoppingCriterion indicating when to stop.\nvector_transport_mthod    - (default_vector_transport_method(M, eltype(x))) a vector transport method to use.\nvelocity                  ‚Äì a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles, per default a random tangent vector per inital position\n\nAll other keyword arguments are passed to decorate_state! for decorators or decorate_objective!, respectively. If you provide the ManifoldGradientObjective directly, these decorations can still be specified\n\nOutput\n\nthe obtained (approximate) minimizer g, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/particle_swarm/#Manopt.particle_swarm!","page":"Particle Swarm Optimization","title":"Manopt.particle_swarm!","text":"patricle_swarm!(M, f, swarm; kwargs...)\npatricle_swarm!(M, mco::AbstractManifoldCostObjective, swarm; kwargs..)\n\nperform the particle swarm optimization algorithm (PSO), starting with the initial swarm [Borckmans2010] whichis then modified in place.\n\nInput\n\nM     ‚Äì a manifold mathcal M\nf     ‚Äì a cost function Fmathcal M‚Ñù to minimize\nswarm ‚Äì ([rand(M) for _ in 1:swarm_size]) ‚Äì an initial swarm of points.\n\nInstead of a cost function f you can also provide an AbstractManifoldCostObjective mco.\n\nFor more details and optional arguments, see particle_swarm.\n\n\n\n\n\n","category":"function"},{"location":"solvers/particle_swarm/#State","page":"Particle Swarm Optimization","title":"State","text":"","category":"section"},{"location":"solvers/particle_swarm/","page":"Particle Swarm Optimization","title":"Particle Swarm Optimization","text":"ParticleSwarmState","category":"page"},{"location":"solvers/particle_swarm/#Manopt.ParticleSwarmState","page":"Particle Swarm Optimization","title":"Manopt.ParticleSwarmState","text":"ParticleSwarmState{P,T} <: AbstractManoptSolverState\n\nDescribes a particle swarm optimizing algorithm, with\n\nFields\n\nx ‚Äì a set of points (of type AbstractVector{P}) on a manifold as initial particle positions\nvelocity ‚Äì a set of tangent vectors (of type AbstractVector{T}) representing the velocities of the particles\ninertia ‚Äì (0.65) the inertia of the patricles\nsocial_weight ‚Äì (1.4) a social weight factor\ncognitive_weight ‚Äì (1.4) a cognitive weight factor\np_temp ‚Äì temporary storage for a point to avoid allocations during a step of the algorithm\nsocial_vec - temporary storage for a tangent vector related to social_weight\ncognitive_vector -  temporary storage for a tangent vector related to cognitive_weight\nstopping_criterion ‚Äì ([StopAfterIteration](@ref)(500) | [StopWhenChangeLess](@ref)(1e-4)) a functor inheriting from [StoppingCriterion`](@ref) indicating when to stop.\nretraction_method ‚Äì (default_retraction_method(M, eltype(x))) the rectraction to use\ninverse_retraction_method - (default_inverse_retraction_method(M, eltype(x))) an inverse retraction to use.\nvector_transport_method - (default_vector_transport_method(M, eltype(x))) a vector transport to use\n\nConstructor\n\nParticleSwarmState(M, x0, velocity; kawrgs...)\n\nconstruct a particle swarm Option for the manifold M starting at initial population x0 with velocities x0, where the manifold is used within the defaults of the other fields mentioned above, which are keyword arguments here.\n\nSee also\n\nparticle_swarm\n\n\n\n\n\n","category":"type"},{"location":"solvers/particle_swarm/#Literature","page":"Particle Swarm Optimization","title":"Literature","text":"","category":"section"},{"location":"solvers/stochastic_gradient_descent/#StochasticGradientDescentSolver","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"","category":"section"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"stochastic_gradient_descent\nstochastic_gradient_descent!","category":"page"},{"location":"solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent","page":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent","text":"stochastic_gradient_descent(M, grad_f, p; kwargs...)\nstochastic_gradient_descent(M, msgo, p; kwargs...)\n\nperform a stochastic gradient descent\n\nInput\n\nM a manifold mathcal M\ngrad_f ‚Äì a gradient function, that either returns a vector of the subgradients or is a vector of gradients\np ‚Äì an initial value x  mathcal M\n\nalternatively to the gradient you can provide an ManifoldStochasticGradientObjective msgo, then using the cost= keyword does not have any effect since if so, the cost is already within the objective.\n\nOptional\n\ncost ‚Äì (missing) you can provide a cost function for example to track the function value\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient(s) works by  allocation (default) form gradF(M, x) or InplaceEvaluation in place, i.e.  is of the form gradF!(M, X, x) (elementwise).\nevaluation_order ‚Äì (:Random) ‚Äì whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Linear) or the default :Random one.\nstopping_criterion (StopAfterIteration(1000))‚Äì a StoppingCriterion\nstepsize (ConstantStepsize(1.0)) a Stepsize\norder_type (:RandomOder) a type of ordering of gradient evaluations. values are :RandomOrder, a :FixedPermutation, :LinearOrder\norder - ([1:n]) the initial permutation, where n is the number of gradients in gradF.\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction to use.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/#Manopt.stochastic_gradient_descent!","page":"Stochastic Gradient Descent","title":"Manopt.stochastic_gradient_descent!","text":"stochastic_gradient_descent!(M, grad_f, p)\nstochastic_gradient_descent!(M, msgo, p)\n\nperform a stochastic gradient descent in place of p.\n\nInput\n\nM a manifold mathcal M\ngrad_f ‚Äì a gradient function, that either returns a vector of the subgradients or is a vector of gradients\np ‚Äì an initial value p  mathcal M\n\nAlternatively to the gradient you can provide an ManifoldStochasticGradientObjective msgo, then using the cost= keyword does not have any effect since if so, the cost is already within the objective.\n\nfor all optional parameters, see stochastic_gradient_descent.\n\n\n\n\n\n","category":"function"},{"location":"solvers/stochastic_gradient_descent/#State","page":"Stochastic Gradient Descent","title":"State","text":"","category":"section"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"StochasticGradientDescentState","category":"page"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradientDescentState","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradientDescentState","text":"StochasticGradientDescentState <: AbstractGradientDescentSolverState\n\nStore the following fields for a default stochastic gradient descent algorithm, see also ManifoldStochasticGradientObjective and stochastic_gradient_descent.\n\nFields\n\np the current iterate\ndirection (StochasticGradient) a direction update to use\nstopping_criterion (StopAfterIteration(1000))‚Äì a StoppingCriterion\nstepsize (ConstantStepsize(1.0)) a Stepsize\nevaluation_order ‚Äì (:Random) ‚Äì whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Linear) or the default :Random one.\norder the current permutation\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction(M, p, X) to use.\n\nConstructor\n\nStochasticGradientDescentState(M, p)\n\nCreate a StochasticGradientDescentState with start point x. all other fields are optional keyword arguments, and the defaults are taken from M.\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"Additionally, the options share a DirectionUpdateRule, so you can also apply MomentumGradient and AverageGradient here. The most inner one should always be.","category":"page"},{"location":"solvers/stochastic_gradient_descent/","page":"Stochastic Gradient Descent","title":"Stochastic Gradient Descent","text":"AbstractGradientGroupProcessor\nStochasticGradient","category":"page"},{"location":"solvers/stochastic_gradient_descent/#Manopt.AbstractGradientGroupProcessor","page":"Stochastic Gradient Descent","title":"Manopt.AbstractGradientGroupProcessor","text":"AbstractStochasticGradientDescentSolverState <: AbstractManoptSolverState\n\nA generic type for all options related to stochastic gradient descent methods\n\n\n\n\n\n","category":"type"},{"location":"solvers/stochastic_gradient_descent/#Manopt.StochasticGradient","page":"Stochastic Gradient Descent","title":"Manopt.StochasticGradient","text":"StochasticGradient <: AbstractGradientGroupProcessor\n\nThe default gradient processor, which just evaluates the (stochastic) gradient or a subset thereof.\n\nConstructor\n\nStochasticGradient(M::AbstractManifold; p=rand(M), X=zero_vector(M, p))\n\nInitialize the stochastic Gradient processor with X, i.e. both M and p are just help variables, though M is mandatory by convention.\n\n\n\n\n\n","category":"type"},{"location":"functions/adjointdifferentials/#adjointDifferentialFunctions","page":"Adjoint Differentials","title":"Adjoint Differentials","text":"","category":"section"},{"location":"functions/adjointdifferentials/","page":"Adjoint Differentials","title":"Adjoint Differentials","text":"Modules = [Manopt]\nPages   = [\"adjoint_differentials.jl\"]","category":"page"},{"location":"functions/adjointdifferentials/#Manopt.adjoint_differential_bezier_control-Tuple{AbstractManifold, AbstractVector{<:BezierSegment}, AbstractVector, AbstractVector}","page":"Adjoint Differentials","title":"Manopt.adjoint_differential_bezier_control","text":"adjoint_differential_bezier_control(\n    M::AbstractManifold,\n    T::AbstractVector,\n    X::AbstractVector,\n)\nadjoint_differential_bezier_control!(\n    M::AbstractManifold,\n    Y::AbstractVector{<:BezierSegment},\n    T::AbstractVector,\n    X::AbstractVector,\n)\n\nEvaluate the adjoint of the differential with respect to the controlpoints at several times T. This can be computed in place of Y.\n\nSee de_casteljau for more details on the curve.\n\n\n\n\n\n","category":"method"},{"location":"functions/adjointdifferentials/#Manopt.adjoint_differential_bezier_control-Tuple{AbstractManifold, AbstractVector{<:BezierSegment}, Any, Any}","page":"Adjoint Differentials","title":"Manopt.adjoint_differential_bezier_control","text":"adjoint_differential_bezier_control(\n    M::AbstractManifold,\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X\n)\nadjoint_differential_bezier_control!(\n    M::AbstractManifold,\n    Y::AbstractVector{<:BezierSegment},\n    B::AbstractVector{<:BezierSegment},\n    t,\n    X\n)\n\nevaluate the adjoint of the differential of a composite B√©zier curve on the manifold M with respect to its control points b based on a points T=(t_i)_i=1^n that are pointwise in t_i01 on the curve and given corresponding tangential vectors X = (Œ∑_i)_i=1^n, Œ∑_iT_Œ≤(t_i)mathcal M This can be computed in place of Y.\n\nSee de_casteljau for more details on the curve.\n\n\n\n\n\n","category":"method"},{"location":"functions/adjointdifferentials/#Manopt.adjoint_differential_bezier_control-Tuple{AbstractManifold, BezierSegment, AbstractVector, AbstractVector}","page":"Adjoint Differentials","title":"Manopt.adjoint_differential_bezier_control","text":"adjoint_differential_bezier_control(\n    M::AbstractManifold,\n    b::BezierSegment,\n    t::AbstractVector,\n    X::AbstractVector,\n)\nadjoint_differential_bezier_control!(\n    M::AbstractManifold,\n    Y::BezierSegment,\n    b::BezierSegment,\n    t::AbstractVector,\n    X::AbstractVector,\n)\n\nevaluate the adjoint of the differential of a B√©zier curve on the manifold M with respect to its control points b based on a points T=(t_i)_i=1^n that are pointwise in t_i01 on the curve and given corresponding tangential vectors X = (Œ∑_i)_i=1^n, Œ∑_iT_Œ≤(t_i)mathcal M This can be computed in place of Y.\n\nSee de_casteljau for more details on the curve and[BergmannGousenbourger2018].\n\n[BergmannGousenbourger2018]: Bergmann, R. and Gousenbourger, P.-Y.: A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve. Frontiers in Applied Mathematics and Statistics, 2018. doi: 10.3389/fams.2018.00059, arXiv: 1807.10090\n\n\n\n\n\n","category":"method"},{"location":"functions/adjointdifferentials/#Manopt.adjoint_differential_bezier_control-Tuple{AbstractManifold, BezierSegment, Any, Any}","page":"Adjoint Differentials","title":"Manopt.adjoint_differential_bezier_control","text":"adjoint_differential_bezier_control(M::AbstractManifold, b::BezierSegment, t, Œ∑)\nadjoint_differential_bezier_control!(\n    M::AbstractManifold,\n    Y::BezierSegment,\n    b::BezierSegment,\n    t,\n    Œ∑,\n)\n\nevaluate the adjoint of the differential of a B√©zier curve on the manifold M with respect to its control points b based on a point t01 on the curve and a tangent vector Œ∑T_Œ≤(t)mathcal M. This can be computed in place of Y.\n\nSee de_casteljau for more details on the curve.\n\n\n\n\n\n","category":"method"},{"location":"functions/adjointdifferentials/#Manopt.adjoint_differential_forward_logs-Union{Tuple{TPR}, Tuple{TSize}, Tuple{TM}, Tuple{ùîΩ}, Tuple{PowerManifold{ùîΩ, TM, TSize, TPR}, Any, Any}} where {ùîΩ, TM, TSize, TPR}","page":"Adjoint Differentials","title":"Manopt.adjoint_differential_forward_logs","text":"Y = adjoint_differential_forward_logs(M, p, X)\nadjoint_differential_forward_logs!(M, Y, p, X)\n\nCompute the adjoint differential of forward_logs F orrucirng, in the power manifold array p, the differential of the function\n\nF_i(p) = sum_j  mathcal I_i log_p_i p_j\n\nwhere i runs over all indices of the PowerManifold manifold M and mathcal I_i denotes the forward neighbors of i Let n be the number dimensions of the PowerManifold manifold (i.e. length(size(x))). Then the input tangent vector lies on the manifold mathcal M = mathcal M^n. The adjoint differential can be computed in place of Y.\n\nInput\n\nM     ‚Äì a PowerManifold manifold\np     ‚Äì an array of points on a manifold\nX     ‚Äì a tangent vector to from the n-fold power of p, where n is the ndims of p\n\nOuput\n\nY ‚Äì resulting tangent vector in T_pmathcal M representing the adjoint   differentials of the logs.\n\n\n\n\n\n","category":"method"},{"location":"solvers/cyclic_proximal_point/#CPPSolver","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"The Cyclic Proximal Point (CPP) algorithm aims to minimize","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"F(x) = sum_i=1^c f_i(x)","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"assuming that the proximal maps operatornameprox_Œª f_i(x) are given in closed form or can be computed efficiently (at least approximately).","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"The algorithm then cycles through these proximal maps, where the type of cycle might differ and the proximal parameter Œª_k changes after each cycle k.","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"For a convergence result on Hadamard manifolds see [Baƒç√°k, 2014].","category":"page"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"cyclic_proximal_point\ncyclic_proximal_point!","category":"page"},{"location":"solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point","page":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point","text":"cyclic_proximal_point(M, f, proxes_f, p)\ncyclic_proximal_point(M, mpo, p)\n\nperform a cyclic proximal point algorithm.\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function fmathcal M‚Ñù to minimize\nproxes_f ‚Äì an Array of proximal maps (Functions) (M,Œª,p) -> q or (M, q, Œª, p) -> q for the summands of f (see evaluation)\np ‚Äì an initial value p  mathcal M\n\nwhere f and the proximal maps proxes_f can also be given directly as a ManifoldProximalMapObjective mpo\n\nOptional\n\nevaluation ‚Äì (AllocatingEvaluation) specify whether the proximal maps work by allocation (default) form prox(M, Œª, x) or InplaceEvaluation in place, i.e. is of the form prox!(M, y, Œª, x).\nevaluation_order ‚Äì (:Linear) ‚Äì whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Random) or the default linear one.\nŒª ‚Äì ( iter -> 1/iter ) a function returning the (square summable but not summable) sequence of Œªi\nstopping_criterion ‚Äì (StopWhenAny(StopAfterIteration(5000),StopWhenChangeLess(10.0^-8))) a StoppingCriterion.\n\nAll other keyword arguments are passed to decorate_state! for decorators or decorate_objective!, respectively. If you provide the ManifoldProximalMapObjective directly, these decorations can still be specified.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/cyclic_proximal_point/#Manopt.cyclic_proximal_point!","page":"Cyclic Proximal Point","title":"Manopt.cyclic_proximal_point!","text":"cyclic_proximal_point!(M, F, proxes, p)\ncyclic_proximal_point!(M, mpo, p)\n\nperform a cyclic proximal point algorithm in place of p.\n\nInput\n\nM ‚Äì a manifold mathcal M\nF ‚Äì a cost function Fmathcal M‚Ñù to minimize\nproxes ‚Äì an Array of proximal maps (Functions) (M, Œª, p) -> q or (M, q, Œª, p) for the summands of F\np ‚Äì an initial value p  mathcal M\n\nwhere f and the proximal maps proxes_f can also be given directly as a ManifoldProximalMapObjective mpo\n\nfor all options, see cyclic_proximal_point.\n\n\n\n\n\n","category":"function"},{"location":"solvers/cyclic_proximal_point/#State","page":"Cyclic Proximal Point","title":"State","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"CyclicProximalPointState","category":"page"},{"location":"solvers/cyclic_proximal_point/#Manopt.CyclicProximalPointState","page":"Cyclic Proximal Point","title":"Manopt.CyclicProximalPointState","text":"CyclicProximalPointState <: AbstractManoptSolverState\n\nstores options for the cyclic_proximal_point algorithm. These are the\n\nFields\n\np ‚Äì the current iterate\nstopping_criterion ‚Äì a StoppingCriterion\nŒª ‚Äì (@(i) -> 1/i) a function for the values of Œª_k per iteration(cycle √¨\noder_type ‚Äì (:LinearOrder) ‚Äì whether to use a randomly permuted sequence (:FixedRandomOrder), a per cycle permuted sequence (:RandomOrder) or the default linear one.\n\nConstructor\n\nCyclicProximalPointState(M, p)\n\nGenerate the options with the following keyword arguments\n\nstopping_criterion (StopAfterIteration(2000)) ‚Äì a StoppingCriterion.\nŒª ( i -> 1.0 / i) ‚Äì a function to compute the Œª_k k  mathbb N,\nevaluation_order ‚Äì (:LinearOrder) ‚Äì a Symbol indicating the order the proxes are applied.\n\nSee also\n\ncyclic_proximal_point\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Debug-Functions","page":"Cyclic Proximal Point","title":"Debug Functions","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"DebugProximalParameter","category":"page"},{"location":"solvers/cyclic_proximal_point/#Manopt.DebugProximalParameter","page":"Cyclic Proximal Point","title":"Manopt.DebugProximalParameter","text":"DebugProximalParameter <: DebugAction\n\nprint the current iterates proximal point algorithm parameter given by AbstractManoptSolverStates o.Œª.\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Record-Functions","page":"Cyclic Proximal Point","title":"Record Functions","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"RecordProximalParameter","category":"page"},{"location":"solvers/cyclic_proximal_point/#Manopt.RecordProximalParameter","page":"Cyclic Proximal Point","title":"Manopt.RecordProximalParameter","text":"RecordProximalParameter <: RecordAction\n\nrecoed the current iterates proximal point algorithm parameter given by in AbstractManoptSolverStates o.Œª.\n\n\n\n\n\n","category":"type"},{"location":"solvers/cyclic_proximal_point/#Literature","page":"Cyclic Proximal Point","title":"Literature","text":"","category":"section"},{"location":"solvers/cyclic_proximal_point/","page":"Cyclic Proximal Point","title":"Cyclic Proximal Point","text":"<ul>\n<li id=\"Baƒç√°k2014\">[<a>Baƒç√°k, 2014</a>]\n  Baƒç√°k, M: <emph>Computing Medians and Means in Hadamard Spaces.</emph>,\n  SIAM Journal on Optimization, Volume 24, Number 3, pp. 1542‚Äì1566,\n  doi: <a href=\"https://doi.org/10.1137/140953393\">10.1137/140953393</a>,\n  arxiv: <a href=\"https://arxiv.org/abs/1210.2145\">1210.2145</a>.\n  </li>\n</ul>","category":"page"},{"location":"functions/costs/#CostFunctions","page":"Cost functions","title":"Cost Functions","text":"","category":"section"},{"location":"functions/costs/","page":"Cost functions","title":"Cost functions","text":"The following cost functions are available","category":"page"},{"location":"functions/costs/","page":"Cost functions","title":"Cost functions","text":"Modules = [Manopt]\nPages   = [\"costs.jl\"]","category":"page"},{"location":"functions/costs/#Manopt.costIntrICTV12-Tuple{AbstractManifold, Vararg{Any, 5}}","page":"Cost functions","title":"Manopt.costIntrICTV12","text":"costIntrICTV12(M, f, u, v, Œ±, Œ≤)\n\nCompute the intrinsic infimal convolution model, where the addition is replaced by a mid point approach and the two functions involved are costTV2 and costTV. The model reads\n\nE(uv) =\n  frac12sum_i  mathcal G\n    d_mathcal Mbigl(g(frac12v_iw_i)f_ibigr)\n  +alphabigl( Œ≤mathrmTV(v) + (1-Œ≤)mathrmTV_2(w) bigr)\n\n\n\n\n\n","category":"method"},{"location":"functions/costs/#Manopt.costL2TV-NTuple{4, Any}","page":"Cost functions","title":"Manopt.costL2TV","text":"costL2TV(M, f, Œ±, x)\n\ncompute the ‚Ñì^2-TV functional on the PowerManifold manifoldMfor given (fixed) dataf(onM), a nonnegative weightŒ±, and evaluated atx(onM`), i.e.\n\nE(x) = d_mathcal M^2(fx) + alpha operatornameTV(x)\n\nSee also\n\ncostTV\n\n\n\n\n\n","category":"method"},{"location":"functions/costs/#Manopt.costL2TV2-Tuple{PowerManifold, Any, Any, Any}","page":"Cost functions","title":"Manopt.costL2TV2","text":"costL2TV2(M, f, Œ≤, x)\n\ncompute the ‚Ñì^2-TV2 functional on the PowerManifold manifold M for given data f, nonnegative parameter Œ≤, and evaluated at x, i.e.\n\nE(x) = d_mathcal M^2(fx) + Œ≤operatornameTV_2(x)\n\nSee also\n\ncostTV2\n\n\n\n\n\n","category":"method"},{"location":"functions/costs/#Manopt.costL2TVTV2-Tuple{PowerManifold, Vararg{Any, 4}}","page":"Cost functions","title":"Manopt.costL2TVTV2","text":"costL2TVTV2(M, f, Œ±, Œ≤, x)\n\ncompute the ‚Ñì^2-TV-TV2 functional on the PowerManifold manifold M for given (fixed) data f (on M), nonnegative weight Œ±, Œ≤, and evaluated at x (on M), i.e.\n\nE(x) = d_mathcal M^2(fx) + alphaoperatornameTV(x)\n  + Œ≤operatornameTV_2(x)\n\nSee also\n\ncostTV, costTV2\n\n\n\n\n\n","category":"method"},{"location":"functions/costs/#Manopt.costTV","page":"Cost functions","title":"Manopt.costTV","text":"costTV(M,x [,p=2,q=1])\n\nCompute the operatornameTV^p functional for data xon the PowerManifold manifold M, i.e. mathcal M = mathcal N^n, where n  mathbb N^k denotes the dimensions of the data x. Let mathcal I_i denote the forward neighbors, i.e. with mathcal G as all indices from mathbf1  mathbb N^k to n we have mathcal I_i = i+e_j j=1kcap mathcal G. The formula reads\n\nE^q(x) = sum_i  mathcal G\n  bigl( sum_j   mathcal I_i d^p_mathcal M(x_ix_j) bigr)^qp\n\nSee also\n\ngrad_TV, prox_TV\n\n\n\n\n\n","category":"function"},{"location":"functions/costs/#Manopt.costTV-Union{Tuple{T}, Tuple{AbstractManifold, Tuple{T, T}}, Tuple{AbstractManifold, Tuple{T, T}, Int64}} where T","page":"Cost functions","title":"Manopt.costTV","text":"costTV(M, x, p)\n\nCompute the operatornameTV^p functional for a tuple pT of pointss on a Manifold M, i.e.\n\nE(x_1x_2) = d_mathcal M^p(x_1x_2) quad x_1x_2  mathcal M\n\nSee also\n\ngrad_TV, prox_TV\n\n\n\n\n\n","category":"method"},{"location":"functions/costs/#Manopt.costTV2","page":"Cost functions","title":"Manopt.costTV2","text":"costTV2(M,x [,p=1])\n\ncompute the operatornameTV_2^p functional for data x on the PowerManifold manifoldmanifold M, i.e. mathcal M = mathcal N^n, where n  mathbb N^k denotes the dimensions of the data x. Let mathcal I_i^pm denote the forward and backward neighbors, respectively, i.e. with mathcal G as all indices from mathbf1  mathbb N^k to n we have mathcal I^pm_i = ipm e_j j=1kcap mathcal I. The formula then reads\n\nE(x) = sum_i  mathcal I j_1   mathcal I^+_i j_2   mathcal I^-_i\nd^p_mathcal M(c_i(x_j_1x_j_2) x_i)\n\nwhere c_i() denotes the mid point between its two arguments that is nearest to x_i.\n\nSee also\n\ngrad_TV2, prox_TV2\n\n\n\n\n\n","category":"function"},{"location":"functions/costs/#Manopt.costTV2-Union{Tuple{T}, Tuple{MT}, Tuple{MT, Tuple{T, T, T}}, Tuple{MT, Tuple{T, T, T}, Any}} where {MT<:AbstractManifold, T}","page":"Cost functions","title":"Manopt.costTV2","text":"costTV2(M,(x1,x2,x3) [,p=1])\n\nCompute the operatornameTV_2^p functional for the 3-tuple of points (x1,x2,x3)on the Manifold M. Denote by\n\n  mathcal C = bigl c   mathcal M   g(tfrac12x_1x_3) text for some geodesic gbigr\n\nthe set of mid points between x_1 and x_3. Then the function reads\n\nd_2^p(x_1x_2x_3) = min_c  mathcal C d_mathcal M(cx_2)\n\nSee also\n\ngrad_TV2, prox_TV2\n\n\n\n\n\n","category":"method"},{"location":"functions/costs/#Manopt.cost_L2_acceleration_bezier-Union{Tuple{P}, Tuple{AbstractManifold, AbstractVector{P}, AbstractVector{<:Integer}, AbstractVector{<:AbstractFloat}, AbstractFloat, AbstractVector{P}}} where P","page":"Cost functions","title":"Manopt.cost_L2_acceleration_bezier","text":"cost_L2_acceleration_bezier(M,B,pts,Œª,d)\n\ncompute the value of the discrete Acceleration of the composite Bezier curve together with a data term, i.e.\n\nfracŒª2sum_i=0^N d_mathcal M(d_i c_B(i))^2+\nsum_i=1^N-1fracd^2_2  B(t_i-1) B(t_i) B(t_i+1)Delta_t^3\n\nwhere for this formula the pts along the curve are equispaced and denoted by t_i and d_2 refers to the second order absolute difference costTV2 (squared), the junction points are denoted by p_i, and to each p_i corresponds one data item in the manifold points given in d. For details on the acceleration approximation, see cost_acceleration_bezier. Note that the Bezi√©r-curve is given in reduces form as a point on a PowerManifold, together with the degrees of the segments and assuming a differentiable curve, the segments can internally be reconstructed.\n\nSee also\n\ngrad_L2_acceleration_bezier, cost_acceleration_bezier, grad_acceleration_bezier\n\n\n\n\n\n","category":"method"},{"location":"functions/costs/#Manopt.cost_acceleration_bezier-Union{Tuple{P}, Tuple{AbstractManifold, AbstractVector{P}, AbstractVector{<:Integer}, AbstractVector{<:AbstractFloat}}} where P","page":"Cost functions","title":"Manopt.cost_acceleration_bezier","text":"cost_acceleration_bezier(\n    M::AbstractManifold,\n    B::AbstractVector{P},\n    degrees::AbstractVector{<:Integer},\n    T::AbstractVector{<:AbstractFloat},\n) where {P}\n\ncompute the value of the discrete Acceleration of the composite Bezier curve\n\nsum_i=1^N-1fracd^2_2  B(t_i-1) B(t_i) B(t_i+1)Delta_t^3\n\nwhere for this formula the pts along the curve are equispaced and denoted by t_i, i=1N, and d_2 refers to the second order absolute difference costTV2 (squared). Note that the Bezi√©r-curve is given in reduces form as a point on a PowerManifold, together with the degrees of the segments and assuming a differentiable curve, the segments can internally be reconstructed.\n\nThis acceleration discretization was introduced in[BergmannGousenbourger2018].\n\nSee also\n\ngrad_acceleration_bezier, cost_L2_acceleration_bezier, grad_L2_acceleration_bezier\n\n[BergmannGousenbourger2018]: Bergmann, R. and Gousenbourger, P.-Y.: A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve. Frontiers in Applied Mathematics and Statistics (2018). doi 10.3389/fams.2018.00059, arXiv: 1807.10090\n\n\n\n\n\n","category":"method"},{"location":"plans/objective/#ObjectiveSection","page":"Objective","title":"A Manifold Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"CurrentModule = Manopt","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"The Objective describes that actual cost function and all its properties.","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"AbstractManifoldObjective\nAbstractDecoratedManifoldObjective","category":"page"},{"location":"plans/objective/#Manopt.AbstractManifoldObjective","page":"Objective","title":"Manopt.AbstractManifoldObjective","text":"AbstractManifoldObjective{E<:AbstractEvaluationType}\n\nDescribe the collection of the optimization function `f\\colon \\mathcal M ‚Üí \\bbR (or even a vectorial range) and its corresponding elements, which might for example be a gradient or (one or more) prxomial maps.\n\nAll these elements should usually be implemented as functions (M, p) -> ..., or (M, X, p) -> ... that is\n\nthe first argument of these functions should be the manifold M they are defined on\nthe argument X is present, if the computation is performed inplace of X (see InplaceEvaluation)\nthe argument p is the place the function (f or one of its elements) is evaluated at.\n\nthe type T indicates the global AbstractEvaluationType.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AbstractDecoratedManifoldObjective","page":"Objective","title":"Manopt.AbstractDecoratedManifoldObjective","text":"AbstractDecoratedManifoldObjective{E<:AbstractEvaluationType,O<:AbstractManifoldObjective}\n\nA common supertype for all decorators of AbstractManifoldObjectives to simplify dispatch.     The second parameter should refer to the undecorated objective (i.e. the most inner one).\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"Which has two main different possibilities for its containing functions concerning the evaluation mode ‚Äì not necessarily the cost, but for example gradient in an AbstractManifoldGradientObjective.","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"AbstractEvaluationType\nAllocatingEvaluation\nInplaceEvaluation\nevaluation_type","category":"page"},{"location":"plans/objective/#Manopt.AbstractEvaluationType","page":"Objective","title":"Manopt.AbstractEvaluationType","text":"AbstractEvaluationType\n\nAn abstract type to specify the kind of evaluation a AbstractManifoldObjective supports.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.AllocatingEvaluation","page":"Objective","title":"Manopt.AllocatingEvaluation","text":"AllocatingEvaluation <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem indicating that the problem uses functions that allocate memory for their result, i.e. they work out of place.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.InplaceEvaluation","page":"Objective","title":"Manopt.InplaceEvaluation","text":"InplaceEvaluation <: AbstractEvaluationType\n\nA parameter for a AbstractManoptProblem indicating that the problem uses functions that do not allocate memory but work on their input, i.e. in place.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.evaluation_type","page":"Objective","title":"Manopt.evaluation_type","text":"evaluation_type(mp::AbstractManoptProblem)\n\nGet the AbstractEvaluationType of the objective in AbstractManoptProblem mp.\n\n\n\n\n\nevaluation_type(::AbstractManifoldObjective{Teval})\n\nGet the AbstractEvaluationType of the objective.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"It sometimes might be nice to set certain parameters within","category":"page"},{"location":"plans/objective/#Cost-Objective","page":"Objective","title":"Cost Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"AbstractManifoldCostObjective\nManifoldCostObjective","category":"page"},{"location":"plans/objective/#Manopt.AbstractManifoldCostObjective","page":"Objective","title":"Manopt.AbstractManifoldCostObjective","text":"AbstractManifoldCostObjective{T<:AbstractEvaluationType} <: AbstractManifoldObjective{T}\n\nRepresenting objectives on manifolds with a cost function implemented.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldCostObjective","page":"Objective","title":"Manopt.ManifoldCostObjective","text":"ManifoldCostObjective{T, TC} <: AbstractManifoldCostObjective{T, TC}\n\nspeficy an AbstractManifoldObjective that does only have information about the cost function fcolon mathbb M  ‚Ñù implemented as a function (M, p) -> c to compute the cost value c at p on the manifold M.\n\ncost ‚Äì a function f mathcal M  ‚Ñù to minimize\n\nConstructors\n\nManifoldCostObjective(f)\n\nGenerate a problem. While this Problem does not have any allocating functions, the type T can be set for consistency reasons with other problems.\n\nUsed with\n\nNelderMead, particle_swarm\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"get_cost\nget_cost_function","category":"page"},{"location":"plans/objective/#Manopt.get_cost","page":"Objective","title":"Manopt.get_cost","text":"get_cost(amp::AbstractManoptProblem, p)\n\nevaluate the cost function f stored within the AbstractManifoldObjective of an AbstractManoptProblem amp at the point p.\n\n\n\n\n\nget_cost(M::AbstractManifold, obj::AbstractManifoldObjective, p)\n\nevaluate the cost function f defined on M stored within the AbstractManifoldObjective at the point p.\n\n\n\n\n\nget_cost(M::AbstractManifold, mco::AbstractManifoldCostObjective, p)\n\nEvaluate the cost function from within the AbstractManifoldCostObjective on M at p.\n\nBy default this implementation assumed that the cost is stored within mco.cost.\n\n\n\n\n\nget_cost(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, i)\n\nEvaluate the ith summand of the cost.\n\nIf you use a single function for the stochastic cost, then only the index √¨=1` is available to evaluate the whole cost.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_cost_function","page":"Objective","title":"Manopt.get_cost_function","text":"get_cost_function(amco::AbstractManifoldCostObjective)\n\nreturn the function to evaluate (just) the cost f(p)=c as a function (M,p) -> c.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Gradient-Objectives","page":"Objective","title":"Gradient Objectives","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"AbstractManifoldGradientObjective\nManifoldGradientObjective\nManifoldAlternatingGradientObjective\nManifoldStochasticGradientObjective\nNonlinearLeastSquaresObjective","category":"page"},{"location":"plans/objective/#Manopt.AbstractManifoldGradientObjective","page":"Objective","title":"Manopt.AbstractManifoldGradientObjective","text":"AbstractManifoldGradientObjective{E<:AbstractEvaluationType, TC, TG} <: AbstractManifoldCostObjective{E, TC}\n\nAn abstract type for all functions that provide a (full) gradient, where T is a AbstractEvaluationType for the gradient function.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldGradientObjective","page":"Objective","title":"Manopt.ManifoldGradientObjective","text":"ManifoldGradientObjective{T<:AbstractEvaluationType} <: AbstractManifoldGradientObjective{T}\n\nspecify an objetive containing a cost and its gradient\n\nFields\n\ncost       ‚Äì a function fcolonmathcal M  ‚Ñù\ngradient!! ‚Äì the gradient operatornamegradfcolonmathcal M  mathcal Tmathcal M of the cost function f.\n\nDepending on the AbstractEvaluationType T the gradient can have to forms\n\nas a function (M, p) -> X that allocates memory for X, i.e. an AllocatingEvaluation\nas a function (M, X, p) -> X that work in place of X, i.e. an InplaceEvaluation\n\nConstructors\n\nManifoldGradientObjective(cost, gradient; evaluation=AllocatingEvaluation())\n\nUsed with\n\ngradient_descent, conjugate_gradient_descent, quasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldAlternatingGradientObjective","page":"Objective","title":"Manopt.ManifoldAlternatingGradientObjective","text":"ManifoldAlternatingGradientObjective{E<:AbstractEvaluationType,TCost,TGradient} <: AbstractManifoldGradientObjective{E}\n\nAn alternating gradient objective consists of\n\na cost function F(x)\na gradient operatornamegradF that is either\ngiven as one function operatornamegradF returning a tangent vector X on M or\nan array of gradient functions operatornamegradF_i, √¨=1,‚Ä¶,n s each returning a component of the gradient\nwhich might be allocating or mutating variants, but not a mix of both.\n\nnote: Note\nThis Objective is usually defined using the ProductManifold from Manifolds.jl, so Manifolds.jl to be loaded.\n\nConstructors\n\nManifoldAlternatingGradientObjective(F, gradF::Function;\n    evaluation=AllocatingEvaluation()\n)\nManifoldAlternatingGradientObjective(F, gradF::AbstractVector{<:Function};\n    evaluation=AllocatingEvaluation()\n)\n\nCreate a alternating gradient problem with an optional cost and the gradient either as one function (returning an array) or a vector of functions.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.ManifoldStochasticGradientObjective","page":"Objective","title":"Manopt.ManifoldStochasticGradientObjective","text":"ManifoldStochasticGradientObjective{T<:AbstractEvaluationType} <: AbstractManifoldGradientObjective{T}\n\nA stochastic gradient objective consists of\n\na(n optional) cost function ``f(p) = \\displaystyle\\sum{i=1}^n fi(p)\nan array of gradients, operatornamegradf_i(p) i=1ldotsn which can be given in two forms\nas one single function (mathcal M p)  (X_1X_n) in (T_pmathcal M)^n\nas a vector of functions bigl( (mathcal M p)  X_1  (mathcal M p)  X_nbigr).\n\nWhere both variants can also be provided as InplaceEvaluation functions, i.e. (M, X, p) -> X, where X is the vector of X1,...Xn and (M, X1, p) -> X1, ..., (M, Xn, p) -> Xn, respectively.\n\nConstructors\n\nManifoldStochasticGradientObjective(\n    grad_f::Function;\n    cost=Missing(),\n    evaluation=AllocatingEvaluation()\n)\nManifoldStochasticGradientObjective(\n    grad_f::AbstractVector{<:Function};\n    cost=Missing(), evaluation=AllocatingEvaluation()\n)\n\nCreate a Stochastic gradient problem with the gradient either as one function (returning an array of tangent vectors) or a vector of functions (each returning one tangent vector).\n\nThe optional cost can also be given as either a single function (returning a number) pr a vector of functions, each returning a value.\n\nUsed with\n\nstochastic_gradient_descent\n\nNote that this can also be used with a gradient_descent, since the (complete) gradient is just the sums of the single gradients.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.NonlinearLeastSquaresObjective","page":"Objective","title":"Manopt.NonlinearLeastSquaresObjective","text":"NonlinearLeastSquaresObjective{T<:AbstractEvaluationType} <: AbstractManifoldObjective{T}\n\nA type for nonlinear least squares problems. T is a AbstractEvaluationType for the F and Jacobian functions.\n\nSpecify a nonlinear least squares problem\n\nFields\n\nf        ‚Äì a function f mathcal M  ‚Ñù^d to minimize\njacobian!!   ‚Äì Jacobian of the function f\njacobian_tangent_basis     ‚Äì the basis of tangent space used for computing the Jacobian.\nnum_components ‚Äì number of values returned by f (equal to d).\n\nDepending on the AbstractEvaluationType T the function F has to be provided:\n\nas a functions (M::AbstractManifold, p) -> v that allocates memory for v itself for an AllocatingEvaluation,\nas a function (M::AbstractManifold, v, p) -> v that works in place of v for a InplaceEvaluation.\n\nAlso the Jacobian jacF is required:\n\nas a functions (M::AbstractManifold, p; basis_domain::AbstractBasis) -> v that allocates memory for v itself for an AllocatingEvaluation,\nas a function (M::AbstractManifold, v, p; basis_domain::AbstractBasis) -> v that works in place of v for an InplaceEvaluation.\n\nConstructors\n\nNonlinearLeastSquaresProblem(M, F, jacF, num_components; evaluation=AllocatingEvaluation(), jacobian_tangent_basis=DefaultOrthonormalBasis())\n\nSee also\n\nLevenbergMarquardt, LevenbergMarquardtState\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"There is also a second variant, if just one function is responsible for computing the cost and the gradient","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ManifoldCostGradientObjective","category":"page"},{"location":"plans/objective/#Manopt.ManifoldCostGradientObjective","page":"Objective","title":"Manopt.ManifoldCostGradientObjective","text":"ManifoldCostGradientObjective{T} <: AbstractManifoldObjective{T}\n\nspecify an objetive containing one function to perform a combined computation of cost and its gradient\n\nFields\n\ncostgrad!! ‚Äì a function that computes both the cost fcolonmathcal M  ‚Ñù and its gradient operatornamegradfcolonmathcal M  mathcal Tmathcal M\n\nDepending on the AbstractEvaluationType T the gradient can have to forms\n\nas a function (M, p) -> (c, X) that allocates memory for the gradient X, i.e. an AllocatingEvaluation\nas a function (M, X, p) -> (c, X) that work in place of X, i.e. an InplaceEvaluation\n\nConstructors\n\nManifoldCostGradientObjective(costgrad; evaluation=AllocatingEvaluation())\n\nUsed with\n\ngradient_descent, conjugate_gradient_descent, quasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-2","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"get_gradient\nget_gradients\nget_gradient_function","category":"page"},{"location":"plans/objective/#Manopt.get_gradient","page":"Objective","title":"Manopt.get_gradient","text":"get_gradient(s::AbstractManoptSolverState)\n\nreturn the (last stored) gradient within AbstractManoptSolverStates`. By default also undecorates the state beforehand\n\n\n\n\n\nget_gradient(amp::AbstractManoptProblem, p)\nget_gradient!(amp::AbstractManoptProblem, X, p)\n\nevaluate the gradient of an AbstractManoptProblem amp at the point p.\n\nThe evaluation is done in place of X for the !-variant.\n\n\n\n\n\nget_gradient(M::AbstractManifold, mgo::AbstractManifoldGradientObjective{T}, p)\nget_gradient!(M::AbstractManifold, X, mgo::AbstractManifoldGradientObjective{T}, p)\n\nevaluate the gradient of a AbstractManifoldGradientObjective{T} mgo at p.\n\nThe evaluation is done in place of X for the !-variant. The T=AllocatingEvaluation problem might still allocate memory within. When the non-mutating variant is called with a T=InplaceEvaluation memory for the result is allocated.\n\nNote that the order of parameters follows the philisophy of Manifolds.jl, namely that even for the mutating variant, the manifold is the first parameter and the (inplace) tangent vector X comes second.\n\n\n\n\n\nget_gradient(agst::AbstractGradientSolverState)\n\nreturn the gradient stored within gradient options. THe default resturns agst.X.\n\n\n\n\n\nget_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p, k)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, Y, p, k)\n\nEvaluate one of the summands gradients operatornamegradf_k, k1n, at x (in place of Y).\n\nIf you use a single function for the stochastic gradient, that works inplace, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\nget_gradient(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradient!(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, X, p)\n\nEvaluate the complete gradient operatornamegrad f = displaystylesum_i=1^n operatornamegrad f_i(p) at p (in place of X).\n\nIf you use a single function for the stochastic gradient, that works inplace, then get_gradient is not available, since the length (or number of elements of the gradient required for allocation) can not be determined.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_gradients","page":"Objective","title":"Manopt.get_gradients","text":"get_gradients(M::AbstractManifold, sgo::ManifoldStochasticGradientObjective, p)\nget_gradients!(M::AbstractManifold, X, sgo::ManifoldStochasticGradientObjective, p)\n\nEvaluate all summands gradients operatornamegradf_i_i=1^n at p (in place of X).\n\nIf you use a single function for the stochastic gradient, that works inplace, then get_gradient is not available, since the length (or number of elements of the gradient) can not be determined.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_gradient_function","page":"Objective","title":"Manopt.get_gradient_function","text":"get_gradient_function(amgo::AbstractManifoldGradientObjective{E<:AbstractEvaluationType})\n\nreturn the function to evaluate (just) the gradient operatornamegrad f(p). Depending on the AbstractEvaluationType E this is a function\n\n(M, p) -> X for the AllocatingEvaluation case\n(M, X, p) -> X for the InplaceEvaluation, i.e. working inplace of X.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Subgradient-Objective","page":"Objective","title":"Subgradient Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ManifoldSubgradientObjective","category":"page"},{"location":"plans/objective/#Manopt.ManifoldSubgradientObjective","page":"Objective","title":"Manopt.ManifoldSubgradientObjective","text":"ManifoldSubgradientObjective{T<:AbstractEvaluationType,C,S} <:AbstractManifoldCostObjective{T, C}\n\nA structure to store information about a objective for a subgradient based optimization problem\n\nFields\n\ncost ‚Äì the function F to be minimized\nsubgradient ‚Äì a function returning a subgradient partial F of F\n\nConstructor\n\nManifoldSubgradientObjective(f, ‚àÇf)\n\nGenerate the ManifoldSubgradientObjective for a subgradient objective, i.e. a (cost) function f(M, p) and a function ‚àÇf(M, p) that returns a not necessarily deterministic element from the subdifferential at p on a manifold M.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-Functions","page":"Objective","title":"Access Functions","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"get_subgradient","category":"page"},{"location":"plans/objective/#Manopt.get_subgradient","page":"Objective","title":"Manopt.get_subgradient","text":"get_subgradient(amp::AbstractManoptProblem, p)\nget_subgradient!(amp::AbstractManoptProblem, X, p)\n\nevaluate the subgradient of an AbstractManoptProblem amp at point p.\n\nThe evaluation is done in place of X for the !-variant. The result might not be deterministic, one element of the subdifferential is returned.\n\n\n\n\n\nX = get_subgradient(M;;AbstractManifold, sgo::ManifoldSubgradientObjective, p)\nget_subgradient!(M;;AbstractManifold, X, sgo::ManifoldSubgradientObjective, p)\n\nEvaluate the (sub)gradient of a ManifoldSubgradientObjective sgo at the point p.\n\nThe evaluation is done in place of X for the !-variant. The result might not be deterministic, one element of the subdifferential is returned.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Proximal-Map-Objective","page":"Objective","title":"Proximal Map Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ManifoldProximalMapObjective","category":"page"},{"location":"plans/objective/#Manopt.ManifoldProximalMapObjective","page":"Objective","title":"Manopt.ManifoldProximalMapObjective","text":"ManifoldProximalMapObjective{E<:AbstractEvaluationType, TC, TP, V <: Vector{<:Integer}} <: AbstractManifoldCostObjective{E, TC}\n\nspecify a problem for solvers based on the evaluation of proximal map(s).\n\nFields\n\ncost - a function Fmathcal M‚Ñù to minimize\nproxes - proximal maps operatornameprox_Œªvarphimathcal Mmathcal M as functions (M, Œª, p) -> q.\nnumber_of_proxes - (ones(length(proxes))` number of proximal Maps per function, e.g. if one of the maps is a combined one such that the proximal Maps functions return more than one entry per function, you have to adapt this value. if not speciifed, it is set to one prox per function.\n\nSee also\n\ncyclic_proximal_point, get_cost, get_proximal_map\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-Functions-2","page":"Objective","title":"Access Functions","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"get_proximal_map","category":"page"},{"location":"plans/objective/#Manopt.get_proximal_map","page":"Objective","title":"Manopt.get_proximal_map","text":"q = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Œª, p)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Œª, p)\nq = get_proximal_map(M::AbstractManifold, mpo::ManifoldProximalMapObjective, Œª, p, i)\nget_proximal_map!(M::AbstractManifold, q, mpo::ManifoldProximalMapObjective, Œª, p, i)\n\nevaluate the (ith) proximal map of ManifoldProximalMapObjective p at the point p of p.M with parameter Œª0.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Hessian-Objective","page":"Objective","title":"Hessian Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ManifoldHessianObjective","category":"page"},{"location":"plans/objective/#Manopt.ManifoldHessianObjective","page":"Objective","title":"Manopt.ManifoldHessianObjective","text":"ManifoldHessianObjective{T<:AbstractEvaluationType,C,G,H,Pre} <: AbstractManifoldGradientObjective{T}\n\nspecify a problem for hessian based algorithms.\n\nFields\n\ncost : a function Fmathcal M‚Ñù to minimize\ngradient     : the gradient operatornamegradFmathcal M  mathcal Tmathcal M of the cost function F\nhessian      : the hessian operatornameHessF(x) mathcal T_x mathcal M  mathcal T_x mathcal M of the cost function F\npreconditioner       : the symmetric, positive definite preconditioner   as an approximation of the inverse of the Hessian of f, i.e. as a map with the same   input variables as the hessian.\n\nDepending on the AbstractEvaluationType T the gradient and can have to forms\n\nas a function (M, p) -> X  and (M, p, X) -> Y, resp. i.e. an AllocatingEvaluation\nas a function (M, X, p) -> X and (M, Y, p, X), resp., i.e. an InplaceEvaluation\n\nConstructor\n\nManifoldHessianObjective(f, grad_f, Hess_f, preconditioner = (M, p, X) -> X;\n    evaluation=AllocatingEvaluation())\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-3","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"get_hessian\nget_preconditioner","category":"page"},{"location":"plans/objective/#Manopt.get_hessian","page":"Objective","title":"Manopt.get_hessian","text":"Y = get_hessian(amp::AbstractManoptProblem{T}, p, X)\nget_hessian!(amp::AbstractManoptProblem{T}, Y, p, X)\n\nevaluate the Hessian of an AbstractManoptProblem amp at p applied to a tangent vector X, i.e. compute operatornameHessf(q)X, which can also happen in-place of Y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_preconditioner","page":"Objective","title":"Manopt.get_preconditioner","text":"get_preconditioner(amp::AbstractManoptProblem, p, X)\n\nevaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function f) of a AbstractManoptProblem amps objective at the point p applied to a tangent vector X.\n\n\n\n\n\nget_preconditioner(M::AbstractManifold, mho::ManifoldHessianObjective, p, X)\n\nevaluate the symmetric, positive definite preconditioner (approximation of the inverse of the Hessian of the cost function F) of a ManifoldHessianObjective mho at the point p applied to a tangent vector X.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Primal-Dual-based-Objetives","page":"Objective","title":"Primal-Dual based Objetives","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"AbstractPrimalDualManifoldObjective\nPrimalDualManifoldObjective\nPrimalDualManifoldSemismoothNewtonObjective","category":"page"},{"location":"plans/objective/#Manopt.AbstractPrimalDualManifoldObjective","page":"Objective","title":"Manopt.AbstractPrimalDualManifoldObjective","text":"AbstractPrimalDualManifoldObjective{E<:AbstractEvaluationType,C,P} <: AbstractManifoldCostObjective{E,C}\n\nA common abstract super type for objectives that consider primal-dual problems.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.PrimalDualManifoldObjective","page":"Objective","title":"Manopt.PrimalDualManifoldObjective","text":"PrimalDualManifoldObjective{E<:AbstractEvaluationType} <: AbstractPrimalDualManifoldObjective{E}\n\nDescribes an Objective linearized or exact Chambolle-Pock algorithm.[BergmannHerzogSilvaLouzeiroTenbrinckVidalNunez2020][ChambollePock2011]\n\nFields\n\nAll fields with !! can either be mutating or nonmutating functions, which should be set depenting on the parameter T <: AbstractEvaluationType.\n\ncost F + G(Œõ()) to evaluate interims cost function values\nlinearized_forward_operator!! linearized operator for the forward operation in the algorithm DŒõ\nlinearized_adjoint_operator!! The adjoint differential (DŒõ)^*  mathcal N  Tmathcal M\nprox_f!! the proximal map belonging to f\nprox_G_dual!! the proximal map belonging to g_n^*\nŒõ!! ‚Äì (fordward_operator) the  forward operator (if given) Œõ mathcal M  mathcal N\n\nEither the linearized operator DŒõ or Œõ are required usually.\n\nConstructor\n\nPrimalDualManifoldObjective(cost, prox_f, prox_G_dual, adjoint_linearized_operator;\n    linearized_forward_operator::Union{Function,Missing}=missing,\n    Œõ::Union{Function,Missing}=missing,\n    evaluation::AbstractEvaluationType=AllocatingEvaluation()\n)\n\nThe last optional argument can be used to provide the 4 or 5 functions as allocating or mutating (in place computation) ones. Note that the first argument is always the manifold under consideration, the mutated one is the second.\n\n[BergmannHerzogSilvaLouzeiroTenbrinckVidalNunez2020]: R. Bergmann, R. Herzog, M. Silva Louzeiro, D. Tenbrinck, J. Vidal-N√∫√±ez: Fenchel Duality Theory and a Primal-Dual Algorithm on Riemannian Manifolds, Foundations of Computational Mathematics, 2021. doi: 10.1007/s10208-020-09486-5 arXiv: 1908.02022\n\n[ChambollePock2011]: A. Chambolle, T. Pock: A first-order primal-dual algorithm for convex problems with applications to imaging, Journal of Mathematical Imaging and Vision 40(1), 120‚Äì145, 2011. doi: 10.1007/s10851-010-0251-1\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.PrimalDualManifoldSemismoothNewtonObjective","page":"Objective","title":"Manopt.PrimalDualManifoldSemismoothNewtonObjective","text":"PrimalDualManifoldSemismoothNewtonObjective{E<:AbstractEvaluationType, TC, LO, ALO, PF, DPF, PG, DPG, L} <: AbstractPrimalDualManifoldObjective{E, TC, PF}\n\nDescribes a Problem for the Primal-dual Riemannian semismooth Newton algorithm. [DiepeveenLellmann2021]\n\nFields\n\ncost F + G(Œõ()) to evaluate interims cost function values\nlinearized_operator the linearization DŒõ() of the operator Œõ().\nlinearized_adjoint_operator The adjoint differential (DŒõ)^* colon mathcal N to Tmathcal M\nprox_F the proximal map belonging to f\ndiff_prox_F the (Clarke Generalized) differential of the proximal maps of F\nprox_G_dual the proximal map belonging to g_n^*\ndiff_prox_dual_G the (Clarke Generalized) differential of the proximal maps of G^ast_n\nŒõ ‚Äì the exact forward operator. This operator is required if Œõ(m)=n does not hold.\n\nConstructor\n\nPrimalDualManifoldSemismoothNewtonObjective(cost, prox_F, prox_G_dual, forward_operator, adjoint_linearized_operator,Œõ)\n\n[DiepeveenLellmann2021]: W. Diepeveen, J. Lellmann: An Inexact Semismooth Newton Method on Riemannian Manifolds with Application to Duality-Based Total Variation Denoising, SIAM Journal on Imaging Sciences, 2021. doi: 10.1137/21M1398513\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-4","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"adjoint_linearized_operator\nforward_operator\nget_differential_dual_prox\nget_differential_primal_prox\nget_dual_prox\nget_primal_prox\nlinearized_forward_operator","category":"page"},{"location":"plans/objective/#Manopt.adjoint_linearized_operator","page":"Objective","title":"Manopt.adjoint_linearized_operator","text":"X = adjoint_linearized_operator(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y)\nadjoint_linearized_operator(N::AbstractManifold, X, apdmo::AbstractPrimalDualManifoldObjective, m, n, Y)\n\nEvaluate the adjoint of the linearized forward operator of (DŒõ(m))^*Y stored within the AbstractPrimalDualManifoldObjective (in place of X). Since YT_nmathcal N, both m and n=Œõ(m) are necessary arguments, mainly because the forward operator Œõ might be missing in p.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.forward_operator","page":"Objective","title":"Manopt.forward_operator","text":"q = forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, p)\nforward_operator!(M::AbstractManifold, N::AbstractManifold, q, apdmo::AbstractPrimalDualManifoldObjective, p)\n\nEvaluate the forward operator of Œõ(x) stored within the TwoManifoldProblem (in place of q).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential_dual_prox","page":"Objective","title":"Manopt.get_differential_dual_prox","text":"Œ∑ = get_differential_dual_prox(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, n, œÑ, X, Œæ)\nget_differential_dual_prox!(N::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective, Œ∑, n, œÑ, X, Œæ)\n\nEvaluate the differential proximal map of G_n^* stored within PrimalDualManifoldSemismoothNewtonObjective\n\nDoperatornameprox_œÑG_n^*(X)Œæ\n\nwhich can also be computed in place of Œ∑.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_differential_primal_prox","page":"Objective","title":"Manopt.get_differential_primal_prox","text":"y = get_differential_primal_prox(M::AbstractManifold, pdsno::PrimalDualManifoldSemismoothNewtonObjective œÉ, x)\nget_differential_primal_prox!(p::TwoManifoldProblem, y, œÉ, x)\n\nEvaluate the differential proximal map of F stored within AbstractPrimalDualManifoldObjective\n\nDoperatornameprox_œÉF(x)X\n\nwhich can also be computed in place of y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_dual_prox","page":"Objective","title":"Manopt.get_dual_prox","text":"Y = get_dual_prox(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, n, œÑ, X)\nget_dual_prox!(N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, Y, n, œÑ, X)\n\nEvaluate the proximal map of g_n^* stored within AbstractPrimalDualManifoldObjective\n\n  Y = operatornameprox_œÑG_n^*(X)\n\nwhich can also be computed in place of Y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_primal_prox","page":"Objective","title":"Manopt.get_primal_prox","text":"q = get_primal_prox(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, œÉ, p)\nget_primal_prox!(M::AbstractManifold, p::AbstractPrimalDualManifoldObjective, q, œÉ, p)\n\nEvaluate the proximal map of F stored within AbstractPrimalDualManifoldObjective\n\noperatornameprox_œÉF(x)\n\nwhich can also be computed in place of y.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.linearized_forward_operator","page":"Objective","title":"Manopt.linearized_forward_operator","text":"Y = linearized_forward_operator(M::AbstractManifold, N::AbstractManifold, apdmo::AbstractPrimalDualManifoldObjective, m, X, n)\nlinearized_forward_operator!(M::AbstractManifold, N::AbstractManifold, Y, apdmo::AbstractPrimalDualManifoldObjective, m, X, n)\n\nEvaluate the linearized operator (differential) DŒõ(m)X stored within the AbstractPrimalDualManifoldObjective (in place of Y), where n = Œõ(m).\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Constrained-Objective","page":"Objective","title":"Constrained Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"Besides the AbstractEvaluationType there is one further property to distinguish among constraint functions, especially the gradients of the constraints.","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ConstraintType\nFunctionConstraint\nVectorConstraint","category":"page"},{"location":"plans/objective/#Manopt.ConstraintType","page":"Objective","title":"Manopt.ConstraintType","text":"ConstraintType\n\nAn abstract type to represent different forms of representing constraints\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.FunctionConstraint","page":"Objective","title":"Manopt.FunctionConstraint","text":"FunctionConstraint <: ConstraintType\n\nA type to indicate that constraints are implemented one whole functions, e.g. g(p)  mathbb R^m.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.VectorConstraint","page":"Objective","title":"Manopt.VectorConstraint","text":"VectorConstraint <: ConstraintType\n\nA type to indicate that constraints are implemented a  vector of functions, e.g. g_i(p)  mathbb R i=1m.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"The ConstraintType is a parameter of the corresponding Objective.","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ConstrainedManifoldObjective","category":"page"},{"location":"plans/objective/#Manopt.ConstrainedManifoldObjective","page":"Objective","title":"Manopt.ConstrainedManifoldObjective","text":"ConstrainedManifoldObjective{T<:AbstractEvaluationType, C <: ConstraintType Manifold} <: AbstractManifoldObjective{T}\n\nDescribes the constrained objective\n\nbeginaligned\n operatorname*argmin_p mathcalM  f(p)\n textsubject to  g_i(p)leq0 quad text for all  i=1m\n quad h_j(p)=0 quad text for all  j=1n\nendaligned\n\nIt consists of\n\nan cost function f(p)\nthe gradient of f, operatornamegradf(p) AbstractManifoldGradientObjective\ninequality constraints g(p), either a function g returning a vector or a vector [g1, g2,...,gm] of functions.\nequality constraints h(p), either a function h returning a vector or a vector [h1, h2,...,hn] of functions.\ngradient(s) of the inequality constraints operatornamegradg(p)  (T_pmathcal M)^m, either a function or a vector of functions.\ngradient(s) of the equality constraints operatornamegradh(p)  (T_pmathcal M)^n, either a function or a vector of functions.\n\nThere are two ways to specify the constraints g and h.\n\nas one Function returning a vector in mathbb R^m and mathbb R^n respecively. This might be easier to implement but requires evaluating all constraints even if only one is needed.\nas a AbstractVector{<:Function} where each function returns a real number. This requires each constrant to be implemented as a single function, but it is possible to evaluate also only a single constraint.\n\nThe gradients operatornamegradg, operatornamegradh have to follow the same form. Additionally they can be implemented as in-place functions or as allocating ones. The gradient operatornamegradF has to be the same kind. This difference is indicated by the evaluation keyword.\n\nConstructors\n\nConstrainedManifoldObjective(f, grad_f, g, grad_g, h, grad_h;\n    evaluation=AllocatingEvaluation()\n)\n\nWhere f, g, h describe the cost, inequality and equality constraints, respecitvely, as described above and grad_f, grad_g, grad_h are the corresponding gradient functions in one of the 4 formats. If the objective does not have inequality constraints, you can set G and gradG no nothing. If the problem does not have equality constraints, you can set H and gradH no nothing or leave them out.\n\nConstrainedManifoldObjective(M::AbstractManifold, F, gradF;\n    G=nothing, gradG=nothing, H=nothing, gradH=nothing;\n    evaluation=AllocatingEvaluation()\n)\n\nA keyword argument variant of the constructor above, where you can leave out either G and gradG or H and gradH but not both.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Access-functions-5","page":"Objective","title":"Access functions","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"get_constraints\nget_equality_constraint\nget_equality_constraints\nget_inequality_constraint\nget_inequality_constraints\nget_grad_equality_constraint\nget_grad_equality_constraints\nget_grad_equality_constraints!\nget_grad_equality_constraint!\nget_grad_inequality_constraint\nget_grad_inequality_constraint!\nget_grad_inequality_constraints\nget_grad_inequality_constraints!","category":"page"},{"location":"plans/objective/#Manopt.get_constraints","page":"Objective","title":"Manopt.get_constraints","text":"get_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p)\n\nReturn the vector (g_1(p)g_m(p)h_1(p)h_n(p)) from the ConstrainedManifoldObjective P containing the values of all constraints at p.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_equality_constraint","page":"Objective","title":"Manopt.get_equality_constraint","text":"get_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j)\n\nevaluate the jth equality constraint (h(p))_j or h_j(p).\n\nnote: Note\nFor the FunctionConstraint representation this still evaluates all constraints.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_equality_constraints","page":"Objective","title":"Manopt.get_equality_constraints","text":"get_equality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p)\n\nevaluate all equality constraints h(p) of bigl(h_1(p) h_2(p)ldotsh_p(p)bigr) of the ConstrainedManifoldObjective P at p.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_inequality_constraint","page":"Objective","title":"Manopt.get_inequality_constraint","text":"get_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, i)\n\nevaluate one equality constraint (g(p))_i or g_i(p).\n\nnote: Note\nFor the FunctionConstraint representation this still evaluates all constraints.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_inequality_constraints","page":"Objective","title":"Manopt.get_inequality_constraints","text":"get_inequality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p)\n\nEvaluate all inequality constraints g(p) or bigl(g_1(p) g_2(p)ldotsg_m(p)bigr) of the ConstrainedManifoldObjective P at p.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_equality_constraint","page":"Objective","title":"Manopt.get_grad_equality_constraint","text":"get_grad_equality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, j)\n\nevaluate the gradient of the j th equality constraint (operatornamegrad h(p))_j or operatornamegrad h_j(x).\n\nnote: Note\nFor the FunctionConstraint variant of the problem, this function still evaluates the full gradient. For the InplaceEvaluation and FunctionConstraint of the problem, this function currently also calls get_equality_constraints, since this is the only way to determine the number of cconstraints. It also allocates a full tangent vector.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_equality_constraints","page":"Objective","title":"Manopt.get_grad_equality_constraints","text":"get_grad_equality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p)\n\neevaluate all gradients of the equality constraints operatornamegrad h(x) or bigl(operatornamegrad h_1(x) operatornamegrad h_2(x)ldots operatornamegradh_n(x)bigr) of the ConstrainedManifoldObjective P at p.\n\nnote: Note\n\n\nfor the InplaceEvaluation and FunctionConstraint variant of the problem,    this function currently also calls get_equality_constraints,    since this is the only way to determine the number of cconstraints.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_equality_constraints!","page":"Objective","title":"Manopt.get_grad_equality_constraints!","text":"get_grad_equality_constraints!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p)\n\nevaluate all gradients of the equality constraints operatornamegrad h(p) or bigl(operatornamegrad h_1(p) operatornamegrad h_2(p)ldotsoperatornamegrad h_n(p)bigr) of the ConstrainedManifoldObjective P at p in place of X, which is a vector ofn` tangent vectors.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_equality_constraint!","page":"Objective","title":"Manopt.get_grad_equality_constraint!","text":"get_grad_equality_constraint!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p, j)\n\nEvaluate the gradient of the jth equality constraint (operatornamegrad h(x))_j or operatornamegrad h_j(x) in place of X\n\nnote: Note\nFor the FunctionConstraint variant of the problem, this function still evaluates the full gradient. For the InplaceEvaluation of the FunctionConstraint of the problem, this function currently also calls get_inequality_constraints, since this is the only way to determine the number of cconstraints and allocates a full vector of tangent vectors\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_inequality_constraint","page":"Objective","title":"Manopt.get_grad_inequality_constraint","text":"get_grad_inequality_constraint(M::AbstractManifold, co::ConstrainedManifoldObjective, p, i)\n\nEvaluate the gradient of the i th inequality constraints (operatornamegrad g(x))_i or operatornamegrad g_i(x).\n\nnote: Note\nFor the FunctionConstraint variant of the problem, this function still evaluates the full gradient. For the InplaceEvaluation and FunctionConstraint of the problem, this function currently also calls get_inequality_constraints, since this is the only way to determine the number of cconstraints.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_inequality_constraint!","page":"Objective","title":"Manopt.get_grad_inequality_constraint!","text":"get_grad_inequality_constraint!(P, X, p, i)\n\nEvaluate the gradient of the ith inequality constraints (operatornamegrad g(x))_i or operatornamegrad g_i(x) of the ConstrainedManifoldObjective P in place of X\n\nnote: Note\nFor the FunctionConstraint variant of the problem, this function still evaluates the full gradient. For the InplaceEvaluation and FunctionConstraint of the problem, this function currently also calls get_inequality_constraints,\n\nsince this is the only way to determine the number of cconstraints. evaluate all gradients of the inequality constraints operatornamegrad h(x) or bigl(g_1(x) g_2(x)ldotsg_m(x)bigr) of the ConstrainedManifoldObjective p at x in place of X, which is a vector ofm` tangent vectors .\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_inequality_constraints","page":"Objective","title":"Manopt.get_grad_inequality_constraints","text":"get_grad_inequality_constraints(M::AbstractManifold, co::ConstrainedManifoldObjective, p)\n\nevaluate all gradients of the inequality constraints operatornamegrad g(p) or bigl(operatornamegrad g_1(p) operatornamegrad g_2(p)operatornamegrad g_m(p)bigr) of the ConstrainedManifoldObjective P at p.\n\nnote: Note\n\n\nfor the InplaceEvaluation and FunctionConstraint variant of the problem,    this function currently also calls get_equality_constraints,    since this is the only way to determine the number of cconstraints.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.get_grad_inequality_constraints!","page":"Objective","title":"Manopt.get_grad_inequality_constraints!","text":"get_grad_inequality_constraints!(M::AbstractManifold, X, co::ConstrainedManifoldObjective, p)\n\nevaluate all gradients of the inequality constraints operatornamegrad g(x) or bigl(operatornamegrad g_1(x) operatornamegrad g_2(x)ldotsoperatornamegrad g_m(x)bigr) of the ConstrainedManifoldObjective P at p in place of X, which is a vector of m tangent vectors.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Decorators-for-AbstractManoptSolverState","page":"Objective","title":"Decorators for AbstractManoptSolverState","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"An objective can be decorated using the following trait and function to initialize","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"dispatch_objective_decorator\nis_objective_decorator\ndecorate_objective!","category":"page"},{"location":"plans/objective/#Manopt.dispatch_objective_decorator","page":"Objective","title":"Manopt.dispatch_objective_decorator","text":"dispatch_objective_decorator(o::AbstractManoptSolverState)\n\nIndicate internally, whether an AbstractManifoldObjective o to be of decorating type, i.e. it stores (encapsulates) an object in itself, by default in the field o.objective.\n\nDecorators indicate this by returning Val{true} for further dispatch.\n\nThe default is Val{false}, i.e. by default an state is not decorated.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.is_objective_decorator","page":"Objective","title":"Manopt.is_objective_decorator","text":"is_object_decorator(s::AbstractManifoldObjective)\n\nIndicate, whether AbstractManifoldObjective s are of decorator type.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.decorate_objective!","page":"Objective","title":"Manopt.decorate_objective!","text":"decorate_objective!(M, o::AbstractManifoldObjective)\n\ndecorate the AbstractManifoldObjectiveo with specific decorators.\n\nOptional Arguments\n\noptional arguments provide necessary details on the decorators. A specific one is used to activate certain decorators.\n\ncache ‚Äì (missing) specify a cache. Currenlty :Simple is supported and :LRU if you load LRUCache.jl. For this case a tuple specifying what to cache and how many can be provided, i.e. (:LRU, [:Cost, :Gradient], 10), where the number specifies the size of each cache. and 10 is the default if one omits the last tuple entry\ncount ‚Äì (missing) specify calls to the objective to be called, see ManifoldCountObjective for the full list\n\nother keywords are ignored.\n\nSee also\n\nobjective_cache_factory\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#CacheSection","page":"Objective","title":"Cache Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"Since single function calls, e.g. to the cost or the gradient, might be expensive, a simple cache objective exists as a decorator, that caches one cost value or gradient.","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"It can be activated/used with the cache= keyword argument available for every solver.","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"Manopt.reset_counters!\nManopt.objective_cache_factory","category":"page"},{"location":"plans/objective/#Manopt.reset_counters!","page":"Objective","title":"Manopt.reset_counters!","text":"reset_counters(co::ManifoldCountObjective, value::Integer=0)\n\nReset all values in the count objective to value.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#Manopt.objective_cache_factory","page":"Objective","title":"Manopt.objective_cache_factory","text":"objective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Symbol)\n\nGenerate a cached variant of the AbstractManifoldObjective o on the AbstractManifold M based on the symbol cache.\n\nThe following caches are available\n\n:Simple generates a SimpleManifoldCachedObjective\n:LRU generates a ManifoldCachedObjective where you should use the form (:LRU, [:Cost, :Gradient]) to specify what should be cached or (:LRU, [:Cost, :Gradient], 100) to specify the cache size. Here this variant defaults to (:LRU, [:Cost, :Gradient], 100), i.e. to cache up to 100 cost and gradient values.[1]\n\n[1]: This cache requires LRUCache.jl to be loaded as well.\n\n\n\n\n\nobjective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array, Array})\nobjective_cache_factory(M::AbstractManifold, o::AbstractManifoldObjective, cache::Tuple{Symbol, Array})\n\nGenerate a cached variant of the AbstractManifoldObjective o on the AbstractManifold M based on the symbol cache[1], where the second element cache[2] are further arguments to the cache and the optional third is passed down as keyword arguments.\n\nFor all available caches see the simpler variant with symbols.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#A-simple-cache","page":"Objective","title":"A simple cache","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"A first generic cache is always available, but it only caches one gradient and one cost function evaluation (for the same point).","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"SimpleManifoldCachedObjective","category":"page"},{"location":"plans/objective/#Manopt.SimpleManifoldCachedObjective","page":"Objective","title":"Manopt.SimpleManifoldCachedObjective","text":" SimpleManifoldCachedObjective{O<:AbstractManifoldGradientObjective{E,TC,TG}, P, T,C} <: AbstractManifoldGradientObjective{E,TC,TG}\n\nProvide a simple cache for an AbstractManifoldGradientObjective that is for a given point p this cache stores a point p and a gradient operatornamegrad f(p) in X as well as a cost value f(p) in c.\n\nBoth X and c are accompanied by booleans to keep track of their validity.\n\nConstructor\n\nSimpleManifoldCachedObjective(M::AbstractManifold, obj::AbstractManifoldGradientObjective; kwargs...)\n\nKeyword\n\np (rand(M)) ‚Äì a point on the manifold to initialize the cache with\nX (get_gradient(M, obj, p) or zero_vector(M,p)) ‚Äì a tangent vector to store the gradient in, see also initialize\nc (get_cost(M, obj, p) or 0.0) ‚Äì a value to store the cost function in initialize\ninitialized (true) ‚Äì whether to initialize the cached X and c or not.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#A-Generic-Cache","page":"Objective","title":"A Generic Cache","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"For the more advanced cache, you need to implement some type of cache yourself, that provides a get! and implement init_caches. This is for example provided if you load LRUCache.jl. Then you obtain","category":"page"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ManifoldCachedObjective\ninit_caches","category":"page"},{"location":"plans/objective/#Manopt.ManifoldCachedObjective","page":"Objective","title":"Manopt.ManifoldCachedObjective","text":"ManifoldCachedObjective{E,P,O<:AbstractManifoldObjective{<:E},C<:NamedTuple{}} <: AbstractDecoratedManifoldObjective{E,P}\n\nCreate a cache for an objective, based on a NamedTuple that stores some kind of cache.\n\nConstructor\n\nManifoldCachedObjective(M, o::AbstractManifoldObjective, caches::Vector{Symbol}; kwargs...)\n\nCreate a cache for the AbstractManifoldObjective where the Symbols in caches indicate, which function evaluations to cache.\n\nSupported Symbols\n\nSymbol Caches calls to (incl. ! variants) Comment\n:Constraints get_constraints vector of numbers\n:Cost get_cost \n:EqualityConstraint get_equality_constraint numbers per (p,i)\n:EqualityConstraints get_equality_constraints vector of numbers\n:GradEqualityConstraint get_grad_equality_constraint tangent vector per (p,i)\n:GradEqualityConstraints get_grad_equality_constraints vector of tangent vectors\n:GradInequalityConstraint get_inequality_constraint tangent vector per (p,i)\n:GradInequalityConstraints get_inequality_constraints vector of tangent vectors\n:Gradient get_gradient(M,p) tangent vectors\n:Hessian get_hessian tangent vectors\n:InequalityConstraint get_inequality_constraint numbers per (p,j)\n:InequalityConstraints get_inequality_constraints vector of numbers\n:Preconditioner get_preconditioner tangent vectors\n:ProximalMap get_proximal_map point per (p,Œª,i)\n:StochasticGradients get_gradients vector of tangent vectors\n:StochasticGradient get_gradient(M, p, i) tangent vector per (p,i)\n:SubGradient get_subgradient tangent vectors\n:SubtrahendGradient get_subtrahend_gradient tangent vectors\n\nKeyword Arguments\n\np           - (rand(M)) the type of the keys to be used in the caches. Defaults to the default representation on M.\nvalue       - (get_cost(M, objective, p)) the type of values for numeric values in the cache, e.g. the cost\nX           - (zero_vector(M,p)) the type of values to be cached for gradient and Hessian calls.\ncache       - ([:Cost]) a vector of symbols indicating which function calls should be cached.\ncache_size  - (10) number of (least recently used) calls to cache\ncache_sizes ‚Äì (Dict{Symbol,Int}()) a named tuple or dictionary specifying the sizes individually for each cache.\n\n\n\n\n\n","category":"type"},{"location":"plans/objective/#Manopt.init_caches","page":"Objective","title":"Manopt.init_caches","text":"init_caches(M::AbstractManifold, caches, T; kwargs...)\n\nGiven a vector of symbols caches, this function sets up the NamedTuple of caches for points/vectors on M, where T is the type of cache to use.\n\n\n\n\n\n","category":"function"},{"location":"plans/objective/#ManifoldCountObjective","page":"Objective","title":"Count Objective","text":"","category":"section"},{"location":"plans/objective/","page":"Objective","title":"Objective","text":"ManifoldCountObjective","category":"page"},{"location":"plans/objective/#Manopt.ManifoldCountObjective","page":"Objective","title":"Manopt.ManifoldCountObjective","text":"ManifoldCountObjective{E,P,O<:AbstractManifoldObjective,I<:Integer} <: AbstractDecoratedManifoldObjective{E,P}\n\nA wrapper for any AbstractManifoldObjective of type O to count different calls to parts of the objective.\n\nFields\n\ncounts a dictionary of symbols mapping to integers keeping the counted values\nobjective the wrapped objective\n\nSupported Symbols\n\nSymbol Counts calls to (incl. ! variants) Comment\n:Constraints get_constraints \n:Cost get_cost \n:EqualityConstraint get_equality_constraint requires vector of counters\n:EqualityConstraints get_equality_constraints does not count single access\n:GradEqualityConstraint get_grad_equality_constraint requires vector of counters\n:GradEqualityConstraints get_grad_equality_constraints does not count single access\n:GradInequalityConstraint get_inequality_constraint requires vector of counters\n:GradInequalityConstraints get_inequality_constraints does not count single access\n:Gradient get_gradient(M,p) \n:Hessian get_hessian \n:InequalityConstraint get_inequality_constraint requires vector of counters\n:InequalityConstraints get_inequality_constraints does not count single access\n:Preconditioner get_preconditioner \n:ProximalMap get_proximal_map \n:StochasticGradients get_gradients \n:StochasticGradient get_gradient(M, p, i) \n:SubGradient get_subgradient \n:SubtrahendGradient get_subtrahend_gradient \n\nConstructors\n\nManifoldCountObjective(objective::AbstractManifoldObjective, counts::Dict{Symbol, <:Integer})\n\nInitialise the ManifoldCountObjective to wrap objective initializing the set of counts\n\nManifoldCountObjective(M::AbtractManifold, objective::AbstractManifoldObjective, count::AbstractVecor{Symbol}, init=0)\n\nCount function calls on objective using the symbols in count initialising all entries to init.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#StoppingCriteria","page":"Stopping Criteria","title":"Stopping Criteria","text":"","category":"section"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Stopping criteria are implemented as a functor, i.e. inherit from the base type","category":"page"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"StoppingCriterion","category":"page"},{"location":"plans/stopping_criteria/#Manopt.StoppingCriterion","page":"Stopping Criteria","title":"Manopt.StoppingCriterion","text":"StoppingCriterion\n\nAn abstract type for the functors representing stopping criteria, i.e. they are callable structures. The naming Scheme follows functions, see for example StopAfterIteration.\n\nEvery StoppingCriterion has to provide a constructor and its function has to have the interface (p,o,i) where a AbstractManoptProblem as well as AbstractManoptSolverState and the current number of iterations are the arguments and returns a Bool whether to stop or not.\n\nBy default each StoppingCriterion should provide a fields reason to provide details when a criterion is met (and that is empty otherwise).\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"They can also be grouped, which is summarized in the type of a set of criteria","category":"page"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"StoppingCriterionSet","category":"page"},{"location":"plans/stopping_criteria/#Manopt.StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.StoppingCriterionSet","text":"StoppingCriterionGroup <: StoppingCriterion\n\nAn abstract type for a Stopping Criterion that itself consists of a set of Stopping criteria. In total it acts as a stopping criterion itself. Examples are StopWhenAny and StopWhenAll that can be used to combine stopping criteria.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Then the stopping criteria s might have certain internal values to check against, and this is done when calling them as a function s(amp::AbstractManoptProblem, ams::AbstractManoptSolverState), where the AbstractManoptProblem and the AbstractManoptSolverState together represent the current state of the solver. The functor returns either false when the stopping criterion is not fulfilled or true otherwise. One field all criteria should have is the s.reason, a string giving the reason to stop, see get_reason.","category":"page"},{"location":"plans/stopping_criteria/#Stopping-Criteria","page":"Stopping Criteria","title":"Stopping Criteria","text":"","category":"section"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"The following generic stopping criteria are available. Some require that, for example, the corresponding AbstractManoptSolverState have a field gradient when the criterion should check that.","category":"page"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Further stopping criteria might be available for individual solvers.","category":"page"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Modules = [Manopt]\nPages = [\"plans/stopping_criterion.jl\"]\nOrder = [:type]\nFilter = t -> t != StoppingCriterion && t != StoppingCriterionSet","category":"page"},{"location":"plans/stopping_criteria/#Manopt.StopAfter","page":"Stopping Criteria","title":"Manopt.StopAfter","text":"StopAfter <: StoppingCriterion\n\nstore a threshold when to stop looking at the complete runtime. It uses time_ns() to measure the time and you provide a Period as a time limit, i.e. Minute(15)\n\nConstructor\n\nStopAfter(t)\n\ninitialize the stopping criterion to a Period t to stop after.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopAfterIteration","page":"Stopping Criteria","title":"Manopt.StopAfterIteration","text":"StopAfterIteration <: StoppingCriterion\n\nA functor for an easy stopping criterion, i.e. to stop after a maximal number of iterations.\n\nFields\n\nmaxIter ‚Äì stores the maximal iteration number where to stop at\nreason ‚Äì stores a reason of stopping if the stopping criterion has one be reached, see get_reason.\n\nConstructor\n\nStopAfterIteration(maxIter)\n\ninitialize the stopafterIteration functor to indicate to stop after maxIter iterations.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenAll","page":"Stopping Criteria","title":"Manopt.StopWhenAll","text":"StopWhenAll <: StoppingCriterion\n\nstore an array of StoppingCriterion elements and indicates to stop, when all indicate to stop. The reason is given by the concatenation of all reasons.\n\nConstructor\n\nStopWhenAll(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAll(c::StoppingCriterion,...)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenAny","page":"Stopping Criteria","title":"Manopt.StopWhenAny","text":"StopWhenAny <: StoppingCriterion\n\nstore an array of StoppingCriterion elements and indicates to stop, when any single one indicates to stop. The reason is given by the concatenation of all reasons (assuming that all non-indicating return \"\").\n\nConstructor\n\nStopWhenAny(c::NTuple{N,StoppingCriterion} where N)\nStopWhenAny(c::StoppingCriterion...)\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenChangeLess","text":"StopWhenChangeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the norm of the change of the optimization variable from within a AbstractManoptSolverState, i.e get_iterate(o). For the storage a StoreStateAction is used\n\nConstructor\n\nStopWhenChangeLess(\n    M::AbstractManifold,\n    Œµ::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    inverse_retraction_method::IRT=default_inverse_retraction_method(manifold)\n)\n\ninitialize the stopping criterion to a threshold Œµ using the StoreStateAction a, which is initialized to just store :Iterate by default. You can also provide an inverseretractionmethod for the distance or a manifol to use its default inverse retraction.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenCostLess","page":"Stopping Criteria","title":"Manopt.StopWhenCostLess","text":"StopWhenCostLess <: StoppingCriterion\n\nstore a threshold when to stop looking at the cost function of the optimization problem from within a AbstractManoptProblem, i.e get_cost(p,get_iterate(o)).\n\nConstructor\n\nStopWhenCostLess(Œµ)\n\ninitialize the stopping criterion to a threshold Œµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenGradientChangeLess","page":"Stopping Criteria","title":"Manopt.StopWhenGradientChangeLess","text":"StopWhenGradientChangeLess <: StoppingCriterion\n\nA stopping criterion based on the change of the gradient\n\n\\lVert \\mathcal T_{p^{(k)}\\gets p^{(k-1)} \\operatorname{grad} f(p^{(k-1)}) -  \\operatorname{grad} f(p^{(k-1)}) \\rVert < Œµ\n\nConstructor\n\nStopWhenGradientChangeLess(\n    M::AbstractManifold,\n    Œµ::Float64;\n    storage::StoreStateAction=StoreStateAction([:Iterate]),\n    vector_transport_method::IRT=default_vector_transport_method(M),\n)\n\nCreate a stopping criterion with threshold Œµ for the change gradient, that is, this criterion indicates to stop when get_gradient is in (norm of) its change less than Œµ, where vector_transport_method denotes the vector transport mathcal T used.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenGradientNormLess","page":"Stopping Criteria","title":"Manopt.StopWhenGradientNormLess","text":"StopWhenGradientNormLess <: StoppingCriterion\n\nA stopping criterion based on the current gradient norm.\n\nConstructor\n\nStopWhenGradientNormLess(Œµ::Float64)\n\nCreate a stopping criterion with threshold Œµ for the gradient, that is, this criterion indicates to stop when get_gradient returns a gradient vector of norm less than Œµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenSmallerOrEqual","page":"Stopping Criteria","title":"Manopt.StopWhenSmallerOrEqual","text":"StopWhenSmallerOrEqual <: StoppingCriterion\n\nA functor for an stopping criterion, where the algorithm if stopped when a variable is smaller than or equal to its minimum value.\n\nFields\n\nvalue ‚Äì stores the variable which has to fall under a threshold for the algorithm to stop\nminValue ‚Äì stores the threshold where, if the value is smaller or equal to this threshold, the algorithm stops\nreason ‚Äì stores a reason of stopping if the stopping criterion has one be reached, see get_reason.\n\nConstructor\n\nStopWhenSmallerOrEqual(value, minValue)\n\ninitialize the stopifsmallerorequal functor to indicate to stop after value is smaller than or equal to minValue.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Manopt.StopWhenStepsizeLess","page":"Stopping Criteria","title":"Manopt.StopWhenStepsizeLess","text":"StopWhenStepsizeLess <: StoppingCriterion\n\nstores a threshold when to stop looking at the last step size determined or found during the last iteration from within a AbstractManoptSolverState.\n\nConstructor\n\nStopWhenStepsizeLess(Œµ)\n\ninitialize the stopping criterion to a threshold Œµ.\n\n\n\n\n\n","category":"type"},{"location":"plans/stopping_criteria/#Functions-for-Stopping-Criteria","page":"Stopping Criteria","title":"Functions for Stopping Criteria","text":"","category":"section"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"There are a few functions to update, combine and modify stopping criteria, especially to update internal values even for stopping criteria already being used within an AbstractManoptSolverState structure.","category":"page"},{"location":"plans/stopping_criteria/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Modules = [Manopt]\nPages = [\"plans/stopping_criterion.jl\"]\nOrder = [:function]","category":"page"},{"location":"plans/stopping_criteria/#Base.:&-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","page":"Stopping Criteria","title":"Base.:&","text":"&(s1,s2)\ns1 & s2\n\nCombine two StoppingCriterion within an StopWhenAll. If either s1 (or s2) is already an StopWhenAll, then s2 (or s1) is appended to the list of StoppingCriterion within s1 (or s2).\n\nExample\n\na = StopAfterIteration(200) & StopWhenChangeLess(1e-6)\nb = a & StopWhenGradientNormLess(1e-6)\n\nIs the same as\n\na = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(1e-6))\nb = StopWhenAll(StopAfterIteration(200), StopWhenChangeLess(1e-6), StopWhenGradientNormLess(1e-6))\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Base.:|-Union{Tuple{T}, Tuple{S}, Tuple{S, T}} where {S<:StoppingCriterion, T<:StoppingCriterion}","page":"Stopping Criteria","title":"Base.:|","text":"|(s1,s2)\ns1 | s2\n\nCombine two StoppingCriterion within an StopWhenAny. If either s1 (or s2) is already an StopWhenAny, then s2 (or s1) is appended to the list of StoppingCriterion within s1 (or s2)\n\nExample\n\na = StopAfterIteration(200) | StopWhenChangeLess(1e-6)\nb = a | StopWhenGradientNormLess(1e-6)\n\nIs the same as\n\na = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(1e-6))\nb = StopWhenAny(StopAfterIteration(200), StopWhenChangeLess(1e-6), StopWhenGradientNormLess(1e-6))\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_active_stopping_criteria-Tuple{sCS} where sCS<:StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.get_active_stopping_criteria","text":"get_active_stopping_criteria(c)\n\nreturns all active stopping criteria, if any, that are within a StoppingCriterion c, and indicated a stop, i.e. their reason is nonempty. To be precise for a simple stopping criterion, this returns either an empty array if no stop is indicated or the stopping criterion as the only element of an array. For a StoppingCriterionSet all internal (even nested) criteria that indicate to stop are returned.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_reason-Tuple{AbstractManoptSolverState}","page":"Stopping Criteria","title":"Manopt.get_reason","text":"get_reason(o)\n\nreturn the current reason stored within the StoppingCriterion from within the AbstractManoptSolverState This reason is empty if the criterion has never been met.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_reason-Tuple{sC} where sC<:StoppingCriterion","page":"Stopping Criteria","title":"Manopt.get_reason","text":"get_reason(c)\n\nreturn the current reason stored within a StoppingCriterion c. This reason is empty if the criterion has never been met.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.get_stopping_criteria-Tuple{S} where S<:StoppingCriterionSet","page":"Stopping Criteria","title":"Manopt.get_stopping_criteria","text":"get_stopping_criteria(c)\n\nreturn the array of internally stored StoppingCriterions for a StoppingCriterionSet c.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{Any, Any, Any}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::Stoppingcriterion, s::Symbol, v::value)\nupdate_stopping_criterion!(s::AbstractManoptSolverState, symbol::Symbol, v::value)\nupdate_stopping_criterion!(c::Stoppingcriterion, ::Val{Symbol}, v::value)\n\nUpdate a value within a stopping criterion, specified by the symbol s, to v. If a criterion does not have a value assigned that corresponds to s, the update is ignored.\n\nFor the second signature, the stopping criterion within the AbstractManoptSolverState o is updated.\n\nTo see which symbol updates which value, see the specific stopping criteria. They should use dispatch per symbol value (the third signature).\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopAfter, Val{:MaxTime}, Dates.Period}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopAfter, :MaxTime, v::Period)\n\nUpdate the time period after which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopAfterIteration, Val{:MaxIteration}, Int64}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopAfterIteration, :;MaxIteration, v::Int)\n\nUpdate the number of iterations after which the algorithm should stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenChangeLess, Val{:MinIterateChange}, Any}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopWhenChangeLess, :MinIterateChange, v::Int)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenCostLess, Val{:MinCost}, Any}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopWhenCostLess, :MinCost, v)\n\nUpdate the minimal cost below which the slgorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenGradientChangeLess, Val{:MinGradientChange}, Any}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopWhenGradientChangeLess, :MinGradientChange, v)\n\nUpdate the minimal change below which an algorithm shall stop.\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenGradientNormLess, Val{:MinGradNorm}, Float64}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopWhenGradientNormLess, :MinGradNorm, v::Float64)\n\nUpdate the minimal gradient norm when an algorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"plans/stopping_criteria/#Manopt.update_stopping_criterion!-Tuple{StopWhenStepsizeLess, Val{:MinStepsize}, Any}","page":"Stopping Criteria","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopWhenStepsizeLess, :MinStepsize, v)\n\nUpdate the minimal step size below which the slgorithm shall stop\n\n\n\n\n\n","category":"method"},{"location":"tutorials/HowToRecord/#How-to-Record-Data-During-the-Iterations","page":"Record values","title":"How to Record Data During the Iterations","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"The recording and debugging features make it possible to record nearly any data during the iterations. This tutorial illustrates how to:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"record one value during the iterations;\nrecord multiple values during the iterations and access them afterwards;\ndefine an own RecordAction to perform individual recordings.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Several predefined recordings exist, for example RecordCost or RecordGradient, if the problem the solver uses provides a gradient. For fields of the State the recording can also be done RecordEntry. For other recordings, for example more advanced computations before storing a value, an own RecordAction can be defined.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We illustrate these using the gradient descent from the Get Started: Optimize! tutorial.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Here we focus on ways to investigate the behaviour during iterations by using Recording techniques.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Let‚Äôs first load the necessary packages.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"using Manopt, Manifolds, Random\nRandom.seed!(42);","category":"page"},{"location":"tutorials/HowToRecord/#The-Objective","page":"Record values","title":"The Objective","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We generate data and define our cost and gradient:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Random.seed!(42)\nm = 30\nM = Sphere(m)\nn = 800\nœÉ = œÄ / 8\nx = zeros(Float64, m + 1)\nx[2] = 1.0\ndata = [exp(M, x, œÉ * rand(M; vector_at=x)) for i in 1:n]\nf(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)\ngrad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"grad_f (generic function with 1 method)","category":"page"},{"location":"tutorials/HowToRecord/#Plain-Examples","page":"Record values","title":"Plain Examples","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"For the high level interfaces of the solvers, like gradient_descent we have to set return_state to true to obtain the whole solver state and not only the resulting minimizer.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Then we can easily use the record= option to add recorded values. This keyword accepts RecordActions as well as several symbols as shortcuts, for example :Cost to record the cost, or if your options have a field f, :f would record that entry. An overview of the symbols that can be used is given here.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We first just record the cost after every iteration","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R = gradient_descent(M, f, grad_f, data[1]; record=:Cost, return_state=true)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 63 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordCost(),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"From the returned state, we see that the GradientDescentState are encapsulated (decorated) within a RecordSolverState.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"For such a state, one can attach different recorders to some operations, currently to :Start. :Stop, and :Iteration, where :Iteration is the default when using the record= keyword with a RecordAction as above. We can access all values recorded during the iterations by calling get_record(R, :Iteation) or since this is the default even shorter","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"63-element Vector{Float64}:\n 0.6868754085841272\n 0.6240211444102516\n 0.5900374782569905\n 0.5691425134106757\n 0.5512819383843195\n 0.542136810022984\n 0.5374585627386623\n 0.5350045365259574\n 0.5337243124406587\n 0.5330491236590466\n 0.5326944302021914\n 0.5325071127227716\n 0.5324084047176342\n ‚ãÆ\n 0.5322977905736713\n 0.5322977905736701\n 0.5322977905736692\n 0.5322977905736687\n 0.5322977905736684\n 0.5322977905736682\n 0.5322977905736682\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736679","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"To record more than one value, you can pass an array of a mix of symbols and RecordActions which formally introduces RecordGroup. Such a group records a tuple of values in every iteration:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R2 = gradient_descent(M, f, grad_f, data[1]; record=[:Iteration, :Cost], return_state=true)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 63 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCost()]),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Here, the symbol :Cost is mapped to using the RecordCost action. The same holds for :Iteration obiously records the current iteration number i. To access these you can first extract the group of records (that is where the :Iterations are recorded ‚Äì note the plural) and then access the :Cost ‚Äú‚Äú‚Äù","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record_action(R2, :Iteration)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"RecordGroup([RecordIteration(), RecordCost()])","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Since iteration is the default, we can also omit it here again. To access single recorded values, one can use","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record_action(R2)[:Cost]","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"63-element Vector{Float64}:\n 0.6868754085841272\n 0.6240211444102516\n 0.5900374782569905\n 0.5691425134106757\n 0.5512819383843195\n 0.542136810022984\n 0.5374585627386623\n 0.5350045365259574\n 0.5337243124406587\n 0.5330491236590466\n 0.5326944302021914\n 0.5325071127227716\n 0.5324084047176342\n ‚ãÆ\n 0.5322977905736713\n 0.5322977905736701\n 0.5322977905736692\n 0.5322977905736687\n 0.5322977905736684\n 0.5322977905736682\n 0.5322977905736682\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736679","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"This can be also done by using a the high level interface get_record","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R2, :Iteration, :Cost)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"63-element Vector{Float64}:\n 0.6868754085841272\n 0.6240211444102516\n 0.5900374782569905\n 0.5691425134106757\n 0.5512819383843195\n 0.542136810022984\n 0.5374585627386623\n 0.5350045365259574\n 0.5337243124406587\n 0.5330491236590466\n 0.5326944302021914\n 0.5325071127227716\n 0.5324084047176342\n ‚ãÆ\n 0.5322977905736713\n 0.5322977905736701\n 0.5322977905736692\n 0.5322977905736687\n 0.5322977905736684\n 0.5322977905736682\n 0.5322977905736682\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736681\n 0.5322977905736679","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Note that the first symbol again refers to the point where we record (not to the thing we record). We can also pass a tuple as second argument to have our own order within the tuples returned. Switching the order of recorded cost and Iteration can be done using ‚Äú‚Äú‚Äù","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R2, :Iteration, (:Iteration, :Cost))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"63-element Vector{Tuple{Int64, Float64}}:\n (1, 0.6868754085841272)\n (2, 0.6240211444102516)\n (3, 0.5900374782569905)\n (4, 0.5691425134106757)\n (5, 0.5512819383843195)\n (6, 0.542136810022984)\n (7, 0.5374585627386623)\n (8, 0.5350045365259574)\n (9, 0.5337243124406587)\n (10, 0.5330491236590466)\n (11, 0.5326944302021914)\n (12, 0.5325071127227716)\n (13, 0.5324084047176342)\n ‚ãÆ\n (52, 0.5322977905736713)\n (53, 0.5322977905736701)\n (54, 0.5322977905736692)\n (55, 0.5322977905736687)\n (56, 0.5322977905736684)\n (57, 0.5322977905736682)\n (58, 0.5322977905736682)\n (59, 0.5322977905736681)\n (60, 0.5322977905736681)\n (61, 0.5322977905736681)\n (62, 0.5322977905736681)\n (63, 0.5322977905736679)","category":"page"},{"location":"tutorials/HowToRecord/#A-more-Complex-Example","page":"Record values","title":"A more Complex Example","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"To illustrate a complicated example let‚Äôs record: * the iteration number, cost and gradient field, but only every sixth iteration; * the iteration at which we stop.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We first generate the problem and the state, to also illustrate the low-level works when not using the high-level iterface gradient_descent.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"p = DefaultManoptProblem(M, ManifoldGradientObjective(f, grad_f))\ns = GradientDescentState(\n    M,\n    copy(data[1]);\n    stopping_criterion=StopAfterIteration(200) | StopWhenGradientNormLess(10.0^-9),\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We now first build a RecordGroup to group the three entries we want to record per iteration. We then put this into a RecordEvery to only record this every 6th iteration","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"rI = RecordEvery(\n    RecordGroup([\n        :Iteration => RecordIteration(),\n        :Cost => RecordCost(),\n        :Gradient => RecordEntry(similar(data[1]), :X),\n    ]),\n    6,\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"and for recodring the final iteration number","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"sI = RecordIteration()","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"RecordIteration()","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We now combine both into the RecordSolverState decorator. It acts completely the same as any AbstractManoptSolverState but records something in every iteration additionally. This is stored in a dictionary of RecordActions, where :Iteration is the action (here the only every 6th iteration group) and the sI which is executed at stop.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Note that the keyword record= in the high level interface gradient_descent only would fill the :Iteration symbol of said dictionary.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"r = RecordSolverState(s, Dict(:Iteration => rI, :Stop => sI))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: not reached\nOverall: not reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration())","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We now call the solver","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"res = solve!(p, r)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 63 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordEvery(RecordGroup([RecordIteration(), RecordCost(), RecordEntry(:X)]), 6, true), Stop = RecordIteration())","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"And we can check the recorded value at :Stop to see how many iterations were performed","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(res, :Stop)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"1-element Vector{Int64}:\n 63","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"and the other values during the iterations are","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(res, :Iteration, (:Iteration, :Cost))","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"10-element Vector{Tuple{Int64, Float64}}:\n (6, 0.542136810022984)\n (12, 0.5325071127227716)\n (18, 0.5323023757104095)\n (24, 0.5322978928223224)\n (30, 0.5322977928970518)\n (36, 0.5322977906274987)\n (42, 0.5322977905749401)\n (48, 0.5322977905736989)\n (54, 0.5322977905736692)\n (60, 0.5322977905736681)","category":"page"},{"location":"tutorials/HowToRecord/#Writing-an-own-[RecordAction](https://manoptjl.org/stable/plans/record/#Manopt.RecordAction)s","page":"Record values","title":"Writing an own RecordActions","text":"","category":"section"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Let‚Äôs investigate where we want to count the number of function evaluations, again just to illustrate, since for the gradient this is just one evaluation per iteration. We first define a cost, that counts its own calls. ‚Äú‚Äú‚Äù","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"mutable struct MyCost{T}\n    data::T\n    count::Int\nend\nMyCost(data::T) where {T} = MyCost{T}(data, 0)\nfunction (c::MyCost)(M, x)\n    c.count += 1\n    return sum(1 / (2 * length(c.data)) * distance.(Ref(M), Ref(x), c.data) .^ 2)\nend","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"and we define an own, new RecordAction, which is a functor, i.e.¬†a struct that is also a function. The function we have to implement is similar to a single solver step in signature, since it might get called every iteration:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"mutable struct RecordCount <: RecordAction\n    recorded_values::Vector{Int}\n    RecordCount() = new(Vector{Int}())\nend\nfunction (r::RecordCount)(p::AbstractManoptProblem, ::AbstractManoptSolverState, i)\n    if i > 0\n        push!(r.recorded_values, get_cost_function(get_objective(p)).count)\n    elseif i < 0 # reset if negative\n        r.recorded_values = Vector{Int}()\n    end\nend","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Now we can initialize the new cost and call the gradient descent. Note that this illustrates also the last use case ‚Äì you can pass symbol-action pairs into the record=array.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"f2 = MyCost(data)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"MyCost{Vector{Vector{Float64}}}([[-0.054658825167894595, -0.5592077846510423, -0.04738273828111257, -0.04682080720921302, 0.12279468849667038, 0.07171438895366239, -0.12930045409417057, -0.22102081626380404, -0.31805333254577767, 0.0065859500152017645  ‚Ä¶  -0.21999168261518043, 0.19570142227077295, 0.340909965798364, -0.0310802190082894, -0.04674431076254687, -0.006088297671169996, 0.01576037011323387, -0.14523596850249543, 0.14526158060820338, 0.1972125856685378], [-0.08192376929745249, -0.5097715132187676, -0.008339904915541005, 0.07289741328038676, 0.11422036270613797, -0.11546739299835748, 0.2296996932628472, 0.1490467170835958, -0.11124820565850364, -0.11790721606521781  ‚Ä¶  -0.16421249630470344, -0.2450575844467715, -0.07570080850379841, -0.07426218324072491, -0.026520181327346338, 0.11555341205250205, -0.0292955762365121, -0.09012096853677576, -0.23470556634911574, -0.026214242996704013], [-0.22951484264859257, -0.6083825348640186, 0.14273766477054015, -0.11947823367023377, 0.05984293499234536, 0.058820835498203126, 0.07577331705863266, 0.1632847202946857, 0.20244385489915745, 0.04389826920203656  ‚Ä¶  0.3222365119325929, 0.009728730325524067, -0.12094785371632395, -0.36322323926212824, -0.0689253407939657, 0.23356953371702974, 0.23489531397909744, 0.078303336494718, -0.14272984135578806, 0.07844539956202407], [-0.0012588500237817606, -0.29958740415089763, 0.036738459489123514, 0.20567651907595125, -0.1131046432541904, -0.06032435985370224, 0.3366633723165895, -0.1694687746143405, -0.001987171245125281, 0.04933779858684409  ‚Ä¶  -0.2399584473006256, 0.19889267065775063, 0.22468755918787048, 0.1780090580180643, 0.023703860700539356, -0.10212737517121755, 0.03807004103115319, -0.20569120952458983, -0.03257704254233959, 0.06925473452536687], [-0.035534309946938375, -0.06645560787329002, 0.14823972268208874, -0.23913346587232426, 0.038347027875883496, 0.10453333143286662, 0.050933995140290705, -0.12319549375687473, 0.12956684644537844, -0.23540367869989412  ‚Ä¶  -0.41471772859912864, -0.1418984610380257, 0.0038321446836859334, 0.23655566917750157, -0.17500681300994742, -0.039189751036839374, -0.08687860620942896, -0.11509948162959047, 0.11378233994840942, 0.38739450723013735], [-0.3122539912469438, -0.3101935557860296, 0.1733113629107006, 0.08968593616209351, -0.1836344261367962, -0.06480023695256802, 0.18165070013886545, 0.19618275767992124, -0.07956460275570058, 0.0325997354656551  ‚Ä¶  0.2845492418767769, 0.17406455870721682, -0.053101230371568706, -0.1382082812981627, 0.005830071475508364, 0.16739264037923055, 0.034365814374995335, 0.09107702398753297, -0.1877250428700409, 0.05116494897806923], [-0.04159442361185588, -0.7768029783272633, 0.06303616666722486, 0.08070518925253539, -0.07396265237309446, -0.06008109299719321, 0.07977141629715745, 0.019511027129056415, 0.08629917589924847, -0.11156298867318722  ‚Ä¶  0.0792587504128044, -0.016444383900170008, -0.181746064577005, -0.01888129512990984, -0.13523922089388968, 0.11358102175659832, 0.07929049608459493, 0.1689565359083833, 0.07673657951723721, -0.1128480905648813], [-0.21221814304651335, -0.5031823821503253, 0.010326342133992458, -0.12438192100961257, 0.04004758695231872, 0.2280527500843805, -0.2096243232022162, -0.16564828762420294, -0.28325749481138984, 0.17033534605245823  ‚Ä¶  -0.13599096505924074, 0.28437770540525625, 0.08424426798544583, -0.1266207606984139, 0.04917635557603396, -0.00012608938533809706, -0.04283220254770056, -0.08771365647566572, 0.14750169103093985, 0.11601120086036351], [0.10683290707435536, -0.17680836277740156, 0.23767458301899405, 0.12011180867097299, -0.029404774462600154, 0.11522028383799933, -0.3318174480974519, -0.17859266746938374, 0.04352373642537759, 0.2530382802667988  ‚Ä¶  0.08879861736692073, -0.004412506987801729, 0.19786810509925895, -0.1397104682727044, 0.09482328498485094, 0.05108149065160893, -0.14578343506951633, 0.3167479772660438, 0.10422673169182732, 0.21573150015891313], [-0.024895624707466164, -0.7473912016432697, -0.1392537238944721, -0.14948896791465557, -0.09765393283580377, 0.04413059403279867, -0.13865379004720355, -0.071032040283992, 0.15604054722246585, -0.10744260463413555  ‚Ä¶  -0.14748067081342833, -0.14743635071251024, 0.0643591937981352, 0.16138827697852615, -0.12656652133603935, -0.06463635704869083, 0.14329582429103488, -0.01113113793821713, 0.29295387893749997, 0.06774523575259782]  ‚Ä¶  [0.011874845316569967, -0.6910596618389588, 0.21275741439477827, -0.014042545524367437, -0.07883613103495014, -0.0021900966696246776, -0.033836430464220496, 0.2925813113264835, -0.04718187201980008, 0.03949680289730036  ‚Ä¶  0.0867736586603294, 0.0404682510051544, -0.24779813848587257, -0.28631514602877145, -0.07211767532456789, -0.15072898498180473, 0.017855923621826746, -0.09795357710255254, -0.14755229203084924, 0.1305005778855436], [0.013457629515450426, -0.3750353654626534, 0.12349883726772073, 0.3521803555005319, 0.2475921439420274, 0.006088649842999206, 0.31203183112392907, -0.036869203979483754, -0.07475746464056504, -0.029297797064479717  ‚Ä¶  0.16867368684091563, -0.09450564983271922, -0.0587273302122711, -0.1326667940553803, -0.25530237980444614, 0.37556905374043376, 0.04922612067677609, 0.2605362549983866, -0.21871556587505667, -0.22915883767386164], [0.03295085436260177, -0.971861604433394, 0.034748713521512035, -0.0494065013245799, -0.01767479281403355, 0.0465459739459587, 0.007470494722096038, 0.003227960072276129, 0.0058328596338402365, -0.037591237446692356  ‚Ä¶  0.03205152122876297, 0.11331109854742015, 0.03044900529526686, 0.017971704993311105, -0.009329252062960229, -0.02939354719650879, 0.022088835776251863, -0.02546111553658854, -0.0026257225461427582, 0.005702111697172774], [0.06968243992532257, -0.7119502191435176, -0.18136614593117445, -0.1695926215673451, 0.01725015359973796, -0.00694164951158388, -0.34621134287344574, 0.024709256792651912, -0.1632255805999673, -0.2158226433583082  ‚Ä¶  -0.14153772108081458, -0.11256850346909901, 0.045109821764180706, -0.1162754336222613, -0.13221711766357983, 0.005365354776191061, 0.012750671705879105, -0.018208207549835407, 0.12458753932455452, -0.31843587960340897], [-0.19830349374441875, -0.6086693423968884, 0.08552341811170468, 0.35781519334042255, 0.15790663648524367, 0.02712571268324985, 0.09855601327331667, -0.05840653973421127, -0.09546429767790429, -0.13414717696055448  ‚Ä¶  -0.0430935804718714, 0.2678584478951765, 0.08780994289014614, 0.01613469379498457, 0.0516187906322884, -0.07383067566731401, -0.1481272738354552, -0.010532317187265649, 0.06555344745952187, -0.1506167863762911], [-0.04347524125197773, -0.6327981074196994, -0.221116680035191, 0.0282207467940456, -0.0855024881522933, 0.12821801740178346, 0.1779499563280024, -0.10247384887512365, 0.0396432464100116, -0.0582580338112627  ‚Ä¶  0.1253893207083573, 0.09628202269764763, 0.3165295473947355, -0.14915034201394833, -0.1376727867817772, -0.004153096613530293, 0.09277957650773738, 0.05917264554031624, -0.12230262590034507, -0.19655728521529914], [-0.10173946348675116, -0.6475660153977272, 0.1260284619729566, -0.11933160462857616, -0.04774310633937567, 0.09093928358804217, 0.041662676324043114, -0.1264739543938265, 0.09605293126911392, -0.16790474428001648  ‚Ä¶  -0.04056684573478108, 0.09351665120940456, 0.15259195558799882, 0.0009949298312580497, 0.09461980828206303, 0.3067004514287283, 0.16129258773733715, -0.18893664085007542, -0.1806865244492513, 0.029319680436405825], [-0.251780954320053, -0.39147463259941456, -0.24359579328578626, 0.30179309757665723, 0.21658893985206484, 0.12304585275893232, 0.28281133086451704, 0.029187615341955325, 0.03616243507191924, 0.029375588909979152  ‚Ä¶  -0.08071746662465404, -0.2176101928258658, 0.20944684921170825, 0.043033273425352715, -0.040505542460853576, 0.17935596149079197, -0.08454569418519972, 0.0545941597033932, 0.12471741052450099, -0.24314124407858329], [0.28156471341150974, -0.6708572780452595, -0.1410302363738465, -0.08322589397277698, -0.022772599832907418, -0.04447265789199677, -0.016448068022011157, -0.07490911512503738, 0.2778432295769144, -0.10191899088372378  ‚Ä¶  -0.057272155080983836, 0.12817478092201395, 0.04623814480781884, -0.12184190164369117, 0.1987855635987229, -0.14533603246124993, -0.16334072868597016, -0.052369977381939437, 0.014904286931394959, -0.2440882678882144], [0.12108727495744157, -0.714787344982596, 0.01632521838262752, 0.04437570556908449, -0.041199280304144284, 0.052984488452616, 0.03796520200156107, 0.2791785910964288, 0.11530429924056099, 0.12178223160398421  ‚Ä¶  -0.07621847481721669, 0.18353870423743013, -0.19066653731436745, -0.09423224997242206, 0.14596847781388494, -0.09747986927777111, 0.16041150122587072, -0.02296513951256738, 0.06786878373578588, 0.15296635978447756]], 0)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"Now for the plain gradient descent, we have to modify the step (to a constant stepsize) and remove the default check whether the cost increases (setting debug to []). We also only look at the first 20 iterations to keep this example small in recorded values. We call","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R3 = gradient_descent(\n    M,\n    f2,\n    grad_f,\n    data[1];\n    record=[:Iteration, :Count => RecordCount(), :Cost],\n    stepsize = ConstantStepsize(1.0),\n    stopping_criterion=StopAfterIteration(20),\n    debug=[],\n    return_state=true,\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 20 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nConstantStepsize(1.0)\n\n## Stopping Criterion\nMax Iteration 20:   reached\nThis indicates convergence: No\n\n## Record\n(Iteration = RecordGroup([RecordIteration(), RecordCount([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), RecordCost()]),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"For :Cost we already learned how to access them, the :Count => introduces the following action to obtain the :Count. We can again access the whole sets of records","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R3)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"20-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 0, 0.5808287253777765)\n (2, 1, 0.5395268557323746)\n (3, 2, 0.5333529073733115)\n (4, 3, 0.5324514620174543)\n (5, 4, 0.5323201743667151)\n (6, 5, 0.5323010518577256)\n (7, 6, 0.5322982658416161)\n (8, 7, 0.532297859847447)\n (9, 8, 0.5322978006725337)\n (10, 9, 0.5322977920461375)\n (11, 10, 0.5322977907883957)\n (12, 11, 0.5322977906049865)\n (13, 12, 0.5322977905782369)\n (14, 13, 0.532297790574335)\n (15, 14, 0.5322977905737657)\n (16, 15, 0.5322977905736823)\n (17, 16, 0.5322977905736703)\n (18, 17, 0.5322977905736688)\n (19, 18, 0.5322977905736683)\n (20, 19, 0.5322977905736683)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"this is equivalent to calling R[:Iteration]. Note that since we introduced :Count we can also access a single recorded value using","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R3[:Iteration, :Count]","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"20-element Vector{Int64}:\n  0\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n 10\n 11\n 12\n 13\n 14\n 15\n 16\n 17\n 18\n 19","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"and we see that the cost function is called once per iteration.","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"If we use this counting cost and run the default gradient descent with Armijo linesearch, we can infer how many Armijo linesearch backtracks are preformed:","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"f3 = MyCost(data)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"MyCost{Vector{Vector{Float64}}}([[-0.054658825167894595, -0.5592077846510423, -0.04738273828111257, -0.04682080720921302, 0.12279468849667038, 0.07171438895366239, -0.12930045409417057, -0.22102081626380404, -0.31805333254577767, 0.0065859500152017645  ‚Ä¶  -0.21999168261518043, 0.19570142227077295, 0.340909965798364, -0.0310802190082894, -0.04674431076254687, -0.006088297671169996, 0.01576037011323387, -0.14523596850249543, 0.14526158060820338, 0.1972125856685378], [-0.08192376929745249, -0.5097715132187676, -0.008339904915541005, 0.07289741328038676, 0.11422036270613797, -0.11546739299835748, 0.2296996932628472, 0.1490467170835958, -0.11124820565850364, -0.11790721606521781  ‚Ä¶  -0.16421249630470344, -0.2450575844467715, -0.07570080850379841, -0.07426218324072491, -0.026520181327346338, 0.11555341205250205, -0.0292955762365121, -0.09012096853677576, -0.23470556634911574, -0.026214242996704013], [-0.22951484264859257, -0.6083825348640186, 0.14273766477054015, -0.11947823367023377, 0.05984293499234536, 0.058820835498203126, 0.07577331705863266, 0.1632847202946857, 0.20244385489915745, 0.04389826920203656  ‚Ä¶  0.3222365119325929, 0.009728730325524067, -0.12094785371632395, -0.36322323926212824, -0.0689253407939657, 0.23356953371702974, 0.23489531397909744, 0.078303336494718, -0.14272984135578806, 0.07844539956202407], [-0.0012588500237817606, -0.29958740415089763, 0.036738459489123514, 0.20567651907595125, -0.1131046432541904, -0.06032435985370224, 0.3366633723165895, -0.1694687746143405, -0.001987171245125281, 0.04933779858684409  ‚Ä¶  -0.2399584473006256, 0.19889267065775063, 0.22468755918787048, 0.1780090580180643, 0.023703860700539356, -0.10212737517121755, 0.03807004103115319, -0.20569120952458983, -0.03257704254233959, 0.06925473452536687], [-0.035534309946938375, -0.06645560787329002, 0.14823972268208874, -0.23913346587232426, 0.038347027875883496, 0.10453333143286662, 0.050933995140290705, -0.12319549375687473, 0.12956684644537844, -0.23540367869989412  ‚Ä¶  -0.41471772859912864, -0.1418984610380257, 0.0038321446836859334, 0.23655566917750157, -0.17500681300994742, -0.039189751036839374, -0.08687860620942896, -0.11509948162959047, 0.11378233994840942, 0.38739450723013735], [-0.3122539912469438, -0.3101935557860296, 0.1733113629107006, 0.08968593616209351, -0.1836344261367962, -0.06480023695256802, 0.18165070013886545, 0.19618275767992124, -0.07956460275570058, 0.0325997354656551  ‚Ä¶  0.2845492418767769, 0.17406455870721682, -0.053101230371568706, -0.1382082812981627, 0.005830071475508364, 0.16739264037923055, 0.034365814374995335, 0.09107702398753297, -0.1877250428700409, 0.05116494897806923], [-0.04159442361185588, -0.7768029783272633, 0.06303616666722486, 0.08070518925253539, -0.07396265237309446, -0.06008109299719321, 0.07977141629715745, 0.019511027129056415, 0.08629917589924847, -0.11156298867318722  ‚Ä¶  0.0792587504128044, -0.016444383900170008, -0.181746064577005, -0.01888129512990984, -0.13523922089388968, 0.11358102175659832, 0.07929049608459493, 0.1689565359083833, 0.07673657951723721, -0.1128480905648813], [-0.21221814304651335, -0.5031823821503253, 0.010326342133992458, -0.12438192100961257, 0.04004758695231872, 0.2280527500843805, -0.2096243232022162, -0.16564828762420294, -0.28325749481138984, 0.17033534605245823  ‚Ä¶  -0.13599096505924074, 0.28437770540525625, 0.08424426798544583, -0.1266207606984139, 0.04917635557603396, -0.00012608938533809706, -0.04283220254770056, -0.08771365647566572, 0.14750169103093985, 0.11601120086036351], [0.10683290707435536, -0.17680836277740156, 0.23767458301899405, 0.12011180867097299, -0.029404774462600154, 0.11522028383799933, -0.3318174480974519, -0.17859266746938374, 0.04352373642537759, 0.2530382802667988  ‚Ä¶  0.08879861736692073, -0.004412506987801729, 0.19786810509925895, -0.1397104682727044, 0.09482328498485094, 0.05108149065160893, -0.14578343506951633, 0.3167479772660438, 0.10422673169182732, 0.21573150015891313], [-0.024895624707466164, -0.7473912016432697, -0.1392537238944721, -0.14948896791465557, -0.09765393283580377, 0.04413059403279867, -0.13865379004720355, -0.071032040283992, 0.15604054722246585, -0.10744260463413555  ‚Ä¶  -0.14748067081342833, -0.14743635071251024, 0.0643591937981352, 0.16138827697852615, -0.12656652133603935, -0.06463635704869083, 0.14329582429103488, -0.01113113793821713, 0.29295387893749997, 0.06774523575259782]  ‚Ä¶  [0.011874845316569967, -0.6910596618389588, 0.21275741439477827, -0.014042545524367437, -0.07883613103495014, -0.0021900966696246776, -0.033836430464220496, 0.2925813113264835, -0.04718187201980008, 0.03949680289730036  ‚Ä¶  0.0867736586603294, 0.0404682510051544, -0.24779813848587257, -0.28631514602877145, -0.07211767532456789, -0.15072898498180473, 0.017855923621826746, -0.09795357710255254, -0.14755229203084924, 0.1305005778855436], [0.013457629515450426, -0.3750353654626534, 0.12349883726772073, 0.3521803555005319, 0.2475921439420274, 0.006088649842999206, 0.31203183112392907, -0.036869203979483754, -0.07475746464056504, -0.029297797064479717  ‚Ä¶  0.16867368684091563, -0.09450564983271922, -0.0587273302122711, -0.1326667940553803, -0.25530237980444614, 0.37556905374043376, 0.04922612067677609, 0.2605362549983866, -0.21871556587505667, -0.22915883767386164], [0.03295085436260177, -0.971861604433394, 0.034748713521512035, -0.0494065013245799, -0.01767479281403355, 0.0465459739459587, 0.007470494722096038, 0.003227960072276129, 0.0058328596338402365, -0.037591237446692356  ‚Ä¶  0.03205152122876297, 0.11331109854742015, 0.03044900529526686, 0.017971704993311105, -0.009329252062960229, -0.02939354719650879, 0.022088835776251863, -0.02546111553658854, -0.0026257225461427582, 0.005702111697172774], [0.06968243992532257, -0.7119502191435176, -0.18136614593117445, -0.1695926215673451, 0.01725015359973796, -0.00694164951158388, -0.34621134287344574, 0.024709256792651912, -0.1632255805999673, -0.2158226433583082  ‚Ä¶  -0.14153772108081458, -0.11256850346909901, 0.045109821764180706, -0.1162754336222613, -0.13221711766357983, 0.005365354776191061, 0.012750671705879105, -0.018208207549835407, 0.12458753932455452, -0.31843587960340897], [-0.19830349374441875, -0.6086693423968884, 0.08552341811170468, 0.35781519334042255, 0.15790663648524367, 0.02712571268324985, 0.09855601327331667, -0.05840653973421127, -0.09546429767790429, -0.13414717696055448  ‚Ä¶  -0.0430935804718714, 0.2678584478951765, 0.08780994289014614, 0.01613469379498457, 0.0516187906322884, -0.07383067566731401, -0.1481272738354552, -0.010532317187265649, 0.06555344745952187, -0.1506167863762911], [-0.04347524125197773, -0.6327981074196994, -0.221116680035191, 0.0282207467940456, -0.0855024881522933, 0.12821801740178346, 0.1779499563280024, -0.10247384887512365, 0.0396432464100116, -0.0582580338112627  ‚Ä¶  0.1253893207083573, 0.09628202269764763, 0.3165295473947355, -0.14915034201394833, -0.1376727867817772, -0.004153096613530293, 0.09277957650773738, 0.05917264554031624, -0.12230262590034507, -0.19655728521529914], [-0.10173946348675116, -0.6475660153977272, 0.1260284619729566, -0.11933160462857616, -0.04774310633937567, 0.09093928358804217, 0.041662676324043114, -0.1264739543938265, 0.09605293126911392, -0.16790474428001648  ‚Ä¶  -0.04056684573478108, 0.09351665120940456, 0.15259195558799882, 0.0009949298312580497, 0.09461980828206303, 0.3067004514287283, 0.16129258773733715, -0.18893664085007542, -0.1806865244492513, 0.029319680436405825], [-0.251780954320053, -0.39147463259941456, -0.24359579328578626, 0.30179309757665723, 0.21658893985206484, 0.12304585275893232, 0.28281133086451704, 0.029187615341955325, 0.03616243507191924, 0.029375588909979152  ‚Ä¶  -0.08071746662465404, -0.2176101928258658, 0.20944684921170825, 0.043033273425352715, -0.040505542460853576, 0.17935596149079197, -0.08454569418519972, 0.0545941597033932, 0.12471741052450099, -0.24314124407858329], [0.28156471341150974, -0.6708572780452595, -0.1410302363738465, -0.08322589397277698, -0.022772599832907418, -0.04447265789199677, -0.016448068022011157, -0.07490911512503738, 0.2778432295769144, -0.10191899088372378  ‚Ä¶  -0.057272155080983836, 0.12817478092201395, 0.04623814480781884, -0.12184190164369117, 0.1987855635987229, -0.14533603246124993, -0.16334072868597016, -0.052369977381939437, 0.014904286931394959, -0.2440882678882144], [0.12108727495744157, -0.714787344982596, 0.01632521838262752, 0.04437570556908449, -0.041199280304144284, 0.052984488452616, 0.03796520200156107, 0.2791785910964288, 0.11530429924056099, 0.12178223160398421  ‚Ä¶  -0.07621847481721669, 0.18353870423743013, -0.19066653731436745, -0.09423224997242206, 0.14596847781388494, -0.09747986927777111, 0.16041150122587072, -0.02296513951256738, 0.06786878373578588, 0.15296635978447756]], 0)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"To not get too many entries let‚Äôs just look at the first 20 iterations again","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"R4 = gradient_descent(\n    M,\n    f3,\n    grad_f,\n    data[1];\n    record=[:Count => RecordCount()],\n    return_state=true,\n)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"# Solver state for `Manopt.jl`s Gradient Descent\nAfter 63 iterations\n\n## Parameters\n* retraction method: ExponentialRetraction()\n\n## Stepsize\nArmijoLineseach() with keyword parameters\n  * initial_stepsize    = 1.0\n  * retraction_method   = ExponentialRetraction()\n  * contraction_factor  = 0.95\n  * sufficient_decrease = 0.1\n\n## Stopping Criterion\nStop When _one_ of the following are fulfilled:\n    Max Iteration 200:  not reached\n    |grad f| < 1.0e-9: reached\nOverall: reached\nThis indicates convergence: Yes\n\n## Record\n(Iteration = RecordGroup([RecordCount([25, 29, 33, 37, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 229, 232, 236, 240, 242, 247, 254, 263, 268, 270, 272, 278])]),)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"get_record(R4)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"63-element Vector{Tuple{Int64}}:\n (25,)\n (29,)\n (33,)\n (37,)\n (40,)\n (44,)\n (48,)\n (52,)\n (56,)\n (60,)\n (64,)\n (68,)\n (72,)\n ‚ãÆ\n (229,)\n (232,)\n (236,)\n (240,)\n (242,)\n (247,)\n (254,)\n (263,)\n (268,)\n (270,)\n (272,)\n (278,)","category":"page"},{"location":"tutorials/HowToRecord/","page":"Record values","title":"Record values","text":"We can see that the number of cost function calls varies, depending on how many linesearch backtrack steps were required to obtain a good stepsize.","category":"page"},{"location":"solvers/ChambollePock/#ChambollePockSolver","page":"Chambolle-Pock","title":"The Riemannian Chambolle-Pock Algorithm","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"The Riemannian Chambolle‚ÄìPock is a generalization of the Chambolle‚ÄìPock algorithm[ChambollePock2011]. It is also known as primal-dual hybrid gradient (PDHG) or primal-dual proximal splitting (PDPS) algorithm.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"In order to minimize over p‚àà\\mathcal M¬ß the cost function consisting of","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"F(p) + G(Œõ(p))","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"where Fmathcal M  overline‚Ñù, Gmathcal N  overline‚Ñù, and Œõmathcal M mathcal N. If the manifolds mathcal M or mathcal N are not Hadamard, it has to be considered locally, i.e. on geodesically convex sets mathcal C subset mathcal M and mathcal D subsetmathcal N such that Œõ(mathcal C) subset mathcal D.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"The algorithm is available in four variants: exact versus linearized (see variant) as well as with primal versus dual relaxation (see relax). For more details, see [BergmannHerzogSilvaLouzeiroTenbrinckVidalNunez2020]. In the following we note the case of the exact, primal relaxed Riemannian Chambolle‚ÄìPock algorithm.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Given base points mmathcal C, n=Œõ(m)mathcal D, initial primal and dual values p^(0) mathcal C, Œæ_n^(0) T_n^*mathcal N, and primal and dual step sizes sigma_0, tau_0, relaxation theta_0, as well as acceleration gamma.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"As an initialization, perform bar p^(0) gets p^(0).","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"The algorithms performs the steps k=1 (until a StoppingCriterion is fulfilled with)","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Œæ^(k+1)_n = operatornameprox_tau_k G_n^*Bigl(Œæ_n^(k) + tau_k bigl(log_n Œõ (bar p^(k))bigr)^flatBigr)\np^(k+1) = operatornameprox_sigma_k Fbiggl(exp_p^(k)Bigl( operatornamePT_p^(k)gets mbigl(-sigma_k DŒõ(m)^*Œæ_n^(k+1)bigr)^sharpBigr)biggr)\nUpdate\ntheta_k = (1+2gammasigma_k)^-frac12\nsigma_k+1 = sigma_ktheta_k\ntau_k+1 =  fractau_ktheta_k\nbar p^(k+1)  = exp_p^(k+1)bigl(-theta_k log_p^(k+1) p^(k)bigr)","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Furthermore you can exchange the exponential map, the logarithmic map, and the parallel transport by a retraction, an inverse retraction, and a vector transport.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Finally you can also update the base points m and n during the iterations. This introduces a few additional vector transports. The same holds for the case Œõ(m^(k))neq n^(k) at some point. All these cases are covered in the algorithm.","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"ChambollePock\nChambollePock!","category":"page"},{"location":"solvers/ChambollePock/#Manopt.ChambollePock","page":"Chambolle-Pock","title":"Manopt.ChambollePock","text":"ChambollePock(\n    M, N, cost, x0, Œæ0, m, n, prox_F, prox_G_dual, adjoint_linear_operator;\n    forward_operator=missing,\n    linearized_forward_operator=missing,\n    evaluation=AllocatingEvaluation()\n)\n\nPerform the Riemannian Chambolle‚ÄìPock algorithm.\n\nGiven a cost function mathcal Emathcal M  ‚Ñù of the form\n\nmathcal E(p) = F(p) + G( Œõ(p) )\n\nwhere Fmathcal M  ‚Ñù, Gmathcal N  ‚Ñù, and Œõmathcal M  mathcal N. The remaining input parameters are\n\np, X primal and dual start points xmathcal M and ŒæT_nmathcal N\nm,n base points on mathcal M and mathcal N, respectively.\nadjoint_linearized_operator the adjoint DŒõ^* of the linearized operator DŒõ(m) T_mmathcal M  T_Œõ(m)mathcal N\nprox_F, prox_G_Dual the proximal maps of F and G^ast_n\n\nnote that depending on the AbstractEvaluationType evaluation the last three parameters as well as the forwardoperator Œõ and the `linearizedforward_operatorcan be given as allocating functions(Manifolds, parameters) -> resultor as mutating functions(Manifold, result, parameters)-> result to spare allocations.\n\nBy default, this performs the exact Riemannian Chambolle Pock algorithm, see the optional parameter DŒõ for their linearized variant.\n\nFor more details on the algorithm, see[BergmannHerzogSilvaLouzeiroTenbrinckVidalNunez2020].\n\nOptional Parameters\n\nacceleration ‚Äì (0.05)\ndual_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the primal prox\nevaluation (AllocatingEvaluation()) specify whether the proximal maps and operators are allocating functions(Manifolds, parameters) -> resultor given as mutating functions(Manifold, result, parameters)-> result to spare allocations.\nŒõ (missing) the (forward) operator Œõ() (required for the :exact variant)\nlinearized_forward_operator (missing) its linearization DŒõ() (required for the :linearized variant)\nprimal_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the dual prox\nrelaxation ‚Äì (1.)\nrelax ‚Äì (:primal) whether to relax the primal or dual\nvariant - (:exact if Œõ is missing, otherwise :linearized) variant to use. Note that this changes the arguments the forward_operator will be called.\nstopping_criterion ‚Äì (stopAtIteration(100)) a StoppingCriterion\nupdate_primal_base ‚Äì (missing) function to update m (identity by default/missing)\nupdate_dual_base ‚Äì (missing) function to update n (identity by default/missing)\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the rectraction to use\ninverse_retraction_method - (default_inverse_retraction_method(M, typeof(p))) an inverse retraction to use.\nvector_transport_method - (default_vector_transport_method(M, typeof(p))) a vector transport to use\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n[BergmannHerzogSilvaLouzeiroTenbrinckVidalNunez2020]: R. Bergmann, R. Herzog, M. Silva Louzeiro, D. Tenbrinck, J. Vidal-N√∫√±ez: Fenchel Duality Theory and a Primal-Dual Algorithm on Riemannian Manifolds, Foundations of Computational Mathematics, 2021. doi: 10.1007/s10208-020-09486-5 arXiv: 1908.02022\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.ChambollePock!","page":"Chambolle-Pock","title":"Manopt.ChambollePock!","text":"ChambollePock(M, N, cost, x0, Œæ0, m, n, prox_F, prox_G_dual, adjoint_linear_operator)\n\nPerform the Riemannian Chambolle‚ÄìPock algorithm in place of x, Œæ, and potentially m, n if they are not fixed. See ChambollePock for details and optional parameters.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#State","page":"Chambolle-Pock","title":"State","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"ChambollePockState","category":"page"},{"location":"solvers/ChambollePock/#Manopt.ChambollePockState","page":"Chambolle-Pock","title":"Manopt.ChambollePockState","text":"ChambollePockState <: AbstractPrimalDualSolverState\n\nstores all options and variables within a linearized or exact Chambolle Pock. The following list provides the order for the constructor, where the previous iterates are initialized automatically and values with a default may be left out.\n\nm - base point on mathcal M\nn - base point on mathcal N\np - an initial point on x^(0) mathcal M (and its previous iterate)\nX - an initial tangent vector X^(0)T^*mathcal N (and its previous iterate)\npbar - the relaxed iterate used in the next dual update step (when using :primal relaxation)\nXbar - the relaxed iterate used in the next primal update step (when using :dual relaxation)\nprimal_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the primal prox\ndual_stepsize ‚Äì (1/sqrt(8)) proximal parameter of the dual prox\nacceleration ‚Äì (0.) acceleration factor due to Chambolle & Pock\nrelaxation ‚Äì (1.) relaxation in the primal relaxation step (to compute pbar)\nrelax ‚Äì (:primal) which variable to relax (:primal or :dual)\nstop - a StoppingCriterion\nvariant ‚Äì (exact) whether to perform an :exact or :linearized Chambolle-Pock\nupdate_primal_base ((p,o,i) -> o.m) function to update the primal base\nupdate_dual_base ((p,o,i) -> o.n) function to update the dual base\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the retraction to use\ninverse_retraction_method - (default_inverse_retraction_method(M, typeof(p))) an inverse retraction to use on the manifold mathcal M.\ninverse_retraction_method_dual - (default_inverse_retraction_method(N, typeof(n))) an inverse retraction to use on manifold mathcal N.\nvector_transport_method - (default_vector_transport_method(M, typeof(p))) a vector transport to use on the manifold mathcal M.\nvector_transport_method_dual - (default_vector_transport_method(N, typeof(n))) a vector transport to use on manifold mathcal N.\n\nwhere for the last two the functions a AbstractManoptProblemp, AbstractManoptSolverStateo and the current iterate i are the arguments. If you activate these to be different from the default identity, you have to provide p.Œõ for the algorithm to work (which might be missing in the linearized case).\n\nConstructor\n\nChambollePockState(M::AbstractManifold, N::AbstractManifold,\n    m::P, n::Q, p::P, X::T, primal_stepsize::Float64, dual_stepsize::Float64;\n    kwargs...\n)\n\nwhere all other fields from above are keyword arguments with their default values given in brackets.\n\nif Manifolds.jl is loaded, N is also a keyword argument and set to TangentBundle(M) by default.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Useful-Terms","page":"Chambolle-Pock","title":"Useful Terms","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"primal_residual\ndual_residual","category":"page"},{"location":"solvers/ChambollePock/#Manopt.primal_residual","page":"Chambolle-Pock","title":"Manopt.primal_residual","text":"primal_residual(p, o, x_old, X_old, n_old)\n\nCompute the primal residual at current iterate k given the necessary values x_k-1 X_k-1, and n_k-1 from the previous iterate.\n\nBigllVert\nfrac1œÉoperatornameretr^-1_x_kx_k-1 -\nV_x_kgets m_kbigl(DŒõ^*(m_k)biglV_n_kgets n_k-1X_k-1 - X_k bigr\nBigrrVert\n\nwhere V_gets is the vector transport used in the ChambollePockState\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.dual_residual","page":"Chambolle-Pock","title":"Manopt.dual_residual","text":"dual_residual(p, o, x_old, X_old, n_old)\n\nCompute the dual residual at current iterate k given the necessary values x_k-1 X_k-1, and n_k-1 from the previous iterate. The formula is slightly different depending on the o.variant used:\n\nFor the :lineaized it reads\n\nBigllVert\nfrac1œÑbigl(\nV_n_kgets n_k-1(X_k-1)\n- X_k\nbigr)\n-\nDŒõ(m_k)bigl\nV_m_kgets x_koperatornameretr^-1_x_kx_k-1\nbigr\nBigrrVert\n\nand for the :exact variant\n\nBigllVert\nfrac1œÑ V_n_kgets n_k-1(X_k-1)\n-\noperatornameretr^-1_n_kbigl(\nŒõ(operatornameretr_m_k(V_m_kgets x_koperatornameretr^-1_x_kx_k-1))\nbigr)\nBigrrVert\n\nwhere in both cases V_gets is the vector transport used in the ChambollePockState.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Debug","page":"Chambolle-Pock","title":"Debug","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"DebugDualBaseIterate\nDebugDualBaseChange\nDebugPrimalBaseIterate\nDebugPrimalBaseChange\nDebugDualChange\nDebugDualIterate\nDebugDualResidual\nDebugPrimalChange\nDebugPrimalIterate\nDebugPrimalResidual\nDebugPrimalDualResidual","category":"page"},{"location":"solvers/ChambollePock/#Manopt.DebugDualBaseIterate","page":"Chambolle-Pock","title":"Manopt.DebugDualBaseIterate","text":"DebugDualBaseIterate(io::IO=stdout)\n\nPrint the dual base variable by using DebugEntry, see their constructors for detail. This method is further set display o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualBaseChange","page":"Chambolle-Pock","title":"Manopt.DebugDualBaseChange","text":"DebugDualChange(; storage=StoreStateAction([:n]), io::IO=stdout)\n\nPrint the change of the dual base variable by using DebugEntryChange, see their constructors for detail, on o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalBaseIterate","page":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseIterate","text":"DebugPrimalBaseIterate()\n\nPrint the primal base variable by using DebugEntry, see their constructors for detail. This method is further set display o.m.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalBaseChange","page":"Chambolle-Pock","title":"Manopt.DebugPrimalBaseChange","text":"DebugPrimalBaseChange(a::StoreStateAction=StoreStateAction([:m]),io::IO=stdout)\n\nPrint the change of the primal base variable by using DebugEntryChange, see their constructors for detail, on o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualChange","page":"Chambolle-Pock","title":"Manopt.DebugDualChange","text":"DebugDualChange(opts...)\n\nPrint the change of the dual variable, similar to DebugChange, see their constructors for detail, but with a different calculation of the change, since the dual variable lives in (possibly different) tangent spaces.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugDualIterate","page":"Chambolle-Pock","title":"Manopt.DebugDualIterate","text":"DebugDualIterate(e)\n\nPrint the dual variable by using DebugEntry, see their constructors for detail. This method is further set display o.X.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugDualResidual","page":"Chambolle-Pock","title":"Manopt.DebugDualResidual","text":"DebugDualResidual <: DebugAction\n\nA Debug action to print the dual residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugDualResidual()\n\nwith the keywords\n\nio (stdout) - stream to perform the debug to\nformat (\"$prefix%s\") format to print the dual residual, using the\nprefix (\"Dual Residual: \") short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalChange","page":"Chambolle-Pock","title":"Manopt.DebugPrimalChange","text":"DebugPrimalChange(opts...)\n\nPrint the change of the primal variable by using DebugChange, see their constructors for detail.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalIterate","page":"Chambolle-Pock","title":"Manopt.DebugPrimalIterate","text":"DebugPrimalIterate(opts...;kwargs...)\n\nPrint the change of the primal variable by using DebugIterate, see their constructors for detail.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalResidual","page":"Chambolle-Pock","title":"Manopt.DebugPrimalResidual","text":"DebugPrimalResidual <: DebugAction\n\nA Debug action to print the primal residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugPrimalResidual()\n\nwith the keywords\n\nio (stdout) - stream to perform the debug to\nformat (\"$prefix%s\") format to print the dual residual, using the\nprefix (\"Primal Residual: \") short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Manopt.DebugPrimalDualResidual","page":"Chambolle-Pock","title":"Manopt.DebugPrimalDualResidual","text":"DebugPrimalDualResidual <: DebugAction\n\nA Debug action to print the primaldual residual. The constructor accepts a printing function and some (shared) storage, which should at least record :Iterate, :X and :n.\n\nConstructor\n\nDebugPrimalDualResidual()\n\nwith the keywords\n\nio (stdout) - stream to perform the debug to\nformat (\"$prefix%s\") format to print the dual residual, using the\nprefix (\"Primal Residual: \") short form to just set the prefix\nstorage (a new StoreStateAction) to store values for the debug.\n\n\n\n\n\n","category":"type"},{"location":"solvers/ChambollePock/#Record","page":"Chambolle-Pock","title":"Record","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"RecordDualBaseIterate\nRecordDualBaseChange\nRecordDualChange\nRecordDualIterate\nRecordPrimalBaseIterate\nRecordPrimalBaseChange\nRecordPrimalChange\nRecordPrimalIterate","category":"page"},{"location":"solvers/ChambollePock/#Manopt.RecordDualBaseIterate","page":"Chambolle-Pock","title":"Manopt.RecordDualBaseIterate","text":"RecordDualBaseIterate(n)\n\nCreate an RecordAction that records the dual base point, i.e. RecordEntry of o.n.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualBaseChange","page":"Chambolle-Pock","title":"Manopt.RecordDualBaseChange","text":"RecordDualBaseChange(e)\n\nCreate an RecordAction that records the dual base point change, i.e. RecordEntryChange of o.n with distance to the last value to store a value.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualChange","page":"Chambolle-Pock","title":"Manopt.RecordDualChange","text":"RecordDualChange()\n\nCreate the action either with a given (shared) Storage, which can be set to the values Tuple, if that is provided).\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordDualIterate","page":"Chambolle-Pock","title":"Manopt.RecordDualIterate","text":"RecordDualIterate(X)\n\nCreate an RecordAction that records the dual base point, i.e. RecordEntry of o.X, so .\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalBaseIterate","page":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseIterate","text":"RecordPrimalBaseIterate(x)\n\nCreate an RecordAction that records the primal base point, i.e. RecordEntry of o.m.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalBaseChange","page":"Chambolle-Pock","title":"Manopt.RecordPrimalBaseChange","text":"RecordPrimalBaseChange()\n\nCreate an RecordAction that records the primal base point change, i.e. RecordEntryChange of o.m with distance to the last value to store a value.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalChange","page":"Chambolle-Pock","title":"Manopt.RecordPrimalChange","text":"RecordPrimalChange(a)\n\nCreate an RecordAction that records the primal value change, i.e. RecordChange, since we just record the change of o.x.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Manopt.RecordPrimalIterate","page":"Chambolle-Pock","title":"Manopt.RecordPrimalIterate","text":"RecordDualBaseIterate(x)\n\nCreate an RecordAction that records the dual base point, i.e. RecordIterate, i.e. o.x.\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/#Internals","page":"Chambolle-Pock","title":"Internals","text":"","category":"section"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"Manopt.update_prox_parameters!","category":"page"},{"location":"solvers/ChambollePock/#Manopt.update_prox_parameters!","page":"Chambolle-Pock","title":"Manopt.update_prox_parameters!","text":"update_prox_parameters!(o)\n\nupdate the prox parameters as described in Algorithm 2 of Chambolle, Pock, 2010, i.e.\n\nŒ∏_n = frac1sqrt1+2Œ≥œÑ_n\nœÑ_n+1 = Œ∏_nœÑ_n\nœÉ_n+1 = fracœÉ_nŒ∏_n\n\n\n\n\n\n","category":"function"},{"location":"solvers/ChambollePock/","page":"Chambolle-Pock","title":"Chambolle-Pock","text":"[ChambollePock2011]: A. Chambolle, T. Pock: A first-order primal-dual algorithm for convex problems with applications to imaging, Journal of Mathematical Imaging and Vision 40(1), 120‚Äì145, 2011. doi: 10.1007/s10851-010-0251-1","category":"page"},{"location":"helpers/data/#Data","page":"Data","title":"Data","text":"","category":"section"},{"location":"helpers/data/","page":"Data","title":"Data","text":"For some manifolds there are artificial or real application data available that can be loaded using the following data functions","category":"page"},{"location":"helpers/data/","page":"Data","title":"Data","text":"Modules = [Manopt]\nPages   = [\"artificialDataFunctions.jl\"]","category":"page"},{"location":"helpers/data/#Manopt.artificialIn_SAR_image-Tuple{Integer}","page":"Data","title":"Manopt.artificialIn_SAR_image","text":"artificialIn_SAR_image([pts=500])\n\ngenerate an artificial InSAR image, i.e. phase valued data, of size pts x pts points.\n\nThis data set was introduced for the numerical examples in\n\nBergmann, R., Laus, F., Steidl, G., Weinmann, A.: Second Order Differences of Cyclic Data and Applications in Variational Denoising SIAM J. Imaging Sci., 7(4), 2916‚Äì2953, 2014. doi: 10.1137/140969993 arxiv: 1405.5349\n\n\n\n\n\n","category":"method"},{"location":"helpers/data/#Manopt.artificial_S1_signal","page":"Data","title":"Manopt.artificial_S1_signal","text":"artificial_S1_signal([pts=500])\n\ngenerate a real-valued signal having piecewise constant, linear and quadratic intervals with jumps in between. If the resulting manifold the data lives on, is the Circle the data is also wrapped to -pipi).\n\nOptional\n\npts ‚Äì (500) number of points to sample the function\n\nBergmann, R., Laus, F., Steidl, G., Weinmann, A.: Second Order Differences of Cyclic Data and Applications in Variational Denoising SIAM J. Imaging Sci., 7(4), 2916‚Äì2953, 2014. doi: 10.1137/140969993 arxiv: 1405.5349\n\n\n\n\n\n","category":"function"},{"location":"helpers/data/#Manopt.artificial_S1_signal-Tuple{Real}","page":"Data","title":"Manopt.artificial_S1_signal","text":"artificial_S1_signal(x)\n\nevaluate the example signal f(x) x   01, of phase-valued data introduces in Sec. 5.1 of\n\nBergmann, R., Laus, F., Steidl, G., Weinmann, A.: Second Order Differences of Cyclic Data and Applications in Variational Denoising SIAM J. Imaging Sci., 7(4), 2916‚Äì2953, 2014. doi: 10.1137/140969993 arxiv: 1405.5349\n\nfor values outside that intervall, this Signal is missing.\n\n\n\n\n\n","category":"method"},{"location":"helpers/data/#Manopt.artificial_S1_slope_signal","page":"Data","title":"Manopt.artificial_S1_slope_signal","text":"artificial_S1_slope_signal([pts=500, slope=4.])\n\nCreates a Signal of (phase-valued) data represented on the CircleManifold with increasing slope.\n\nOptional\n\npts ‚Äì (500) number of points to sample the function.\nslope ‚Äì (4.0) initial slope that gets increased afterwards\n\nThis data set was introduced for the numerical examples in\n\nBergmann, R., Laus, F., Steidl, G., Weinmann, A.: Second Order Differences of Cyclic Data and Applications in Variational Denoising SIAM J. Imaging Sci., 7(4), 2916‚Äì2953, 2014. doi: 10.1137/140969993 arxiv: 1405.5349\n\n\n\n\n\n","category":"function"},{"location":"helpers/data/#Manopt.artificial_S2_composite_bezier_curve-Tuple{}","page":"Data","title":"Manopt.artificial_S2_composite_bezier_curve","text":"artificial_S2_composite_bezier_curve()\n\nCreate the artificial curve in the Sphere(2) consisting of 3 segments between the four points\n\np_0 = beginbmatrix001endbmatrix^mathrmT\np_1 = beginbmatrix0-10endbmatrix^mathrmT\np_2 = beginbmatrix-100endbmatrix^mathrmT\np_3 = beginbmatrix00-1endbmatrix^mathrmT\n\nwhere each segment is a cubic Bez√©r curve, i.e. each point, except p_3 has a first point within the following segment b_i^+, i=012 and a last point within the previous segment, except for p_0, which are denoted by b_i^-, i=123. This curve is differentiable by the conditions b_i^- = gamma_b_i^+p_i(2), i=12, where gamma_ab is the shortest_geodesic connecting a and b. The remaining points are defined as\n\nbeginaligned\n    b_0^+ = exp_p_0fracpi8sqrt2beginpmatrix1-10endpmatrix^mathrmT\n    b_1^+ = exp_p_1-fracpi4sqrt2beginpmatrix-101endpmatrix^mathrmT\n    b_2^+ = exp_p_2fracpi4sqrt2beginpmatrix01-1endpmatrix^mathrmT\n    b_3^- = exp_p_3-fracpi8sqrt2beginpmatrix-110endpmatrix^mathrmT\nendaligned\n\nThis example was used within minimization of acceleration of the paper\n\nBergmann, R., Gousenbourger, P.-Y.: A variational model for data fitting on manifolds by minimizing the acceleration of a B√©zier curve, Front. Appl. Math. Stat. 12, 2018. doi: 10.3389/fams.2018.00059 arxiv: 1807.10090\n\n\n\n\n\n","category":"method"},{"location":"helpers/data/#Manopt.artificial_S2_lemniscate","page":"Data","title":"Manopt.artificial_S2_lemniscate","text":"artificial_S2_lemniscate(p [,pts=128,a=œÄ/2,interval=[0,2œÄ])\n\nGenerate a Signal on the Sphere mathbb S^2 by creating the Lemniscate of Bernoulli in the tangent space of p sampled at pts points and use exp to get a signal on the Sphere.\n\nInput\n\np ‚Äì the tangent space the Lemniscate is created in\npts ‚Äì (128) number of points to sample the Lemniscate\na ‚Äì (œÄ/2) defines a half axis of the Lemniscate to cover a  half sphere.\ninterval ‚Äì ([0,2*œÄ]) range to sample the lemniscate at, the default value refers to one closed curve\n\nThis dataset was used in the numerical example of Section 5.1 of\n\nBaƒç√°k, M., Bergmann, R., Steidl, G., Weinmann, A.: A Second Order Non-Smooth Variational Model for Restoring Manifold-Valued Images SIAM J. Sci. Comput. 38(1), A567‚ÄìA597, 2016. doi: 10.1137/15M101988X arxiv: 1506.02409\n\n\n\n\n\n","category":"function"},{"location":"helpers/data/#Manopt.artificial_S2_lemniscate-2","page":"Data","title":"Manopt.artificial_S2_lemniscate","text":"artificial_S2_lemniscate(p, t::Float64; a::Float64=œÄ/2)\n\nGenerate a point from the signal on the Sphere mathbb S^2 by creating the Lemniscate of Bernoulli in the tangent space of p sampled at t and use √®xpto obtain a point on the [Sphere`](https://juliamanifolds.github.io/Manifolds.jl/stable/manifolds/sphere.html).\n\nInput\n\np ‚Äì the tangent space the Lemniscate is created in\nt ‚Äì value to sample the Lemniscate at\n\nOptional Values\n\na ‚Äì (œÄ/2) defines a half axis of the Lemniscate to cover a half sphere.\n\nThis dataset was used in the numerical example of Section 5.1 of\n\nBaƒç√°k, M., Bergmann, R., Steidl, G., Weinmann, A.: A Second Order Non-Smooth Variational Model for Restoring Manifold-Valued Images SIAM J. Sci. Comput. 38(1), A567‚ÄìA597, 2016. doi: 10.1137/15M101988X arxiv: 1506.02409\n\n\n\n\n\n","category":"function"},{"location":"helpers/data/#Manopt.artificial_S2_rotation_image-Tuple{}","page":"Data","title":"Manopt.artificial_S2_rotation_image","text":"artificial_S2_rotation_image([pts=64, rotations=(.5,.5)])\n\nCreate an image with a rotation on each axis as a parametrization.\n\nOptional Parameters\n\npts ‚Äì (64) number of pixels along one dimension\nrotations ‚Äì ((.5,.5)) number of total rotations performed on the axes.\n\nThis dataset was used in the numerical example of Section 5.1 of\n\nBaƒç√°k, M., Bergmann, R., Steidl, G., Weinmann, A.: A Second Order Non-Smooth Variational Model for Restoring Manifold-Valued Images SIAM J. Sci. Comput. 38(1), A567‚ÄìA597, 2016. doi: 10.1137/15M101988X arxiv: 1506.02409\n\n\n\n\n\n","category":"method"},{"location":"helpers/data/#Manopt.artificial_S2_whirl_image-Tuple{Int64}","page":"Data","title":"Manopt.artificial_S2_whirl_image","text":"artificial_S2_whirl_image([pts::Int=64])\n\nGenerate an artificial image of data on the 2 sphere,\n\nArguments\n\npts ‚Äì (64) size of the image in ptstimespts pixel.\n\nThis example dataset was used in the numerical example in Section 5.5 of\n\nLaus, F., Nikolova, M., Persch, J., Steidl, G.: A Nonlocal Denoising Algorithm for Manifold-Valued Images Using Second Order Statistics, SIAM J. Imaging Sci., 10(1), 416‚Äì448, 2017. doi:  10.1137/16M1087114 arxiv: 1607.08481\n\nIt is based on artificial_S2_rotation_image extended by small whirl patches.\n\n\n\n\n\n","category":"method"},{"location":"helpers/data/#Manopt.artificial_S2_whirl_patch","page":"Data","title":"Manopt.artificial_S2_whirl_patch","text":"artificial_S2_whirl_patch([pts=5])\n\ncreate a whirl within the ptstimespts patch of Sphere(@ref)(2)-valued image data.\n\nThese patches are used within artificial_S2_whirl_image.\n\nOptional Parameters\n\npts ‚Äì (5) size of the patch. If the number is odd, the center is the north pole.\n\n\n\n\n\n","category":"function"},{"location":"helpers/data/#Manopt.artificial_SPD_image","page":"Data","title":"Manopt.artificial_SPD_image","text":"artificial_SPD_image([pts=64, stepsize=1.5])\n\ncreate an artificial image of symmetric positive definite matrices of size ptstimespts pixel with a jump of size stepsize.\n\nThis dataset was used in the numerical example of Section 5.2 of\n\nBaƒç√°k, M., Bergmann, R., Steidl, G., Weinmann, A.: A Second Order Non-Smooth Variational Model for Restoring Manifold-Valued Images SIAM J. Sci. Comput. 38(1), A567‚ÄìA597, 2016. doi: 10.1137/15M101988X arxiv: 1506.02409\n\n\n\n\n\n","category":"function"},{"location":"helpers/data/#Manopt.artificial_SPD_image2-Tuple{Any, Any}","page":"Data","title":"Manopt.artificial_SPD_image2","text":"artificial_SPD_image2([pts=64, fraction=.66])\n\ncreate an artificial image of symmetric positive definite matrices of size ptstimespts pixel with right hand side fraction is moved upwards.\n\nThis data set was introduced in the numerical examples of Section of\n\nBergmann, R., Persch, J., Steidl, G.: A Parallel Douglas Rachford Algorithm for Minimizing ROF-like Functionals on Images with Values in Symmetric Hadamard Manifolds SIAM J. Imaging. Sci. 9(3), pp. 901-937, 2016. doi: 10.1137/15M1052858 arxiv: 1512.02814\n\n\n\n\n\n","category":"method"},{"location":"solvers/alternating_gradient_descent/#AlternatingGradientDescentSolver","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"","category":"section"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"alternating_gradient_descent\nalternating_gradient_descent!","category":"page"},{"location":"solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent","page":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent","text":"alternating_gradient_descent(M::ProductManifold, f, grad_f, p=rand(M))\nalternating_gradient_descent(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\n\nperform an alternating gradient descent\n\nInput\n\nM ‚Äì the product manifold mathcal M = mathcal M_1  mathcal M_2   mathcal M_n\nf ‚Äì the objective function (cost) defined on M.\ngrad_f ‚Äì a gradient, that can be of two cases\nis a single function returning an ArrayPartition or\nis a vector functions each returning a component part of the whole gradient\np ‚Äì an initial value p_0  mathcal M\n\nOptional\n\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient(s) works by  allocation (default) form gradF(M, x) or InplaceEvaluation in place, i.e.  is of the form gradF!(M, X, x) (elementwise).\nevaluation_order ‚Äì (:Linear) ‚Äì whether to use a randomly permuted sequence (:FixedRandom), a per cycle permuted sequence (:Random) or the default :Linear one.\ninner_iterations‚Äì (5) how many gradient steps to take in a component before alternating to the next\nstopping_criterion (StopAfterIteration(1000))‚Äì a StoppingCriterion\nstepsize (ArmijoLinesearch()) a Stepsize\norder - ([1:n]) the initial permutation, where n is the number of gradients in gradF.\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction(M, p, X) to use.\n\nOutput\n\nusually the obtained (approximate) minimizer, see get_solver_return for details\n\nnote: Note\nThis Problem requires the ProductManifold from Manifolds.jl, so Manifolds.jl needs to be loaded.\n\nnote: Note\nThe input of each of the (component) gradients is still the whole vector X, just that all other then the ith input component are assumed to be fixed and just the ith components gradient is computed / returned.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#Manopt.alternating_gradient_descent!","page":"Alternating Gradient Descent","title":"Manopt.alternating_gradient_descent!","text":"alternating_gradient_descent!(M::ProductManifold, f, grad_f, p)\nalternating_gradient_descent!(M::ProductManifold, ago::ManifoldAlternatingGradientObjective, p)\n\nperform a alternating gradient descent in place of p.\n\nInput\n\nM a product manifold mathcal M\nf ‚Äì the objective functioN (cost)\ngrad_f ‚Äì a gradient function, that either returns a vector of the subgradients or is a vector of gradients\np ‚Äì an initial value p_0  mathcal M\n\nyou can also pass a ManifoldAlternatingGradientObjective ago containing f and grad_f instead.\n\nfor all optional parameters, see alternating_gradient_descent.\n\n\n\n\n\n","category":"function"},{"location":"solvers/alternating_gradient_descent/#State","page":"Alternating Gradient Descent","title":"State","text":"","category":"section"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"AlternatingGradientDescentState","category":"page"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradientDescentState","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradientDescentState","text":"AlternatingGradientDescentState <: AbstractGradientDescentSolverState\n\nStore the fields for an alternating gradient descent algorithm, see also alternating_gradient_descent.\n\nFields\n\ndirection (AlternatingGradient(zero_vector(M, x)) a DirectionUpdateRule\nevaluation_order ‚Äì (:Linear) ‚Äì whether\ninner_iterations‚Äì (5) how many gradient steps to take in a component before alternating to the next to use a randomly permuted sequence (:FixedRandom), a per cycle newly permuted sequence (:Random) or the default :Linear evaluation order.\norder the current permutation\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction(M,x,Œæ) to use.\nstepsize (ConstantStepsize(M)) a Stepsize\nstopping_criterion (StopAfterIteration(1000))‚Äì a StoppingCriterion\np the current iterate\nX (zero_vector(M,p)) the current gradient tangent vector\nk, √¨` internal counters for the outer and inner iterations, respectively.\n\nConstructors\n\nAlternatingGradientDescentState(M, p; kwargs...)\n\nGenerate the options for point p and and where inner_iterations, order_type, order, retraction_method, stopping_criterion, and stepsize` are keyword arguments\n\n\n\n\n\n","category":"type"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"Additionally, the options share a DirectionUpdateRule, which chooses the current component, so they can be decorated further; The most inner one should always be the following one though.","category":"page"},{"location":"solvers/alternating_gradient_descent/","page":"Alternating Gradient Descent","title":"Alternating Gradient Descent","text":"AlternatingGradient","category":"page"},{"location":"solvers/alternating_gradient_descent/#Manopt.AlternatingGradient","page":"Alternating Gradient Descent","title":"Manopt.AlternatingGradient","text":"AlternatingGradient <: DirectionUpdateRule\n\nThe default gradient processor, which just evaluates the (alternating) gradient on one of the components\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#tCG","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint Truncated Conjugate-Gradient Method","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"The aim is to solve the trust-region subproblem","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"operatorname*argmin_Œ∑    T_xmathcalM m_x(Œ∑) = F(x) +\noperatornamegradF(x) Œ∑_x + frac12 \nmathcalHŒ∑ Œ∑_x","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"textst  Œ∑ Œ∑_x leq Œî^2","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"on a manifold by using the Steihaug-Toint truncated conjugate-gradient method, abbreviated tCG-method. All terms involving the trust-region radius use an inner product w.r.t. the preconditioner; this is because the iterates grow in length w.r.t. the preconditioner, guaranteeing that we do not re-enter the trust-region.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Initialization","page":"Steihaug-Toint TCG Method","title":"Initialization","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"Initialize Œ∑_0 = Œ∑ if using randomized approach and Œ∑ the zero tangent vector otherwise, r_0 = operatornamegradF(x), z_0 = operatornameP(r_0), Œ¥_0 = z_0 and k=0","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Iteration","page":"Steihaug-Toint TCG Method","title":"Iteration","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"Repeat until a convergence criterion is reached","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"Set Œ± =fracr_k z_k_xŒ¥_k mathcalHŒ¥_k_x and  Œ∑_k Œ∑_k_x^* = Œ∑_k operatornameP(Œ∑_k)_x +  2Œ± Œ∑_k operatornameP(Œ¥_k)_x +  Œ±^2  Œ¥_k operatornameP(Œ¥_k)_x.\nIf Œ¥_k mathcalHŒ¥_k_x  0 or Œ∑_k Œ∑_k_x^*  Œî^2  return Œ∑_k+1 = Œ∑_k + œÑ Œ¥_k and stop.\nSet Œ∑_k^*= Œ∑_k + Œ± Œ¥_k, if  Œ∑_k Œ∑_k_x + frac12 Œ∑_k  operatornameHessF (Œ∑_k)_x_x  Œ∑_k^*  Œ∑_k^*_x + frac12 Œ∑_k^*  operatornameHessF (Œ∑_k)_ x_x  set Œ∑_k+1 = Œ∑_k else set Œ∑_k+1 = Œ∑_k^*.\nSet r_k+1 = r_k + Œ± mathcalHŒ¥_k,   z_k+1 = operatornameP(r_k+1),   Œ≤ = fracr_k+1  z_k+1_xr_k z_k _x and Œ¥_k+1 = -z_k+1 + Œ≤ Œ¥_k.\nSet k=k+1.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Result","page":"Steihaug-Toint TCG Method","title":"Result","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"The result is given by the last computed Œ∑_k.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Remarks","page":"Steihaug-Toint TCG Method","title":"Remarks","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"The operatornameP() denotes the symmetric, positive deÔ¨Ånite preconditioner. It is required if a randomized approach is used i.e. using a random tangent vector Œ∑_0 as the initial vector. The idea behind it is to avoid saddle points. Preconditioning is simply a rescaling of the variables and thus a redefinition of the shape of the trust region. Ideally operatornameP() is a cheap, positive approximation of the inverse of the Hessian of F at x. On default, the preconditioner is just the identity.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"To step number 2: obtain œÑ from the positive root of leftlVert Œ∑_k + œÑ Œ¥_k rightrVert_operatornameP x = Œî what becomes after the conversion of the equation to","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":" œÑ = frac-Œ∑_k operatornameP(Œ¥_k)_x +\n sqrtŒ∑_k operatornameP(Œ¥_k)_x^2 +\n Œ¥_k operatornameP(Œ¥_k)_x ( Œî^2 -\n Œ∑_k operatornameP(Œ∑_k)_x)\n Œ¥_k operatornameP(Œ¥_k)_x","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"It can occur that Œ¥_k operatornameHessF (Œ¥_k)_x_x = Œ∫  0 at iteration k. In this case, the model is not strictly convex, and the stepsize Œ± =fracr_k z_k_x Œ∫ computed in step 1. does not give a reduction in the model function m_x(). Indeed, m_x() is unbounded from below along the line Œ∑_k + Œ± Œ¥_k. If our aim is to minimize the model within the trust-region, it makes far more sense to reduce m_x() along Œ∑_k + Œ± Œ¥_k as much as we can while staying within the trust-region, and this means moving to the trust-region boundary along this line. Thus, when Œ∫  0 at iteration k, we replace Œ± = fracr_k z_k_xŒ∫ with œÑ described as above. The other possibility is that Œ∑_k+1 would lie outside the trust-region at iteration k (i.e. Œ∑_k Œ∑_k_x^*   Œî^2 that can be identified with the norm of Œ∑_k+1). In particular, when operatornameHessF ()_x is positive deÔ¨Ånite and Œ∑_k+1 lies outside the trust region, the solution to the trust-region problem must lie on the trust-region boundary. Thus, there is no reason to continue with the conjugate gradient iteration, as it stands, as subsequent iterates will move further outside the trust-region boundary. A sensible strategy, just as in the case considered above, is to move to the trust-region boundary by finding œÑ.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"Although it is virtually impossible in practice to know how many iterations are necessary to provide a good estimate Œ∑_k of the trust-region subproblem, the method stops after a certain number of iterations, which is realised by StopAfterIteration. In order to increase the convergence rate of the underlying trust-region method, see trust_regions, a typical stopping criterion is to stop as soon as an iteration k is reached for which","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"  Vert r_k Vert_x leqq Vert r_0 Vert_x min left( Vert r_0 Vert^Œ∏_x Œ∫ right)","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"holds, where 0  Œ∫  1 and Œ∏  0 are chosen in advance. This is realized in this method by StopWhenResidualIsReducedByFactorOrPower. It can be shown shown that under appropriate conditions the iterates x_k of the underlying trust-region method converge to nondegenerate critical points with an order of convergence of at least min left( Œ∏ + 1 2 right), see [Absil, Mahony, Sepulchre, 2008]. The method also aborts if the curvature of the model is negative, i.e. if langle delta_k mathcalHŒ¥_k rangle_x leqq 0, which is realised by StopWhenCurvatureIsNegative. If the next possible approximate solution Œ∑_k^* calculated in iteration k lies outside the trust region, i.e. if lVert Œ∑_k^* rVert_x geq Œî, then the method aborts, which is realised by StopWhenTrustRegionIsExceeded. Furthermore, the method aborts if the new model value evaluated at Œ∑_k^* is greater than the previous model value evaluated at Œ∑_k, which is realised by StopWhenModelIncreased.","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Interface","page":"Steihaug-Toint TCG Method","title":"Interface","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"  truncated_conjugate_gradient_descent\n  truncated_conjugate_gradient_descent!","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent","page":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent","text":"truncated_conjugate_gradient_descent(M, f, grad_f, p; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, p, X; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, Hess_f; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p; kwargs...)\ntruncated_conjugate_gradient_descent(M, f, grad_f, Hess_f, p, X; kwargs...)\ntruncated_conjugate_gradient_descent(M, mho::ManifoldHessianObjective, p, X; kwargs...)\n\nsolve the trust-region subproblem\n\noperatorname*argmin_Œ∑  T_pM\nm_p(Œ∑) quadtextwhere\nm_p(Œ∑) = f(p) + operatornamegrad f(p)Œ∑_x + frac12operatornameHess f(p)Œ∑Œ∑_x\n\ntextsuch thatquad Œ∑Œ∑_x  Œî^2\n\non a manifold M by using the Steihaug-Toint truncated conjugate-gradient method, abbreviated tCG-method. For a description of the algorithm and theorems offering convergence guarantees, see the reference:\n\nP.-A. Absil, C.G. Baker, K.A. Gallivan,   Trust-region methods on Riemannian manifolds, FoCM, 2007.   doi: 10.1007/s10208-005-0179-9\nA. R. Conn, N. I. M. Gould, P. L. Toint, Trust-region methods, SIAM,   MPS, 2000. doi: 10.1137/1.9780898719857\n\nInput\n\nSee signatures above, you can leave out only the Hessian, the vector, the point and the vector, or all 3.\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function F mathcal M  ‚Ñù to minimize\ngrad_f ‚Äì the gradient operatornamegradf mathcal M  Tmathcal M of F\nHess_f ‚Äì (optional, cf. ApproxHessianFiniteDifference) the hessian operatornameHessf T_pmathcal M  T_pmathcal M, X  operatornameHessF(p)X = _Xoperatornamegradf(p)\np ‚Äì a point on the manifold p  mathcal M\nX ‚Äì an update tangential vector X  T_pmathcal M\n\nOptional\n\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient and hessian work by  allocation (default) or InplaceEvaluation in place\npreconditioner ‚Äì a preconditioner for the hessian H\nŒ∏ ‚Äì (1.0) 1+Œ∏ is the superlinear convergence target rate. The method aborts   if the residual is less than or equal to the initial residual to the power of 1+Œ∏.\nŒ∫ ‚Äì (0.1) the linear convergence target rate. The method aborts if the   residual is less than or equal to Œ∫ times the initial residual.\nrandomize ‚Äì set to true if the trust-region solve is to be initiated with a   random tangent vector. If set to true, no preconditioner will be   used. This option is set to true in some scenarios to escape saddle   points, but is otherwise seldom activated.\ntrust_region_radius ‚Äì (injectivity_radius(M)/4) a trust-region radius\nproject! : (copyto!) specify a projection operation for tangent vectors   for numerical stability. A function (M, Y, p, X) -> ... working in place of Y.   per default, no projection is perfomed, set it to project! to activate projection.\nstopping_criterion ‚Äì (StopAfterIteration| [StopWhenResidualIsReducedByFactorOrPower](@ref) | 'StopWhenCurvatureIsNegative|StopWhenTrustRegionIsExceeded )   a functor inheriting from StoppingCriterion indicating when to stop,   where for the default, the maximal number of iterations is set to the dimension of the   manifold, the power factor is Œ∏, the reduction factor is Œ∫.\n\nand the ones that are passed to decorate_state! for decorators.\n\nOutput\n\nthe obtained (approximate) minimizer eta^*, see get_solver_return for details\n\nsee also\n\ntrust_regions\n\n\n\n\n\n","category":"function"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.truncated_conjugate_gradient_descent!","page":"Steihaug-Toint TCG Method","title":"Manopt.truncated_conjugate_gradient_descent!","text":"truncated_conjugate_gradient_descent!(M, f, grad_f, Hess_f, p, X; kwargs...)\ntruncated_conjugate_gradient_descent!(M, f, grad_f, p, X; kwargs...)\n\nsolve the trust-region subproblem in place of X (and p).\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function F mathcal M  ‚Ñù to minimize\ngrad_f ‚Äì the gradient operatornamegradf mathcal M  Tmathcal M of f\nHess_f ‚Äì the hessian operatornameHessf(x) T_pmathcal M  T_pmathcal M, X  operatornameHessf(p)X\np ‚Äì a point on the manifold p  mathcal M\nX ‚Äì an update tangential vector X  T_xmathcal M\n\nFor more details and all optional arguments, see truncated_conjugate_gradient_descent.\n\n\n\n\n\n","category":"function"},{"location":"solvers/truncated_conjugate_gradient_descent/#State","page":"Steihaug-Toint TCG Method","title":"State","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"TruncatedConjugateGradientState","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.TruncatedConjugateGradientState","page":"Steihaug-Toint TCG Method","title":"Manopt.TruncatedConjugateGradientState","text":"TruncatedConjugateGradientState <: AbstractHessianSolverState\n\ndescribe the Steihaug-Toint truncated conjugate-gradient method, with\n\nFields\n\na default value is given in brackets if a parameter can be left out in initialization.\n\nx : a point, where the trust-region subproblem needs   to be solved\nŒ∑ : a tangent vector (called update vector), which solves the   trust-region subproblem after successful calculation by the algorithm\nstop : a StoppingCriterion.\ngradient : the gradient at the current iterate\nŒ¥ : search direction\ntrust_region_radius : (injectivity_radius(M)/4) the trust-region radius\nresidual : the gradient\nrandomize : indicates if the trust-region solve and so the algorithm is to be       initiated with a random tangent vector. If set to true, no       preconditioner will be used. This option is set to true in some       scenarios to escape saddle points, but is otherwise seldom activated.\nproject! : (copyto!) specify a projection operation for tangent vectors   for numerical stability. A function (M, Y, p, X) -> ... working in place of Y.   per default, no projection is perfomed, set it to project! to activate projection.\n\nConstructor\n\nTruncatedConjugateGradientState(M, p=rand(M), Œ∑=zero_vector(M,p);\n    trust_region_radius=injectivity_radius(M)/4,\n    randomize=false,\n    Œ∏=1.0,\n    Œ∫=0.1,\n    project!=copyto!,\n)\n\nand a slightly involved `stopping_criterion`\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Stopping-Criteria","page":"Steihaug-Toint TCG Method","title":"Stopping Criteria","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"StopWhenResidualIsReducedByFactorOrPower\nStopWhenTrustRegionIsExceeded\nStopWhenCurvatureIsNegative\nStopWhenModelIncreased\nupdate_stopping_criterion!(::StopWhenResidualIsReducedByFactorOrPower, ::Val{:ResidualPower}, ::Any)\nupdate_stopping_criterion!(::StopWhenResidualIsReducedByFactorOrPower, ::Val{:ResidualFactor}, ::Any)","category":"page"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenResidualIsReducedByFactorOrPower","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenResidualIsReducedByFactorOrPower","text":"StopWhenResidualIsReducedByFactorOrPower <: StoppingCriterion\n\nA functor for testing if the norm of residual at the current iterate is reduced either by a power of 1+Œ∏ or by a factor Œ∫ compared to the norm of the initial residual, i.e. Vert r_k Vert_x leqq Vert r_0 Vert_x \nmin left( kappa Vert r_0 Vert_x^theta right).\n\nFields\n\nŒ∫ ‚Äì the reduction factor\nŒ∏ ‚Äì part of the reduction power\nreason ‚Äì stores a reason of stopping if the stopping criterion has one be   reached, see get_reason.\n\nConstructor\n\nStopWhenResidualIsReducedByFactorOrPower(; Œ∫=0.1, Œ∏=1.0)\n\ninitialize the StopWhenResidualIsReducedByFactorOrPower functor to indicate to stop after the norm of the current residual is lesser than either the norm of the initial residual to the power of 1+Œ∏ or the norm of the initial residual times Œ∫.\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenTrustRegionIsExceeded","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenTrustRegionIsExceeded","text":"StopWhenTrustRegionIsExceeded <: StoppingCriterion\n\nA functor for testing if the norm of the next iterate in the  Steihaug-Toint tcg mehtod is larger than the trust-region radius, i.e. Vert Œ∑_k^* Vert_x  trust_region_radius. terminate the algorithm when the trust region has been left.\n\nFields\n\nreason ‚Äì stores a reason of stopping if the stopping criterion has one be   reached, see get_reason.\n\nConstructor\n\nStopWhenTrustRegionIsExceeded()\n\ninitialize the StopWhenTrustRegionIsExceeded functor to indicate to stop after the norm of the next iterate is greater than the trust-region radius.\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenCurvatureIsNegative","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenCurvatureIsNegative","text":"StopWhenCurvatureIsNegative <: StoppingCriterion\n\nA functor for testing if the curvature of the model is negative, i.e. langle delta_k operatornameHessF(delta_k)rangle_x leqq 0. In this case, the model is not strictly convex, and the stepsize as computed does not give a reduction of the model.\n\nFields\n\nreason ‚Äì stores a reason of stopping if the stopping criterion has one be   reached, see get_reason.\n\nConstructor\n\nStopWhenCurvatureIsNegative()\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.StopWhenModelIncreased","page":"Steihaug-Toint TCG Method","title":"Manopt.StopWhenModelIncreased","text":"StopWhenModelIncreased <: StoppingCriterion\n\nA functor for testing if the curvature of the model value increased.\n\nFields\n\nreason ‚Äì stores a reason of stopping if the stopping criterion has one be   reached, see get_reason.\n\nConstructor\n\nStopWhenModelIncreased()\n\nSee also\n\ntruncated_conjugate_gradient_descent, trust_regions\n\n\n\n\n\n","category":"type"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.update_stopping_criterion!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualPower}, Any}","page":"Steihaug-Toint TCG Method","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualPower, v)\n\nUpdate the residual Power Œ∏  to v.\n\n\n\n\n\n","category":"method"},{"location":"solvers/truncated_conjugate_gradient_descent/#Manopt.update_stopping_criterion!-Tuple{StopWhenResidualIsReducedByFactorOrPower, Val{:ResidualFactor}, Any}","page":"Steihaug-Toint TCG Method","title":"Manopt.update_stopping_criterion!","text":"update_stopping_criterion!(c::StopWhenResidualIsReducedByFactorOrPower, :ResidualFactor, v)\n\nUpdate the residual Factor Œ∫ to v.\n\n\n\n\n\n","category":"method"},{"location":"solvers/truncated_conjugate_gradient_descent/#Literature","page":"Steihaug-Toint TCG Method","title":"Literature","text":"","category":"section"},{"location":"solvers/truncated_conjugate_gradient_descent/","page":"Steihaug-Toint TCG Method","title":"Steihaug-Toint TCG Method","text":"<ul>\n<li id=\"AbsilMahonySepulchre2008\">[<a>Absil, Mahony, Sepulchre, 2008</a>]\n  Absil, Pierre-Antoine and Mahony, Robert and Sepulchre, Rodolphe:\n  <emph> Optimization Algorithms on Matrix Manifolds </emph>\n  Mathematics of Computation - Math. Comput., Volume 78.\n  doi: <a href=\"https://doi.org/10.1515/9781400830244\">10.1515/9781400830244</a>,\n</li>\n</ul>","category":"page"},{"location":"solvers/LevenbergMarquardt/#Levenberg-Marquardt","page":"Levenberg‚ÄìMarquardt","title":"Levenberg-Marquardt","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/","page":"Levenberg‚ÄìMarquardt","title":"Levenberg‚ÄìMarquardt","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/LevenbergMarquardt/","page":"Levenberg‚ÄìMarquardt","title":"Levenberg‚ÄìMarquardt","text":"LevenbergMarquardt\nLevenbergMarquardt!","category":"page"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt","page":"Levenberg‚ÄìMarquardt","title":"Manopt.LevenbergMarquardt","text":"LevenbergMarquardt(M, f, jacobian_f, p, num_components=-1)\n\nSolve an optimization problem of the form\n\noperatornameargmin_p  mathcal M frac12 lVert f(p) rVert^2\n\nwhere fcolonmathcal M to ‚Ñù^d is a continuously differentiable function, using the Riemannian Levenberg-Marquardt algorithm [Peeters1993]. The implementation follows Algorithm 1[Adachi2022].\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function F mathcal M‚Ñù^d\njacobian_f ‚Äì the Jacobian of f. The Jacobian jacF is supposed to accept a keyword argument basis_domain which specifies basis of the tangent space at a given point in which the Jacobian is to be calculated. By default it should be the DefaultOrthonormalBasis.\np ‚Äì an initial value p  mathcal M\nnum_components ‚Äì length of the vector returned by the cost function (d). By default its value is -1 which means that it will be determined automatically by calling F one additional time. Only possible when evaluation is AllocatingEvaluation, for mutating evaluation this must be explicitly specified.\n\nThese can also be passed as a NonlinearLeastSquaresObjective, then the keyword jacobian_tangent_basis below is ignored\n\nOptional\n\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient works by allocation (default) form gradF(M, x) or InplaceEvaluation in place, i.e. is of the form gradF!(M, X, x).\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction(M,x,Œæ) to use.\nstopping_criterion ‚Äì (StopWhenAny(StopAfterIteration(200),StopWhenGradientNormLess(1e-12))) a functor inheriting from StoppingCriterion indicating when to stop.\nexpect_zero_residual ‚Äì (false) whether or not the algorithm might expect that the value of residual (objective) at mimimum is equal to 0.\n\nAll other keyword arguments are passed to decorate_state! for decorators or decorate_objective!, respectively. If you provide the ManifoldGradientObjective directly, these decorations can still be specified\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\nReferences\n\n[Adachi2022]: S. Adachi, T. Okuno, and A. Takeda, ‚ÄúRiemannian Levenberg-Marquardt Method with Global and Local Convergence Properties.‚Äù arXiv, Oct. 01, 2022. arXiv: 2210.00253.\n\n[Peeters1993]: R. L. M. Peeters, ‚ÄúOn a Riemannian version of the Levenberg-Marquardt algorithm,‚Äù VU University Amsterdam, Faculty of Economics, Business Administration and Econometrics, Serie Research Memoranda 0011, 1993. link: https://econpapers.repec.org/paper/vuawpaper/1993-11.htm.\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardt!","page":"Levenberg‚ÄìMarquardt","title":"Manopt.LevenbergMarquardt!","text":"LevenbergMarquardt!(M, f, jacobian_f, p, num_components=-1; kwargs...)\n\nFor more options see LevenbergMarquardt.\n\n\n\n\n\n","category":"function"},{"location":"solvers/LevenbergMarquardt/#Options","page":"Levenberg‚ÄìMarquardt","title":"Options","text":"","category":"section"},{"location":"solvers/LevenbergMarquardt/","page":"Levenberg‚ÄìMarquardt","title":"Levenberg‚ÄìMarquardt","text":"LevenbergMarquardtState","category":"page"},{"location":"solvers/LevenbergMarquardt/#Manopt.LevenbergMarquardtState","page":"Levenberg‚ÄìMarquardt","title":"Manopt.LevenbergMarquardtState","text":"LevenbergMarquardtState{P,T} <: AbstractGradientSolverState\n\nDescribes a Gradient based descent algorithm, with\n\nFields\n\nA default value is given in brackets if a parameter can be left out in initialization.\n\nx ‚Äì a point (of type P) on a manifold as starting point\nstop ‚Äì (StopAfterIteration(200) | StopWhenGradientNormLess(1e-12) | StopWhenStepsizeLess(1e-12)) a StoppingCriterion\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the retraction to use, defaults to the default set for your manifold.\nresidual_values ‚Äì value of F calculated in the solver setup or the previous iteration\nresidual_values_temp ‚Äì value of F for the current proposal point\njacF ‚Äì the current Jacobian of F\ngradient ‚Äì the current gradient of F\nstep_vector ‚Äì the tangent vector at x that is used to move to the next point\nlast_stepsize ‚Äì length of step_vector\nŒ∑ ‚Äì parameter of the algorithm, the higher it is the more likely the algorithm will be to reject new proposal points\ndamping_term ‚Äì current value of the damping term\ndamping_term_min ‚Äì initial (and also minimal) value of the damping term\nŒ≤ ‚Äì parameter by which the damping term is multiplied when the current new point is rejected\nexpect_zero_residual ‚Äì (false) if true, the algorithm expects that the value of residual (objective) at mimimum is equal to 0.\n\nConstructor\n\nLevenbergMarquardtState(M, initialX, initial_residual_values, initial_jacF; initial_vector), kwargs...)\n\nGenerate Levenberg-Marquardt options.\n\nSee also\n\ngradient_descent, LevenbergMarquardt\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#ExactPenaltySolver","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"","category":"section"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"  exact_penalty_method\n  exact_penalty_method!","category":"page"},{"location":"solvers/exact_penalty_method/#Manopt.exact_penalty_method","page":"Exact Penalty Method","title":"Manopt.exact_penalty_method","text":"exact_penalty_method(M, F, gradF, p=rand(M); kwargs...)\nexact_penalty_method(M, cmo::ConstrainedManifoldObjective, p=rand(M); kwargs...)\n\nperform the exact penalty method (EPM)[LiuBoumal2020]. The aim of the EPM is to find a solution of the constrained optimisation task\n\nbeginaligned\nmin_p mathcalM f(p)\ntextsubject to  g_i(p)leq 0 quad text for  i= 1  m\nquad h_j(p)=0 quad  text for  j=1n\nendaligned\n\nwhere M is a Riemannian manifold, and f, g_i_i=1^m and h_j_j=1^n are twice continuously differentiable functions from M to ‚Ñù. For that a weighted L_1-penalty term for the violation of the constraints is added to the objective\n\nf(x) + œÅ (sum_i=1^m maxleft0 g_i(x)right + sum_j=1^n vert h_j(x)vert)\n\nwhere œÅ0 is the penalty parameter. Since this is non-smooth, a SmoothingTechnique with parameter u is applied, see the ExactPenaltyCost.\n\nIn every step k of the exact penalty method, the smoothed objective is then minimized over all x mathcalM. Then, the accuracy tolerance œµ and the smoothing parameter u are updated by setting\n\nœµ^(k)=maxœµ_min Œ∏_œµ œµ^(k-1)\n\nwhere œµ_min is the lowest value œµ is allowed to become and Œ∏_œµ  (01) is constant scaling factor, and\n\nu^(k) = max u_min theta_u u^(k-1) \n\nwhere u_min is the lowest value u is allowed to become and Œ∏_u  (01) is constant scaling factor.\n\nLast, we update the penalty parameter œÅ according to\n\nœÅ^(k) = begincases\nœÅ^(k-1)Œ∏_œÅ   textif  displaystyle max_j in mathcalEi in mathcalI Bigl vert h_j(x^(k)) vert g_i(x^(k))Bigr geq u^(k-1) Bigr) \nœÅ^(k-1)  textelse\nendcases\n\nwhere Œ∏_œÅ in (01) is a constant scaling factor.\n\n[LiuBoumal2020]: C. Liu, N. Boumal, Simple Algorithms for Optimization on Riemannian Manifolds with Constraints, In: Applied Mathematics & Optimization, vol 82, 949‚Äì981 (2020), doi 10.1007/s00245-019-09564-3, arXiv: 1901.10000. Matlab source: https://github.com/losangle/Optimization-on-manifolds-with-extra-constraints\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function fmathcal M‚Ñù to minimize\ngrad_f ‚Äì the gradient of the cost function\n\nOptional (if not called with the ConstrainedManifoldObjective cmo)\n\ng ‚Äì (nothing) the inequality constraints\nh ‚Äì (nothing) the equality constraints\ngrad_g ‚Äì (nothing) the gradient of the inequality constraints\ngrad_h ‚Äì (nothing) the gradient of the equality constraints\n\nNote that one of the pairs (g, grad_g) or (h, grad_h) has to be proviede. Otherwise the problem is not constrained and you can also call e.g. quasi_Newton\n\nOptional\n\nsmoothing ‚Äì (LogarithmicSumOfExponentials) SmoothingTechnique to use\nœµ ‚Äì (1e‚Äì3) the accuracy tolerance\nœµ_exponent ‚Äì (1/100) exponent of the œµ update factor;\nœµ_min ‚Äì (1e-6) the lower bound for the accuracy tolerance\nu ‚Äì (1e‚Äì1) the smoothing parameter and threshold for violation of the constraints\nu_exponent ‚Äì (1/100) exponent of the u update factor;\nu_min ‚Äì (1e-6) the lower bound for the smoothing parameter and threshold for violation of the constraints\nœÅ ‚Äì (1.0) the penalty parameter\nmin_stepsize ‚Äì (1e-10) the minimal step size\nsub_cost ‚Äì (ExactPenaltyCost(problem, œÅ, u; smoothing=smoothing)) use this exact penality cost, expecially with the same numbers œÅ,u as in the options for the sub problem\nsub_grad ‚Äì (ExactPenaltyGrad(problem, œÅ, u; smoothing=smoothing)) use this exact penality gradient, expecially with the same numbers œÅ,u as in the options for the sub problem\nsub_kwargs ‚Äì keyword arguments to decorate the sub options, e.g. with debug.\nsub_stopping_criterion ‚Äì (StopAfterIteration(200) |StopWhenGradientNormLess(œµ) |StopWhenStepsizeLess(1e-10)) specify a stopping criterion for the subsolver.\nsub_problem ‚Äì (DefaultManoptProblem(M,ManifoldGradientObjective(sub_cost, sub_grad; evaluation=evaluation) ‚Äì ` problem for the subsolver\nsub_state ‚Äì (QuasiNewtonState) using QuasiNewtonLimitedMemoryDirectionUpdate with InverseBFGS and sub_stopping_criterion as a stopping criterion. See also sub_kwargs.\nstopping_criterion ‚Äì (StopAfterIteration(300) | (StopWhenSmallerOrEqual(œµ, œµ_min) & StopWhenChangeLess(1e-10)) a functor inheriting from StoppingCriterion indicating when to stop.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/exact_penalty_method/#Manopt.exact_penalty_method!","page":"Exact Penalty Method","title":"Manopt.exact_penalty_method!","text":"exact_penalty_method!(M, f, grad_f, p; kwargs...)\nexact_penalty_method!(M, cmo::ConstrainedManifoldObjective, p; kwargs...)\n\nperform the exact penalty method (EPM)[LiuBoumal2020] in place of p.\n\nFor all options, see exact_penalty_method.\n\n\n\n\n\n","category":"function"},{"location":"solvers/exact_penalty_method/#State","page":"Exact Penalty Method","title":"State","text":"","category":"section"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"ExactPenaltyMethodState","category":"page"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyMethodState","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyMethodState","text":"ExactPenaltyMethodState{P,T} <: AbstractManoptSolverState\n\nDescribes the exact penalty method, with\n\nFields\n\na default value is given in brackets if a parameter can be left out in initialization.\n\np ‚Äì a set point on a manifold as starting point\nsub_problem ‚Äì an AbstractManoptProblem problem for the subsolver\nsub_state ‚Äì an AbstractManoptSolverState for the subsolver\nœµ ‚Äì (1e‚Äì3) the accuracy tolerance\nœµ_min ‚Äì (1e-6) the lower bound for the accuracy tolerance\nu ‚Äì (1e‚Äì1) the smoothing parameter and threshold for violation of the constraints\nu_min ‚Äì (1e-6) the lower bound for the smoothing parameter and threshold for violation of the constraints\nœÅ ‚Äì (1.0) the penalty parameter\nŒ∏_œÅ ‚Äì (0.3) the scaling factor of the penalty parameter\nstopping_criterion ‚Äì (StopWhenAny(StopAfterIteration(300),StopWhenAll(StopWhenSmallerOrEqual(œµ, œµ_min),StopWhenChangeLess(min_stepsize)))) a functor inheriting from StoppingCriterion indicating when to stop.\n\nConstructor\n\nExactPenaltyMethodState(M::AbstractManifold, p, sub_problem, sub_state; kwargs...)\n\nconstruct an exact penalty options with the fields and defaults as above, where the manifold M is used for defaults in the keyword arguments.\n\nSee also\n\nexact_penalty_method\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Helping-Functions","page":"Exact Penalty Method","title":"Helping Functions","text":"","category":"section"},{"location":"solvers/exact_penalty_method/","page":"Exact Penalty Method","title":"Exact Penalty Method","text":"ExactPenaltyCost\nExactPenaltyGrad\nSmoothingTechnique\nLinearQuadraticHuber\nLogarithmicSumOfExponentials","category":"page"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyCost","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyCost","text":"ExactPenaltyCost{S, Pr, R}\n\nRepresent the cost of the exact penalty method based on a ConstrainedManifoldObjective P and a parameter œÅ given by\n\nf(p) + œÅBigl(\n    sum_i=0^m max0g_i(p) + sum_j=0^n lvert h_j(p)rvert\nBigr)\n\nwhere we use an additional parameter u and a smoothing technique, e.g. LogarithmicSumOfExponentials or LinearQuadraticHuber to obtain a smooth cost function. This struct is also a functor (M,p) -> v of the cost v.\n\nFields\n\nP, œÅ, u as mentioned above.\n\nConstructor\n\nExactPenaltyCost(co::ConstrainedManifoldObjective, œÅ, u; smoothing=LinearQuadraticHuber())\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.ExactPenaltyGrad","page":"Exact Penalty Method","title":"Manopt.ExactPenaltyGrad","text":"ExactPenaltyGrad{S, CO, R}\n\nRepresent the gradient of the ExactPenaltyCost based on a ConstrainedManifoldObjective co and a parameter œÅ and a smoothing technique, which uses an additional parameter u.\n\nThis struct is also a functor in both formats\n\n(M, p) -> X to compute the gradient in allocating fashion.\n(M, X, p) to compute the gradient in in-place fashion.\n\nFields\n\nP, œÅ, u as mentioned above.\n\nConstructor\n\nExactPenaltyGradient(co::ConstrainedManifoldObjective, œÅ, u; smoothing=LinearQuadraticHuber())\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.SmoothingTechnique","page":"Exact Penalty Method","title":"Manopt.SmoothingTechnique","text":"abstract type SmoothingTechnique\n\nSpecify a smoothing technique, e.g. for the ExactPenaltyCost and ExactPenaltyGrad.\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber","page":"Exact Penalty Method","title":"Manopt.LinearQuadraticHuber","text":"LinearQuadraticHuber <: SmoothingTechnique\n\nSpecify a smoothing based on max0x  mathcal P(xu) for some u, where\n\nmathcal P(x u) = begincases\n  0  text if  x leq 0\n  fracx^22u  text if  0 leq x leq u\n  x-fracu2  text if  x geq u\nendcases\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials","page":"Exact Penalty Method","title":"Manopt.LogarithmicSumOfExponentials","text":"LogarithmicSumOfExponentials <: SmoothingTechnique\n\nSpecify a smoothing based on maxab  u log(mathrme^fracau+mathrme^fracbu) for some u.\n\n\n\n\n\n","category":"type"},{"location":"solvers/exact_penalty_method/#Literature","page":"Exact Penalty Method","title":"Literature","text":"","category":"section"},{"location":"functions/proximal_maps/#proximalMapFunctions","page":"Proximal Maps","title":"Proximal Maps","text":"","category":"section"},{"location":"functions/proximal_maps/","page":"Proximal Maps","title":"Proximal Maps","text":"For a function varphimathcal M ‚Ñù the proximal map is defined as","category":"page"},{"location":"functions/proximal_maps/","page":"Proximal Maps","title":"Proximal Maps","text":"displaystyleoperatornameprox_Œªvarphi(x)\n= operatorname*argmin_y  mathcal M d_mathcal M^2(xy) + Œªvarphi(y)\nquad Œª  0","category":"page"},{"location":"functions/proximal_maps/","page":"Proximal Maps","title":"Proximal Maps","text":"where d_mathcal M mathcal M times mathcal M  ‚Ñù denotes the geodesic distance on mathcal M. While it might still be difficult to compute the minimizer, there are several proximal maps known (locally) in closed form. Furthermore if x^star  mathcal M is a minimizer of varphi, then","category":"page"},{"location":"functions/proximal_maps/","page":"Proximal Maps","title":"Proximal Maps","text":"displaystyleoperatornameprox_Œªvarphi(x^star) = x^star","category":"page"},{"location":"functions/proximal_maps/","page":"Proximal Maps","title":"Proximal Maps","text":"i.e. a minimizer is a fixed point of the proximal map.","category":"page"},{"location":"functions/proximal_maps/","page":"Proximal Maps","title":"Proximal Maps","text":"This page lists all proximal maps available within Manopt. To add you own, just extend the functions/proximal_maps.jl file.","category":"page"},{"location":"functions/proximal_maps/","page":"Proximal Maps","title":"Proximal Maps","text":"Modules = [Manopt]\nPages   = [\"proximal_maps.jl\"]","category":"page"},{"location":"functions/proximal_maps/#Manopt.project_collaborative_TV","page":"Proximal Maps","title":"Manopt.project_collaborative_TV","text":"project_collaborative_TV(M, Œª, x, Œû[, p=2,q=1])\nproject_collaborative_TV!(M, Œò, Œª, x, Œû[, p=2,q=1])\n\ncompute the projection onto collaborative Norm unit (or Œ±-) ball, i.e. of the function\n\nF^q(x) = sum_imathcal G\n  Bigl( sum_jmathcal I_i\n    sum_k=1^d lVert X_ijrVert_x^pBigr)^fracqp\n\nwhere mathcal G is the set of indices for xmathcal M and mathcal I_i is the set of its forward neighbors. The computation can also be done in place of Œò.\n\nThis is adopted from the paper by Duran, M√∂ller, Sbert, Cremers: Collaborative Total Variation: A General Framework for Vectorial TV Models (arxiv: 1508.01308), where the most inner norm is not on a manifold but on a vector space, see their Example 3 for details.\n\n\n\n\n\n","category":"function"},{"location":"functions/proximal_maps/#Manopt.prox_TV","page":"Proximal Maps","title":"Manopt.prox_TV","text":"Œæ = prox_TV(M,Œª,x [,p=1])\n\ncompute the proximal maps operatornameprox_Œªvarphi of all forward differences occurring in the power manifold array, i.e. varphi(xixj) = d_mathcal M^p(xixj) with xi and xj are array elemets of x and j = i+e_k, where e_k is the kth unit vector. The parameter Œª is the prox parameter.\n\nInput\n\nM ‚Äì a Manifold\nŒª ‚Äì a real value, parameter of the proximal map\nx ‚Äì a point.\n\nOptional\n\n(default is given in brackets)\n\np ‚Äì (1) exponent of the distance of the TV term\n\nOuput\n\ny ‚Äì resulting  point containing with all mentioned proximal points evaluated (in a cyclic order). The computation can also be done in place\n\n\n\n\n\n","category":"function"},{"location":"functions/proximal_maps/#Manopt.prox_TV-Union{Tuple{T}, Tuple{AbstractManifold, Number, Tuple{T, T}}, Tuple{AbstractManifold, Number, Tuple{T, T}, Int64}} where T","page":"Proximal Maps","title":"Manopt.prox_TV","text":"[y1,y2] = prox_TV(M, Œª, [x1,x2] [,p=1])\nprox_TV!(M, [y1,y2] Œª, [x1,x2] [,p=1])\n\nCompute the proximal map operatornameprox_Œªvarphi of œÜ(xy) = d_mathcal M^p(xy) with parameter Œª.\n\nInput\n\nM ‚Äì a Manifold\nŒª ‚Äì a real value, parameter of the proximal map\n(x1,x2) ‚Äì a tuple of two points,\n\nOptional\n\n(default is given in brackets)\n\np ‚Äì (1) exponent of the distance of the TV term\n\nOuput\n\n(y1,y2) ‚Äì resulting tuple of points of the operatornameprox_ŒªœÜ((x1,x2)). The result can also be computed in place.\n\n\n\n\n\n","category":"method"},{"location":"functions/proximal_maps/#Manopt.prox_TV2-Union{Tuple{T}, Tuple{AbstractManifold, Any, Tuple{T, T, T}}, Tuple{AbstractManifold, Any, Tuple{T, T, T}, Int64}} where T","page":"Proximal Maps","title":"Manopt.prox_TV2","text":"(y1,y2,y3) = prox_TV2(M,Œª,(x1,x2,x3),[p=1], kwargs...)\nprox_TV2!(M, y, Œª,(x1,x2,x3),[p=1], kwargs...)\n\nCompute the proximal map operatornameprox_Œªvarphi of varphi(x_1x_2x_3) = d_mathcal M^p(c(x_1x_3)x_2) with parameter Œª>0, where c(xz) denotes the mid point of a shortest geodesic from x1 to x3 that is closest to x2. The result can be computed in place of y.\n\nInput\n\nM          ‚Äì a manifold\nŒª          ‚Äì a real value, parameter of the proximal map\n(x1,x2,x3) ‚Äì a tuple of three points\np ‚Äì (1) exponent of the distance of the TV term\n\nOptional\n\nkwargs... ‚Äì parameters for the internal subgradient_method     (if M is neither Euclidean nor Circle, since for these a closed form     is given)\n\nOutput\n\n(y1,y2,y3) ‚Äì resulting tuple of points of the proximal map. The computation can also be done in place.\n\n\n\n\n\n","category":"method"},{"location":"functions/proximal_maps/#Manopt.prox_TV2-Union{Tuple{T}, Tuple{N}, Tuple{PowerManifold{N, T}, Any, Any}, Tuple{PowerManifold{N, T}, Any, Any, Int64}} where {N, T}","page":"Proximal Maps","title":"Manopt.prox_TV2","text":"y = prox_TV2(M, Œª, x[, p=1])\nprox_TV2!(M, y, Œª, x[, p=1])\n\ncompute the proximal maps operatornameprox_Œªvarphi of all centered second order differences occuring in the power manifold array, i.e. varphi(x_kx_ix_j) = d_2(x_kx_ix_j), where kj are backward and forward neighbors (along any dimension in the array of x). The parameter Œª is the prox parameter.\n\nInput\n\nM ‚Äì a Manifold\nŒª ‚Äì a real value, parameter of the proximal map\nx ‚Äì a points.\n\nOptional\n\n(default is given in brackets)\n\np ‚Äì (1) exponent of the distance of the TV term\n\nOutput\n\ny ‚Äì resulting point with all mentioned proximal points evaluated (in a cylic order). The computation can also be done in place.\n\n\n\n\n\n","category":"method"},{"location":"functions/proximal_maps/#Manopt.prox_distance","page":"Proximal Maps","title":"Manopt.prox_distance","text":"y = prox_distance(M,Œª,f,x [, p=2])\nprox_distance!(M, y, Œª, f, x [, p=2])\n\ncompute the proximal map operatornameprox_Œªvarphi with parameter Œª of œÜ(x) = frac1pd_mathcal M^p(fx). For the mutating variant the computation is done in place of y.\n\nInput\n\nM ‚Äì a Manifold mathcal M\nŒª ‚Äì the prox parameter\nf ‚Äì a point f  mathcal M (the data)\nx ‚Äì the argument of the proximal map\n\nOptional argument\n\np ‚Äì (2) exponent of the distance.\n\nOuput\n\ny ‚Äì the result of the proximal map of œÜ\n\n\n\n\n\n","category":"function"},{"location":"functions/proximal_maps/#Manopt.prox_parallel_TV","page":"Proximal Maps","title":"Manopt.prox_parallel_TV","text":"y = prox_parallel_TV(M, Œª, x [,p=1])\nprox_parallel_TV!(M, y, Œª, x [,p=1])\n\ncompute the proximal maps operatornameprox_ŒªœÜ of all forward differences occurring in the power manifold array, i.e. œÜ(x_ix_j) = d_mathcal M^p(x_ix_j) with xi and xj are array elements of x and j = i+e_k, where e_k is the kth unit vector. The parameter Œª is the prox parameter.\n\nInput\n\nM     ‚Äì a PowerManifold manifold\nŒª     ‚Äì a real value, parameter of the proximal map\nx     ‚Äì a point\n\nOptional\n\n(default is given in brackets)\n\np ‚Äì (1) exponent of the distance of the TV term\n\nOuput\n\ny  ‚Äì resulting Array of points with all mentioned proximal points evaluated (in a parallel within the arrays elements). The computation can also be done in place.\n\nSee also prox_TV\n\n\n\n\n\n","category":"function"},{"location":"plans/#planSection","page":"Specify a Solver","title":"Plans for solvers","text":"","category":"section"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"CurrentModule = Manopt","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"For any optimisation performed in Manopt.jl we need information about both the optimisation task or ‚Äúproblem‚Äù at hand as well as the solver and all its parameters. This together is called a plan in Manopt.jl and it consists of two data structures:","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"The Manopt Problem describes all static data of our task, most prominently the manifold and the objective.\nThe Solver State describes all varying data and parameters for the solver we aim to use. This also means that each solver has its own data structure for the state.","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"By splitting these two parts, we can use one problem and solve it using different solvers.","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"Still there might be the need to set certain parameters within any of these structures. For that there is","category":"page"},{"location":"plans/","page":"Specify a Solver","title":"Specify a Solver","text":"set_manopt_parameter!\nManopt.status_summary","category":"page"},{"location":"plans/#Manopt.set_manopt_parameter!","page":"Specify a Solver","title":"Manopt.set_manopt_parameter!","text":"set_manopt_parameter!(ams::AbstractManoptSolverState, element::Symbol, value)\n\nSet a certain field/element from the AbstractManoptSolverState ams to value. This function should dispatch onVal(element)`.\n\n\n\n\n\nset_manopt_parameter!(ams::AbstractManoptProblem, element::Symbol, field::Symbol , value)\n\nSet a certain field/element from the AbstractManoptProblem ams to value. This function should dispatch onVal(element)`.\n\nBy default this passes on to the inner objective, see set_manopt_parameter!\n\n\n\n\n\nset_manopt_parameter!(amo::AbstractManifoldObjective, element::Symbol, field::Symbol , value)\n\nSet a certain field/element from the AbstractManifoldObjective amo to value. This function should dispatch onVal(element)andVal{field}`.\n\n\n\n\n\nset_manopt_parameter!(f, element::Symbol , value)\n\nIn general we assume that the parameter we set refers to a functor/function. This function should dispatch on Val{element}. By default this function just returns f, so it assumes, when using just a function instead of a fuctor, the parameter element is irrelevant for this case.\n\n\n\n\n\n","category":"function"},{"location":"plans/#Manopt.status_summary","page":"Specify a Solver","title":"Manopt.status_summary","text":"status_summary(e)\n\nReturn a string reporting about the current status of e, where e is a type from Manopt, e.g. an AbstractManoptSolverStates.\n\nThis method is similar to show but just returns a string. It might also be more verbose in explaining, or hide internal information.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/ConstrainedOptimization/#How-to-do-Constrained-Optimization","page":"Do Contrained Optimization","title":"How to do Constrained Optimization","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Ronny Bergmann","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"This tutorial is a short introduction to using solvers for constraint optimisation in Manopt.jl.","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Introduction","page":"Do Contrained Optimization","title":"Introduction","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"A constraint optimisation problem is given by","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"tagP\nbeginalign*\noperatorname*argmin_pinmathcal M  f(p)\ntextsuch that quad g(p) leq 0\nquad h(p) = 0\nendalign*","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"where fcolon mathcal M  ‚Ñù is a cost function, and gcolon mathcal M  ‚Ñù^m and hcolon mathcal M  ‚Ñù^n are the inequality and equality constraints, respectively. The leq and = in (P) are meant elementwise.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"This can be seen as a balance between moving constraints into the geometry of a manifold mathcal M and keeping some, since they can be handled well in algorithms, see (Bergmann and Herzog, 2019), (Liu and Boumal, 2019) for details.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"using Distributions, LinearAlgebra, Manifolds, Manopt, Random\nRandom.seed!(42);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"In this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrayte the different available forms.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"We will consider the problem of a Nonnegative PCA, cf.¬†Section 5.1.2 in (Liu and Boumal, 2019):","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"let v_0  ‚Ñù^d, lVert v_0 rVert=1 be given spike signal, that is a signal that is sparse with only s=lfloor Œ¥d rfloor nonzero entries.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Z = sqrtœÉ v_0v_0^mathrmT+N","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"where sigma is a signal-to-noise ratio and N is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation 1d on the off-diagonals and 2d on the daigonal","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"d = 150; # dimension of v0\nœÉ = 0.1^2; # SNR\nŒ¥ = 0.1; s = Int(floor(Œ¥ * d)); # Sparsity\nS = sample(1:d, s; replace=false);\nv0 =  [i ‚àà S ? 1 / sqrt(s) : 0.0 for i in 1:d];\nN = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);\nZ = Z = sqrt(œÉ) * v0 * transpose(v0) + N;","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"In order to recover v_0 we consider the constrained optimisation problem on the sphere mathcal S^d-1 given by","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"beginalign*\noperatorname*argmin_pinmathcal S^d-1  -p^mathrmTZp^mathrmT\ntextsuch that quad p geq 0\nendalign*","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"or in the previous notation f(p) = -p^mathrmTZp^mathrmT and g(p) = -p. We first initialize the manifold under consideration","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"M = Sphere(d - 1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Sphere(149, ‚Ñù)","category":"page"},{"location":"tutorials/ConstrainedOptimization/#A-first-Augmented-Lagrangian-Run","page":"Do Contrained Optimization","title":"A first Augmented Lagrangian Run","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"We first defined f and g as usual functions","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"f(M, p) = -transpose(p) * Z * p;\ng(M, p) = -p;","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"since f is a functions defined in the embedding ‚Ñù^d as well, we obtain its gradient by projection.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"grad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"For the constraints this is a little more involved, since each function g_i = g(p)_i = p_i has to return its own gradient. These are again in the embedding just operatornamegrad g_i(p) = -e_i the i th unit vector. We can project these again onto the tangent space at p:","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"grad_g(M, p) = project.(\n    Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"We further start in a random point:","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"p0 = rand(M);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Let‚Äôs check a few things for the initial point","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"f(M, p0)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"0.0057476048331242344","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"How much the function g is positive","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"maximum(g(M, p0))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"0.17885478285466855","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Now as a first method we can just call the Augmented Lagrangian Method with a simple call:","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"@time v1 = augmented_Lagrangian_method(\n    M, f, grad_f, p0; g=g, grad_g=grad_g,\n    debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Œîp : %1.5e\"), 20, \"\\n\"],\n    stopping_criterion = StopAfterIteration(300) | (\n        StopWhenSmallerOrEqual(:œµ, 1e-5) & StopWhenChangeLess(1e-8)\n    )\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Initial F(x): 0.005748 | \n# 20    F(x): -0.123842 | Œîp : 9.99649e-01\n# 40    F(x): -0.123842 | Œîp : 4.49057e-06\n# 60    F(x): -0.123842 | Œîp : 2.43595e-07\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-5).\nThe algorithm performed a step with a change (7.297321508879131e-19) less than 9.77237220955808e-6.\n 10.721157 seconds (11.95 M allocations: 3.581 GiB, 9.04% gc time, 75.73% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Now we have both a lower function value and the point is nearly within the constraints, ‚Ä¶ up to numerical inaccuracies","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"f(M, v1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"-0.12384226501652346","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"maximum( g(M, v1) )","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"5.0016030837045246e-21","category":"page"},{"location":"tutorials/ConstrainedOptimization/#A-faster-Augmented-Lagrangian-Run","page":"Do Contrained Optimization","title":"A faster Augmented Lagrangian Run","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Now this is a little slow, so we can modify two things, that we will directly do both ‚Äì but one could also just change one of these ‚Äì :","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Gradients should be evaluated in place, so for example","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"grad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"The constraints are currently always evaluated all together, since the function grad_g always returns a vector of gradients.  We first change the constraints function into a vector of functions.  We further change the gradient both into a vector of gradient functions operatornamegrad g_i i=1ldotsd, as well as gradients that are computed in place.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"g2 = [(M, p) -> -p[i] for i in 1:d];\ngrad_g2! = [\n    (M, X, p) -> project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d\n];","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"We obtain","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"@time v2 = augmented_Lagrangian_method(\n        M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n        debug=[:Iteration, :Cost, :Stop, \" | \", (:Change, \"Œîp : %1.5e\"), 20, \"\\n\"],\n        stopping_criterion = StopAfterIteration(300) | (\n          StopWhenSmallerOrEqual(:œµ, 1e-5) & StopWhenChangeLess(1e-8)\n        )\n    );","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Initial F(x): 0.005748 | \n# 20    F(x): -0.123842 | Œîp : 9.99849e-01\n# 40    F(x): -0.123842 | Œîp : 3.34452e-04\n# 60    F(x): -0.123842 | Œîp : 8.49435e-05\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-5).\nThe algorithm performed a step with a change (2.357347845016813e-15) less than 9.77237220955808e-6.\n  3.387588 seconds (4.16 M allocations: 1.322 GiB, 5.34% gc time, 59.31% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"As a technical remark: Note that (by default) the change to InplaceEvaluations affects both the constrained solver as well as the inner solver of the subproblem in each iteration.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"f(M, v2)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"-0.12384249958168167","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"maximum(g(M, v2))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"2.561407150514962e-16","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"These are the very similar to the previous values but the solver took much less time and less memory allocations.","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Exact-Penalty-Method","page":"Do Contrained Optimization","title":"Exact Penalty Method","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"As a second solver, we have the Exact Penalty Method, which currenlty is available with two smoothing variants, which make an inner solver for smooth optimisationm, that is by default again [quasi Newton] possible: LogarithmicSumOfExponentials and LinearQuadraticHuber. We compare both here as well. The first smoothing technique is the default, so we can just call","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"@time v3 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Initial F(x): 0.005748 | \n# 50    F(x): -0.123072 | Last Change: 0.981274\n# 100   F(x): -0.123840 | Last Change: 0.014049\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (5.050819406841458e-7) less than 1.0e-6.\n  4.626740 seconds (5.81 M allocations: 3.227 GiB, 13.77% gc time, 45.82% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"We obtain a similar cost value as for the Augmented Lagrangian Solver above, but here the constraint is actually fulfilled and not just numerically ‚Äúon the boundary‚Äù.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"f(M, v3)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"-0.12384024970459133","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"maximum(g(M, v3))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"-3.5868774339445668e-6","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"The second smoothing technique is often beneficial, when we have a lot of constraints (in the above mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"@time v4 = exact_penalty_method(\n    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!,\n    evaluation=InplaceEvaluation(),\n    smoothing=LinearQuadraticHuber(),\n    debug=[:Iteration, :Cost, :Stop, \" | \", :Change, 50, \"\\n\"],\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Initial F(x): 0.005748 | \n# 50    F(x): -0.123845 | Last Change: 0.009026\n# 100   F(x): -0.123842 | Last Change: 0.000843\nThe value of the variable (œµ) is smaller than or equal to its threshold (1.0e-6).\nThe algorithm performed a step with a change (3.0927140891273913e-7) less than 1.0e-6.\n  2.296264 seconds (2.85 M allocations: 589.907 MiB, 4.87% gc time, 75.78% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"For the result we see the same behaviour as for the other smoothing.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"f(M, v4)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"-0.12384248680490538","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"maximum(g(M, v4))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"2.712001613056835e-8","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Comparing-to-the-unconstraint-solver","page":"Do Contrained Optimization","title":"Comparing to the unconstraint solver","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"We can compare this to the global optimum on the sphere, which is the unconstraint optimisation problem; we can just use Quasi Newton.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Note that this is much faster, since every iteration of the algorithms above does a quasi-Newton call as well.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"@time w1 = quasi_Newton(\n    M, f, grad_f!, p0; evaluation=InplaceEvaluation()\n);","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"  0.969769 seconds (613.48 k allocations: 60.309 MiB, 1.50% gc time, 98.03% compilation time)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"f(M, w1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"-0.1402190180980729","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"But for sure here the constraints here are not fulfilled and we have veru positive entries in g(w_1)","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"maximum(g(M, w1))","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"0.11762414497055224","category":"page"},{"location":"tutorials/ConstrainedOptimization/#Literature","page":"Do Contrained Optimization","title":"Literature","text":"","category":"section"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Bergmann, R. and Herzog, R. (2019) ‚ÄúIntrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds,‚Äù SIAM Journal on Optimization, 29(4), pp. 2423‚Äì2444. Available at: https://doi.org/10.1137/18M1181602.","category":"page"},{"location":"tutorials/ConstrainedOptimization/","page":"Do Contrained Optimization","title":"Do Contrained Optimization","text":"Liu, C. and Boumal, N. (2019) ‚ÄúSimple algorithms for optimization on Riemannian manifolds with constraints,‚Äù Applied Mathematics & Optimization [Preprint]. Available at: https://doi.org/10.1007/s00245-019-09564-3.","category":"page"},{"location":"helpers/exports/#Exports","page":"Exports","title":"Exports","text":"","category":"section"},{"location":"helpers/exports/","page":"Exports","title":"Exports","text":"Exports aim to provide a consistent generation of images of your results. For example if you record the trace your algorithm walks on the Sphere, you can easily export this trace to a rendered image using asymptote_export_S2_signals and render the result with Asymptote. Despite these, you can always record values during your iterations, and export these, for example to csv.","category":"page"},{"location":"helpers/exports/#Asymptote","page":"Exports","title":"Asymptote","text":"","category":"section"},{"location":"helpers/exports/","page":"Exports","title":"Exports","text":"The following functions provide exports both in graphics and/or raw data using Asymptote.","category":"page"},{"location":"helpers/exports/","page":"Exports","title":"Exports","text":"Modules = [Manopt]\nPages   = [\"Asymptote.jl\"]","category":"page"},{"location":"helpers/exports/#Manopt.asymptote_export_S2_data-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_S2_data","text":"asymptote_export_S2_data(filename)\n\nExport given data as an array of points on the sphere, i.e. one-, two- or three-dimensional data with points on the Sphere mathbb S^2.\n\nInput\n\nfilename ‚Äì a file to store the Asymptote code in.\n\nOptional Arguments (Data)\n\ndata ‚Äì a point representing the 1-,2-, or 3-D array of points\nelevation_color_scheme - A ColorScheme for elevation\nscale_axes - ((1/3,1/3,1/3)) move spheres closer to each other by a factor per direction\n\nOptional Arguments (Asymptote)\n\narrow_head_size - (1.8) size of the arrowheads of the vectors (in mm)\ncamera_position - position of the camrea (default: centered above xy-plane) szene\ntarget - position the camera points at (default: center of xy-plane within data).\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.asymptote_export_S2_signals-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_S2_signals","text":"asymptote_export_S2_signals(filename; points, curves, tangent_vectors, colors, options...)\n\nExport given points, curves, and tangent_vectors on the sphere mathbb S^2 to Asymptote.\n\nInput\n\nfilename ‚Äì a file to store the Asymptote code in.\n\nOptional Arguments (Data)\n\ncolors - dictionary of color arrays (indexed by symbols :points, :curves and :tvector) where each entry has to provide as least as many colors as the length of the corresponding sets.\ncurves ‚Äì an Array of Arrays of points on the sphere, where each inner array is interpreted as a curve and is accompanied by an entry within colors\npoints ‚Äì an Array of Arrays of points on the sphere where each inner array is itnerpreted as a set of points and is accompanied by an entry within colors\ntangent_vectors ‚Äì an Array of Arrays of tuples, where the first is a points, the second a tangent vector and each set of vectors is accompanied by an entry from within colors\n\nOptional Arguments (Asymptote)\n\narrow_head_size - (6.0) size of the arrowheads of the tangent vectors\narrow_head_sizes ‚Äì overrides the previous value to specify a value per tVector set.\ncamera_position - ((1., 1., 0.)) position of the camera in the Asymptote szene\nline_width ‚Äì (1.0) size of the lines used to draw the curves.\nline_widths ‚Äì overrides the previous value to specify a value per curve and tVector set.\ndot_size ‚Äì (1.0) size of the dots used to draw the points.\ndot_sizes ‚Äì overrides the previous value to specify a value per point set.\nsphere_color ‚Äì (RGBA{Float64}(0.85, 0.85, 0.85, 0.6)) color of the sphere the data is drawn on\nsphere_line_color ‚Äì  (RGBA{Float64}(0.75, 0.75, 0.75, 0.6)) color of the lines on the sphere\nsphere_line_width ‚Äì (0.5) line width of the lines on the sphere\ntarget ‚Äì ((0.,0.,0.)) position the camera points at\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.asymptote_export_SPD-Tuple{String}","page":"Exports","title":"Manopt.asymptote_export_SPD","text":"asymptote_export_SPD(filename)\n\nexport given data as a point on a Power(SymmetricPOsitiveDefinnite(3))} manifold, i.e. one-, two- or three-dimensional data with points on the manifold of symmetric positive definite matrices.\n\nInput\n\nfilename ‚Äì a file to store the Asymptote code in.\n\nOptional Arguments (Data)\n\ndata ‚Äì a point representing the 1-,2-, or 3-D array of SPD matrices\ncolor_scheme - A ColorScheme for Geometric Anisotropy Index\nscale_axes - ((1/3,1/3,1/3)) move symmetric positive definite matrices closer to each other by a factor per direction compared to the distance esimated by the maximal eigenvalue of all involved SPD points\n\nOptional Arguments (Asymptote)\n\ncamera_position - position of the camrea (default: centered above xy-plane) szene.\ntarget - position the camera points at (default: center of xy-plane within data).\n\nBoth values camera_position and target are scaled by scaledAxes*EW, where EW is the maximal eigenvalue in the data.\n\n\n\n\n\n","category":"method"},{"location":"helpers/exports/#Manopt.render_asymptote-Tuple{Any}","page":"Exports","title":"Manopt.render_asymptote","text":"render_asymptote(filename; render=4, format=\"png\", ...)\n\nrender an exported asymptote file specified in the filename, which can also be given as a relative or full path\n\nInput\n\nfilename ‚Äì filename of the exported asy and rendered image\n\nKeyword Arguments\n\nthe default values are given in brackets\n\nrender ‚Äì (4) render level of asymptote, i.e. its -render option\nformat ‚Äì (\"png\") final rendered format, i.e. asymptote's -f option\nexport_file - (the filename with format as ending) specify the export filename\n\n\n\n\n\n","category":"method"},{"location":"plans/problem/#ProblemSection","page":"Problem","title":"A Manopt Problem","text":"","category":"section"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"CurrentModule = Manopt","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"A problem describes all static data of an optimisation task and has as a super type","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"AbstractManoptProblem\nget_objective\nget_manifold","category":"page"},{"location":"plans/problem/#Manopt.AbstractManoptProblem","page":"Problem","title":"Manopt.AbstractManoptProblem","text":"AbstractManoptProblem{M<:AbstractManifold}\n\nDescribe a Riemannian optimization problem with all static (not-changing) properties.\n\nThe most prominent features that should always be stated here are\n\nthe AbstractManifold mathcal M (cf. ManifoldsBase.jl#AbstractManifold)\nthe cost function fcolon mathcal M  ‚Ñù\n\nUsually the cost should be within an AbstractManifoldObjective.\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/#Manopt.get_objective","page":"Problem","title":"Manopt.get_objective","text":"get_objective(o::AbstractManifoldObjective, recursive=true)\n\nreturn the (one step) undecorated AbstractManifoldObjective of the (possibly) decorated o. As long as your decorated objective stores the objetive within o.objective and the dispatch_objective_decorator is set to Val{true}, the internal state are extracted automatically.\n\nBy default the objective that is stored within a decorated objective is assumed to be at o.objective. Overwrtie _get_objective(o, ::Val{true}, recursive) to change this bevahiour for your objectiveo` for both the recursive and the nonrecursive case.\n\nIf recursive is set to false, only the most outer decorator is taken away instead of all.\n\n\n\n\n\nget_objective(mp::AbstractManoptProblem)\n\nreturn the objective AbstractManifoldObjective stored within an AbstractManoptProblem.\n\n\n\n\n\n","category":"function"},{"location":"plans/problem/#Manopt.get_manifold","page":"Problem","title":"Manopt.get_manifold","text":"get_manifold(amp::AbstractManoptProblem)\n\nreturn the manifold stored within an AbstractManoptProblem\n\n\n\n\n\n","category":"function"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"Usually, such a problem is determined by the manifold or domain of the optimisation and the objective with all its properties used within an algorithm ‚Äì see The Objective. For that we can just use","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"DefaultManoptProblem","category":"page"},{"location":"plans/problem/#Manopt.DefaultManoptProblem","page":"Problem","title":"Manopt.DefaultManoptProblem","text":"DefaultManoptProblem{TM <: AbstractManifold, Objective <: AbstractManifoldObjective}\n\nModel a default manifold problem, that (just) consists of the domain of optimisation, that is an AbstractManifold and an AbstractManifoldObjective\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"The exception to these are the primal dual-based solvers (Chambolle-Pock and the PD Semismooth Newton]), which both need two manifolds as their domain(s), hence thre also exists a","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"TwoManifoldProblem","category":"page"},{"location":"plans/problem/#Manopt.TwoManifoldProblem","page":"Problem","title":"Manopt.TwoManifoldProblem","text":"TwoManifoldProblem{\n    MT<:AbstractManifold,NT<:AbstractManifold,O<:AbstractManifoldObjective\n} <: AbstractManoptProblem{MT}\n\nAn abstract type for primal-dual-based problems.\n\n\n\n\n\n","category":"type"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"From the two ingredients here, you can find more information about","category":"page"},{"location":"plans/problem/","page":"Problem","title":"Problem","text":"the AbstractManifold in ManifoldsBase.jl\nthe AbstractManifoldObjective on the page about the objective.","category":"page"},{"location":"solvers/quasi_Newton/#quasiNewton","page":"Quasi-Newton","title":"Riemannian quasi-Newton methods","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"    CurrentModule = Manopt","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"    quasi_Newton\n    quasi_Newton!","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.quasi_Newton","page":"Quasi-Newton","title":"Manopt.quasi_Newton","text":"quasi_Newton(M, f, grad_f, p)\n\nPerform a quasi Newton iteration for f on the manifold M starting in the point p.\n\nThe kth iteration consists of\n\nCompute the search direction Œ∑_k = -mathcalB_k operatornamegradf (p_k) or solve mathcalH_k Œ∑_k = -operatornamegradf (p_k).\nDetermine a suitable stepsize Œ±_k along the curve gamma(Œ±) = R_p_k(Œ± Œ∑_k) e.g. by using WolfePowellLinesearch.\nCompute p_{k+1} = R_{p_k}(Œ±_k Œ∑_k)`.\nDefine s_k = T_p_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) and y_k = operatornamegradf(p_k+1) - T_p_k Œ±_k Œ∑_k(operatornamegradf(p_k)).\nCompute the new approximate Hessian H_k+1 or its inverse B_k.\n\nInput\n\nM ‚Äì a manifold mathcalM.\nf ‚Äì a cost function F  mathcalM ‚Ñù to minimize.\ngrad_f‚Äì the gradient operatornamegradF  mathcalM T_xmathcal M of F.\np ‚Äì an initial value p  mathcalM.\n\nOptional\n\nbasis ‚Äì (DefaultOrthonormalBasis()) basis within the tangent space(s) to represent the Hessian (inverse).\ncautious_update ‚Äì (false) ‚Äì whether or not to use a QuasiNewtonCautiousDirectionUpdate\ncautious_function ‚Äì ((x) -> x*10^(-4)) ‚Äì a monotone increasing function that is zero at 0 and strictly increasing at 0 for the cautious update.\ndirection_update ‚Äì (InverseBFGS()) the update rule to use.\nevaluation ‚Äì (AllocatingEvaluation) specify whether the gradient works by  allocation (default) form gradF(M, x) or InplaceEvaluation in place, i.e.  is of the form gradF!(M, X, x).\ninitial_operator ‚Äì (Matrix{Float64}(I,n,n)) initial matrix to use die the approximation, where n=manifold_dimension(M), see also scale_initial_operator.\nmemory_size ‚Äì (20) limited memory, number of s_k y_k to store. Set to a negative value to use a full memory representation\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) a retraction method to use, by default the exponential map.\nscale_initial_operator - (true) scale initial operator with fracs_ky_k_p_klVert y_krVert_p_k in the computation\nstabilize ‚Äì (true) stabilize the method numerically by projecting computed (Newton-) directions to the tangent space to reduce numerical errors\nstepsize ‚Äì (WolfePowellLinesearch(retraction_method, vector_transport_method)) specify a Stepsize.\nstopping_criterion - (StopWhenAny(StopAfterIteration(max(1000, memory_size)), StopWhenGradientNormLess(10^(-6))) specify a StoppingCriterion\nvector_transport_method ‚Äì (default_vector_transport_method(M, typeof(p))) a vector transport to use.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Manopt.quasi_Newton!","page":"Quasi-Newton","title":"Manopt.quasi_Newton!","text":"quasi_Newton!(M, F, gradF, x; options...)\n\nPerform a quasi Newton iteration for F on the manifold M starting in the point x using a retraction R and a vector transport T.\n\nInput\n\nM ‚Äì a manifold mathcalM.\nF ‚Äì a cost function F mathcalM ‚Ñù to minimize.\ngradF‚Äì the gradient operatornamegradF  mathcalM  T_xmathcal M of F implemented as gradF(M,p).\nx ‚Äì an initial value x  mathcalM.\n\nFor all optional parameters, see quasi_Newton.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/#Background","page":"Quasi-Newton","title":"Background","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"The aim is to minimize a real-valued function on a Riemannian manifold, i.e.","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"min f(x) quad x  mathcalM","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Riemannian quasi-Newtonian methods are as generalizations of their Euclidean counterparts Riemannian line search methods. These methods determine a search direction Œ∑_k  T_x_k mathcalM at the current iterate x_k and a suitable stepsize Œ±_k along gamma(Œ±) = R_x_k(Œ± Œ∑_k), where R T mathcalM mathcalM is a retraction. The next iterate is obtained by","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"x_k+1 = R_x_k(Œ±_k Œ∑_k)","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"In quasi-Newton methods, the search direction is given by","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Œ∑_k = -mathcalH_k^-1operatornamegradf (x_k) = -mathcalB_k operatornamegrad (x_k)","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where mathcalH_k  T_x_k mathcalM T_x_k mathcalM is a positive definite self-adjoint operator, which approximates the action of the Hessian operatornameHess f (x_k) and mathcalB_k = mathcalH_k^-1. The idea of quasi-Newton methods is instead of creating a complete new approximation of the Hessian operator operatornameHess f(x_k+1) or its inverse at every iteration, the previous operator mathcalH_k or mathcalB_k is updated by a convenient formula using the obtained information about the curvature of the objective function during the iteration. The resulting operator mathcalH_k+1 or mathcalB_k+1 acts on the tangent space T_x_k+1 mathcalM of the freshly computed iterate x_k+1. In order to get a well-defined method, the following requirements are placed on the new operator mathcalH_k+1 or mathcalB_k+1 that is created by an update. Since the Hessian operatornameHess f(x_k+1) is a self-adjoint operator on the tangent space T_x_k+1 mathcalM, and mathcalH_k+1 approximates it, we require that mathcalH_k+1 or mathcalB_k+1 is also self-adjoint on T_x_k+1 mathcalM. In order to achieve a steady descent, we want Œ∑_k to be a descent direction in each iteration. Therefore we require, that mathcalH_k+1 or mathcalB_k+1 is a positive definite operator on T_x_k+1 mathcalM. In order to get information about the curvature of the objective function into the new operator mathcalH_k+1 or mathcalB_k+1, we require that it satisfies a form of a Riemannian quasi-Newton equation:","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"mathcalH_k+1 T_x_k rightarrow x_k+1(R_x_k^-1(x_k+1)) = operatornamegrad(x_k+1) - T_x_k rightarrow x_k+1(operatornamegradf(x_k))","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"or","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"mathcalB_k+1 operatornamegradf(x_k+1) - T_x_k rightarrow x_k+1(operatornamegradf(x_k)) = T_x_k rightarrow x_k+1(R_x_k^-1(x_k+1))","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where T_x_k rightarrow x_k+1  T_x_k mathcalM T_x_k+1 mathcalM and the chosen retraction R is the associated retraction of T. We note that, of course, not all updates in all situations will meet these conditions in every iteration. For specific quasi-Newton updates, the fulfillment of the Riemannian curvature condition, which requires that","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"g_x_k+1(s_k y_k)  0","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"holds, is a requirement for the inheritance of the self-adjointness and positive definiteness of the mathcalH_k or mathcalB_k to the operator mathcalH_k+1 or mathcalB_k+1. Unfortunately, the fulfillment of the Riemannian curvature condition is not given by a step size alpha_k  0 that satisfies the generalized Wolfe conditions. However, in order to create a positive definite operator mathcalH_k+1 or mathcalB_k+1 in each iteration, the so-called locking condition was introduced in [HuangGallivanAbsil2015], which requires that the isometric vector transport T^S, which is used in the update formula, and its associate retraction R fulfill","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"T^Sx Œæ_x(Œæ_x) = Œ≤ T^Rx Œæ_x(Œæ_x) quad Œ≤ = fraclVert Œæ_x rVert_xlVert T^Rx Œæ_x(Œæ_x) rVert_R_x(Œæ_x)","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where T^R is the vector transport by differentiated retraction. With the requirement that the isometric vector transport T^S and its associated retraction R satisfies the locking condition and using the tangent vector","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"y_k = Œ≤_k^-1 operatornamegradf(x_k+1) - T^Sx_k Œ±_k Œ∑_k(operatornamegradf(x_k))","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"where","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Œ≤_k = fraclVert Œ±_k Œ∑_k rVert_x_klVert T^Rx_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) rVert_x_k+1","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"in the update, it can be shown that choosing a stepsize Œ±_k  0 that satisfies the Riemannian Wolfe conditions leads to the fulfillment of the Riemannian curvature condition, which in turn implies that the operator generated by the updates is positive definite. In the following we denote the specific operators in matrix notation and hence use H_k and B_k, respectively.","category":"page"},{"location":"solvers/quasi_Newton/#Direction-Updates","page":"Quasi-Newton","title":"Direction Updates","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"In general there are different ways to compute a fixed AbstractQuasiNewtonUpdateRule. In general these are represented by","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"AbstractQuasiNewtonDirectionUpdate\nQuasiNewtonMatrixDirectionUpdate\nQuasiNewtonLimitedMemoryDirectionUpdate\nQuasiNewtonCautiousDirectionUpdate","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonDirectionUpdate","page":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonDirectionUpdate","text":"AbstractQuasiNewtonDirectionUpdate\n\nAn abstract representation of an Quasi Newton Update rule to determine the next direction given current QuasiNewtonState.\n\nAll subtypes should be functors, i.e. one should be able to call them as H(M,x,d) to compute a new direction update.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonMatrixDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonMatrixDirectionUpdate","text":"QuasiNewtonMatrixDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThese AbstractQuasiNewtonDirectionUpdates represent any quasi-Newton update rule, where the operator is stored as a matrix. A distinction is made between the update of the approximation of the Hessian, H_k mapsto H_k+1, and the update of the approximation of the Hessian inverse, B_k mapsto B_k+1. For the first case, the coordinates of the search direction Œ∑_k with respect to a basis b_i^n_i=1 are determined by solving a linear system of equations, i.e.\n\ntextSolve quad hatŒ∑_k = - H_k widehatoperatornamegradf(x_k)\n\nwhere H_k is the matrix representing the operator with respect to the basis b_i^n_i=1 and widehatoperatornamegradf(x_k) represents the coordinates of the gradient of the objective function f in x_k with respect to the basis b_i^n_i=1. If a method is chosen where Hessian inverse is approximated, the coordinates of the search direction Œ∑_k with respect to a basis b_i^n_i=1 are obtained simply by matrix-vector multiplication, i.e.\n\nhatŒ∑_k = - B_k widehatoperatornamegradf(x_k)\n\nwhere B_k is the matrix representing the operator with respect to the basis b_i^n_i=1 and widehatoperatornamegradf(x_k) as above. In the end, the search direction Œ∑_k is generated from the coordinates hateta_k and the vectors of the basis b_i^n_i=1 in both variants. The AbstractQuasiNewtonUpdateRule indicates which quasi-Newton update rule is used. In all of them, the Euclidean update formula is used to generate the matrix H_k+1 and B_k+1, and the basis b_i^n_i=1 is transported into the upcoming tangent space T_x_k+1 mathcalM, preferably with an isometric vector transport, or generated there.\n\nFields\n\nupdate ‚Äì a AbstractQuasiNewtonUpdateRule.\nbasis ‚Äì the basis.\nmatrix ‚Äì (Matrix{Float64}(I, manifold_dimension(M), manifold_dimension(M))) the matrix which represents the approximating operator.\nscale ‚Äì (`true) indicates whether the initial matrix (= identity matrix) should be scaled before the first update.\nvector_transport_method ‚Äì (vector_transport_method)an AbstractVectorTransportMethod\n\nConstructor\n\nQuasiNewtonMatrixDirectionUpdate(M::AbstractManifold, update, basis, matrix;\nscale=true, vector_transport_method=default_vector_transport_method(M))\n\nGenerate the Update rule with defaults from a manifold and the names corresponding to the fields above.\n\nSee also\n\nQuasiNewtonLimitedMemoryDirectionUpdate QuasiNewtonCautiousDirectionUpdate AbstractQuasiNewtonDirectionUpdate\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonLimitedMemoryDirectionUpdate","text":"QuasiNewtonLimitedMemoryDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThis AbstractQuasiNewtonDirectionUpdate represents the limited-memory Riemanian BFGS update, where the approximating  operator is represented by m stored pairs of tangent vectors  widetildes_i widetildey_i_i=k-m^k-1 in the k-th iteration. For the calculation of the search direction Œ∑_k, the generalisation of the two-loop recursion is used (see [HuangGallivanAbsil2015]), since it only requires inner products and linear combinations of tangent vectors in T_x_k mathcalM. For that the stored pairs of tangent vectors  widetildes_i widetildey_i_i=k-m^k-1, the gradient operatornamegradf(x_k) of the objective function f in x_k and the positive definite self-adjoint operator\n\nmathcalB^(0)_k = fracg_x_k(s_k-1 y_k-1)g_x_k(y_k-1 y_k-1)  mathrmid_T_x_k mathcalM\n\nare used. The two-loop recursion can be understood as that the InverseBFGS update is executed m times in a row on mathcalB^(0)_k using the tangent vectors  widetildes_i widetildey_i_i=k-m^k-1, and in the same time the resulting operator mathcalB^LRBFGS_k  is directly applied on operatornamegradf(x_k). When updating there are two cases: if there is still free memory, i.e. k  m, the previously stored vector pairs  widetildes_i widetildey_i_i=k-m^k-1 have to be transported into the upcoming tangent space T_x_k+1 mathcalM; if there is no free memory, the oldest pair  widetildes_km widetildey_km has to be discarded and then all the remaining vector pairs  widetildes_i widetildey_i_i=k-m+1^k-1 are transported into the tangent space T_x_k+1 mathcalM. After that we calculate and store s_k = widetildes_k = T^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) and y_k = widetildey_k. This process ensures that new information about the objective function is always included and the old, probably no longer relevant, information is discarded.\n\nFields\n\nmemory_s ‚Äì the set of the stored (and transported) search directions times step size  widetildes_i_i=k-m^k-1.\nmemory_y ‚Äì set of the stored gradient differences  widetildey_i_i=k-m^k-1.\nŒæ ‚Äì a variable used in the two-loop recursion.\nœÅ ‚Äì a variable used in the two-loop recursion.\nscale ‚Äì\nvector_transport_method ‚Äì a AbstractVectorTransportMethod\nmessage ‚Äì a string containing a potential warning that might have appeared\n\nConstructor\n\nQuasiNewtonLimitedMemoryDirectionUpdate(\n    M::AbstractManifold,\n    x,\n    update::AbstractQuasiNewtonUpdateRule,\n    memory_size;\n    initial_vector=zero_vector(M,x),\n    scale=1.0\n    project=true\n    )\n\nSee also\n\nInverseBFGS QuasiNewtonCautiousDirectionUpdate AbstractQuasiNewtonDirectionUpdate\n\n[HuangGallivanAbsil2015]: Huang, Wen and Gallivan, K. A. and Absil, P.-A., A Broyden Class of Quasi-Newton Methods for Riemannian Optimization, SIAM J. Optim., 25 (2015), pp. 1660-1685. doi: 10.1137/140955483\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonCautiousDirectionUpdate","page":"Quasi-Newton","title":"Manopt.QuasiNewtonCautiousDirectionUpdate","text":"QuasiNewtonCautiousDirectionUpdate <: AbstractQuasiNewtonDirectionUpdate\n\nThese AbstractQuasiNewtonDirectionUpdates represent any quasi-Newton update rule, which are based on the idea of a so-called cautious update. The search direction is calculated as given in QuasiNewtonMatrixDirectionUpdate or QuasiNewtonLimitedMemoryDirectionUpdate, butut the update  then is only executed if\n\nfracg_x_k+1(y_ks_k)lVert s_k rVert^2_x_k+1 geq theta(lVert operatornamegradf(x_k) rVert_x_k)\n\nis satisfied, where theta is a monotone increasing function satisfying theta(0) = 0 and theta is strictly increasing at 0. If this is not the case, the corresponding update will be skipped, which means that for QuasiNewtonMatrixDirectionUpdate the matrix H_k or B_k is not updated. The basis b_i^n_i=1 is nevertheless transported into the upcoming tangent space T_x_k+1 mathcalM, and for QuasiNewtonLimitedMemoryDirectionUpdate neither the oldest vector pair  widetildes_km widetildey_km is discarded nor the newest vector pair  widetildes_k widetildey_k is added into storage, but all stored vector pairs  widetildes_i widetildey_i_i=k-m^k-1 are transported into the tangent space T_x_k+1 mathcalM. If InverseBFGS or InverseBFGS is chosen as update, then the resulting method follows the method of [HuangAbsilGallivan2018], taking into account that the corresponding step size is chosen.\n\nFields\n\nupdate ‚Äì an AbstractQuasiNewtonDirectionUpdate\nŒ∏ ‚Äì a monotone increasing function satisfying Œ∏(0) = 0 and Œ∏ is strictly increasing at 0.\n\nConstructor\n\nQuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonMatrixDirectionUpdate; Œ∏ = x -> x)\nQuasiNewtonCautiousDirectionUpdate(U::QuasiNewtonLimitedMemoryDirectionUpdate; Œ∏ = x -> x)\n\nGenerate a cautious update for either a matrix based or a limited memorz based update rule.\n\nSee also\n\nQuasiNewtonMatrixDirectionUpdate QuasiNewtonLimitedMemoryDirectionUpdate\n\n[HuangAbsilGallivan2018]: Huang, Wen and Absil, P.-A and Gallivan, Kyle, A Riemannian BFGS Method Without Differentiated Retraction for Nonconvex Optimization Problems, SIAM J. Optim., 28 (2018), pp. 470-495. doi: 10.1137/17M1127582\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Hessian-Update-Rules","page":"Quasi-Newton","title":"Hessian Update Rules","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"Using","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"update_hessian!","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.update_hessian!","page":"Quasi-Newton","title":"Manopt.update_hessian!","text":"update_hessian!(d, amp, st, p_old, iter)\n\nupdate the hessian wihtin the QuasiNewtonState o given a AbstractManoptProblem amp as well as the an AbstractQuasiNewtonDirectionUpdate d and the last iterate p_old. Note that the current (iterth) iterate is already stored in o.x.\n\nSee also AbstractQuasiNewtonUpdateRule for the different rules that are available within d.\n\n\n\n\n\n","category":"function"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"the following update formulae for either H_k+1 or B_k+1 are available.","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"AbstractQuasiNewtonUpdateRule\nBFGS\nDFP\nBroyden\nSR1\nInverseBFGS\nInverseDFP\nInverseBroyden\nInverseSR1","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.AbstractQuasiNewtonUpdateRule","page":"Quasi-Newton","title":"Manopt.AbstractQuasiNewtonUpdateRule","text":"AbstractQuasiNewtonUpdateRule\n\nSpecify a type for the different AbstractQuasiNewtonDirectionUpdates, that is, e.g. for a QuasiNewtonMatrixDirectionUpdate there are several differeent updates to the matrix, while the default for QuasiNewtonLimitedMemoryDirectionUpdate the most prominent is InverseBFGS.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.BFGS","page":"Quasi-Newton","title":"Manopt.BFGS","text":"BFGS <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemanian BFGS update is used in the Riemannian quasi-Newton method.\n\nWe denote by widetildeH_k^mathrmBFGS the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nH^mathrmBFGS_k+1 = widetildeH^mathrmBFGS_k  + fracy_k y^mathrmT_k s^mathrmT_k y_k - fracwidetildeH^mathrmBFGS_k s_k s^mathrmT_k widetildeH^mathrmBFGS_k s^mathrmT_k widetildeH^mathrmBFGS_k s_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.DFP","page":"Quasi-Newton","title":"Manopt.DFP","text":"DFP <: AbstractQuasiNewtonUpdateRule\n\nindicates in an AbstractQuasiNewtonDirectionUpdate that the Riemanian DFP update is used in the Riemannian quasi-Newton method.\n\nWe denote by widetildeH_k^mathrmDFP the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nH^mathrmDFP_k+1 = Bigl(\n  mathrmid_T_x_k+1 mathcalM - fracy_k s^mathrmT_ks^mathrmT_k y_k\nBigr)\nwidetildeH^mathrmDFP_k\nBigl(\n  mathrmid_T_x_k+1 mathcalM - fracs_k y^mathrmT_ks^mathrmT_k y_k\nBigr) + fracy_k y^mathrmT_ks^mathrmT_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.Broyden","page":"Quasi-Newton","title":"Manopt.Broyden","text":"Broyden <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemanian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of BFGS and DFP.\n\nWe denote by widetildeH_k^mathrmBr the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nH^mathrmBr_k+1 = widetildeH^mathrmBr_k\n  - fracwidetildeH^mathrmBr_k s_k s^mathrmT_k widetildeH^mathrmBr_ks^mathrmT_k widetildeH^mathrmBr_k s_k + fracy_k y^mathrmT_ks^mathrmT_k y_k\n  + œÜ_k s^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigl(\n        fracy_ks^mathrmT_k y_k - fracwidetildeH^mathrmBr_k s_ks^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigr)\n  Bigl(\n        fracy_ks^mathrmT_k y_k - fracwidetildeH^mathrmBr_k s_ks^mathrmT_k widetildeH^mathrmBr_k s_k\n  Bigr)^mathrmT\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively, and œÜ_k is the Broyden factor which is :constant by default but can also be set to :Davidon.\n\nConstructor\n\nBroyden(œÜ, update_rule::Symbol = :constant)\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.SR1","page":"Quasi-Newton","title":"Manopt.SR1","text":"SR1 <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the Riemanian SR1 update is used in the Riemannian quasi-Newton method.\n\nWe denote by widetildeH_k^mathrmSR1 the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nH^mathrmSR1_k+1 = widetildeH^mathrmSR1_k\n+ frac\n  (y_k - widetildeH^mathrmSR1_k s_k) (y_k - widetildeH^mathrmSR1_k s_k)^mathrmT\n\n(y_k - widetildeH^mathrmSR1_k s_k)^mathrmT s_k\n\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\nThis method can be stabilized by only performing the update if denominator is larger than rlVert s_krVert_x_k+1lVert y_k - widetildeH^mathrmSR1_k s_k rVert_x_k+1 for some r0. For more details, see Section 6.2 in [NocedalWright2006]\n\n[NocedalWright2006]: Nocedal, J., Wright, S.: Numerical Optimization, Second Edition, Springer, 2006. doi: 10.1007/978-0-387-40065-5\n\nConstructor\n\nSR1(r::Float64=-1.0)\n\nGenerate the SR1 update, which by default does not include the check (since the default sets t0`)\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseBFGS","page":"Quasi-Newton","title":"Manopt.InverseBFGS","text":"InverseBFGS <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemanian BFGS update is used in the Riemannian quasi-Newton method.\n\nWe denote by widetildeB_k^mathrmBFGS the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nB^mathrmBFGS_k+1  = Bigl(\n  mathrmid_T_x_k+1 mathcalM - fracs_k y^mathrmT_k s^mathrmT_k y_k\nBigr)\nwidetildeB^mathrmBFGS_k\nBigl(\n  mathrmid_T_x_k+1 mathcalM - fracy_k s^mathrmT_k s^mathrmT_k y_k\nBigr) + fracs_k s^mathrmT_ks^mathrmT_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseDFP","page":"Quasi-Newton","title":"Manopt.InverseDFP","text":"InverseDFP <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemanian DFP update is used in the Riemannian quasi-Newton method.\n\nWe denote by widetildeB_k^mathrmDFP the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nB^mathrmDFP_k+1 = widetildeB^mathrmDFP_k + fracs_k s^mathrmT_ks^mathrmT_k y_k\n  - fracwidetildeB^mathrmDFP_k y_k y^mathrmT_k widetildeB^mathrmDFP_ky^mathrmT_k widetildeB^mathrmDFP_k y_k\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseBroyden","page":"Quasi-Newton","title":"Manopt.InverseBroyden","text":"InverseBroyden <: AbstractQuasiNewtonUpdateRule\n\nIndicates in AbstractQuasiNewtonDirectionUpdate that the Riemanian Broyden update is used in the Riemannian quasi-Newton method, which is as a convex combination of InverseBFGS and InverseDFP.\n\nWe denote by widetildeH_k^mathrmBr the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nB^mathrmBr_k+1 = widetildeB^mathrmBr_k\n - fracwidetildeB^mathrmBr_k y_k y^mathrmT_k widetildeB^mathrmBr_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n   + fracs_k s^mathrmT_ks^mathrmT_k y_k\n + œÜ_k y^mathrmT_k widetildeB^mathrmBr_k y_k\n Bigl(\n     fracs_ks^mathrmT_k y_k - fracwidetildeB^mathrmBr_k y_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n    Bigr) Bigl(\n        fracs_ks^mathrmT_k y_k - fracwidetildeB^mathrmBr_k y_ky^mathrmT_k widetildeB^mathrmBr_k y_k\n Bigr)^mathrmT\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively, and œÜ_k is the Broyden factor which is :constant by default but can also be set to :Davidon.\n\nConstructor\n\nInverseBroyden(œÜ, update_rule::Symbol = :constant)\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Manopt.InverseSR1","page":"Quasi-Newton","title":"Manopt.InverseSR1","text":"InverseSR1 <: AbstractQuasiNewtonUpdateRule\n\nindicates in AbstractQuasiNewtonDirectionUpdate that the inverse Riemanian SR1 update is used in the Riemannian quasi-Newton method.\n\nWe denote by widetildeB_k^mathrmSR1 the operator concatenated with a vector transport and its inverse before and after to act on x_k+1 = R_x_k(Œ±_k Œ∑_k). Then the update formula reads\n\nB^mathrmSR1_k+1 = widetildeB^mathrmSR1_k\n+ frac\n  (s_k - widetildeB^mathrmSR1_k y_k) (s_k - widetildeB^mathrmSR1_k y_k)^mathrmT\n\n  (s_k - widetildeB^mathrmSR1_k y_k)^mathrmT y_k\n\n\nwhere s_k and y_k are the coordinate vectors with respect to the current basis (from QuasiNewtonState) of\n\nT^S_x_k Œ±_k Œ∑_k(Œ±_k Œ∑_k) quadtextandquad\noperatornamegradf(x_k+1) - T^S_x_k Œ±_k Œ∑_k(operatornamegradf(x_k))  T_x_k+1 mathcalM\n\nrespectively.\n\nThis method can be stabilized by only performing the update if denominator is larger than rlVert y_krVert_x_k+1lVert s_k - widetildeH^mathrmSR1_k y_k rVert_x_k+1 for some r0. For more details, see Section 6.2 in [NocedalWright2006].\n\nConstructor\n\nInverseSR1(r::Float64=-1.0)\n\nGenerate the InverseSR1 update, which by default does not include the check, since the default sets t0`.\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#State","page":"Quasi-Newton","title":"State","text":"","category":"section"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"The quasi Newton algorithm is based on a DefaultManoptProblem.","category":"page"},{"location":"solvers/quasi_Newton/","page":"Quasi-Newton","title":"Quasi-Newton","text":"QuasiNewtonState","category":"page"},{"location":"solvers/quasi_Newton/#Manopt.QuasiNewtonState","page":"Quasi-Newton","title":"Manopt.QuasiNewtonState","text":"QuasiNewtonState <: AbstractManoptSolverState\n\nThese Quasi Newton AbstractManoptSolverState represent any quasi-Newton based method and can be used with any update rule for the direction.\n\nFields\n\np ‚Äì the current iterate, a point on a manifold\nX ‚Äì the current gradient\nsk ‚Äì the current step\nyk the current gradient difference\ndirection_update - an AbstractQuasiNewtonDirectionUpdate rule.\nretraction_method ‚Äì an AbstractRetractionMethod\nstop ‚Äì a StoppingCriterion\n\nConstructor\n\nQuasiNewtonState(\n    M::AbstractManifold,\n    x;\n    initial_vector=zero_vector(M,x),\n    direction_update::D=QuasiNewtonLimitedMemoryDirectionUpdate(M, x, InverseBFGS(), 20;\n        vector_transport_method=vector_transport_method,\n    )\n    stopping_criterion=StopAfterIteration(1000) | StopWhenGradientNormLess(1e-6),\n    retraction_method::RM=default_retraction_method(M, typeof(p)),\n    vector_transport_method::VTM=default_vector_transport_method(M, typeof(p)),\n    stepsize=default_stepsize(M; QuasiNewtonState)\n)\n\nSee also\n\nquasi_Newton\n\n\n\n\n\n","category":"type"},{"location":"solvers/quasi_Newton/#Literature","page":"Quasi-Newton","title":"Literature","text":"","category":"section"},{"location":"solvers/NelderMead/#NelderMeadSolver","page":"Nelder‚ÄìMead","title":"Nelder Mead Method","text":"","category":"section"},{"location":"solvers/NelderMead/","page":"Nelder‚ÄìMead","title":"Nelder‚ÄìMead","text":"CurrentModule = Manopt","category":"page"},{"location":"solvers/NelderMead/","page":"Nelder‚ÄìMead","title":"Nelder‚ÄìMead","text":"    NelderMead\n    NelderMead!","category":"page"},{"location":"solvers/NelderMead/#Manopt.NelderMead","page":"Nelder‚ÄìMead","title":"Manopt.NelderMead","text":"NelderMead(M::AbstractManifold, f [, population::NelderMeadSimplex])\nNelderMead(M::AbstractManifold, mco::AbstractManifoldCostObjective [, population::NelderMeadSimplex])\n\nSolve a Nelder-Mead minimization problem for the cost function fcolon mathcal M on the manifold M. If the initial population p is not given, a random set of points is chosen.\n\nThis algorithm is adapted from the Euclidean Nelder-Mead method, see https://en.wikipedia.org/wiki/Nelder‚ÄìMead_method and http://www.optimization-online.org/DB_FILE/2007/08/1742.pdf.\n\nInput\n\nM ‚Äì a manifold mathcal M\nf ‚Äì a cost function to minimize\npopulation ‚Äì (n+1 rand(M)s) an initial population of n+1 points, where n is the dimension of the manifold M.\n\nOptional\n\nstopping_criterion ‚Äì (StopAfterIteration(2000) |StopWhenPopulationConcentrated()) a StoppingCriterion\nŒ± ‚Äì (1.) reflection parameter (Œ±  0)\nŒ≥ ‚Äì (2.) expansion parameter (Œ≥)\nœÅ ‚Äì (1/2) contraction parameter, 0  œÅ  frac12,\nœÉ ‚Äì (1/2) shrink coefficient, 0  œÉ  1\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the rectraction to use\ninverse_retraction_method - (default_inverse_retraction_method(M, typeof(p))) an inverse retraction to use.\n\nand the ones that are passed to decorate_state! for decorators.\n\nnote: Note\nThe manifold M used here has to either provide a mean(M, pts) or you have to load Manifolds.jl to use its statistics part.\n\nOutput\n\nthe obtained (approximate) minimizer p^*, see get_solver_return for details\n\n\n\n\n\n","category":"function"},{"location":"solvers/NelderMead/#Manopt.NelderMead!","page":"Nelder‚ÄìMead","title":"Manopt.NelderMead!","text":"NelderMead(M::AbstractManifold, f [, population::NelderMeadSimplex])\n\nSolve a Nelder Mead minimization problem for the cost function f on the manifold M. If the initial population population is not given, a random set of points is chosen. If it is given, the computation is done in place of population.\n\nFor more options see NelderMead.\n\n\n\n\n\n","category":"function"},{"location":"solvers/NelderMead/#State","page":"Nelder‚ÄìMead","title":"State","text":"","category":"section"},{"location":"solvers/NelderMead/","page":"Nelder‚ÄìMead","title":"Nelder‚ÄìMead","text":"    NelderMeadState","category":"page"},{"location":"solvers/NelderMead/#Manopt.NelderMeadState","page":"Nelder‚ÄìMead","title":"Manopt.NelderMeadState","text":"NelderMeadState <: AbstractManoptSolverState\n\nDescribes all parameters and the state of a Nealer-Mead heuristic based optimization algorithm.\n\nFields\n\nThe naming of these parameters follows the Wikipedia article of the Euclidean case. The default is given in brackets, the required value range after the description\n\npopulation ‚Äì an Array{point,1} of n+1 points x_i, i=1n+1, where n is the dimension of the manifold.\nstopping_criterion ‚Äì (StopAfterIteration(2000) |StopWhenPopulationConcentrated()) a StoppingCriterion\nŒ± ‚Äì (1.) reflection parameter (Œ±  0)\nŒ≥ ‚Äì (2.) expansion parameter (Œ≥  0)\nœÅ ‚Äì (1/2) contraction parameter, 0  œÅ  frac12,\nœÉ ‚Äì (1/2) shrink coefficient, 0  œÉ  1\np ‚Äì (copy(population.pts[1])) - a field to collect the current best value (initialized to some point here)\nretraction_method ‚Äì (default_retraction_method(M, typeof(p))) the rectraction to use.\ninverse_retraction_method - (default_inverse_retraction_method(M, typeof(p))) an inverse retraction to use.\n\nConstructors\n\nNelderMead(M[, population::NelderMeadSimplex]; kwargs...)\n\nConstruct a Nelder-Mead Option with a default popultion (if not provided) of set of dimension(M)+1 random points stored in NelderMeadSimplex.\n\nIn the constructor all fields (besides the population) are keyword arguments.\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#Simplex","page":"Nelder‚ÄìMead","title":"Simplex","text":"","category":"section"},{"location":"solvers/NelderMead/","page":"Nelder‚ÄìMead","title":"Nelder‚ÄìMead","text":"NelderMeadSimplex","category":"page"},{"location":"solvers/NelderMead/#Manopt.NelderMeadSimplex","page":"Nelder‚ÄìMead","title":"Manopt.NelderMeadSimplex","text":"NelderMeadSimplex\n\nA simplex for the Nelder-Mead algorithm.\n\nConstructors\n\nNelderMeadSimplex(M::AbstractManifold)\n\nConstruct a  simplex using n+1 random points from manifold M, where n is the manifold dimension of M.\n\nNelderMeadSimplex(\n    M::AbstractManifold,\n    p,\n    B::AbstractBasis=DefaultOrthonormalBasis();\n    a::Real=0.025,\n    retraction_method::AbstractRetractionMethod=default_retraction_method(M, typeof(p)),\n)\n\nConstruct a simplex from a basis B with one point being p and other points constructed by moving by a in each principal direction defined by basis B of the tangent space at point p using retraction retraction_method. This works similarly to how the initial simplex is constructed in the Euclidean Nelder-Mead algorithm, just in the tangent space at point p.\n\n\n\n\n\n","category":"type"},{"location":"solvers/NelderMead/#Additional-Stopping-Criteria","page":"Nelder‚ÄìMead","title":"Additional Stopping Criteria","text":"","category":"section"},{"location":"solvers/NelderMead/","page":"Nelder‚ÄìMead","title":"Nelder‚ÄìMead","text":"StopWhenPopulationConcentrated","category":"page"},{"location":"solvers/NelderMead/#Manopt.StopWhenPopulationConcentrated","page":"Nelder‚ÄìMead","title":"Manopt.StopWhenPopulationConcentrated","text":"StopWhenPopulationConcentrated <: StoppingCriterion\n\nA stopping criterion for NelderMead to indicate to stop when both\n\nthe maximal distance of the first to the remaining the cost values and\nthe maximal diistance of the first to the remaining the population points\n\ndrops below a ceertain tolerance tol_f and tol_p, respectively.\n\nConstructor\n\nStopWhenPopulationConcentrated(tol_f::Real=1e-8, tol_x::Real=1e-8)\n\n\n\n\n\n","category":"type"}]
}
