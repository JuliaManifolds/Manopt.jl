<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Do constrained Optimization · Manopt.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Manopt.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../about/">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="../Optimize!/">Get Started: Optimize!</a></li><li><a class="tocitem" href="../AutomaticDifferentiation/">Use AD in Manopt</a></li><li><a class="tocitem" href="../HowToRecord/">Record Values</a></li><li class="is-active"><a class="tocitem" href>Do constrained Optimization</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#A-first-Augmented-Lagrangian-Run"><span>A first Augmented Lagrangian Run</span></a></li><li><a class="tocitem" href="#A-faster-Augmented-Lagrangian-Run"><span>A faster Augmented Lagrangian Run</span></a></li><li><a class="tocitem" href="#Exact-Penalty-Method"><span>Exact Penalty Method</span></a></li><li><a class="tocitem" href="#Comparing-to-the-unconstraint-solver"><span>Comparing to the unconstraint solver</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../GeodesicRegression/">Do Geodesic Regression</a></li><li><a class="tocitem" href="../Bezier/">Use Bézier Curves</a></li><li><a class="tocitem" href="../SecondOrderDifference/">Compute a Second Order Difference</a></li><li><a class="tocitem" href="../StochasticGradientDescent/">Do Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../Benchmark/">Speed up! Using <code>gradF!</code></a></li><li><a class="tocitem" href="../JacobiFields/">Illustrate Jacobi Fields</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../../solvers/">Introduction</a></li><li><a class="tocitem" href="../../solvers/alternating_gradient_descent/">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/augmented_Lagrangian_method/">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../../solvers/ChambollePock/">Chambolle-Pock</a></li><li><a class="tocitem" href="../../solvers/conjugate_gradient_descent/">Conjugate gradient descent</a></li><li><a class="tocitem" href="../../solvers/cyclic_proximal_point/">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../../solvers/DouglasRachford/">Douglas–Rachford</a></li><li><a class="tocitem" href="../../solvers/exact_penalty_method/">Exact Penalty Method</a></li><li><a class="tocitem" href="../../solvers/FrankWolfe/">Frank-Wolfe</a></li><li><a class="tocitem" href="../../solvers/gradient_descent/">Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/NelderMead/">Nelder–Mead</a></li><li><a class="tocitem" href="../../solvers/particle_swarm/">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../../solvers/primal_dual_semismooth_Newton/">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../../solvers/quasi_Newton/">Quasi-Newton</a></li><li><a class="tocitem" href="../../solvers/stochastic_gradient_descent/">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/subgradient/">Subgradient method</a></li><li><a class="tocitem" href="../../solvers/truncated_conjugate_gradient_descent/">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../../solvers/trust_regions/">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/robustPCA/">Robust PCA</a></li><li><a class="tocitem" href="../../examples/smallestEigenvalue/">Rayleigh quotient</a></li><li><a class="tocitem" href="../../examples/FrankWolfeSPDMean/">Frank Wolfe for Riemannian Center of Mass</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../../plans/">Specify a Solver</a></li><li><a class="tocitem" href="../../plans/problem/">Problem</a></li><li><a class="tocitem" href="../../plans/options/">Options</a></li><li><a class="tocitem" href="../../plans/stepsize/">Stepsize</a></li><li><a class="tocitem" href="../../plans/stopping_criteria/">Stopping Criteria</a></li><li><a class="tocitem" href="../../plans/debug/">Debug Output</a></li><li><a class="tocitem" href="../../plans/record/">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../../functions/">Introduction</a></li><li><a class="tocitem" href="../../functions/bezier/">Bézier curves</a></li><li><a class="tocitem" href="../../functions/costs/">Cost functions</a></li><li><a class="tocitem" href="../../functions/differentials/">Differentials</a></li><li><a class="tocitem" href="../../functions/adjointdifferentials/">Adjoint Differentials</a></li><li><a class="tocitem" href="../../functions/gradients/">Gradients</a></li><li><a class="tocitem" href="../../functions/Jacobi_fields/">Jacobi Fields</a></li><li><a class="tocitem" href="../../functions/proximal_maps/">Proximal Maps</a></li><li><a class="tocitem" href="../../functions/manifold/">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../../helpers/checks/">Checks</a></li><li><a class="tocitem" href="../../helpers/data/">Data</a></li><li><a class="tocitem" href="../../helpers/errorMeasures/">Error Measures</a></li><li><a class="tocitem" href="../../helpers/exports/">Exports</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../../notation/">Notation</a></li><li><a class="tocitem" href="../../list/">Function Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to...</a></li><li class="is-active"><a href>Do constrained Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Do constrained Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/main/nothing" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><style>
    table {
        display: table !important;
        margin: 2rem auto !important;
        border-top: 2pt solid rgba(0,0,0,0.2);
        border-bottom: 2pt solid rgba(0,0,0,0.2);
    }

    pre, div {
        margin-top: 1.4rem !important;
        margin-bottom: 1.4rem !important;
    }

    .code-output {
        padding: 0.7rem 0.5rem !important;
    }

    .admonition-body {
        padding: 0em 1.25em !important;
    }
</style>

<!-- PlutoStaticHTML.Begin -->
<!--
    # This information is used for caching.
    [PlutoStaticHTML.State]
    input_sha = "84269f22fa79bd9e01e506480dda0cc088a5a8c62035e7cae83ad190052be488"
    julia_version = "1.8.3"
-->

<div class="markdown"><h1>How to do Constrained Optimization</h1><p>This tutorial is a short introduction to using solvers for constraint optimisation in <a href="https://manoptjl.org"><code>Manopt.jl</code></a>.</p></div>

<h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><div class="markdown">
<p>A constraint optimisation problem is given by</p><p class="tex">$$\tag{P}
\begin{align*}
\operatorname*{arg\,min}_{p\in\mathcal M} &amp; f(p)\\
\text{such that} &amp;\quad g(p) \leq 0\\
&amp;\quad h(p) = 0,\\
\end{align*}$$</p><p>where <span class="tex">$f\colon \mathcal M → ℝ$</span> is a cost function, and <span class="tex">$g\colon \mathcal M → ℝ^m$</span> and <span class="tex">$h\colon \mathcal M → ℝ^n$</span> are the inequality and equality constraints, respectively. The <span class="tex">$\leq$</span> and <span class="tex">$=$</span> in (P) are meant elementwise.</p><p>This can be seen as a balance between moving constraints into the geometry of a manifold <span class="tex">$\mathcal M$</span> and keeping some, since they can be handled well in algorithms, see <a class="footnote" href="#footnote-BergmannHerzog2019">[BergmannHerzog2019]</a>, <a class="footnote" href="#footnote-LiuBoumal2020">[LiuBoumal2020]</a> for details.</p></div>


<div class="markdown"><p>Let's first again load the necessary packages</p></div>

<pre class='language-julia'><code class='language-julia'>using Distributions, LinearAlgebra, Manifolds, Manopt, Random, PlutoUI</code></pre>


<pre class='language-julia'><code class='language-julia'>Random.seed!(42);</code></pre>



<div class="markdown"><p>In this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrayte the different available forms.</p></div>


<div class="markdown"><p>We will consider the problem of a Nonnegative PCA, cf. Section 5.1.2 in <a class="footnote" href="#footnote-LiuBoumal2020">[LiuBoumal2020]</a>:</p><p>let <span class="tex">$v_0 ∈ ℝ^d$</span>, <span class="tex">$\lVert v_0 \rVert=1$</span> be given spike signal, that is a signal that is sparse with only <span class="tex">$s=\lfloor δd \rfloor$</span> nonzero entries.</p><p class="tex">$$  Z = \sqrt{σ} v_0v_0^{\mathrm{T}}+N,$$</p><p>where <span class="tex">$\sigma$</span> is a signal-to-noise ratio and <span class="tex">$N$</span> is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation <span class="tex">$1/d$</span> on the off-diagonals and <span class="tex">$2/d$</span> on the daigonal</p></div>

<pre class='language-julia'><code class='language-julia'>d = 150; # dimension of v0</code></pre>


<pre class='language-julia'><code class='language-julia'>σ = 0.1^2; # SNR</code></pre>


<pre class='language-julia'><code class='language-julia'>δ = 0.1; s = Int(floor(δ * d)); # Sparsity</code></pre>


<pre class='language-julia'><code class='language-julia'>S = sample(1:d, s; replace=false);</code></pre>


<pre class='language-julia'><code class='language-julia'>v0 =  [i ∈ S ? 1 / sqrt(s) : 0.0 for i in 1:d];</code></pre>


<pre class='language-julia'><code class='language-julia'>N = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);</code></pre>


<pre class='language-julia'><code class='language-julia'> Z = Z = sqrt(σ) * v0 * transpose(v0) + N;</code></pre>



<div class="markdown"><p>In order to recover <span class="tex">$v_0$</span> we consider the constrained optimisation problem on the sphere <span class="tex">$\mathcal S^{d-1}$</span> given by</p><p class="tex">$$\begin{align*}
\operatorname*{arg\,min}_{p\in\mathcal S^{d-1}} &amp; -p^{\mathrm{T}}Zp^{\mathrm{T}}\\
\text{such that} &amp;\quad p \geq 0\\
\end{align*}$$</p><p>or in the previous notation <span class="tex">$f(p) = -p^{\mathrm{T}}Zp^{\mathrm{T}}$</span> and <span class="tex">$g(p) = -p$</span>. We first initialize the manifold under consideration</p></div>

<pre class='language-julia'><code class='language-julia'>M = Sphere(d - 1)</code></pre>
<pre class="code-output documenter-example-output" id="var-M">Sphere(149, ℝ)</pre>

<h2 id="A-first-Augmented-Lagrangian-Run"><a class="docs-heading-anchor" href="#A-first-Augmented-Lagrangian-Run">A first Augmented Lagrangian Run</a><a id="A-first-Augmented-Lagrangian-Run-1"></a><a class="docs-heading-anchor-permalink" href="#A-first-Augmented-Lagrangian-Run" title="Permalink"></a></h2><div class="markdown">
<p>We first defined <span class="tex">$f$</span>  and <span class="tex">$g$</span> as usual functions</p></div>

<pre class='language-julia'><code class='language-julia'>f(M, p) = -transpose(p) * Z * p;</code></pre>


<pre class='language-julia'><code class='language-julia'>g(M, p) = -p;</code></pre>



<div class="markdown"><p>since <span class="tex">$f$</span> is a functions defined in the embedding <span class="tex">$ℝ^d$</span> as well, we obtain its gradient by projection.</p></div>

<pre class='language-julia'><code class='language-julia'>grad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p);</code></pre>



<div class="markdown"><p>For the constraints this is a little more involved, since each function <span class="tex">$g_i = g(p)_i = p_i$</span> has to return its own gradient. These are again in the embedding just <span class="tex">$\operatorname{grad} g_i(p) = -e_i$</span> the <span class="tex">$i$</span> th unit vector. We can project these again onto the tangent space at <span class="tex">$p$</span>:</p></div>

<pre class='language-julia'><code class='language-julia'>grad_g(M, p) = project.(
    Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]
);</code></pre>



<div class="markdown"><p>We further start in a random point:</p></div>

<pre class='language-julia'><code class='language-julia'>x0 = random_point(M);</code></pre>



<div class="markdown"><p>Let's check a few things for the initial point</p></div>

<pre class='language-julia'><code class='language-julia'>f(M, x0)</code></pre>
<pre class="code-output documenter-example-output" id="var-hash480326">0.0016721209906309096</pre>


<div class="markdown"><p>How much the function g is positive</p></div>

<pre class='language-julia'><code class='language-julia'>maximum(g(M, x0))</code></pre>
<pre class="code-output documenter-example-output" id="var-hash676505">0.21740156992394805</pre>


<div class="markdown"><p>Now as a first method we can just call the <a href="https://manoptjl.org/stable/solvers/augmented_Lagrangian_method/">Augmented Lagrangian Method</a> with a simple call:</p></div>

<pre class='language-julia'><code class='language-julia'>with_terminal() do
    @time global v1 = augmented_Lagrangian_method(
    	M, f, grad_f, x0; G=g, gradG=grad_g,
    	debug=[:Iteration, :Cost, :Stop, " | ", :Change, 50, "\n"],
    );
end</code></pre>
<pre id="plutouiterminal">Initial F(x): 0.001672 | 
# 50    F(x): -0.128677 | Last Change: 1.042303
# 100   F(x): -0.128677 | Last Change: 0.000000
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (3.332000937312528e-8) less than 1.0e-6.
 19.057699 seconds (30.01 M allocations: 16.764 GiB, 19.11% gc time, 31.09% compilation time)
</pre>


<div class="markdown"><p>Now we have both a lower function value and the point is nearly within the constraints, ... up to numerical inaccuracies</p></div>

<pre class='language-julia'><code class='language-julia'>f(M, v1)</code></pre>
<pre class="code-output documenter-example-output" id="var-hash810540">-0.12867704687272666</pre>

<pre class='language-julia'><code class='language-julia'>maximum( g(M, v1) )</code></pre>
<pre class="code-output documenter-example-output" id="var-hash168124">5.1445477966707756e-20</pre>

<h2 id="A-faster-Augmented-Lagrangian-Run"><a class="docs-heading-anchor" href="#A-faster-Augmented-Lagrangian-Run">A faster Augmented Lagrangian Run</a><a id="A-faster-Augmented-Lagrangian-Run-1"></a><a class="docs-heading-anchor-permalink" href="#A-faster-Augmented-Lagrangian-Run" title="Permalink"></a></h2><div class="markdown">
</div>


<div class="markdown"><p>Now this is a little slow, so we can modify two things, that we will directly do both – but one could also just change one of these – :</p><ol><li><p>Gradients should be evaluated in place, so for example</p></li></ol></div>

<pre class='language-julia'><code class='language-julia'>grad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p);</code></pre>



<div class="markdown"><ol start="2"><li><p>The constraints are currently always evaluated all together, since the function <code>grad_g</code> always returns a vector of gradients.</p></li></ol><p>We first change the constraints function into a vector of functions. We further change the gradient <em>both</em> into a vector of gradient functions <span class="tex">$\operatorname{grad} g_i, i=1,\ldots,d$</span>, <em>as well as</em> gradients that are computed in place.</p></div>

<pre class='language-julia'><code class='language-julia'>g2 = [(M, p) -&gt; -p[i] for i in 1:d];</code></pre>


<pre class='language-julia'><code class='language-julia'>grad_g2! = [
    (M, X, p) -&gt; project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d
];</code></pre>


<pre class='language-julia'><code class='language-julia'>with_terminal() do
    @time global v2 = augmented_Lagrangian_method(
    	M, f, grad_f!, x0; G=g2, gradG=grad_g2!, evaluation=MutatingEvaluation(),
    	debug=[:Iteration, :Cost, :Stop, " | ", :Change, 50, "\n"],
    );
end</code></pre>
<pre id="plutouiterminal">Initial F(x): 0.001672 | 
# 50    F(x): -0.128677 | Last Change: 1.042402
# 100   F(x): -0.128677 | Last Change: 0.000000
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (0.0) less than 1.0e-6.
  3.271136 seconds (4.87 M allocations: 3.367 GiB, 15.35% gc time, 48.27% compilation time)
</pre>


<div class="markdown"><p>As a technical remark: Note that (by default) the change to <a href="https://manoptjl.org/stable/plans/problem/#Manopt.MutatingEvaluation"><code>MutatingEvaluation</code></a>s affects both the constrained solver as well as the inner solver of the subproblem in each iteration.</p></div>

<pre class='language-julia'><code class='language-julia'>f(M, v2)</code></pre>
<pre class="code-output documenter-example-output" id="var-hash792719">-0.12867704079630077</pre>

<pre class='language-julia'><code class='language-julia'>maximum(g(M, v2))</code></pre>
<pre class="code-output documenter-example-output" id="var-hash126869">5.174781713125965e-10</pre>


<div class="markdown"><p>These are the very similar to the previous values but the solver took much less time and less memory allocations.</p></div>

<h2 id="Exact-Penalty-Method"><a class="docs-heading-anchor" href="#Exact-Penalty-Method">Exact Penalty Method</a><a id="Exact-Penalty-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Exact-Penalty-Method" title="Permalink"></a></h2><div class="markdown">
</div>


<div class="markdown"><p>As a second solver, we have the <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/">Exact Penalty Method</a>, which currenlty is available with two smoothing variants, which make an inner solver for smooth optimisationm, that is by default again [quasi Newton] possible: <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials"><code>LogarithmicSumOfExponentials</code></a> and <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber"><code>LinearQuadraticHuber</code></a>. We compare both here as well. The first smoothing technique is the default, so we can just call</p></div>

<pre class='language-julia'><code class='language-julia'>with_terminal() do
    @time global v3 = exact_penalty_method(
    	M, f, grad_f!, x0; G=g2, gradG=grad_g2!, evaluation=MutatingEvaluation(),
    	debug=[:Iteration, :Cost, :Stop, " | ", :Change, 50, "\n"],
    );
end</code></pre>
<pre id="plutouiterminal">Initial F(x): 0.001672 | 
# 50    F(x): -0.127799 | Last Change: 1.022585
# 100   F(x): -0.128674 | Last Change: 0.014687
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (1.4901161193847656e-8) less than 1.0e-6.
  3.163171 seconds (5.79 M allocations: 3.803 GiB, 14.85% gc time, 43.74% compilation time)
</pre>


<div class="markdown"><p>We obtain a similar cost value as for the Augmented Lagrangian Solver above, but here the constraint is actually fulfilled and not just numerically “on the boundary”.</p></div>

<pre class='language-julia'><code class='language-julia'>f(M, v3)</code></pre>
<pre class="code-output documenter-example-output" id="var-hash372234">-0.1286746197071847</pre>

<pre class='language-julia'><code class='language-julia'>maximum(g(M, v3))</code></pre>
<pre class="code-output documenter-example-output" id="var-hash114721">-3.58797728898447e-6</pre>


<div class="markdown"><p>The second smoothing technique is often beneficial, when we have a lot of constraints (in the above mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time.</p></div>

<pre class='language-julia'><code class='language-julia'>with_terminal() do
    @time global v4 = exact_penalty_method(
    	M, f, grad_f!, x0; G=g2, gradG=grad_g2!, evaluation=MutatingEvaluation(),
        smoothing=LinearQuadraticHuber(),
    	debug=[:Iteration, :Cost, :Stop, " | ", :Change, 50, "\n"],
    );
end</code></pre>
<pre id="plutouiterminal">Initial F(x): 0.001672 | 
# 50    F(x): -0.128680 | Last Change: 0.009615
# 100   F(x): -0.128677 | Last Change: 0.000728
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (2.9802322387695312e-8) less than 1.0e-6.
  1.527700 seconds (3.23 M allocations: 731.238 MiB, 7.21% gc time, 69.90% compilation time)
</pre>


<div class="markdown"><p>For the result we see the same behaviour as for the other smoothing.</p></div>

<pre class='language-julia'><code class='language-julia'>f(M, v4)</code></pre>
<pre class="code-output documenter-example-output" id="var-hash501413">-0.12867708755899424</pre>

<pre class='language-julia'><code class='language-julia'>maximum(g(M, v4))</code></pre>
<pre class="code-output documenter-example-output" id="var-hash104892">2.6893626899798612e-8</pre>

<h2 id="Comparing-to-the-unconstraint-solver"><a class="docs-heading-anchor" href="#Comparing-to-the-unconstraint-solver">Comparing to the unconstraint solver</a><a id="Comparing-to-the-unconstraint-solver-1"></a><a class="docs-heading-anchor-permalink" href="#Comparing-to-the-unconstraint-solver" title="Permalink"></a></h2><div class="markdown">
<p>We can compare this to the <em>global</em> optimum on the sphere, which is the unconstraint optimisation problem; we can just use Quasi Newton.</p><p>Note that this is much faster, since every iteration of the algorithms above does a quasi-Newton call as well.</p></div>

<pre class='language-julia'><code class='language-julia'>with_terminal() do
    @time global w1 = quasi_Newton(
        M, f, grad_f!, x0; evaluation=MutatingEvaluation()
    );
end</code></pre>
<pre id="plutouiterminal">  0.492494 seconds (743.87 k allocations: 68.842 MiB, 3.29% gc time, 97.15% compilation time)
</pre>

<pre class='language-julia'><code class='language-julia'>f(M, w1)</code></pre>
<pre class="code-output documenter-example-output" id="var-hash126300">-0.14489450475637666</pre>


<div class="markdown"><p>But for sure here the constraints here are not fulfilled and we have veru positive entries in <span class="tex">$g(w_1)$</span></p></div>

<pre class='language-julia'><code class='language-julia'>maximum(g(M, w1))</code></pre>
<pre class="code-output documenter-example-output" id="var-hash765286">0.28312055236725453</pre>

<h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="markdown">
<div class="footnote" id="footnote-BergmannHerzog2019"><p class="footnote-title">BergmannHerzog2019</p><blockquote><p>R. Bergmann, R. Herzog, <strong>Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds</strong>, In: SIAM Journal on Optimization 29(4), pp. 2423–2444 (2019) doi: <a href="https://doi.org/10.1137/18M1181602">10.1137/18M1181602</a>, arXiv: <a href="https://arxiv.org/abs/1804.06214">1804.06214</a>.</p></blockquote></div><div class="footnote" id="footnote-LiuBoumal2020"><p class="footnote-title">LiuBoumal2020</p><blockquote><p>C. Liu, N. Boumal, <strong>Simple Algorithms for Optimization on Riemannian Manifolds with Constraints</strong>, In: Applied Mathematics &amp; Optimization 82, pp. 949–981 (2020), doi <a href="https://doi.org/10.1007/s00245-019-09564-3">10.1007/s00245-019-09564-3</a>, arXiv: <a href="https://arxiv.org/abs/1901.10000">1901.10000</a>.</p></blockquote></div></div>




<!-- PlutoStaticHTML.End --></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../HowToRecord/">« Record Values</a><a class="docs-footer-nextpage" href="../GeodesicRegression/">Do Geodesic Regression »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Friday 25 November 2022 07:01">Friday 25 November 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
