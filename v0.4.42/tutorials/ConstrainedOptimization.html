<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Do Constrained Optimization · Manopt.jl</title><meta name="title" content="Do Constrained Optimization · Manopt.jl"/><meta property="og:title" content="Do Constrained Optimization · Manopt.jl"/><meta property="twitter:title" content="Do Constrained Optimization · Manopt.jl"/><meta name="description" content="Documentation for Manopt.jl."/><meta property="og:description" content="Documentation for Manopt.jl."/><meta property="twitter:description" content="Documentation for Manopt.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img src="../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">Manopt.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><a class="tocitem" href="../about.html">About</a></li><li><span class="tocitem">How to...</span><ul><li><a class="tocitem" href="Optimize!.html">Get started: Optimize!</a></li><li><a class="tocitem" href="InplaceGradient.html">Speedup using Inplace computations</a></li><li><a class="tocitem" href="AutomaticDifferentiation.html">Use Automatic Differentiation</a></li><li><a class="tocitem" href="EmbeddingObjectives.html">Define Objectives in the Embedding</a></li><li><a class="tocitem" href="CountAndCache.html">Count and use a Cache</a></li><li><a class="tocitem" href="HowToDebug.html">Print Debug Output</a></li><li><a class="tocitem" href="HowToRecord.html">Record values</a></li><li><a class="tocitem" href="ImplementASolver.html">Implement a Solver</a></li><li class="is-active"><a class="tocitem" href="ConstrainedOptimization.html">Do Constrained Optimization</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#A-first-Augmented-Lagrangian-Run"><span>A first Augmented Lagrangian Run</span></a></li><li><a class="tocitem" href="#A-faster-Augmented-Lagrangian-Run"><span>A faster Augmented Lagrangian Run</span></a></li><li><a class="tocitem" href="#Exact-Penalty-Method"><span>Exact Penalty Method</span></a></li><li><a class="tocitem" href="#Comparing-to-the-unconstraint-solver"><span>Comparing to the unconstraint solver</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="GeodesicRegression.html">Do Geodesic Regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../solvers/index.html">Introduction</a></li><li><a class="tocitem" href="../solvers/adaptive-regularization-with-cubics.html">Adaptive Regularization with Cubics</a></li><li><a class="tocitem" href="../solvers/alternating_gradient_descent.html">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../solvers/augmented_Lagrangian_method.html">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../solvers/ChambollePock.html">Chambolle-Pock</a></li><li><a class="tocitem" href="../solvers/conjugate_gradient_descent.html">Conjugate gradient descent</a></li><li><a class="tocitem" href="../solvers/cyclic_proximal_point.html">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../solvers/difference_of_convex.html">Difference of Convex</a></li><li><a class="tocitem" href="../solvers/DouglasRachford.html">Douglas–Rachford</a></li><li><a class="tocitem" href="../solvers/exact_penalty_method.html">Exact Penalty Method</a></li><li><a class="tocitem" href="../solvers/FrankWolfe.html">Frank-Wolfe</a></li><li><a class="tocitem" href="../solvers/gradient_descent.html">Gradient Descent</a></li><li><a class="tocitem" href="../solvers/LevenbergMarquardt.html">Levenberg–Marquardt</a></li><li><a class="tocitem" href="../solvers/NelderMead.html">Nelder–Mead</a></li><li><a class="tocitem" href="../solvers/particle_swarm.html">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../solvers/primal_dual_semismooth_Newton.html">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../solvers/quasi_Newton.html">Quasi-Newton</a></li><li><a class="tocitem" href="../solvers/stochastic_gradient_descent.html">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../solvers/subgradient.html">Subgradient method</a></li><li><a class="tocitem" href="../solvers/truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../solvers/trust_regions.html">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../plans/index.html">Specify a Solver</a></li><li><a class="tocitem" href="../plans/problem.html">Problem</a></li><li><a class="tocitem" href="../plans/objective.html">Objective</a></li><li><a class="tocitem" href="../plans/state.html">Solver State</a></li><li><a class="tocitem" href="../plans/stepsize.html">Stepsize</a></li><li><a class="tocitem" href="../plans/stopping_criteria.html">Stopping Criteria</a></li><li><a class="tocitem" href="../plans/debug.html">Debug Output</a></li><li><a class="tocitem" href="../plans/record.html">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../functions/index.html">Introduction</a></li><li><a class="tocitem" href="../functions/bezier.html">Bézier curves</a></li><li><a class="tocitem" href="../functions/costs.html">Cost functions</a></li><li><a class="tocitem" href="../functions/differentials.html">Differentials</a></li><li><a class="tocitem" href="../functions/adjoint_differentials.html">Adjoint Differentials</a></li><li><a class="tocitem" href="../functions/gradients.html">Gradients</a></li><li><a class="tocitem" href="../functions/proximal_maps.html">Proximal Maps</a></li><li><a class="tocitem" href="../functions/manifold.html">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../helpers/checks.html">Checks</a></li><li><a class="tocitem" href="../helpers/data.html">Data</a></li><li><a class="tocitem" href="../helpers/errorMeasures.html">Error Measures</a></li><li><a class="tocitem" href="../helpers/exports.html">Exports</a></li></ul></li><li><a class="tocitem" href="../contributing.html">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../extensions.html">Extensions</a></li><li><a class="tocitem" href="../notation.html">Notation</a></li><li><a class="tocitem" href="../changelog.html">Changelog</a></li><li><a class="tocitem" href="../references.html">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to...</a></li><li class="is-active"><a href="ConstrainedOptimization.html">Do Constrained Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="ConstrainedOptimization.html">Do Constrained Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/tutorials/ConstrainedOptimization.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="How-to-do-Constrained-Optimization"><a class="docs-heading-anchor" href="#How-to-do-Constrained-Optimization">How to do Constrained Optimization</a><a id="How-to-do-Constrained-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-do-Constrained-Optimization" title="Permalink"></a></h1><p>Ronny Bergmann</p><p>This tutorial is a short introduction to using solvers for constraint optimisation in <a href="https://manoptjl.org"><code>Manopt.jl</code></a>.</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>A constraint optimisation problem is given by</p><p class="math-container">\[\tag{P}
\begin{align*}
\operatorname*{arg\,min}_{p\in\mathcal M} &amp; f(p)\\
\text{such that} &amp;\quad g(p) \leq 0\\
&amp;\quad h(p) = 0,\\
\end{align*}\]</p><p>where <span>$f\colon \mathcal M → ℝ$</span> is a cost function, and <span>$g\colon \mathcal M → ℝ^m$</span> and <span>$h\colon \mathcal M → ℝ^n$</span> are the inequality and equality constraints, respectively. The <span>$\leq$</span> and <span>$=$</span> in (P) are meant elementwise.</p><p>This can be seen as a balance between moving constraints into the geometry of a manifold <span>$\mathcal M$</span> and keeping some, since they can be handled well in algorithms, see [<a href="../references.html#BergmannHerzog:2019">BH19</a>], [<a href="../references.html#LiuBoumal:2019">LB19</a>] for details.</p><pre><code class="language-julia hljs">using Distributions, LinearAlgebra, Manifolds, Manopt, Random
Random.seed!(42);</code></pre><p>In this tutorial we want to look at different ways to specify the problem and its implications. We start with specifying an example problems to illustrayte the different available forms.</p><p>We will consider the problem of a Nonnegative PCA, cf. Section 5.1.2 in [<a href="../references.html#LiuBoumal:2019">LB19</a>]</p><p>let <span>$v_0 ∈ ℝ^d$</span>, <span>$\lVert v_0 \rVert=1$</span> be given spike signal, that is a signal that is sparse with only <span>$s=\lfloor δd \rfloor$</span> nonzero entries.</p><p class="math-container">\[Z = \sqrt{σ} v_0v_0^{\mathrm{T}}+N,\]</p><p>where <span>$\sigma$</span> is a signal-to-noise ratio and <span>$N$</span> is a matrix with random entries, where the diagonal entries are distributed with zero mean and standard deviation <span>$1/d$</span> on the off-diagonals and <span>$2/d$</span> on the daigonal</p><pre><code class="language-julia hljs">d = 150; # dimension of v0
σ = 0.1^2; # SNR
δ = 0.1; s = Int(floor(δ * d)); # Sparsity
S = sample(1:d, s; replace=false);
v0 =  [i ∈ S ? 1 / sqrt(s) : 0.0 for i in 1:d];
N = rand(Normal(0, 1 / d), (d, d)); N[diagind(N, 0)] .= rand(Normal(0, 2 / d), d);
Z = Z = sqrt(σ) * v0 * transpose(v0) + N;</code></pre><p>In order to recover <span>$v_0$</span> we consider the constrained optimisation problem on the sphere <span>$\mathcal S^{d-1}$</span> given by</p><p class="math-container">\[\begin{align*}
\operatorname*{arg\,min}_{p\in\mathcal S^{d-1}} &amp; -p^{\mathrm{T}}Zp^{\mathrm{T}}\\
\text{such that} &amp;\quad p \geq 0\\
\end{align*}\]</p><p>or in the previous notation <span>$f(p) = -p^{\mathrm{T}}Zp^{\mathrm{T}}$</span> and <span>$g(p) = -p$</span>. We first initialize the manifold under consideration</p><pre><code class="language-julia hljs">M = Sphere(d - 1)</code></pre><pre><code class="nohighlight hljs">Sphere(149, ℝ)</code></pre><h2 id="A-first-Augmented-Lagrangian-Run"><a class="docs-heading-anchor" href="#A-first-Augmented-Lagrangian-Run">A first Augmented Lagrangian Run</a><a id="A-first-Augmented-Lagrangian-Run-1"></a><a class="docs-heading-anchor-permalink" href="#A-first-Augmented-Lagrangian-Run" title="Permalink"></a></h2><p>We first defined <span>$f$</span> and <span>$g$</span> as usual functions</p><pre><code class="language-julia hljs">f(M, p) = -transpose(p) * Z * p;
g(M, p) = -p;</code></pre><p>since <span>$f$</span> is a functions defined in the embedding <span>$ℝ^d$</span> as well, we obtain its gradient by projection.</p><pre><code class="language-julia hljs">grad_f(M, p) = project(M, p, -transpose(Z) * p - Z * p);</code></pre><p>For the constraints this is a little more involved, since each function <span>$g_i = g(p)_i = p_i$</span> has to return its own gradient. These are again in the embedding just <span>$\operatorname{grad} g_i(p) = -e_i$</span> the <span>$i$</span> th unit vector. We can project these again onto the tangent space at <span>$p$</span>:</p><pre><code class="language-julia hljs">grad_g(M, p) = project.(
    Ref(M), Ref(p), [[i == j ? -1.0 : 0.0 for j in 1:d] for i in 1:d]
);</code></pre><p>We further start in a random point:</p><pre><code class="language-julia hljs">p0 = rand(M);</code></pre><p>Let’s check a few things for the initial point</p><pre><code class="language-julia hljs">f(M, p0)</code></pre><pre><code class="nohighlight hljs">0.005747604833124234</code></pre><p>How much the function g is positive</p><pre><code class="language-julia hljs">maximum(g(M, p0))</code></pre><pre><code class="nohighlight hljs">0.17885478285466855</code></pre><p>Now as a first method we can just call the <a href="https://manoptjl.org/stable/solvers/augmented_Lagrangian_method/">Augmented Lagrangian Method</a> with a simple call:</p><pre><code class="language-julia hljs">@time v1 = augmented_Lagrangian_method(
    M, f, grad_f, p0; g=g, grad_g=grad_g,
    debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, (:Change, &quot;Δp : %1.5e&quot;), 20, &quot;\n&quot;],
    stopping_criterion = StopAfterIteration(300) | (
        StopWhenSmallerOrEqual(:ϵ, 1e-5) &amp; StopWhenChangeLess(1e-8)
    )
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): 0.005748 | 
# 20    f(x): -0.123842 | Δp : 9.99682e-01
# 40    f(x): -0.123842 | Δp : 8.13541e-07
# 60    f(x): -0.123842 | Δp : 7.85694e-04
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-5).
The algorithm performed a step with a change (1.7450108123172955e-15) less than 9.77237220955808e-6.
 18.071726 seconds (44.16 M allocations: 32.359 GiB, 9.40% gc time, 41.18% compilation time)</code></pre><p>Now we have both a lower function value and the point is nearly within the constraints, … up to numerical inaccuracies</p><pre><code class="language-julia hljs">f(M, v1)</code></pre><pre><code class="nohighlight hljs">-0.12384244779997305</code></pre><pre><code class="language-julia hljs">maximum( g(M, v1) )</code></pre><pre><code class="nohighlight hljs">7.912675333644102e-18</code></pre><h2 id="A-faster-Augmented-Lagrangian-Run"><a class="docs-heading-anchor" href="#A-faster-Augmented-Lagrangian-Run">A faster Augmented Lagrangian Run</a><a id="A-faster-Augmented-Lagrangian-Run-1"></a><a class="docs-heading-anchor-permalink" href="#A-faster-Augmented-Lagrangian-Run" title="Permalink"></a></h2><p>Now this is a little slow, so we can modify two things, that we will directly do both – but one could also just change one of these – :</p><ol><li>Gradients should be evaluated in place, so for example</li></ol><pre><code class="language-julia hljs">grad_f!(M, X, p) = project!(M, X, p, -transpose(Z) * p - Z * p);</code></pre><ol><li>The constraints are currently always evaluated all together, since the function <code>grad_g</code> always returns a vector of gradients.  We first change the constraints function into a vector of functions.  We further change the gradient <em>both</em> into a vector of gradient functions <span>$\operatorname{grad} g_i, i=1,\ldots,d$</span>, <em>as well as</em> gradients that are computed in place.</li></ol><pre><code class="language-julia hljs">g2 = [(M, p) -&gt; -p[i] for i in 1:d];
grad_g2! = [
    (M, X, p) -&gt; project!(M, X, p, [i == j ? -1.0 : 0.0 for j in 1:d]) for i in 1:d
];</code></pre><p>We obtain</p><pre><code class="language-julia hljs">@time v2 = augmented_Lagrangian_method(
        M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),
        debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, (:Change, &quot;Δp : %1.5e&quot;), 20, &quot;\n&quot;],
        stopping_criterion = StopAfterIteration(300) | (
          StopWhenSmallerOrEqual(:ϵ, 1e-5) &amp; StopWhenChangeLess(1e-8)
        )
    );</code></pre><pre><code class="nohighlight hljs">Initial f(x): 0.005748 | 
# 20    f(x): -0.123842 | Δp : 9.99544e-01
# 40    f(x): -0.123842 | Δp : 1.92065e-03
# 60    f(x): -0.123842 | Δp : 4.84931e-06
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-5).
The algorithm performed a step with a change (2.7435918100802105e-17) less than 9.77237220955808e-6.
  4.127770 seconds (6.65 M allocations: 3.738 GiB, 6.16% gc time, 42.55% compilation time)</code></pre><p>As a technical remark: Note that (by default) the change to <a href="https://manoptjl.org/stable/plans/problem/#Manopt.InplaceEvaluation"><code>InplaceEvaluation</code></a>s affects both the constrained solver as well as the inner solver of the subproblem in each iteration.</p><pre><code class="language-julia hljs">f(M, v2)</code></pre><pre><code class="nohighlight hljs">-0.12384239276300012</code></pre><pre><code class="language-julia hljs">maximum(g(M, v2))</code></pre><pre><code class="nohighlight hljs">2.2466899389459647e-18</code></pre><p>These are the very similar to the previous values but the solver took much less time and less memory allocations.</p><h2 id="Exact-Penalty-Method"><a class="docs-heading-anchor" href="#Exact-Penalty-Method">Exact Penalty Method</a><a id="Exact-Penalty-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Exact-Penalty-Method" title="Permalink"></a></h2><p>As a second solver, we have the <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/">Exact Penalty Method</a>, which currenlty is available with two smoothing variants, which make an inner solver for smooth optimisationm, that is by default again [quasi Newton] possible: <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LogarithmicSumOfExponentials"><code>LogarithmicSumOfExponentials</code></a> and <a href="https://manoptjl.org/stable/solvers/exact_penalty_method/#Manopt.LinearQuadraticHuber"><code>LinearQuadraticHuber</code></a>. We compare both here as well. The first smoothing technique is the default, so we can just call</p><pre><code class="language-julia hljs">@time v3 = exact_penalty_method(
    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!, evaluation=InplaceEvaluation(),
    debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, :Change, 50, &quot;\n&quot;],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): 0.005748 | 
# 50    f(x): -0.123071 | Last Change: 0.981116
# 100   f(x): -0.123840 | Last Change: 0.014124
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (2.202641515349944e-7) less than 1.0e-6.
  3.489436 seconds (5.93 M allocations: 3.134 GiB, 12.89% gc time, 52.27% compilation time)</code></pre><p>We obtain a similar cost value as for the Augmented Lagrangian Solver above, but here the constraint is actually fulfilled and not just numerically “on the boundary”.</p><pre><code class="language-julia hljs">f(M, v3)</code></pre><pre><code class="nohighlight hljs">-0.12384029692539944</code></pre><pre><code class="language-julia hljs">maximum(g(M, v3))</code></pre><pre><code class="nohighlight hljs">-3.582398293370528e-6</code></pre><p>The second smoothing technique is often beneficial, when we have a lot of constraints (in the above mentioned vectorial manner), since we can avoid several gradient evaluations for the constraint functions here. This leads to a faster iteration time.</p><pre><code class="language-julia hljs">@time v4 = exact_penalty_method(
    M, f, grad_f!, p0; g=g2, grad_g=grad_g2!,
    evaluation=InplaceEvaluation(),
    smoothing=LinearQuadraticHuber(),
    debug=[:Iteration, :Cost, :Stop, &quot; | &quot;, :Change, 50, &quot;\n&quot;],
);</code></pre><pre><code class="nohighlight hljs">Initial f(x): 0.005748 | 
# 50    f(x): -0.123845 | Last Change: 0.009235
# 100   f(x): -0.123843 | Last Change: 0.000107
The value of the variable (ϵ) is smaller than or equal to its threshold (1.0e-6).
The algorithm performed a step with a change (3.586352489111338e-7) less than 1.0e-6.
  1.805654 seconds (2.85 M allocations: 521.251 MiB, 4.89% gc time, 80.91% compilation time)</code></pre><p>For the result we see the same behaviour as for the other smoothing.</p><pre><code class="language-julia hljs">f(M, v4)</code></pre><pre><code class="nohighlight hljs">-0.12384258173223292</code></pre><pre><code class="language-julia hljs">maximum(g(M, v4))</code></pre><pre><code class="nohighlight hljs">2.7028045565194566e-8</code></pre><h2 id="Comparing-to-the-unconstraint-solver"><a class="docs-heading-anchor" href="#Comparing-to-the-unconstraint-solver">Comparing to the unconstraint solver</a><a id="Comparing-to-the-unconstraint-solver-1"></a><a class="docs-heading-anchor-permalink" href="#Comparing-to-the-unconstraint-solver" title="Permalink"></a></h2><p>We can compare this to the <em>global</em> optimum on the sphere, which is the unconstraint optimisation problem; we can just use Quasi Newton.</p><p>Note that this is much faster, since every iteration of the algorithms above does a quasi-Newton call as well.</p><pre><code class="language-julia hljs">@time w1 = quasi_Newton(
    M, f, grad_f!, p0; evaluation=InplaceEvaluation()
);</code></pre><pre><code class="nohighlight hljs">  1.107591 seconds (1.46 M allocations: 133.183 MiB, 4.05% gc time, 98.74% compilation time)</code></pre><pre><code class="language-julia hljs">f(M, w1)</code></pre><pre><code class="nohighlight hljs">-0.14021901809807297</code></pre><p>But for sure here the constraints here are not fulfilled and we have veru positive entries in <span>$g(w_1)$</span></p><pre><code class="language-julia hljs">maximum(g(M, w1))</code></pre><pre><code class="nohighlight hljs">0.11762414497055226</code></pre><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[BH19]</dt><dd><div>R. Bergmann and R. Herzog. <em>Intrinsic formulation of KKT conditions and constraint qualifications on smooth manifolds</em>. <a href="https://doi.org/10.1137/18M1181602">SIAM Journal on Optimization <strong>29</strong>, 2423–2444</a> (2019), arXiv: <a href="https://arxiv.org/abs/1804.06214">1804.06214</a>.</div></dd><dt>[LB19]</dt><dd><div>C. Liu and N. Boumal. <a href="https://arxiv.org/abs/1901.10000"><em>Simple algorithms for optimization on Riemannian manifolds with constraints</em></a>. <a href="https://doi.org/10.1007/s00245-019-09564-3">Applied Mathematics &amp; Optimization</a> (2019).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="ImplementASolver.html">« Implement a Solver</a><a class="docs-footer-nextpage" href="GeodesicRegression.html">Do Geodesic Regression »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.2 on <span class="colophon-date" title="Monday 6 November 2023 12:02">Monday 6 November 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
