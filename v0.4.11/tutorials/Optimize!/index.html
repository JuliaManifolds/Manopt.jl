<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Get started: Optimize! · Manopt.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Manopt.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../about/">About</a></li><li><span class="tocitem">How to...</span><ul><li class="is-active"><a class="tocitem" href>Get started: Optimize!</a><ul class="internal"><li><a class="tocitem" href="#Loading-the-necessary-packages"><span>Loading the necessary packages</span></a></li><li><a class="tocitem" href="#Example-2:-Computing-the-median-of-symmetric-positive-definite-matrices."><span>Example 2: Computing the median of symmetric positive definite matrices.</span></a></li><li><a class="tocitem" href="#Literature"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="../InplaceGradient/">Speedup using Inplace computations</a></li><li><a class="tocitem" href="../AutomaticDifferentiation/">Use Automatic Differentiation</a></li><li><a class="tocitem" href="../HowToRecord/">Record values</a></li><li><a class="tocitem" href="../ConstrainedOptimization/">Do Contrained Optimization</a></li><li><a class="tocitem" href="../GeodesicRegression/">Do Geodesic Regression</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../../solvers/">Introduction</a></li><li><a class="tocitem" href="../../solvers/alternating_gradient_descent/">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/augmented_Lagrangian_method/">Augmented Lagrangian Method</a></li><li><a class="tocitem" href="../../solvers/ChambollePock/">Chambolle-Pock</a></li><li><a class="tocitem" href="../../solvers/conjugate_gradient_descent/">Conjugate gradient descent</a></li><li><a class="tocitem" href="../../solvers/cyclic_proximal_point/">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../../solvers/DouglasRachford/">Douglas–Rachford</a></li><li><a class="tocitem" href="../../solvers/exact_penalty_method/">Exact Penalty Method</a></li><li><a class="tocitem" href="../../solvers/FrankWolfe/">Frank-Wolfe</a></li><li><a class="tocitem" href="../../solvers/gradient_descent/">Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/LevenbergMarquardt/">Levenberg–Marquardt</a></li><li><a class="tocitem" href="../../solvers/NelderMead/">Nelder–Mead</a></li><li><a class="tocitem" href="../../solvers/particle_swarm/">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../../solvers/primal_dual_semismooth_Newton/">Primal-dual Riemannian semismooth Newton</a></li><li><a class="tocitem" href="../../solvers/quasi_Newton/">Quasi-Newton</a></li><li><a class="tocitem" href="../../solvers/stochastic_gradient_descent/">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../../solvers/subgradient/">Subgradient method</a></li><li><a class="tocitem" href="../../solvers/truncated_conjugate_gradient_descent/">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../../solvers/trust_regions/">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../../plans/">Specify a Solver</a></li><li><a class="tocitem" href="../../plans/problem/">Problem</a></li><li><a class="tocitem" href="../../plans/objective/">Objective</a></li><li><a class="tocitem" href="../../plans/state/">Solver State</a></li><li><a class="tocitem" href="../../plans/stepsize/">Stepsize</a></li><li><a class="tocitem" href="../../plans/stopping_criteria/">Stopping Criteria</a></li><li><a class="tocitem" href="../../plans/debug/">Debug Output</a></li><li><a class="tocitem" href="../../plans/record/">Recording values</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../../functions/">Introduction</a></li><li><a class="tocitem" href="../../functions/bezier/">Bézier curves</a></li><li><a class="tocitem" href="../../functions/costs/">Cost functions</a></li><li><a class="tocitem" href="../../functions/differentials/">Differentials</a></li><li><a class="tocitem" href="../../functions/adjointdifferentials/">Adjoint Differentials</a></li><li><a class="tocitem" href="../../functions/gradients/">Gradients</a></li><li><a class="tocitem" href="../../functions/proximal_maps/">Proximal Maps</a></li><li><a class="tocitem" href="../../functions/manifold/">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../../helpers/checks/">Checks</a></li><li><a class="tocitem" href="../../helpers/data/">Data</a></li><li><a class="tocitem" href="../../helpers/errorMeasures/">Error Measures</a></li><li><a class="tocitem" href="../../helpers/exports/">Exports</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../../notation/">Notation</a></li><li><a class="tocitem" href="../../extensions/">Extensions</a></li><li><a class="tocitem" href="../../list/">Function Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to...</a></li><li class="is-active"><a href>Get started: Optimize!</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Get started: Optimize!</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/docs/src/tutorials/Optimize!.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Get-Started:-Optimize!"><a class="docs-heading-anchor" href="#Get-Started:-Optimize!">Get Started: Optimize!</a><a id="Get-Started:-Optimize!-1"></a><a class="docs-heading-anchor-permalink" href="#Get-Started:-Optimize!" title="Permalink"></a></h1><p>In this tutorial, we will both introduce the basics of optimisation on manifolds as well as how to use <a href="https://manoptjl.org"><code>Manopt.jl</code></a> to perform optimisation on manifolds in <a href="https://julialang.org">Julia</a>.</p><p>For more theoretical background, see e.g. (do Carmo, 1992) for an introduction to Riemannian manifolds and (Absil, Mahony and Sepulchre, 2008) or (Boumal, 2022) to read more about optimisation thereon.</p><p>Let <span>$\mathcal M$</span> denote a <a href="https://juliamanifolds.github.io/Manifolds.jl/stable/interface.html#ManifoldsBase.Manifold">Riemannian manifold</a> and let <span>$f\colon \mathcal M → ℝ$</span> be a cost function. We aim to compute a point <span>$p^*$</span> where <span>$f$</span> is <em>minimal</em> or in other words <span>$p^*$</span> is a <em>minimizer</em> of <span>$f$</span>.</p><p>We also write this as</p><p class="math-container">\[    \operatorname*{arg\,min}_{p ∈ \mathcal M} f(p)\]</p><p>and would like to find <span>$p^*$</span> numerically. As an example we take the generalisation of the <a href="https://en.wikipedia.org/wiki/Arithmetic_mean">(arithemtic) mean</a>. In the Euclidean case with<span>$d\in\mathbb N$</span>, that is for <span>$n\in \mathbb N$</span> data points <span>$y_1,\ldots,y_n \in \mathbb R^d$</span> the mean</p><p class="math-container">\[  \sum_{i=1}^n y_i\]</p><p>can not be directly generalised to data <span>$q_1,\ldots,q_n$</span>, since on a manifold we do not have an addition. But the mean can also be charcterised as</p><p class="math-container">\[  \operatorname*{arg\,min}_{x\in\mathbb R^d} \frac{1}{2n}\sum_{i=1}^n \lVert x - y_i\rVert^2\]</p><p>and using the Riemannian distance <span>$d_\mathcal M$</span>, this can be written on Riemannian manifolds. We obtain the <em>Riemannian Center of Mass</em> (Karcher, 1977)</p><p class="math-container">\[  \operatorname*{arg\,min}_{p\in\mathbb R^d}
  \frac{1}{2n} \sum_{i=1}^n d_{\mathcal M}^2(p, q_i)\]</p><p>Fortunately the gradient can be computed and is</p><p class="math-container">\[  \operatorname*{arg\,min}_{p\in\mathbb R^d} \frac{1}{n} \sum_{i=1}^n -\log_p q_i\]</p><h2 id="Loading-the-necessary-packages"><a class="docs-heading-anchor" href="#Loading-the-necessary-packages">Loading the necessary packages</a><a id="Loading-the-necessary-packages-1"></a><a class="docs-heading-anchor-permalink" href="#Loading-the-necessary-packages" title="Permalink"></a></h2><p>Let’s assume you have already installed both Manotp and Manifolds in Julia (using e.g. <code>using Pkg; Pkg.add([&quot;Manopt&quot;, &quot;Manifolds&quot;])</code>). Then we can get started by loading both packages – and <code>Random</code> for persistency in this tutorial.</p><pre><code class="language-julia hljs">using Manopt, Manifolds, Random, LinearAlgebra
Random.seed!(42);</code></pre><p>Now assume we are on the <a href="https://juliamanifolds.github.io/Manifolds.jl/latest/manifolds/sphere.html">Sphere</a> <span>$\mathcal M = \mathbb S^2$</span> and we generate some random points “around” some initial point <span>$p$</span></p><pre><code class="language-julia hljs">n = 100
σ = π / 8
M = Sphere(2)
p = 1 / sqrt(2) * [1.0, 0.0, 1.0]
data = [exp(M, p,  σ * rand(M; vector_at=p)) for i in 1:n];</code></pre><p>Now we can define the cost function <span>$f$</span> and its (Riemannian) gradient <span>$\operatorname{grad} f$</span> for the Riemannian center of mass:</p><pre><code class="language-julia hljs">f(M, p) = sum(1 / (2 * n) * distance.(Ref(M), Ref(p), data) .^ 2)
grad_f(M, p) = sum(1 / n * grad_distance.(Ref(M), data, Ref(p)));</code></pre><p>and just call <a href="https://manoptjl.org/stable/solvers/gradient_descent/"><code>gradient_descent</code></a>. For a first start, we do not have to provide more than the manifold, the cost, the gradient, and a starting point, which we just set to the first data point</p><pre><code class="language-julia hljs">m1 = gradient_descent(M, f, grad_f, data[1])</code></pre><pre><code class="nohighlight hljs">3-element Vector{Float64}:
 0.6868392795563908
 0.006531600623587405
 0.7267799820108911</code></pre><p>In order to get more details, we further add the <code>debug=</code> keyword argument, which act as a <a href="https://en.wikipedia.org/wiki/Decorator_pattern">decorator pattern</a>.</p><p>This way we can easily specify a certain debug to be printed. The goal is to get an output of the form</p><pre><code class="language- hljs"># i | Last Change: [...] | F(x): [...] |</code></pre><p>but where we also want to fix the display format for the change and the cost numbers (the <code>[...]</code>) to have a certain format. Furthermore, the reason why the solver stopped should be printed at the end</p><p>These can easily be specified using either a Symbol – using the default format for numbers – or a tuple of a symbol and a format-string in the <code>debug=</code> keyword that is avaiable for every solver. We can also – for illustration reasons – just look at the first 6 steps by setting a <a href="https://manoptjl.org/stable/plans/stopping_criteria/"><code>stopping_criterion=</code></a></p><pre><code class="language-julia hljs">m2 = gradient_descent(M, f, grad_f, data[1];
    debug=[:Iteration,(:Change, &quot;|Δp|: %1.9f |&quot;),
        (:Cost, &quot; F(x): %1.11f | &quot;), &quot;\n&quot;, :Stop],
    stopping_criterion = StopAfterIteration(6)
  )</code></pre><pre><code class="nohighlight hljs">Initial  F(x): 0.32487988924 |
# 1     |Δp|: 1.063609017 | F(x): 0.25232524046 |
# 2     |Δp|: 0.809858671 | F(x): 0.20966960102 |
# 3     |Δp|: 0.616665145 | F(x): 0.18546505598 |
# 4     |Δp|: 0.470841764 | F(x): 0.17121604104 |
# 5     |Δp|: 0.359345690 | F(x): 0.16300825911 |
# 6     |Δp|: 0.274597420 | F(x): 0.15818548927 |
The algorithm reached its maximal number of iterations (6).

3-element Vector{Float64}:
  0.7533872481682506
 -0.060531070555836286
  0.6547851890466333</code></pre><p>See <a href="https://manoptjl.org/stable/plans/debug/#Manopt.DebugActionFactory-Tuple%7BSymbol%7D">here</a> for the list of available symbols.</p><div class="admonition is-info"><header class="admonition-header">Technical Detail</header><div class="admonition-body"></div></div><p>    The <code>debug=</code> keyword is actually a list of <a href="https://manoptjl.org/stable/plans/debug/#Manopt.DebugAction"><code>DebugActions</code></a> added to every iteration, allowing you to write your own ones even. Additionally, <code>:Stop</code> is an action added to the end of the solver to display the reason why the solver stopped.</p><p>The default stopping criterion for <a href="https://manoptjl.org/stable/solvers/gradient_descent/"><code>gradient_descent</code></a> is, to either stopwhen the gradient is small (<code>&lt;1e-9</code>) or a max number of iterations is reached (as a fallback. Combining stopping-criteria can be done by <code>|</code> or <code>&amp;</code>. We further pass a number <code>25</code> to <code>debug=</code> to only an output every <code>25</code>th iteration:</p><pre><code class="language-julia hljs">m3 = gradient_descent(M, f, grad_f, data[1];
    debug=[:Iteration,(:Change, &quot;|Δp|: %1.9f |&quot;),
        (:Cost, &quot; F(x): %1.11f | &quot;), &quot;\n&quot;, :Stop, 25],
    stopping_criterion = StopWhenGradientNormLess(1e-14) | StopAfterIteration(400),
)</code></pre><pre><code class="nohighlight hljs">Initial  F(x): 0.32487988924 |
# 25    |Δp|: 0.459715605 | F(x): 0.15145076374 |
# 50    |Δp|: 0.000551270 | F(x): 0.15145051509 |
# 75    |Δp|: 0.000000674 | F(x): 0.15145051509 |
The algorithm reached approximately critical point after 75 iterations; the gradient norm (2.2455867775217738e-15) is less than 1.0e-14.

3-element Vector{Float64}:
 0.6868392794788665
 0.006531600680779426
 0.7267799820836411</code></pre><p>We can finally use another way to determine the stepsize, for example a little more expensive <a href="https://manoptjl.org/stable/plans/stepsize/#Manopt.ArmijoLinesearch"><code>ArmijoLineSeach</code></a> than the default <a href="https://manoptjl.org/stable/plans/stepsize/">stepsize</a> rule used on the Sphere.</p><pre><code class="language-julia hljs">m4 = gradient_descent(M, f, grad_f, data[1];
    debug=[:Iteration,(:Change, &quot;|Δp|: %1.9f |&quot;),
        (:Cost, &quot; F(x): %1.11f | &quot;), &quot;\n&quot;, :Stop, 2],
      stepsize = ArmijoLinesearch(M; contraction_factor=0.999, sufficient_decrease=0.5),
    stopping_criterion = StopWhenGradientNormLess(1e-14) | StopAfterIteration(400),
)</code></pre><pre><code class="nohighlight hljs">Initial  F(x): 0.32487988924 |
# 2     |Δp|: 0.001318138 | F(x): 0.15145051509 |
# 4     |Δp|: 0.000000021 | F(x): 0.15145051509 |
# 6     |Δp|: 0.000000021 | F(x): 0.15145051509 |
The algorithm reached approximately critical point after 7 iterations; the gradient norm (2.014814589152431e-15) is less than 1.0e-14.

3-element Vector{Float64}:
 0.6868392794788668
 0.006531600680779305
 0.7267799820836411</code></pre><p>Then we reach approximately the same point as in the previous run, but in far less steps</p><pre><code class="language-julia hljs">[f(M, m3)-f(M,m4), distance(M, m3, m4)]</code></pre><pre><code class="nohighlight hljs">2-element Vector{Float64}:
 1.942890293094024e-16
 2.9802322387695312e-8</code></pre><h2 id="Example-2:-Computing-the-median-of-symmetric-positive-definite-matrices."><a class="docs-heading-anchor" href="#Example-2:-Computing-the-median-of-symmetric-positive-definite-matrices.">Example 2: Computing the median of symmetric positive definite matrices.</a><a id="Example-2:-Computing-the-median-of-symmetric-positive-definite-matrices.-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2:-Computing-the-median-of-symmetric-positive-definite-matrices." title="Permalink"></a></h2><p>For the second example let’s consider the manifold of <a href="https://juliamanifolds.github.io/Manifolds.jl/stable/manifolds/symmetricpositivedefinite.html"><span>$3 × 3$</span> symmetric positive definite matrices</a> and again 100 random points</p><pre><code class="language-julia hljs">N = SymmetricPositiveDefinite(3)
m = 100
σ = 0.005
q = Matrix{Float64}(I, 3, 3)
data2 = [exp(N, q, σ * rand(N; vector_at=q)) for i in 1:m];</code></pre><p>Instead of the mean, let’s consider a non-smooth optimisation task: The median can be generalized to Manifolds as the minimiser of the sum of distances, see e.g. (Bačák, 2014). We define</p><pre><code class="language-julia hljs">g(N, q) = sum(1 / (2 * m) * distance.(Ref(N), Ref(q), data2))</code></pre><pre><code class="nohighlight hljs">g (generic function with 1 method)</code></pre><p>Since the function is non-smooth, we can not use a gradient-based approach. But since for every summand the <a href="https://manoptjl.org/stable/functions/proximal_maps/#Manopt.prox_distance">proximal map</a> is available, we can use the <a href="https://manoptjl.org/stable/solvers/cyclic_proximal_point/">cyclic proximal point algorithm (CPPA)</a>. We hence define the vector of proximal maps as</p><pre><code class="language-julia hljs">proxes_g = Function[(N, λ, q) -&gt; prox_distance(N, λ / m, di, q, 1) for di in data2];</code></pre><p>Besides also looking at a some debug prints, we can also easily record these values. Similarly to <code>debug=</code>, <code>record=</code> also accepts Symbols, see list <a href="https://manoptjl.org/stable/plans/record/#Manopt.RecordFactory-Tuple%7BAbstractManoptSolverState,%20Vector%7D">here</a>, to indicate things to record. We further set <code>return_state</code> to true to obtain not just the (approximate) minimizer.</p><pre><code class="language-julia hljs">s = cyclic_proximal_point(N, g, proxes_g, data2[1];
  debug=[:Iteration,&quot; | &quot;,:Change,&quot; | &quot;,(:Cost, &quot;F(x): %1.12f&quot;),&quot;\n&quot;, 1000, :Stop,
        ],
        record=[:Iteration, :Change, :Cost, :Iterate],
        return_state=true,
    );</code></pre><pre><code class="nohighlight hljs">Initial  |  | F(x): 0.004628871966
# 1000

 | Last Change: 0.005022 | F(x): 0.003271791321
# 2000

 | Last Change: 0.000013 | F(x): 0.003271774443
# 3000

 | Last Change: 0.000004 | F(x): 0.003271771311
# 4000

 | Last Change: 0.000002 | F(x): 0.003271770214
# 5000

 | Last Change: 0.000001 | F(x): 0.003271769706
The algorithm reached its maximal number of iterations (5000).</code></pre><p>!!!note &quot;Technical Detail&quot;    The recording is realised by <a href="https://manoptjl.org/stable/plans/record/#Manopt.RecordAction"><code>RecordActions</code></a> that are (also) executed at every iteration. These can also be individually implemented and added to the <code>record=</code> array instead of symbols.</p><p>First, the computed median can be accessed as</p><pre><code class="language-julia hljs">median = get_solver_result(s)</code></pre><pre><code class="nohighlight hljs">3×3 Matrix{Float64}:
 1.00054      6.1464e-5    0.000343679
 6.1464e-5    1.00007      0.000101879
 0.000343679  0.000101879  1.00044</code></pre><p>but we can also look at the recorded values. For simplicity (of output), lets just look at the recorded values at iteration 42</p><pre><code class="language-julia hljs">get_record(s)[42]</code></pre><pre><code class="nohighlight hljs">(42, 7.640883870061361e-6, 0.0032798026498283275, [1.0002117366518994 0.00014357556816643746 0.00028004648707080637; 0.00014357556816643746 0.9999321794912776 0.00029370555482273464; 0.0002800464870708619 0.0002937055548227485 1.000391810942462])</code></pre><p>But we can also access whole serieses and see that the cost does not decrease that fast; actually, the CPPA might converge relatively slow. For that we can for example access the <code>:Cost</code> that was recorded every <code>:Iterate</code> as well as the (maybe a little boring) <code>:Iteration</code>-number in a semilogplot.</p><pre><code class="language-julia hljs">x = get_record(s, :Iteration, :Iteration)
y = get_record(s, :Iteration, :Cost)
using Plots
plot(x,y,xaxis=:log, label=&quot;CPPA Cost&quot;)</code></pre><p><img src="../Optimize!_files/figure-commonmark/cell-17-output-1.png" alt/></p><h2 id="Literature"><a class="docs-heading-anchor" href="#Literature">Literature</a><a id="Literature-1"></a><a class="docs-heading-anchor-permalink" href="#Literature" title="Permalink"></a></h2><p>Absil, P.-A., Mahony, R. and Sepulchre, R. (2008) <em>Optimization algorithms on matrix manifolds</em>. Princeton University Press. Available at: <a href="https://doi.org/10.1515/9781400830244">https://doi.org/10.1515/9781400830244</a>.</p><p>Bačák, M. (2014) “Computing medians and means in Hadamard spaces,” <em>SIAM Journal on Optimization</em>, 24(3), pp. 1542–1566. Available at: <a href="https://doi.org/10.1137/140953393">https://doi.org/10.1137/140953393</a>.</p><p>Boumal, N. (2022) <em>An introduction to optimization on smooth manifolds</em>. Available at: <a href="https://www.nicolasboumal.net/book">https://www.nicolasboumal.net/book</a>.</p><p>do Carmo, M.P. (1992) <em>Riemannian geometry</em>. Birkhäuser Boston, Inc., Boston, MA (Mathematics: Theory &amp; applications), p. xiv+300. Available at: <a href="https://doi.org/10.1007/978-1-4757-2201-7">https://doi.org/10.1007/978-1-4757-2201-7</a>.</p><p>Karcher, H. (1977) “Riemannian center of mass and mollifier smoothing,” <em>Communications on Pure and Applied Mathematics</em>, 30(5), pp. 509–541. Available at: <a href="https://doi.org/10.1002/cpa.3160300502">https://doi.org/10.1002/cpa.3160300502</a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../about/">« About</a><a class="docs-footer-nextpage" href="../InplaceGradient/">Speedup using Inplace computations »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 27 March 2023 11:39">Monday 27 March 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
